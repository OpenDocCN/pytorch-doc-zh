["```py\nimport torch\nimport torchaudio\n\nprint(torch.__version__)\nprint([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n2.2.0\n2.2.0 \n```", "```py\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nfrom torchaudio.io import StreamReader \n```", "```py\nfrom torchaudio.utils import ffmpeg_utils \n```", "```py\nprint(\"FFmpeg Library versions:\")\nfor [k](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), [ver](https://docs.python.org/3/library/stdtypes.html#tuple \"builtins.tuple\") in ffmpeg_utils.get_versions().items():\n    print(f\" {[k](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")}:\\t{'.'.join(str(v)  for  v  in  [ver](https://docs.python.org/3/library/stdtypes.html#tuple \"builtins.tuple\"))}\") \n```", "```py\nFFmpeg Library versions:\n  libavcodec:   60.3.100\n  libavdevice:  60.1.100\n  libavfilter:  9.3.100\n  libavformat:  60.3.100\n  libavutil:    58.2.100 \n```", "```py\nprint(\"Available NVDEC Decoders:\")\nfor [k](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") in ffmpeg_utils.get_video_decoders().keys():\n    if \"cuvid\" in [k](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"):\n        print(f\" - {[k](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")}\") \n```", "```py\nAvailable NVDEC Decoders:\n - av1_cuvid\n - h264_cuvid\n - hevc_cuvid\n - mjpeg_cuvid\n - mpeg1_cuvid\n - mpeg2_cuvid\n - mpeg4_cuvid\n - vc1_cuvid\n - vp8_cuvid\n - vp9_cuvid \n```", "```py\nprint(\"Avaialbe GPU:\")\nprint([torch.cuda.get_device_properties](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_properties.html#torch.cuda.get_device_properties \"torch.cuda.get_device_properties\")(0)) \n```", "```py\nAvaialbe GPU:\n_CudaDeviceProperties(name='NVIDIA A10G', major=8, minor=6, total_memory=22515MB, multi_processor_count=80) \n```", "```py\n[src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = torchaudio.utils.download_asset(\n    \"tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4_small.mp4\"\n) \n```", "```py\n 0%|          | 0.00/31.8M [00:00<?, ?B/s]\n 65%|######5   | 20.8M/31.8M [00:00<00:00, 218MB/s]\n100%|##########| 31.8M/31.8M [00:00<00:00, 198MB/s] \n```", "```py\ns = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\ns.add_video_stream(5, decoder=\"h264_cuvid\")\ns.fill_buffer()\n(video,) = s.pop_chunks() \n```", "```py\nprint(video.shape, [video.dtype](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\")) \n```", "```py\ntorch.Size([5, 3, 540, 960]) torch.uint8 \n```", "```py\nprint([video.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")) \n```", "```py\ncpu \n```", "```py\ns = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\ns.add_video_stream(5, decoder=\"h264_cuvid\", hw_accel=\"cuda:0\")\ns.fill_buffer()\n(video,) = s.pop_chunks()\n\nprint(video.shape, [video.dtype](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\"), [video.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")) \n```", "```py\ntorch.Size([5, 3, 540, 960]) torch.uint8 cuda:0 \n```", "```py\n# Video data is sent to CUDA device 0, decoded and\n# converted on the same device.\ns.add_video_stream(\n    ...,\n    decoder=\"h264_cuvid\",\n    decoder_option={\"gpu\": \"0\"},\n    hw_accel=\"cuda:0\",\n) \n```", "```py\n# Video data is sent to CUDA device 0, and decoded there.\n# Then it is transfered to CUDA device 1, and converted to\n# CUDA tensor.\ns.add_video_stream(\n    ...,\n    decoder=\"h264_cuvid\",\n    decoder_option={\"gpu\": \"0\"},\n    hw_accel=\"cuda:1\",\n) \n```", "```py\ndef test_decode(decoder: str, seek: float):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.seek(seek)\n    s.add_video_stream(1, decoder=decoder)\n    s.fill_buffer()\n    (video,) = s.pop_chunks()\n    return video[0] \n```", "```py\n[timestamps](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [12, 19, 45, 131, 180]\n\n[cpu_frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [test_decode(decoder=\"h264\", seek=ts) for ts in [timestamps](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")]\n[cuda_frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [test_decode(decoder=\"h264_cuvid\", seek=ts) for ts in [timestamps](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")] \n```", "```py\ndef yuv_to_rgb([frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n    [frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [frames.cpu](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")().to([torch.float](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\"))\n    y = [frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[..., 0, :, :]\n    u = [frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[..., 1, :, :]\n    v = [frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[..., 2, :, :]\n\n    y /= 255\n    u = u / 255 - 0.5\n    v = v / 255 - 0.5\n\n    r = y + 1.14 * v\n    g = y + -0.396 * u - 0.581 * v\n    b = y + 2.029 * u\n\n    rgb = [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack \"torch.stack\")([r, g, b], -1)\n    rgb = (rgb * 255).clamp(0, 255).to([torch.uint8](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\"))\n    return rgb.numpy() \n```", "```py\ndef plot():\n    n_rows = len([timestamps](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n    fig, axes = plt.subplots(n_rows, 2, figsize=[12.8, 16.0])\n    for i in range(n_rows):\n        axes[i][0].imshow(yuv_to_rgb([cpu_frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i]))\n        axes[i][1].imshow(yuv_to_rgb([cuda_frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i]))\n\n    axes[0][0].set_title(\"Software decoder\")\n    axes[0][1].set_title(\"HW decoder\")\n    plt.setp(axes, xticks=[], yticks=[])\n    plt.tight_layout()\n\nplot() \n```", "```py\ndef test_options(option):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.seek(87)\n    s.add_video_stream(1, decoder=\"h264_cuvid\", hw_accel=\"cuda:0\", decoder_option=option)\n    s.fill_buffer()\n    (video,) = s.pop_chunks()\n    print(f\"Option: {option}:\\t{video.shape}\")\n    return video[0] \n```", "```py\n[original](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = test_options(option=None)\n[resized](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = test_options(option={\"resize\": \"480x270\"})\n[cropped](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = test_options(option={\"crop\": \"135x135x240x240\"})\n[cropped_and_resized](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = test_options(option={\"crop\": \"135x135x240x240\", \"resize\": \"640x360\"}) \n```", "```py\nOption: None:   torch.Size([1, 3, 540, 960])\nOption: {'resize': '480x270'}:  torch.Size([1, 3, 270, 480])\nOption: {'crop': '135x135x240x240'}:    torch.Size([1, 3, 270, 480])\nOption: {'crop': '135x135x240x240', 'resize': '640x360'}:       torch.Size([1, 3, 360, 640]) \n```", "```py\ndef plot():\n    fig, axes = plt.subplots(2, 2, figsize=[12.8, 9.6])\n    axes[0][0].imshow(yuv_to_rgb([original](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n    axes[0][1].imshow(yuv_to_rgb([resized](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n    axes[1][0].imshow(yuv_to_rgb([cropped](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n    axes[1][1].imshow(yuv_to_rgb([cropped_and_resized](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n\n    axes[0][0].set_title(\"Original\")\n    axes[0][1].set_title(\"Resized\")\n    axes[1][0].set_title(\"Cropped\")\n    axes[1][1].set_title(\"Cropped and resized\")\n    plt.tight_layout()\n    return fig\n\nplot() \n```", "```py\n<Figure size 1280x960 with 4 Axes> \n```", "```py\nffmpeg -y -f lavfi -t 12.05 -i mptestsrc -movflags +faststart mptestsrc.mp4 \n```", "```py\n[test_src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = torchaudio.utils.download_asset(\"tutorial-assets/mptestsrc.mp4\") \n```", "```py\n 0%|          | 0.00/232k [00:00<?, ?B/s]\n100%|##########| 232k/232k [00:00<00:00, 126MB/s] \n```", "```py\ndef decode_resize_ffmpeg(mode, height, width, seek):\n    filter_desc = None if mode is None else f\"scale={width}:{height}:sws_flags={mode}\"\n    s = StreamReader([test_src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(1, filter_desc=filter_desc)\n    s.seek(seek)\n    s.fill_buffer()\n    (chunk,) = s.pop_chunks()\n    return chunk \n```", "```py\ndef decode_resize_cuvid(height, width, seek):\n    s = StreamReader([test_src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(1, decoder=\"h264_cuvid\", decoder_option={\"resize\": f\"{width}x{height}\"}, hw_accel=\"cuda:0\")\n    s.seek(seek)\n    s.fill_buffer()\n    (chunk,) = s.pop_chunks()\n    return chunk.cpu() \n```", "```py\n[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\") = {\"height\": 224, \"width\": 224, \"seek\": 3}\n\n[frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [\n    decode_resize_ffmpeg(None, **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"neighbor\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"bilinear\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"bicubic\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_cuvid(**[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"spline\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"lanczos:param0=1\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"lanczos:param0=3\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n    decode_resize_ffmpeg(\"lanczos:param0=5\", **[params](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")),\n] \n```", "```py\ndef plot():\n    fig, axes = plt.subplots(3, 3, figsize=[12.8, 15.2])\n    for i, f in enumerate([frames](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        h, w = f.shape[2:4]\n        f = f[..., : h // 4, : w // 4]\n        axes[i // 3][i % 3].imshow(yuv_to_rgb(f[0]))\n    axes[0][0].set_title(\"Original\")\n    axes[0][1].set_title(\"nearest neighbor\")\n    axes[0][2].set_title(\"bilinear\")\n    axes[1][0].set_title(\"bicubic\")\n    axes[1][1].set_title(\"NVDEC\")\n    axes[1][2].set_title(\"spline\")\n    axes[2][0].set_title(\"lanczos(1)\")\n    axes[2][1].set_title(\"lanczos(3)\")\n    axes[2][2].set_title(\"lanczos(5)\")\n\n    plt.setp(axes, xticks=[], yticks=[])\n    plt.tight_layout()\n\nplot() \n```", "```py\ndef test_decode_cuda([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), decoder, hw_accel=\"cuda\", frames_per_chunk=5):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(frames_per_chunk, decoder=decoder, hw_accel=hw_accel)\n\n    num_frames = 0\n    chunk = None\n    t0 = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")()\n    for (chunk,) in s.stream():\n        num_frames += chunk.shape[0]\n    elapsed = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")() - t0\n    print(f\" - Shape: {chunk.shape}\")\n    fps = num_frames / elapsed\n    print(f\" - Processed {num_frames} frames in {elapsed:.2f} seconds. ({fps:.2f} fps)\")\n    return fps \n```", "```py\ndef test_decode_cpu([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), threads, decoder=None, frames_per_chunk=5):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(frames_per_chunk, decoder=decoder, decoder_option={\"threads\": f\"{threads}\"})\n\n    num_frames = 0\n    device = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\")\n    t0 = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")()\n    for i, (chunk,) in enumerate(s.stream()):\n        if i == 0:\n            print(f\" - Shape: {chunk.shape}\")\n        num_frames += chunk.shape[0]\n        chunk = chunk.to(device)\n    elapsed = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")() - t0\n    fps = num_frames / elapsed\n    print(f\" - Processed {num_frames} frames in {elapsed:.2f} seconds. ({fps:.2f} fps)\")\n    return fps \n```", "```py\ndef run_decode_tests([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), frames_per_chunk=5):\n    fps = []\n    print(f\"Testing: {[os.path.basename](https://docs.python.org/3/library/os.path.html#os.path.basename \"os.path.basename\")([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))}\")\n    for threads in [1, 4, 8, 16]:\n        print(f\"* Software decoding (num_threads={threads})\")\n        fps.append(test_decode_cpu([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), threads))\n    print(\"* Hardware decoding\")\n    fps.append(test_decode_cuda([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), decoder=\"h264_cuvid\"))\n    return fps \n```", "```py\n[src_qvga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = torchaudio.utils.download_asset(\"tutorial-assets/testsrc2_qvga.h264.mp4\")\n[fps_qvga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = run_decode_tests([src_qvga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n 0%|          | 0.00/1.06M [00:00<?, ?B/s]\n100%|##########| 1.06M/1.06M [00:00<00:00, 164MB/s]\nTesting: testsrc2_qvga.h264.mp4\n* Software decoding (num_threads=1)\n - Shape: torch.Size([5, 3, 240, 320])\n - Processed 900 frames in 0.50 seconds. (1814.92 fps)\n* Software decoding (num_threads=4)\n - Shape: torch.Size([5, 3, 240, 320])\n - Processed 900 frames in 0.34 seconds. (2662.94 fps)\n* Software decoding (num_threads=8)\n - Shape: torch.Size([5, 3, 240, 320])\n - Processed 900 frames in 0.31 seconds. (2900.70 fps)\n* Software decoding (num_threads=16)\n - Shape: torch.Size([5, 3, 240, 320])\n - Processed 895 frames in 0.33 seconds. (2695.54 fps)\n* Hardware decoding\n - Shape: torch.Size([5, 3, 240, 320])\n - Processed 900 frames in 1.97 seconds. (456.78 fps) \n```", "```py\n[src_vga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = torchaudio.utils.download_asset(\"tutorial-assets/testsrc2_vga.h264.mp4\")\n[fps_vga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = run_decode_tests([src_vga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n 0%|          | 0.00/3.59M [00:00<?, ?B/s]\n 57%|#####7    | 2.05M/3.59M [00:00<00:00, 10.8MB/s]\n100%|##########| 3.59M/3.59M [00:00<00:00, 18.0MB/s]\nTesting: testsrc2_vga.h264.mp4\n* Software decoding (num_threads=1)\n - Shape: torch.Size([5, 3, 480, 640])\n - Processed 900 frames in 1.22 seconds. (735.23 fps)\n* Software decoding (num_threads=4)\n - Shape: torch.Size([5, 3, 480, 640])\n - Processed 900 frames in 0.67 seconds. (1345.22 fps)\n* Software decoding (num_threads=8)\n - Shape: torch.Size([5, 3, 480, 640])\n - Processed 900 frames in 0.65 seconds. (1392.83 fps)\n* Software decoding (num_threads=16)\n - Shape: torch.Size([5, 3, 480, 640])\n - Processed 895 frames in 0.67 seconds. (1343.21 fps)\n* Hardware decoding\n - Shape: torch.Size([5, 3, 480, 640])\n - Processed 900 frames in 0.35 seconds. (2564.27 fps) \n```", "```py\n[src_xga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = torchaudio.utils.download_asset(\"tutorial-assets/testsrc2_xga.h264.mp4\")\n[fps_xga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = run_decode_tests([src_xga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n 0%|          | 0.00/9.22M [00:00<?, ?B/s]\n100%|##########| 9.22M/9.22M [00:00<00:00, 130MB/s]\nTesting: testsrc2_xga.h264.mp4\n* Software decoding (num_threads=1)\n - Shape: torch.Size([5, 3, 768, 1024])\n - Processed 900 frames in 2.68 seconds. (335.40 fps)\n* Software decoding (num_threads=4)\n - Shape: torch.Size([5, 3, 768, 1024])\n - Processed 900 frames in 1.20 seconds. (753.01 fps)\n* Software decoding (num_threads=8)\n - Shape: torch.Size([5, 3, 768, 1024])\n - Processed 900 frames in 1.17 seconds. (770.70 fps)\n* Software decoding (num_threads=16)\n - Shape: torch.Size([5, 3, 768, 1024])\n - Processed 895 frames in 1.22 seconds. (736.33 fps)\n* Hardware decoding\n - Shape: torch.Size([5, 3, 768, 1024])\n - Processed 900 frames in 0.62 seconds. (1449.68 fps) \n```", "```py\ndef plot():\n    fig, ax = plt.subplots(figsize=[9.6, 6.4])\n\n    for items in zip([fps_qvga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [fps_vga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [fps_xga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), \"ov^sx\"):\n        ax.plot(items[:-1], marker=items[-1])\n    ax.grid(axis=\"both\")\n    ax.set_xticks([0, 1, 2], [\"QVGA (320x240)\", \"VGA (640x480)\", \"XGA (1024x768)\"])\n    ax.legend(\n        [\n            \"Software Decoding (threads=1)\",\n            \"Software Decoding (threads=4)\",\n            \"Software Decoding (threads=8)\",\n            \"Software Decoding (threads=16)\",\n            \"Hardware Decoding (CUDA Tensor)\",\n        ]\n    )\n    ax.set_title(\"Speed of processing video frames\")\n    ax.set_ylabel(\"Frames per second\")\n    plt.tight_layout()\n\nplot() \n```", "```py\ndef test_decode_then_resize([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), height, width, mode=\"bicubic\", frames_per_chunk=5):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(frames_per_chunk, decoder_option={\"threads\": \"8\"})\n\n    num_frames = 0\n    device = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\")\n    chunk = None\n    t0 = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")()\n    for (chunk,) in s.stream():\n        num_frames += chunk.shape[0]\n        chunk = [torch.nn.functional.interpolate](https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html#torch.nn.functional.interpolate \"torch.nn.functional.interpolate\")(chunk, [height, width], mode=mode, antialias=True)\n        chunk = chunk.to(device)\n    elapsed = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")() - t0\n    fps = num_frames / elapsed\n    print(f\" - Shape: {chunk.shape}\")\n    print(f\" - Processed {num_frames} frames in {elapsed:.2f} seconds. ({fps:.2f} fps)\")\n    return fps \n```", "```py\ndef test_decode_and_resize([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), height, width, mode=\"bicubic\", frames_per_chunk=5):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(\n        frames_per_chunk, filter_desc=f\"scale={width}:{height}:sws_flags={mode}\", decoder_option={\"threads\": \"8\"}\n    )\n\n    num_frames = 0\n    device = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\")\n    chunk = None\n    t0 = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")()\n    for (chunk,) in s.stream():\n        num_frames += chunk.shape[0]\n        chunk = chunk.to(device)\n    elapsed = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")() - t0\n    fps = num_frames / elapsed\n    print(f\" - Shape: {chunk.shape}\")\n    print(f\" - Processed {num_frames} frames in {elapsed:.2f} seconds. ({fps:.2f} fps)\")\n    return fps \n```", "```py\ndef test_hw_decode_and_resize([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), decoder, decoder_option, hw_accel=\"cuda\", frames_per_chunk=5):\n    s = StreamReader([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    s.add_video_stream(5, decoder=decoder, decoder_option=decoder_option, hw_accel=hw_accel)\n\n    num_frames = 0\n    chunk = None\n    t0 = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")()\n    for (chunk,) in s.stream():\n        num_frames += chunk.shape[0]\n    elapsed = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")() - t0\n    fps = num_frames / elapsed\n    print(f\" - Shape: {chunk.shape}\")\n    print(f\" - Processed {num_frames} frames in {elapsed:.2f} seconds. ({fps:.2f} fps)\")\n    return fps \n```", "```py\ndef run_resize_tests([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")):\n    print(f\"Testing: {[os.path.basename](https://docs.python.org/3/library/os.path.html#os.path.basename \"os.path.basename\")([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))}\")\n    height, width = 224, 224\n    print(\"* Software decoding with PyTorch interpolate\")\n    cpu_resize1 = test_decode_then_resize([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), height=height, width=width)\n    print(\"* Software decoding with FFmpeg scale\")\n    cpu_resize2 = test_decode_and_resize([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), height=height, width=width)\n    print(\"* Hardware decoding with resize\")\n    cuda_resize = test_hw_decode_and_resize([src](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), decoder=\"h264_cuvid\", decoder_option={\"resize\": f\"{width}x{height}\"})\n    return [cpu_resize1, cpu_resize2, cuda_resize] \n```", "```py\n[fps_qvga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = run_resize_tests([src_qvga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\nTesting: testsrc2_qvga.h264.mp4\n* Software decoding with PyTorch interpolate\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 0.68 seconds. (1329.86 fps)\n* Software decoding with FFmpeg scale\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 0.36 seconds. (2481.48 fps)\n* Hardware decoding with resize\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 2.00 seconds. (450.11 fps) \n```", "```py\n[fps_vga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = run_resize_tests([src_vga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\nTesting: testsrc2_vga.h264.mp4\n* Software decoding with PyTorch interpolate\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 1.37 seconds. (655.33 fps)\n* Software decoding with FFmpeg scale\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 0.59 seconds. (1533.16 fps)\n* Hardware decoding with resize\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 0.35 seconds. (2569.63 fps) \n```", "```py\n[fps_xga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = run_resize_tests([src_xga](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\nTesting: testsrc2_xga.h264.mp4\n* Software decoding with PyTorch interpolate\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 3.05 seconds. (295.39 fps)\n* Software decoding with FFmpeg scale\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 1.10 seconds. (818.51 fps)\n* Hardware decoding with resize\n - Shape: torch.Size([5, 3, 224, 224])\n - Processed 900 frames in 0.62 seconds. (1452.98 fps) \n```", "```py\ndef plot():\n    fig, ax = plt.subplots(figsize=[9.6, 6.4])\n\n    for items in zip([fps_qvga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [fps_vga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [fps_xga](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), \"ov^sx\"):\n        ax.plot(items[:-1], marker=items[-1])\n    ax.grid(axis=\"both\")\n    ax.set_xticks([0, 1, 2], [\"QVGA (320x240)\", \"VGA (640x480)\", \"XGA (1024x768)\"])\n    ax.legend(\n        [\n            \"Software decoding\\nwith resize\\n(PyTorch interpolate)\",\n            \"Software decoding\\nwith resize\\n(FFmpeg scale)\",\n            \"NVDEC\\nwith resizing\",\n        ]\n    )\n    ax.set_title(\"Speed of processing video frames\")\n    ax.set_xlabel(\"Input video resolution\")\n    ax.set_ylabel(\"Frames per second\")\n    plt.tight_layout()\n\nplot() \n```"]