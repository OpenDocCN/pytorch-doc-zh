["```py\ntorch.library.define(qualname, schema, *, lib=None, tags=())\u00b6\n```", "```py\ntorch.library.define(lib, schema, alias_analysis='')\n```", "```py\n>>> import torch\n>>> import numpy as np\n>>>\n>>> # Define the operator\n>>> torch.library.define(\"mylib::sin\", \"(Tensor x) -> Tensor\")\n>>>\n>>> # Add implementations for the operator\n>>> @torch.library.impl(\"mylibrary::sin\", \"cpu\")\n>>> def f(x):\n>>>     return torch.from_numpy(np.sin(x.numpy()))\n>>>\n>>> # Call the new operator from torch.ops.\n>>> x = torch.randn(3)\n>>> y = torch.ops.mylib.sin(x)\n>>> assert torch.allclose(y, x) \n```", "```py\ntorch.library.impl(qualname, types, func=None, *, lib=None)\u00b6\n```", "```py\ntorch.library.impl(lib, name, dispatch_key='')\n```", "```py\n>>> import torch\n>>> import numpy as np\n>>>\n>>> # Define the operator\n>>> torch.library.define(\"mylibrary::sin\", \"(Tensor x) -> Tensor\")\n>>>\n>>> # Add implementations for the cpu device\n>>> @torch.library.impl(\"mylibrary::sin\", \"cpu\")\n>>> def f(x):\n>>>     return torch.from_numpy(np.sin(x.numpy()))\n>>>\n>>> x = torch.randn(3)\n>>> y = torch.ops.mylibrary.sin(x)\n>>> assert torch.allclose(y, x.sin()) \n```", "```py\ntorch.library.impl_abstract(qualname, func=None, *, lib=None, _stacklevel=1)\u00b6\n```", "```py\n>>> import torch\n>>> import numpy as np\n>>> from torch import Tensor\n>>>\n>>> # Example 1: an operator without data-dependent output shape\n>>> torch.library.define(\n>>>     \"mylib::custom_linear\",\n>>>     \"(Tensor x, Tensor weight, Tensor bias) -> Tensor\")\n>>>\n>>> @torch.library.impl_abstract(\"mylib::custom_linear\")\n>>> def custom_linear_abstract(x, weight):\n>>>     assert x.dim() == 2\n>>>     assert weight.dim() == 2\n>>>     assert bias.dim() == 1\n>>>     assert x.shape[1] == weight.shape[1]\n>>>     assert weight.shape[0] == bias.shape[0]\n>>>     assert x.device == weight.device\n>>>\n>>>     return (x @ weight.t()) + bias\n>>>\n>>> # Example 2: an operator with data-dependent output shape\n>>> torch.library.define(\"mylib::custom_nonzero\", \"(Tensor x) -> Tensor\")\n>>>\n>>> @torch.library.impl_abstract(\"mylib::custom_nonzero\")\n>>> def custom_nonzero_abstract(x):\n>>>     # Number of nonzero-elements is data-dependent.\n>>>     # Since we cannot peek at the data in an abstract impl,\n>>>     # we use the ctx object to construct a new symint that\n>>>     # represents the data-dependent size.\n>>>     ctx = torch.library.get_ctx()\n>>>     nnz = ctx.new_dynamic_size()\n>>>     shape = [nnz, x.dim()]\n>>>     result = x.new_empty(shape, dtype=torch.int64)\n>>>     return result\n>>>\n>>> @torch.library.impl(\"mylib::custom_nonzero\", \"cpu\")\n>>> def custom_nonzero_cpu(x):\n>>>     x_np = x.numpy()\n>>>     res = np.stack(np.nonzero(x_np), axis=1)\n>>>     return torch.tensor(res, device=x.device) \n```", "```py\ntorch.library.get_ctx()\u00b6\n```", "```py\nclass torch.library.Library(ns, kind, dispatch_key='')\u00b6\n```", "```py\ndefine(schema, alias_analysis='', *, tags=())\u00b6\n```", "```py\n>>> my_lib = Library(\"foo\", \"DEF\")\n>>> my_lib.define(\"sum(Tensor self) -> Tensor\") \n```", "```py\nimpl(op_name, fn, dispatch_key='')\u00b6\n```", "```py\n>>> my_lib = Library(\"aten\", \"IMPL\")\n>>> def div_cpu(self, other):\n>>>     return self * (1 / other)\n>>> my_lib.impl(\"div.Tensor\", div_cpu, \"CPU\") \n```", "```py\ntorch.library.fallthrough_kernel()\u00b6\n```"]