- en: torchtext.nn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/text/stable/nn_modules.html](https://pytorch.org/text/stable/nn_modules.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '## MultiheadAttentionContainer[](#multiheadattentioncontainer "Permalink to
    this heading")'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A multi-head attention container
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**nhead** – the number of heads in the multiheadattention model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**in_proj_container** – A container of multi-head in-projection linear layers
    (a.k.a nn.Linear).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**attention_layer** – The custom attention layer. The input sent from MHA container
    to the attention layer is in the shape of (…, L, N * H, E / H) for query and (…,
    S, N * H, E / H) for key/value while the output shape of the attention layer is
    expected to be (…, L, N * H, E / H). The attention_layer needs to support broadcast
    if users want the overall MultiheadAttentionContainer with broadcast.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**out_proj** – The multi-head out-projection layer (a.k.a nn.Linear).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**batch_first** – If `True`, then the input and output tensors are provided
    as (…, N, L, E). Default: `False`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples::'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**query** (*Tensor*) – The query of the attention function. See “Attention
    Is All You Need” for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**key** (*Tensor*) – The keys of the attention function. See “Attention Is
    All You Need” for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**value** (*Tensor*) – The values of the attention function. See “Attention
    Is All You Need” for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**attn_mask** (*BoolTensor**,* *optional*) – 3D mask that prevents attention
    to certain positions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bias_k** (*Tensor**,* *optional*) – one more key and value sequence to be
    added to keys at sequence dim (dim=-3). Those are used for incremental decoding.
    Users should provide `bias_v`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bias_v** (*Tensor**,* *optional*) – one more key and value sequence to be
    added to values at sequence dim (dim=-3). Those are used for incremental decoding.
    Users should also provide `bias_k`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shape:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inputs:'
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'query: \((..., L, N, E)\)'
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'key: \((..., S, N, E)\)'
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'value: \((..., S, N, E)\)'
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'attn_mask, bias_k and bias_v: same with the shape of the corresponding args
    in attention layer.'
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Outputs:'
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'attn_output: \((..., L, N, E)\)'
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'attn_output_weights: \((N * H, L, S)\)'
  prefs:
  - PREF_BQ
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Note: It’s optional to have the query/key/value inputs with more than three
    dimensions (for broadcast purpose). The MultiheadAttentionContainer module will
    operate on the last three dimensions.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: where where L is the target length, S is the sequence length, H is the number
    of attention heads, N is the batch size, and E is the embedding dimension.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: InProjContainer[](#inprojcontainer "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: A in-proj container to project query/key/value in MultiheadAttention. This module
    happens before reshaping the projected query/key/value into multiple heads. See
    the linear layers (bottom) of Multi-head Attention in Fig 2 of Attention Is All
    You Need paper. Also check the usage example in torchtext.nn.MultiheadAttentionContainer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**query_proj** – a proj layer for query. A typical projection layer is torch.nn.Linear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**key_proj** – a proj layer for key. A typical projection layer is torch.nn.Linear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**value_proj** – a proj layer for value. A typical projection layer is torch.nn.Linear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Projects the input sequences using in-proj layers. query/key/value are simply
    passed to the forward func of query/key/value_proj, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**query** (*Tensor*) – The query to be projected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**key** (*Tensor*) – The keys to be projected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**value** (*Tensor*) – The values to be projected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples::'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: ScaledDotProduct[](#scaleddotproduct "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Processes a projected query and key-value pair to apply scaled dot product attention.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**dropout** ([*float*](https://docs.python.org/3/library/functions.html#float
    "(in Python v3.12)")) – probability of dropping an attention weight.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**batch_first** – If `True`, then the input and output tensors are provided
    as (batch, seq, feature). Default: `False`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples::'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Uses a scaled dot product with the projected key-value pair to update the projected
    query.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**query** (*Tensor*) – Projected query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**key** (*Tensor*) – Projected key'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**value** (*Tensor*) – Projected value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**attn_mask** (*BoolTensor**,* *optional*) – 3D mask that prevents attention
    to certain positions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**attn_mask** – 3D mask that prevents attention to certain positions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bias_k** (*Tensor**,* *optional*) – one more key and value sequence to be
    added to keys at sequence dim (dim=-3). Those are used for incremental decoding.
    Users should provide `bias_v`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bias_v** (*Tensor**,* *optional*) – one more key and value sequence to be
    added to values at sequence dim (dim=-3). Those are used for incremental decoding.
    Users should also provide `bias_k`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shape:'
  prefs: []
  type: TYPE_NORMAL
- en: 'query: \((..., L, N * H, E / H)\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'key: \((..., S, N * H, E / H)\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'value: \((..., S, N * H, E / H)\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'attn_mask: \((N * H, L, S)\), positions with `True` are not allowed to attend'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: while `False` values will be unchanged.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'bias_k and bias_v:bias: \((1, N * H, E / H)\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Output: \((..., L, N * H, E / H)\), \((N * H, L, S)\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note: It’s optional to have the query/key/value inputs with more than three
    dimensions (for broadcast purpose).'
  prefs: []
  type: TYPE_NORMAL
- en: The ScaledDotProduct module will operate on the last three dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: where L is the target length, S is the source length, H is the number of attention
    heads, N is the batch size, and E is the embedding dimension.
  prefs: []
  type: TYPE_NORMAL
