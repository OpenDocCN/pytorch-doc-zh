["```py\n    from torch.utils.data.backward_compatibility import worker_init_fn\n    DataLoader(dp, num_workers=4, worker_init_fn=worker_init_fn, drop_last=True) \n    ```", "```py\n# import datasets\nfrom torchtext.datasets import IMDB\n\ntrain_iter = IMDB(split='train')\n\ndef tokenize(label, line):\n    return line.split()\n\ntokens = []\nfor label, line in train_iter:\n    tokens += tokenize(label, line) \n```", "```py\ntorchtext.datasets.AG_NEWS(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.AmazonReviewFull(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.AmazonReviewPolarity(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.CoLA(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'dev', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.DBpedia(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.IMDB(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.MNLI(root='.data', split=('train', 'dev_matched', 'dev_mismatched'))\u00b6\n```", "```py\ntorchtext.datasets.MRPC(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.QNLI(root='.data', split=('train', 'dev', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.QQP(root: str)\u00b6\n```", "```py\ntorchtext.datasets.RTE(root='.data', split=('train', 'dev', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.SogouNews(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.SST2(root='.data', split=('train', 'dev', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.STSB(root='.data', split=('train', 'dev', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.WNLI(root='.data', split=('train', 'dev', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.YahooAnswers(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.YelpReviewFull(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.YelpReviewPolarity(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.PennTreebank(root='.data', split: Union[Tuple[str], str] = ('train', 'valid', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.WikiText2(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'valid', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.WikiText103(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'valid', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.IWSLT2016(root='.data', split=('train', 'valid', 'test'), language_pair=('de', 'en'), valid_set='tst2013', test_set='tst2014')\u00b6\n```", "```py\n>>> from torchtext.datasets import IWSLT2016\n>>> train_iter, valid_iter, test_iter = IWSLT2016()\n>>> src_sentence, tgt_sentence = next(iter(train_iter)) \n```", "```py\ntorchtext.datasets.IWSLT2017(root='.data', split=('train', 'valid', 'test'), language_pair=('de', 'en'))\u00b6\n```", "```py\n>>> from torchtext.datasets import IWSLT2017\n>>> train_iter, valid_iter, test_iter = IWSLT2017()\n>>> src_sentence, tgt_sentence = next(iter(train_iter)) \n```", "```py\ntorchtext.datasets.Multi30k(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'valid', 'test'), language_pair: Tuple[str] = ('de', 'en'))\u00b6\n```", "```py\ntorchtext.datasets.CoNLL2000Chunking(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.UDPOS(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'valid', 'test'))\u00b6\n```", "```py\ntorchtext.datasets.SQuAD1(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'dev'))\u00b6\n```", "```py\ntorchtext.datasets.SQuAD2(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'dev'))\u00b6\n```", "```py\ntorchtext.datasets.CC100(root: str, language_code: str = 'en')\u00b6\n```", "```py\ntorchtext.datasets.EnWik9(root: str)\u00b6\n```"]