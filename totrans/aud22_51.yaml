- en: torchaudio.transforms¶
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/audio/stable/transforms.html](https://pytorch.org/audio/stable/transforms.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`torchaudio.transforms` module contains common audio processings and feature
    extractions. The following diagram shows the relationship between some of the
    available transforms.'
  prefs: []
  type: TYPE_NORMAL
- en: '![https://download.pytorch.org/torchaudio/tutorial-assets/torchaudio_feature_extractions.png](../Images/82ba49f78e3cd14b6e337acaf57b11e2.png)'
  prefs: []
  type: TYPE_IMG
- en: Transforms are implemented using [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module
    "(in PyTorch v2.1)"). Common ways to build a processing pipeline are to define
    custom Module class or chain Modules together using [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential
    "(in PyTorch v2.1)"), then move it to a target device and data type.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Please check out tutorials that cover in-depth usage of trasforms.
  prefs: []
  type: TYPE_NORMAL
- en: '![Audio Feature Extractions](../Images/fc6b9ddc12696e086aaac0cd46a41785.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Audio Feature Extractions](tutorials/audio_feature_extractions_tutorial.html#sphx-glr-tutorials-audio-feature-extractions-tutorial-py)'
  prefs: []
  type: TYPE_NORMAL
- en: Audio Feature Extractions
  prefs: []
  type: TYPE_NORMAL
- en: Utility[¶](#utility "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| [`AmplitudeToDB`](generated/torchaudio.transforms.AmplitudeToDB.html#torchaudio.transforms.AmplitudeToDB
    "torchaudio.transforms.AmplitudeToDB") | Turn a tensor from the power/amplitude
    scale to the decibel scale. |'
  prefs: []
  type: TYPE_TB
- en: '| [`MuLawEncoding`](generated/torchaudio.transforms.MuLawEncoding.html#torchaudio.transforms.MuLawEncoding
    "torchaudio.transforms.MuLawEncoding") | Encode signal based on mu-law companding.
    |'
  prefs: []
  type: TYPE_TB
- en: '| [`MuLawDecoding`](generated/torchaudio.transforms.MuLawDecoding.html#torchaudio.transforms.MuLawDecoding
    "torchaudio.transforms.MuLawDecoding") | Decode mu-law encoded signal. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Resample`](generated/torchaudio.transforms.Resample.html#torchaudio.transforms.Resample
    "torchaudio.transforms.Resample") | Resample a signal from one frequency to another.
    |'
  prefs: []
  type: TYPE_TB
- en: '| [`Fade`](generated/torchaudio.transforms.Fade.html#torchaudio.transforms.Fade
    "torchaudio.transforms.Fade") | Add a fade in and/or fade out to an waveform.
    |'
  prefs: []
  type: TYPE_TB
- en: '| [`Vol`](generated/torchaudio.transforms.Vol.html#torchaudio.transforms.Vol
    "torchaudio.transforms.Vol") | Adjust volume of waveform. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Loudness`](generated/torchaudio.transforms.Loudness.html#torchaudio.transforms.Loudness
    "torchaudio.transforms.Loudness") | Measure audio loudness according to the ITU-R
    BS.1770-4 recommendation. |'
  prefs: []
  type: TYPE_TB
- en: '| [`AddNoise`](generated/torchaudio.transforms.AddNoise.html#torchaudio.transforms.AddNoise
    "torchaudio.transforms.AddNoise") | Scales and adds noise to waveform per signal-to-noise
    ratio. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Convolve`](generated/torchaudio.transforms.Convolve.html#torchaudio.transforms.Convolve
    "torchaudio.transforms.Convolve") | Convolves inputs along their last dimension
    using the direct method. |'
  prefs: []
  type: TYPE_TB
- en: '| [`FFTConvolve`](generated/torchaudio.transforms.FFTConvolve.html#torchaudio.transforms.FFTConvolve
    "torchaudio.transforms.FFTConvolve") | Convolves inputs along their last dimension
    using FFT. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Speed`](generated/torchaudio.transforms.Speed.html#torchaudio.transforms.Speed
    "torchaudio.transforms.Speed") | Adjusts waveform speed. |'
  prefs: []
  type: TYPE_TB
- en: '| [`SpeedPerturbation`](generated/torchaudio.transforms.SpeedPerturbation.html#torchaudio.transforms.SpeedPerturbation
    "torchaudio.transforms.SpeedPerturbation") | Applies the speed perturbation augmentation
    introduced in *Audio augmentation for speech recognition* [[Ko *et al.*, 2015](references.html#id58
    "Tom Ko, Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur. Audio augmentation
    for speech recognition. In Proc. Interspeech 2015, 3586–3589\. 2015\. doi:10.21437/Interspeech.2015-711.")].
    |'
  prefs: []
  type: TYPE_TB
- en: '| [`Deemphasis`](generated/torchaudio.transforms.Deemphasis.html#torchaudio.transforms.Deemphasis
    "torchaudio.transforms.Deemphasis") | De-emphasizes a waveform along its last
    dimension. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Preemphasis`](generated/torchaudio.transforms.Preemphasis.html#torchaudio.transforms.Preemphasis
    "torchaudio.transforms.Preemphasis") | Pre-emphasizes a waveform along its last
    dimension. |'
  prefs: []
  type: TYPE_TB
- en: Feature Extractions[¶](#feature-extractions "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| [`Spectrogram`](generated/torchaudio.transforms.Spectrogram.html#torchaudio.transforms.Spectrogram
    "torchaudio.transforms.Spectrogram") | Create a spectrogram from a audio signal.
    |'
  prefs: []
  type: TYPE_TB
- en: '| [`InverseSpectrogram`](generated/torchaudio.transforms.InverseSpectrogram.html#torchaudio.transforms.InverseSpectrogram
    "torchaudio.transforms.InverseSpectrogram") | Create an inverse spectrogram to
    recover an audio signal from a spectrogram. |'
  prefs: []
  type: TYPE_TB
- en: '| [`MelScale`](generated/torchaudio.transforms.MelScale.html#torchaudio.transforms.MelScale
    "torchaudio.transforms.MelScale") | Turn a normal STFT into a mel frequency STFT
    with triangular filter banks. |'
  prefs: []
  type: TYPE_TB
- en: '| [`InverseMelScale`](generated/torchaudio.transforms.InverseMelScale.html#torchaudio.transforms.InverseMelScale
    "torchaudio.transforms.InverseMelScale") | Estimate a STFT in normal frequency
    domain from mel frequency domain. |'
  prefs: []
  type: TYPE_TB
- en: '| [`MelSpectrogram`](generated/torchaudio.transforms.MelSpectrogram.html#torchaudio.transforms.MelSpectrogram
    "torchaudio.transforms.MelSpectrogram") | Create MelSpectrogram for a raw audio
    signal. |'
  prefs: []
  type: TYPE_TB
- en: '| [`GriffinLim`](generated/torchaudio.transforms.GriffinLim.html#torchaudio.transforms.GriffinLim
    "torchaudio.transforms.GriffinLim") | Compute waveform from a linear scale magnitude
    spectrogram using the Griffin-Lim transformation. |'
  prefs: []
  type: TYPE_TB
- en: '| [`MFCC`](generated/torchaudio.transforms.MFCC.html#torchaudio.transforms.MFCC
    "torchaudio.transforms.MFCC") | Create the Mel-frequency cepstrum coefficients
    from an audio signal. |'
  prefs: []
  type: TYPE_TB
- en: '| [`LFCC`](generated/torchaudio.transforms.LFCC.html#torchaudio.transforms.LFCC
    "torchaudio.transforms.LFCC") | Create the linear-frequency cepstrum coefficients
    from an audio signal. |'
  prefs: []
  type: TYPE_TB
- en: '| [`ComputeDeltas`](generated/torchaudio.transforms.ComputeDeltas.html#torchaudio.transforms.ComputeDeltas
    "torchaudio.transforms.ComputeDeltas") | Compute delta coefficients of a tensor,
    usually a spectrogram. |'
  prefs: []
  type: TYPE_TB
- en: '| [`PitchShift`](generated/torchaudio.transforms.PitchShift.html#torchaudio.transforms.PitchShift
    "torchaudio.transforms.PitchShift") | Shift the pitch of a waveform by `n_steps`
    steps. |'
  prefs: []
  type: TYPE_TB
- en: '| [`SlidingWindowCmn`](generated/torchaudio.transforms.SlidingWindowCmn.html#torchaudio.transforms.SlidingWindowCmn
    "torchaudio.transforms.SlidingWindowCmn") | Apply sliding-window cepstral mean
    (and optionally variance) normalization per utterance. |'
  prefs: []
  type: TYPE_TB
- en: '| [`SpectralCentroid`](generated/torchaudio.transforms.SpectralCentroid.html#torchaudio.transforms.SpectralCentroid
    "torchaudio.transforms.SpectralCentroid") | Compute the spectral centroid for
    each channel along the time axis. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Vad`](generated/torchaudio.transforms.Vad.html#torchaudio.transforms.Vad
    "torchaudio.transforms.Vad") | Voice Activity Detector. |'
  prefs: []
  type: TYPE_TB
- en: Augmentations[¶](#augmentations "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following transforms implement popular augmentation techniques known as
    *SpecAugment* [[Park *et al.*, 2019](references.html#id6 "Daniel S. Park, William
    Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D. Cubuk, and Quoc V. Le.
    Specaugment: a simple data augmentation method for automatic speech recognition.
    Interspeech 2019, Sep 2019\. URL: http://dx.doi.org/10.21437/Interspeech.2019-2680,
    doi:10.21437/interspeech.2019-2680.")].'
  prefs: []
  type: TYPE_NORMAL
- en: '| [`FrequencyMasking`](generated/torchaudio.transforms.FrequencyMasking.html#torchaudio.transforms.FrequencyMasking
    "torchaudio.transforms.FrequencyMasking") | Apply masking to a spectrogram in
    the frequency domain. |'
  prefs: []
  type: TYPE_TB
- en: '| [`TimeMasking`](generated/torchaudio.transforms.TimeMasking.html#torchaudio.transforms.TimeMasking
    "torchaudio.transforms.TimeMasking") | Apply masking to a spectrogram in the time
    domain. |'
  prefs: []
  type: TYPE_TB
- en: '| [`TimeStretch`](generated/torchaudio.transforms.TimeStretch.html#torchaudio.transforms.TimeStretch
    "torchaudio.transforms.TimeStretch") | Stretch stft in time without modifying
    pitch for a given rate. |'
  prefs: []
  type: TYPE_TB
- en: Loss[¶](#loss "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| [`RNNTLoss`](generated/torchaudio.transforms.RNNTLoss.html#torchaudio.transforms.RNNTLoss
    "torchaudio.transforms.RNNTLoss") | Compute the RNN Transducer loss from *Sequence
    Transduction with Recurrent Neural Networks* [[Graves, 2012](references.html#id18
    "Alex Graves. Sequence transduction with recurrent neural networks. 2012\. arXiv:1211.3711.")].
    |'
  prefs: []
  type: TYPE_TB
- en: Multi-channel[¶](#multi-channel "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| [`PSD`](generated/torchaudio.transforms.PSD.html#torchaudio.transforms.PSD
    "torchaudio.transforms.PSD") | Compute cross-channel power spectral density (PSD)
    matrix. |'
  prefs: []
  type: TYPE_TB
- en: '| [`MVDR`](generated/torchaudio.transforms.MVDR.html#torchaudio.transforms.MVDR
    "torchaudio.transforms.MVDR") | Minimum Variance Distortionless Response (MVDR)
    module that performs MVDR beamforming with Time-Frequency masks. |'
  prefs: []
  type: TYPE_TB
- en: '| [`RTFMVDR`](generated/torchaudio.transforms.RTFMVDR.html#torchaudio.transforms.RTFMVDR
    "torchaudio.transforms.RTFMVDR") | Minimum Variance Distortionless Response (*MVDR*
    [[Capon, 1969](references.html#id34 "Jack Capon. High-resolution frequency-wavenumber
    spectrum analysis. Proceedings of the IEEE, 57(8):1408–1418, 1969.")]) module
    based on the relative transfer function (RTF) and power spectral density (PSD)
    matrix of noise. |'
  prefs: []
  type: TYPE_TB
- en: '| [`SoudenMVDR`](generated/torchaudio.transforms.SoudenMVDR.html#torchaudio.transforms.SoudenMVDR
    "torchaudio.transforms.SoudenMVDR") | Minimum Variance Distortionless Response
    (*MVDR* [[Capon, 1969](references.html#id34 "Jack Capon. High-resolution frequency-wavenumber
    spectrum analysis. Proceedings of the IEEE, 57(8):1408–1418, 1969.")]) module
    based on the method proposed by *Souden et, al.* [[Souden *et al.*, 2009](references.html#id28
    "Mehrez Souden, Jacob Benesty, and Sofiene Affes. On optimal frequency-domain
    multichannel linear filtering for noise reduction. In IEEE Transactions on audio,
    speech, and language processing, volume 18, 260–276\. IEEE, 2009.")]. |'
  prefs: []
  type: TYPE_TB
