["```py\n# Imports\nimport copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport time\n\nplt.ion() \n```", "```py\npip  install  numpy\npip  install  --pre  torch  torchvision  -f  https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n# For CUDA support use https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html \n```", "```py\nimport torch\nfrom torchvision import transforms, datasets\n\n# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(224),\n        transforms.RandomCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data/hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n                                              shuffle=True, num_workers=8)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n```", "```py\nimport torchvision\n\ndef imshow(inp, title=None, ax=None, figsize=(5, 5)):\n  \"\"\"Imshow for Tensor.\"\"\"\n  inp = inp.numpy().transpose((1, 2, 0))\n  mean = np.array([0.485, 0.456, 0.406])\n  std = np.array([0.229, 0.224, 0.225])\n  inp = std * inp + mean\n  inp = np.clip(inp, 0, 1)\n  if ax is None:\n    fig, ax = plt.subplots(1, figsize=figsize)\n  ax.imshow(inp)\n  ax.set_xticks([])\n  ax.set_yticks([])\n  if title is not None:\n    ax.set_title(title)\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs, nrow=4)\n\nfig, ax = plt.subplots(1, figsize=(10, 10))\nimshow(out, title=[class_names[x] for x in classes], ax=ax) \n```", "```py\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25, device='cpu'):\n  \"\"\"\n Support function for model training.\n\n Args:\n model: Model to be trained\n criterion: Optimization criterion (loss)\n optimizer: Optimizer to use for training\n scheduler: Instance of ``torch.optim.lr_scheduler``\n num_epochs: Number of epochs\n device: Device to run the training on. Must be 'cpu' or 'cuda'\n \"\"\"\n  since = time.time()\n\n  best_model_wts = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n\n  for epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()  # Set model to training mode\n      else:\n        model.eval()   # Set model to evaluate mode\n\n      running_loss = 0.0\n      running_corrects = 0\n\n      # Iterate over data.\n      for inputs, labels in dataloaders[phase]:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward\n        # track history if only in train\n        with torch.set_grad_enabled(phase == 'train'):\n          outputs = model(inputs)\n          _, preds = torch.max(outputs, 1)\n          loss = criterion(outputs, labels)\n\n          # backward + optimize only if in training phase\n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n\n        # statistics\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n      if phase == 'train':\n        scheduler.step()\n\n      epoch_loss = running_loss / dataset_sizes[phase]\n      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n      print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n        phase, epoch_loss, epoch_acc))\n\n      # deep copy the model\n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model_wts = copy.deepcopy(model.state_dict())\n\n    print()\n\n  time_elapsed = time.time() - since\n  print('Training complete in {:.0f}m {:.0f}s'.format(\n    time_elapsed // 60, time_elapsed % 60))\n  print('Best val Acc: {:4f}'.format(best_acc))\n\n  # load best model weights\n  model.load_state_dict(best_model_wts)\n  return model \n```", "```py\ndef visualize_model(model, rows=3, cols=3):\n  was_training = model.training\n  model.eval()\n  current_row = current_col = 0\n  fig, ax = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n\n  with torch.no_grad():\n    for idx, (imgs, lbls) in enumerate(dataloaders['val']):\n      imgs = imgs.cpu()\n      lbls = lbls.cpu()\n\n      outputs = model(imgs)\n      _, preds = torch.max(outputs, 1)\n\n      for jdx in range(imgs.size()[0]):\n        imshow(imgs.data[jdx], ax=ax[current_row, current_col])\n        ax[current_row, current_col].axis('off')\n        ax[current_row, current_col].set_title('predicted: {}'.format(class_names[preds[jdx]]))\n\n        current_col += 1\n        if current_col >= cols:\n          current_row += 1\n          current_col = 0\n        if current_row >= rows:\n          model.train(mode=was_training)\n          return\n    model.train(mode=was_training) \n```", "```py\nimport torchvision.models.quantization as models\n\n# You will need the number of filters in the `fc` for future use.\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_fe = models.resnet18(pretrained=True, progress=True, quantize=True)\nnum_ftrs = model_fe.fc.in_features \n```", "```py\nfrom torch import nn\n\ndef create_combined_model(model_fe):\n  # Step 1\\. Isolate the feature extractor.\n  model_fe_features = nn.Sequential(\n    model_fe.quant,  # Quantize the input\n    model_fe.conv1,\n    model_fe.bn1,\n    model_fe.relu,\n    model_fe.maxpool,\n    model_fe.layer1,\n    model_fe.layer2,\n    model_fe.layer3,\n    model_fe.layer4,\n    model_fe.avgpool,\n    model_fe.dequant,  # Dequantize the output\n  )\n\n  # Step 2\\. Create a new \"head\"\n  new_head = nn.Sequential(\n    nn.Dropout(p=0.5),\n    nn.Linear(num_ftrs, 2),\n  )\n\n  # Step 3\\. Combine, and don't forget the quant stubs.\n  new_model = nn.Sequential(\n    model_fe_features,\n    nn.Flatten(1),\n    new_head,\n  )\n  return new_model \n```", "```py\nimport torch.optim as optim\nnew_model = create_combined_model(model_fe)\nnew_model = new_model.to('cpu')\n\ncriterion = nn.CrossEntropyLoss()\n\n# Note that we are only training the head.\noptimizer_ft = optim.SGD(new_model.parameters(), lr=0.01, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) \n```", "```py\nnew_model = train_model(new_model, criterion, optimizer_ft, exp_lr_scheduler,\n                        num_epochs=25, device='cpu')\n\nvisualize_model(new_model)\nplt.tight_layout() \n```", "```py\n# notice `quantize=False`\nmodel = models.resnet18(pretrained=True, progress=True, quantize=False)\nnum_ftrs = model.fc.in_features\n\n# Step 1\nmodel.train()\nmodel.fuse_model()\n# Step 2\nmodel_ft = create_combined_model(model)\nmodel_ft[0].qconfig = torch.quantization.default_qat_qconfig  # Use default QAT configuration\n# Step 3\nmodel_ft = torch.quantization.prepare_qat(model_ft, inplace=True) \n```", "```py\nfor param in model_ft.parameters():\n  param.requires_grad = True\n\nmodel_ft.to(device)  # We can fine-tune on GPU if available\n\ncriterion = nn.CrossEntropyLoss()\n\n# Note that we are training everything, so the learning rate is lower\n# Notice the smaller learning rate\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.1)\n\n# Decay LR by a factor of 0.3 every several epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.3)\n\nmodel_ft_tuned = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                             num_epochs=25, device=device) \n```", "```py\nfrom torch.quantization import convert\nmodel_ft_tuned.cpu()\n\nmodel_quantized_and_trained = convert(model_ft_tuned, inplace=False) \n```", "```py\nvisualize_model(model_quantized_and_trained)\n\nplt.ioff()\nplt.tight_layout()\nplt.show() \n```"]