# torchaudio.prototype.pipelines

> 原文：[https://pytorch.org/audio/stable/prototype.pipelines.html](https://pytorch.org/audio/stable/prototype.pipelines.html)

pipelines子包含有具有预训练权重和相关实用程序的模型的API。

## RNN-T流式/非流式ASR[](#rnn-t-streaming-non-streaming-asr "跳转到此标题")

### 预训练模型[](#pretrained-models "跳转到此标题")

| [`EMFORMER_RNNT_BASE_MUSTC`](generated/torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_MUSTC.html#torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_MUSTC "torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_MUSTC") | 预训练的Emformer-RNNT基于ASR管道，能够执行流式和非流式推断。 |
| --- | --- |
| [`EMFORMER_RNNT_BASE_TEDLIUM3`](generated/torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_TEDLIUM3.html#torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_TEDLIUM3 "torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_TEDLIUM3") | 预训练的Emformer-RNNT基于ASR管道，能够执行流式和非流式推断。 |

## HiFiGAN Vocoder[](#hifigan-vocoder "跳转到此标题")

### 接口[](#interface "跳转到此标题")

[`HiFiGANVocoderBundle`](generated/torchaudio.prototype.pipelines.HiFiGANVocoderBundle.html#torchaudio.prototype.pipelines.HiFiGANVocoderBundle "torchaudio.prototype.pipelines.HiFiGANVocoderBundle")定义了能够将mel频谱图转换为波形的HiFiGAN Vocoder管道。

| [`HiFiGANVocoderBundle`](generated/torchaudio.prototype.pipelines.HiFiGANVocoderBundle.html#torchaudio.prototype.pipelines.HiFiGANVocoderBundle "torchaudio.prototype.pipelines.HiFiGANVocoderBundle") | 数据类，捆绑了与预训练[`HiFiGANVocoder`](generated/torchaudio.prototype.models.HiFiGANVocoder.html#torchaudio.prototype.models.HiFiGANVocoder "torchaudio.prototype.models.HiFiGANVocoder")相关的信息。 |
| --- | --- |

### 预训练模型[](#id1 "跳转到此标题")

| [`HIFIGAN_VOCODER_V3_LJSPEECH`](generated/torchaudio.prototype.pipelines.HIFIGAN_VOCODER_V3_LJSPEECH.html#torchaudio.prototype.pipelines.HIFIGAN_VOCODER_V3_LJSPEECH "torchaudio.prototype.pipelines.HIFIGAN_VOCODER_V3_LJSPEECH") | HiFiGAN Vocoder管道，训练于*LJ Speech数据集*[[Ito and Johnson, 2017](references.html#id7 "Keith Ito and Linda Johnson. The lj speech dataset. \url https://keithito.com/LJ-Speech-Dataset/, 2017.")]。 |
| --- | --- |

## VGGish[](#vggish "跳转到此标题")

### 接口[](#id3 "跳转到此标题")

| [`VGGishBundle`](generated/torchaudio.prototype.pipelines.VGGishBundle.html#torchaudio.prototype.pipelines.VGGishBundle "torchaudio.prototype.pipelines.VGGishBundle") | VGGish[[Hershey等人，2017](references.html#id70 "Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jort F. Gemmeke, Aren Jansen, Channing Moore, Manoj Plakal, Devin Platt, Rif A. Saurous, Bryan Seybold, Malcolm Slaney, Ron Weiss, and Kevin Wilson. Cnn architectures for large-scale audio classification. In International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2017\. URL: https://arxiv.org/abs/1609.09430.")]推断管道，从[torchvggish](https://github.com/harritaylor/torchvggish)和[tensorflow-models](https://github.com/tensorflow/models/tree/master/research/audioset)移植而来。 |
| --- | --- |
| [`VGGishBundle.VGGish`](generated/torchaudio.prototype.pipelines.VGGishBundle.VGGish.html#torchaudio.prototype.pipelines.VGGishBundle.VGGish "torchaudio.prototype.pipelines.VGGishBundle.VGGish") | VGGish模型的实现[[Hershey等人，2017](references.html#id70 "Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jort F. Gemmeke, Aren Jansen, Channing Moore, Manoj Plakal, Devin Platt, Rif A. Saurous, Bryan Seybold, Malcolm Slaney, Ron Weiss, and Kevin Wilson. Cnn architectures for large-scale audio classification. In International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2017\. URL: https://arxiv.org/abs/1609.09430.")]。 |
| [`VGGishBundle.VGGishInputProcessor`](generated/torchaudio.prototype.pipelines.VGGishBundle.VGGishInputProcessor.html#torchaudio.prototype.pipelines.VGGishBundle.VGGishInputProcessor "torchaudio.prototype.pipelines.VGGishBundle.VGGishInputProcessor") | 将原始波形转换为用作VGGish输入的示例批次。 |

### 预训练模型

| [`VGGISH`](generated/torchaudio.prototype.pipelines.VGGISH.html#torchaudio.prototype.pipelines.VGGISH "torchaudio.prototype.pipelines.VGGISH") | 从 [torchvggish](https://github.com/harritaylor/torchvggish) 和 [tensorflow-models](https://github.com/tensorflow/models/tree/master/research/audioset) 移植的预训练VGGish [[Hershey *et al.*, 2017](references.html#id70 "Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jort F. Gemmeke, Aren Jansen, Channing Moore, Manoj Plakal, Devin Platt, Rif A. Saurous, Bryan Seybold, Malcolm Slaney, Ron Weiss, and Kevin Wilson. Cnn architectures for large-scale audio classification. In International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2017\. URL: https://arxiv.org/abs/1609.09430.")] 推理流程。 |
| --- | --- |
