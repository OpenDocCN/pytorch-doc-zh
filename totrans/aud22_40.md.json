["```py\nimport torch\nimport torchaudio\n\nprint(torch.__version__)\nprint([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\")\nprint([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")) \n```", "```py\n2.2.0\n2.2.0\ncuda \n```", "```py\nfrom dataclasses import [dataclass](https://docs.python.org/3/library/dataclasses.html#dataclasses.dataclass \"dataclasses.dataclass\")\n\nimport IPython\nimport matplotlib.pyplot as plt\n\n[torch.random.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed \"torch.manual_seed\")(0)\n\n[SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\") \n```", "```py\nbundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\nmodel = bundle.get_model().to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n[labels](https://docs.python.org/3/library/stdtypes.html#tuple \"builtins.tuple\") = bundle.get_labels()\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), _ = torchaudio.load([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), _ = model([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")))\n    [emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = torch.log_softmax([emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), dim=-1)\n\n[emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].cpu().detach()\n\nprint([labels](https://docs.python.org/3/library/stdtypes.html#tuple \"builtins.tuple\")) \n```", "```py\n('-', '|', 'E', 'T', 'A', 'O', 'N', 'I', 'H', 'S', 'R', 'D', 'L', 'U', 'M', 'W', 'C', 'F', 'G', 'Y', 'P', 'B', 'V', 'K', \"'\", 'X', 'J', 'Q', 'Z') \n```", "```py\ndef plot():\n    fig, ax = plt.subplots()\n    img = ax.imshow([emission.T](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n    ax.set_title(\"Frame-wise class probability\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Labels\")\n    fig.colorbar(img, ax=ax, shrink=0.6, location=\"bottom\")\n    fig.tight_layout()\n\nplot() \n```", "```py\n# We enclose the transcript with space tokens, which represent SOS and EOS.\n[transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"|I|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT|\"\n[dictionary](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\") = {c: i for i, c in enumerate([labels](https://docs.python.org/3/library/stdtypes.html#tuple \"builtins.tuple\"))}\n\n[tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [[dictionary](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[c] for c in [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")]\nprint(list(zip([transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))))\n\ndef get_trellis([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), blank_id=0):\n    num_frame = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0)\n    num_tokens = len([tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n\n    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.zeros](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros \"torch.zeros\")((num_frame, num_tokens))\n    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[1:, 0] = [torch.cumsum](https://pytorch.org/docs/stable/generated/torch.cumsum.html#torch.cumsum \"torch.cumsum\")([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[1:, blank_id], 0)\n    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0, 1:] = -float(\"inf\")\n    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[-num_tokens + 1 :, 0] = float(\"inf\")\n\n    for t in range(num_frame - 1):\n        [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t + 1, 1:] = [torch.maximum](https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum \"torch.maximum\")(\n            # Score for staying at the same token\n            [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t, 1:] + [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t, blank_id],\n            # Score for changing to the next token\n            [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t, :-1] + [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t, [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[1:]],\n        )\n    return [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n\n[trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = get_trellis([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) \n```", "```py\n[('|', 1), ('I', 7), ('|', 1), ('H', 8), ('A', 4), ('D', 11), ('|', 1), ('T', 3), ('H', 8), ('A', 4), ('T', 3), ('|', 1), ('C', 16), ('U', 13), ('R', 10), ('I', 7), ('O', 5), ('S', 9), ('I', 7), ('T', 3), ('Y', 19), ('|', 1), ('B', 21), ('E', 2), ('S', 9), ('I', 7), ('D', 11), ('E', 2), ('|', 1), ('M', 14), ('E', 2), ('|', 1), ('A', 4), ('T', 3), ('|', 1), ('T', 3), ('H', 8), ('I', 7), ('S', 9), ('|', 1), ('M', 14), ('O', 5), ('M', 14), ('E', 2), ('N', 6), ('T', 3), ('|', 1)] \n```", "```py\ndef plot():\n    fig, ax = plt.subplots()\n    img = ax.imshow([trellis.T](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), origin=\"lower\")\n    ax.annotate(\"- Inf\", ([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) / 5, [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) / 1.5))\n    ax.annotate(\"+ Inf\", ([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0) - [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) / 5, [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) / 3))\n    fig.colorbar(img, ax=ax, shrink=0.6, location=\"bottom\")\n    fig.tight_layout()\n\nplot() \n```", "```py\n@dataclass\nclass Point:\n    token_index: int\n    time_index: int\n    score: float\n\ndef backtrack([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), blank_id=0):\n    t, j = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0) - 1, [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) - 1\n\n    [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [Point(j, t, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t, blank_id].exp().item())]\n    while j > 0:\n        # Should not happen but just in case\n        assert t > 0\n\n        # 1\\. Figure out if the current position was stay or change\n        # Frame-wise score of stay vs change\n        p_stay = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t - 1, blank_id]\n        p_change = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t - 1, [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[j]]\n\n        # Context-aware score for stay vs change\n        stayed = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t - 1, j] + p_stay\n        changed = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t - 1, j - 1] + p_change\n\n        # Update position\n        t -= 1\n        if changed > stayed:\n            j -= 1\n\n        # Store the path with frame-wise probability.\n        prob = (p_change if changed > stayed else p_stay).exp().item()\n        [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\").append(Point(j, t, prob))\n\n    # Now j == 0, which means, it reached the SoS.\n    # Fill up the rest for the sake of visualization\n    while t > 0:\n        prob = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[t - 1, blank_id].exp().item()\n        [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\").append(Point(j, t - 1, prob))\n        t -= 1\n\n    return [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[::-1]\n\n[path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = backtrack([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\nfor p in [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    print(p) \n```", "```py\nPoint(token_index=0, time_index=0, score=0.9999996423721313)\nPoint(token_index=0, time_index=1, score=0.9999996423721313)\nPoint(token_index=0, time_index=2, score=0.9999996423721313)\nPoint(token_index=0, time_index=3, score=0.9999996423721313)\nPoint(token_index=0, time_index=4, score=0.9999996423721313)\nPoint(token_index=0, time_index=5, score=0.9999996423721313)\nPoint(token_index=0, time_index=6, score=0.9999996423721313)\nPoint(token_index=0, time_index=7, score=0.9999996423721313)\nPoint(token_index=0, time_index=8, score=0.9999998807907104)\nPoint(token_index=0, time_index=9, score=0.9999996423721313)\nPoint(token_index=0, time_index=10, score=0.9999996423721313)\nPoint(token_index=0, time_index=11, score=0.9999998807907104)\nPoint(token_index=0, time_index=12, score=0.9999996423721313)\nPoint(token_index=0, time_index=13, score=0.9999996423721313)\nPoint(token_index=0, time_index=14, score=0.9999996423721313)\nPoint(token_index=0, time_index=15, score=0.9999996423721313)\nPoint(token_index=0, time_index=16, score=0.9999996423721313)\nPoint(token_index=0, time_index=17, score=0.9999996423721313)\nPoint(token_index=0, time_index=18, score=0.9999998807907104)\nPoint(token_index=0, time_index=19, score=0.9999996423721313)\nPoint(token_index=0, time_index=20, score=0.9999996423721313)\nPoint(token_index=0, time_index=21, score=0.9999996423721313)\nPoint(token_index=0, time_index=22, score=0.9999996423721313)\nPoint(token_index=0, time_index=23, score=0.9999997615814209)\nPoint(token_index=0, time_index=24, score=0.9999998807907104)\nPoint(token_index=0, time_index=25, score=0.9999998807907104)\nPoint(token_index=0, time_index=26, score=0.9999998807907104)\nPoint(token_index=0, time_index=27, score=0.9999998807907104)\nPoint(token_index=0, time_index=28, score=0.9999985694885254)\nPoint(token_index=0, time_index=29, score=0.9999943971633911)\nPoint(token_index=0, time_index=30, score=0.9999842643737793)\nPoint(token_index=1, time_index=31, score=0.9846165180206299)\nPoint(token_index=1, time_index=32, score=0.9999706745147705)\nPoint(token_index=1, time_index=33, score=0.15376661717891693)\nPoint(token_index=1, time_index=34, score=0.9999172687530518)\nPoint(token_index=2, time_index=35, score=0.6086705327033997)\nPoint(token_index=2, time_index=36, score=0.9997723698616028)\nPoint(token_index=3, time_index=37, score=0.9997134804725647)\nPoint(token_index=3, time_index=38, score=0.9999358654022217)\nPoint(token_index=4, time_index=39, score=0.9861685633659363)\nPoint(token_index=4, time_index=40, score=0.9242331385612488)\nPoint(token_index=5, time_index=41, score=0.926007866859436)\nPoint(token_index=5, time_index=42, score=0.01556419488042593)\nPoint(token_index=5, time_index=43, score=0.9998375177383423)\nPoint(token_index=6, time_index=44, score=0.9988489151000977)\nPoint(token_index=7, time_index=45, score=0.1021796241402626)\nPoint(token_index=7, time_index=46, score=0.9999427795410156)\nPoint(token_index=8, time_index=47, score=0.9999943971633911)\nPoint(token_index=8, time_index=48, score=0.9979604482650757)\nPoint(token_index=9, time_index=49, score=0.0360121876001358)\nPoint(token_index=9, time_index=50, score=0.06167365238070488)\nPoint(token_index=9, time_index=51, score=4.336783240432851e-05)\nPoint(token_index=10, time_index=52, score=0.9999799728393555)\nPoint(token_index=11, time_index=53, score=0.9967040419578552)\nPoint(token_index=11, time_index=54, score=0.9999257326126099)\nPoint(token_index=11, time_index=55, score=0.9999982118606567)\nPoint(token_index=12, time_index=56, score=0.9990678429603577)\nPoint(token_index=12, time_index=57, score=0.9999996423721313)\nPoint(token_index=12, time_index=58, score=0.9999996423721313)\nPoint(token_index=12, time_index=59, score=0.8453492522239685)\nPoint(token_index=12, time_index=60, score=0.9999996423721313)\nPoint(token_index=13, time_index=61, score=0.9996009469032288)\nPoint(token_index=13, time_index=62, score=0.999998927116394)\nPoint(token_index=14, time_index=63, score=0.00353023293428123)\nPoint(token_index=14, time_index=64, score=1.0)\nPoint(token_index=14, time_index=65, score=1.0)\nPoint(token_index=14, time_index=66, score=0.9999915361404419)\nPoint(token_index=15, time_index=67, score=0.9971516132354736)\nPoint(token_index=15, time_index=68, score=0.9999990463256836)\nPoint(token_index=15, time_index=69, score=0.9999992847442627)\nPoint(token_index=15, time_index=70, score=0.9999997615814209)\nPoint(token_index=15, time_index=71, score=0.9999998807907104)\nPoint(token_index=15, time_index=72, score=0.9999880790710449)\nPoint(token_index=15, time_index=73, score=0.011415631510317326)\nPoint(token_index=15, time_index=74, score=0.9999977350234985)\nPoint(token_index=16, time_index=75, score=0.9996123909950256)\nPoint(token_index=16, time_index=76, score=0.999998927116394)\nPoint(token_index=16, time_index=77, score=0.9729099869728088)\nPoint(token_index=16, time_index=78, score=0.999998927116394)\nPoint(token_index=17, time_index=79, score=0.9949352145195007)\nPoint(token_index=17, time_index=80, score=0.999998927116394)\nPoint(token_index=17, time_index=81, score=0.9999123811721802)\nPoint(token_index=17, time_index=82, score=0.9999774694442749)\nPoint(token_index=18, time_index=83, score=0.6568986177444458)\nPoint(token_index=18, time_index=84, score=0.9984309077262878)\nPoint(token_index=18, time_index=85, score=0.9999876022338867)\nPoint(token_index=19, time_index=86, score=0.9993754029273987)\nPoint(token_index=19, time_index=87, score=0.9999988079071045)\nPoint(token_index=19, time_index=88, score=0.10457336902618408)\nPoint(token_index=19, time_index=89, score=0.9999969005584717)\nPoint(token_index=20, time_index=90, score=0.39713507890701294)\nPoint(token_index=20, time_index=91, score=0.9999932050704956)\nPoint(token_index=21, time_index=92, score=1.69728946275427e-06)\nPoint(token_index=21, time_index=93, score=0.9861241579055786)\nPoint(token_index=21, time_index=94, score=0.9999960660934448)\nPoint(token_index=22, time_index=95, score=0.9992733597755432)\nPoint(token_index=22, time_index=96, score=0.9993415474891663)\nPoint(token_index=22, time_index=97, score=0.9999983310699463)\nPoint(token_index=23, time_index=98, score=0.9999971389770508)\nPoint(token_index=23, time_index=99, score=0.9999998807907104)\nPoint(token_index=23, time_index=100, score=0.9999995231628418)\nPoint(token_index=23, time_index=101, score=0.9999732971191406)\nPoint(token_index=24, time_index=102, score=0.9983206391334534)\nPoint(token_index=24, time_index=103, score=0.9999991655349731)\nPoint(token_index=24, time_index=104, score=0.9999996423721313)\nPoint(token_index=24, time_index=105, score=0.9999998807907104)\nPoint(token_index=24, time_index=106, score=1.0)\nPoint(token_index=24, time_index=107, score=0.9998623132705688)\nPoint(token_index=24, time_index=108, score=0.9999980926513672)\nPoint(token_index=25, time_index=109, score=0.9988552331924438)\nPoint(token_index=25, time_index=110, score=0.9999798536300659)\nPoint(token_index=26, time_index=111, score=0.8575102090835571)\nPoint(token_index=26, time_index=112, score=0.9999847412109375)\nPoint(token_index=27, time_index=113, score=0.9870213866233826)\nPoint(token_index=27, time_index=114, score=1.8971080862684175e-05)\nPoint(token_index=27, time_index=115, score=0.9999794960021973)\nPoint(token_index=28, time_index=116, score=0.9998254179954529)\nPoint(token_index=28, time_index=117, score=0.9999990463256836)\nPoint(token_index=29, time_index=118, score=0.9999732971191406)\nPoint(token_index=29, time_index=119, score=0.0009179709595628083)\nPoint(token_index=29, time_index=120, score=0.9993636012077332)\nPoint(token_index=30, time_index=121, score=0.9975398778915405)\nPoint(token_index=30, time_index=122, score=0.0003043622418772429)\nPoint(token_index=30, time_index=123, score=0.9999344348907471)\nPoint(token_index=31, time_index=124, score=6.090586339269066e-06)\nPoint(token_index=31, time_index=125, score=0.9833256006240845)\nPoint(token_index=32, time_index=126, score=0.9974588751792908)\nPoint(token_index=33, time_index=127, score=0.0008251128601841629)\nPoint(token_index=33, time_index=128, score=0.9965149164199829)\nPoint(token_index=34, time_index=129, score=0.017433946952223778)\nPoint(token_index=34, time_index=130, score=0.9989169836044312)\nPoint(token_index=35, time_index=131, score=0.9999697208404541)\nPoint(token_index=36, time_index=132, score=0.9999842643737793)\nPoint(token_index=36, time_index=133, score=0.9997639060020447)\nPoint(token_index=37, time_index=134, score=0.5118544101715088)\nPoint(token_index=37, time_index=135, score=0.9998302459716797)\nPoint(token_index=38, time_index=136, score=0.0852130874991417)\nPoint(token_index=38, time_index=137, score=0.004070050548762083)\nPoint(token_index=38, time_index=138, score=0.9999815225601196)\nPoint(token_index=39, time_index=139, score=0.012034581042826176)\nPoint(token_index=39, time_index=140, score=0.9999980926513672)\nPoint(token_index=39, time_index=141, score=0.0005822110688313842)\nPoint(token_index=39, time_index=142, score=0.9999072551727295)\nPoint(token_index=40, time_index=143, score=0.9999960660934448)\nPoint(token_index=40, time_index=144, score=0.9999980926513672)\nPoint(token_index=40, time_index=145, score=0.9999916553497314)\nPoint(token_index=41, time_index=146, score=0.9971168041229248)\nPoint(token_index=41, time_index=147, score=0.9981781244277954)\nPoint(token_index=41, time_index=148, score=0.9999310970306396)\nPoint(token_index=42, time_index=149, score=0.9879370331764221)\nPoint(token_index=42, time_index=150, score=0.9997633099555969)\nPoint(token_index=42, time_index=151, score=0.9999535083770752)\nPoint(token_index=43, time_index=152, score=0.9999715089797974)\nPoint(token_index=44, time_index=153, score=0.31822556257247925)\nPoint(token_index=44, time_index=154, score=0.999782145023346)\nPoint(token_index=45, time_index=155, score=0.01603216677904129)\nPoint(token_index=45, time_index=156, score=0.999901294708252)\nPoint(token_index=46, time_index=157, score=0.46628203988075256)\nPoint(token_index=46, time_index=158, score=0.9999994039535522)\nPoint(token_index=46, time_index=159, score=0.9999996423721313)\nPoint(token_index=46, time_index=160, score=0.9999995231628418)\nPoint(token_index=46, time_index=161, score=0.9999996423721313)\nPoint(token_index=46, time_index=162, score=0.9999996423721313)\nPoint(token_index=46, time_index=163, score=0.9999996423721313)\nPoint(token_index=46, time_index=164, score=0.9999995231628418)\nPoint(token_index=46, time_index=165, score=0.9999995231628418)\nPoint(token_index=46, time_index=166, score=0.9999996423721313)\nPoint(token_index=46, time_index=167, score=0.9999996423721313)\nPoint(token_index=46, time_index=168, score=0.9999995231628418) \n```", "```py\ndef plot_trellis_with_path([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n    # To plot trellis with path, we take advantage of 'nan' value\n    trellis_with_path = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").clone()\n    for _, p in enumerate([path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        trellis_with_path[[p.time_index](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), [p.token_index](https://docs.python.org/3/library/functions.html#int \"builtins.int\")] = float(\"nan\")\n    plt.imshow(trellis_with_path.T, origin=\"lower\")\n    plt.title(\"The path found by backtracking\")\n    plt.tight_layout()\n\nplot_trellis_with_path([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) \n```", "```py\n# Merge the labels\n@dataclass\nclass Segment:\n    label: str\n    start: int\n    end: int\n    score: float\n\n    def __repr__(self):\n        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n\n    @property\n    def length(self):\n        return self.end - self.start\n\ndef merge_repeats([path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n    i1, i2 = 0, 0\n    [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = []\n    while i1 < len([path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        while i2 < len([path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) and [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i1].token_index == [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i2].token_index:\n            i2 += 1\n        score = sum([path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[k].score for k in range(i1, i2)) / (i2 - i1)\n        [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\").append(\n            Segment(\n                [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")[[path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i1].token_index],\n                [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i1].time_index,\n                [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i2 - 1].time_index + 1,\n                score,\n            )\n        )\n        i1 = i2\n    return [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")\n\n[segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = merge_repeats([path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\nfor seg in [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    print(seg) \n```", "```py\n|       (1.00): [    0,    31)\nI       (0.78): [   31,    35)\n|       (0.80): [   35,    37)\nH       (1.00): [   37,    39)\nA       (0.96): [   39,    41)\nD       (0.65): [   41,    44)\n|       (1.00): [   44,    45)\nT       (0.55): [   45,    47)\nH       (1.00): [   47,    49)\nA       (0.03): [   49,    52)\nT       (1.00): [   52,    53)\n|       (1.00): [   53,    56)\nC       (0.97): [   56,    61)\nU       (1.00): [   61,    63)\nR       (0.75): [   63,    67)\nI       (0.88): [   67,    75)\nO       (0.99): [   75,    79)\nS       (1.00): [   79,    83)\nI       (0.89): [   83,    86)\nT       (0.78): [   86,    90)\nY       (0.70): [   90,    92)\n|       (0.66): [   92,    95)\nB       (1.00): [   95,    98)\nE       (1.00): [   98,   102)\nS       (1.00): [  102,   109)\nI       (1.00): [  109,   111)\nD       (0.93): [  111,   113)\nE       (0.66): [  113,   116)\n|       (1.00): [  116,   118)\nM       (0.67): [  118,   121)\nE       (0.67): [  121,   124)\n|       (0.49): [  124,   126)\nA       (1.00): [  126,   127)\nT       (0.50): [  127,   129)\n|       (0.51): [  129,   131)\nT       (1.00): [  131,   132)\nH       (1.00): [  132,   134)\nI       (0.76): [  134,   136)\nS       (0.36): [  136,   139)\n|       (0.50): [  139,   143)\nM       (1.00): [  143,   146)\nO       (1.00): [  146,   149)\nM       (1.00): [  149,   152)\nE       (1.00): [  152,   153)\nN       (0.66): [  153,   155)\nT       (0.51): [  155,   157)\n|       (0.96): [  157,   169) \n```", "```py\ndef plot_trellis_with_segments([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")):\n    # To plot trellis with path, we take advantage of 'nan' value\n    trellis_with_path = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").clone()\n    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") != \"|\":\n            trellis_with_path[[seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") : [seg.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), i] = float(\"nan\")\n\n    fig, [ax1, ax2] = plt.subplots(2, 1, sharex=True)\n    ax1.set_title(\"Path, label and probability for each label\")\n    ax1.imshow(trellis_with_path.T, origin=\"lower\", aspect=\"auto\")\n\n    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") != \"|\":\n            ax1.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), ([seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), i - 0.7), size=\"small\")\n            ax1.annotate(f\"{[seg.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"):.2f}\", ([seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), i + 3), size=\"small\")\n\n    ax2.set_title(\"Label probability with and without repetation\")\n    xs, hs, ws = [], [], []\n    for seg in [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") != \"|\":\n            xs.append(([seg.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\") + [seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) / 2 + 0.4)\n            hs.append([seg.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"))\n            ws.append([seg.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\") - [seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"))\n            ax2.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), ([seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") + 0.8, -0.07))\n    ax2.bar(xs, hs, width=ws, color=\"gray\", alpha=0.5, edgecolor=\"black\")\n\n    xs, hs = [], []\n    for p in [path](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n        label = [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")[[p.token_index](https://docs.python.org/3/library/functions.html#int \"builtins.int\")]\n        if label != \"|\":\n            xs.append([p.time_index](https://docs.python.org/3/library/functions.html#int \"builtins.int\") + 1)\n            hs.append([p.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"))\n\n    ax2.bar(xs, hs, width=0.5, alpha=0.5)\n    ax2.axhline(0, color=\"black\")\n    ax2.grid(True, axis=\"y\")\n    ax2.set_ylim(-0.1, 1.1)\n    fig.tight_layout()\n\nplot_trellis_with_segments([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n# Merge words\ndef merge_words([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), separator=\"|\"):\n    words = []\n    i1, i2 = 0, 0\n    while i1 < len([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        if i2 >= len([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) or [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i2].label == separator:\n            if i1 != i2:\n                segs = [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i1:i2]\n                word = \"\".join([[seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") for seg in segs])\n                score = sum([seg.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") * seg.length for seg in segs) / sum(seg.length for seg in segs)\n                words.append(Segment(word, [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i1].start, [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i2 - 1].end, score))\n            i1 = i2 + 1\n            i2 = i1\n        else:\n            i2 += 1\n    return words\n\n[word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = merge_words([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\nfor word in [word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    print(word) \n```", "```py\nI       (0.78): [   31,    35)\nHAD     (0.84): [   37,    44)\nTHAT    (0.52): [   45,    53)\nCURIOSITY       (0.89): [   56,    92)\nBESIDE  (0.94): [   95,   116)\nME      (0.67): [  118,   124)\nAT      (0.66): [  126,   129)\nTHIS    (0.70): [  131,   139)\nMOMENT  (0.88): [  143,   157) \n```", "```py\ndef plot_alignments([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), sample_rate=bundle.sample_rate):\n    trellis_with_path = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").clone()\n    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") != \"|\":\n            trellis_with_path[[seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") : [seg.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), i] = float(\"nan\")\n\n    fig, [ax1, ax2] = plt.subplots(2, 1)\n\n    ax1.imshow(trellis_with_path.T, origin=\"lower\", aspect=\"auto\")\n    ax1.set_facecolor(\"lightgray\")\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n\n    for word in [word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n        ax1.axvspan([word.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") - 0.5, [word.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\") - 0.5, edgecolor=\"white\", facecolor=\"none\")\n\n    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") != \"|\":\n            ax1.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), ([seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), i - 0.7), size=\"small\")\n            ax1.annotate(f\"{[seg.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"):.2f}\", ([seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), i + 3), size=\"small\")\n\n    # The original waveform\n    ratio = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0) / sample_rate / [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0)\n    ax2.specgram([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), Fs=sample_rate)\n    for word in [word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n        x0 = ratio * [word.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n        x1 = ratio * [word.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n        ax2.axvspan(x0, x1, facecolor=\"none\", edgecolor=\"white\", hatch=\"/\")\n        ax2.annotate(f\"{[word.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"):.2f}\", (x0, sample_rate * 0.51), annotation_clip=False)\n\n    for seg in [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") != \"|\":\n            ax2.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"), ([seg.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") * ratio, sample_rate * 0.55), annotation_clip=False)\n    ax2.set_xlabel(\"time [second]\")\n    ax2.set_yticks([])\n    fig.tight_layout()\n\nplot_alignments(\n    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"),\n    [segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"),\n    [word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"),\n    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0],\n) \n```", "```py\ndef display_segment(i):\n    ratio = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) / [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0)\n    word = [word_segments](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[i]\n    x0 = int(ratio * [word.start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"))\n    x1 = int(ratio * [word.end](https://docs.python.org/3/library/functions.html#int \"builtins.int\"))\n    print(f\"{[word.label](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")} ({[word.score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"):.2f}): {x0  /  bundle.sample_rate:.3f} - {x1  /  bundle.sample_rate:.3f} sec\")\n    segment = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[:, x0:x1]\n    return IPython.display.Audio(segment.numpy(), rate=bundle.sample_rate) \n```", "```py\n# Generate the audio for each segment\nprint([transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\nIPython.display.Audio([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n|I|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT| \n```", "```py\ndisplay_segment(0) \n```", "```py\nI (0.78): 0.624 - 0.704 sec \n```", "```py\ndisplay_segment(1) \n```", "```py\nHAD (0.84): 0.744 - 0.885 sec \n```", "```py\ndisplay_segment(2) \n```", "```py\nTHAT (0.52): 0.905 - 1.066 sec \n```", "```py\ndisplay_segment(3) \n```", "```py\nCURIOSITY (0.89): 1.127 - 1.851 sec \n```", "```py\ndisplay_segment(4) \n```", "```py\nBESIDE (0.94): 1.911 - 2.334 sec \n```", "```py\ndisplay_segment(5) \n```", "```py\nME (0.67): 2.374 - 2.495 sec \n```", "```py\ndisplay_segment(6) \n```", "```py\nAT (0.66): 2.535 - 2.595 sec \n```", "```py\ndisplay_segment(7) \n```", "```py\nTHIS (0.70): 2.635 - 2.796 sec \n```", "```py\ndisplay_segment(8) \n```", "```py\nMOMENT (0.88): 2.877 - 3.159 sec \n```"]