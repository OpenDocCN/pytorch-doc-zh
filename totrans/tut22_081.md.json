["```py\n# If you need e.g. CUDA 9.0 support, please replace \"cpu\" with \"cu90\" in the URL below.\nwget  https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip\nunzip  libtorch-shared-with-deps-latest.zip \n```", "```py\n#include  <torch/torch.h>\n#include  <iostream>\n\nint  main()  {\n  torch::Tensor  tensor  =  torch::eye(3);\n  std::cout  <<  tensor  <<  std::endl;\n} \n```", "```py\ncmake_minimum_required(VERSION  3.0  FATAL_ERROR)\nproject(dcgan)\n\nfind_package(Torch  REQUIRED)\n\nadd_executable(dcgan  dcgan.cpp)\ntarget_link_libraries(dcgan  \"${TORCH_LIBRARIES}\")\nset_property(TARGET  dcgan  PROPERTY  CXX_STANDARD  14) \n```", "```py\ndcgan/\n  CMakeLists.txt\n  dcgan.cpp \n```", "```py\nroot@fa350df05ecf:/home#  mkdir  build\nroot@fa350df05ecf:/home#  cd  build\nroot@fa350df05ecf:/home/build#  cmake  -DCMAKE_PREFIX_PATH=/path/to/libtorch  ..\n--  The  C  compiler  identification  is  GNU  5.4.0\n--  The  CXX  compiler  identification  is  GNU  5.4.0\n--  Check  for  working  C  compiler:  /usr/bin/cc\n--  Check  for  working  C  compiler:  /usr/bin/cc  --  works\n--  Detecting  C  compiler  ABI  info\n--  Detecting  C  compiler  ABI  info  -  done\n--  Detecting  C  compile  features\n--  Detecting  C  compile  features  -  done\n--  Check  for  working  CXX  compiler:  /usr/bin/c++\n--  Check  for  working  CXX  compiler:  /usr/bin/c++  --  works\n--  Detecting  CXX  compiler  ABI  info\n--  Detecting  CXX  compiler  ABI  info  -  done\n--  Detecting  CXX  compile  features\n--  Detecting  CXX  compile  features  -  done\n--  Looking  for  pthread.h\n--  Looking  for  pthread.h  -  found\n--  Looking  for  pthread_create\n--  Looking  for  pthread_create  -  not  found\n--  Looking  for  pthread_create  in  pthreads\n--  Looking  for  pthread_create  in  pthreads  -  not  found\n--  Looking  for  pthread_create  in  pthread\n--  Looking  for  pthread_create  in  pthread  -  found\n--  Found  Threads:  TRUE\n--  Found  torch:  /path/to/libtorch/lib/libtorch.so\n--  Configuring  done\n--  Generating  done\n--  Build  files  have  been  written  to:  /home/build\nroot@fa350df05ecf:/home/build#  cmake  --build  .  --config  Release\nScanning  dependencies  of  target  dcgan\n[  50%]  Building  CXX  object  CMakeFiles/dcgan.dir/dcgan.cpp.o\n[100%]  Linking  CXX  executable  dcgan\n[100%]  Built  target  dcgan \n```", "```py\nroot@fa350df05ecf:/home/build#  ./dcgan\n1  0  0\n0  1  0\n0  0  1\n[  Variable[CPUFloatType]{3,3}  ] \n```", "```py\nimport torch\n\nclass Net(torch.nn.Module):\n  def __init__(self, N, M):\n    super(Net, self).__init__()\n    self.W = torch.nn.Parameter(torch.randn(N, M))\n    self.b = torch.nn.Parameter(torch.randn(M))\n\n  def forward(self, input):\n    return torch.addmm(self.b, input, self.W) \n```", "```py\n#include  <torch/torch.h>\n\nstruct  Net  :  torch::nn::Module  {\n  Net(int64_t  N,  int64_t  M)  {\n  W  =  register_parameter(\"W\",  torch::randn({N,  M}));\n  b  =  register_parameter(\"b\",  torch::randn(M));\n  }\n  torch::Tensor  forward(torch::Tensor  input)  {\n  return  torch::addmm(b,  input,  W);\n  }\n  torch::Tensor  W,  b;\n}; \n```", "```py\nclass Net(torch.nn.Module):\n  def __init__(self, N, M):\n      super(Net, self).__init__()\n      # Registered as a submodule behind the scenes\n      self.linear = torch.nn.Linear(N, M)\n      self.another_bias = torch.nn.Parameter(torch.rand(M))\n\n  def forward(self, input):\n    return self.linear(input) + self.another_bias \n```", "```py\n>>> net = Net(4, 5)\n>>> print(list(net.parameters()))\n[Parameter containing:\ntensor([0.0808, 0.8613, 0.2017, 0.5206, 0.5353], requires_grad=True), Parameter containing:\ntensor([[-0.3740, -0.0976, -0.4786, -0.4928],\n [-0.1434,  0.4713,  0.1735, -0.3293],\n [-0.3467, -0.3858,  0.1980,  0.1986],\n [-0.1975,  0.4278, -0.1831, -0.2709],\n [ 0.3730,  0.4307,  0.3236, -0.0629]], requires_grad=True), Parameter containing:\ntensor([ 0.2038,  0.4638, -0.2023,  0.1230, -0.0516], requires_grad=True)] \n```", "```py\nstruct  Net  :  torch::nn::Module  {\n  Net(int64_t  N,  int64_t  M)\n  :  linear(register_module(\"linear\",  torch::nn::Linear(N,  M)))  {\n  another_bias  =  register_parameter(\"b\",  torch::randn(M));\n  }\n  torch::Tensor  forward(torch::Tensor  input)  {\n  return  linear(input)  +  another_bias;\n  }\n  torch::nn::Linear  linear;\n  torch::Tensor  another_bias;\n}; \n```", "```py\nint  main()  {\n  Net  net(4,  5);\n  for  (const  auto&  p  :  net.parameters())  {\n  std::cout  <<  p  <<  std::endl;\n  }\n} \n```", "```py\nroot@fa350df05ecf:/home/build#  ./dcgan\n0.0345\n1.4456\n-0.6313\n-0.3585\n-0.4008\n[  Variable[CPUFloatType]{5}  ]\n-0.1647  0.2891  0.0527  -0.0354\n0.3084  0.2025  0.0343  0.1824\n-0.4630  -0.2862  0.2500  -0.0420\n0.3679  -0.1482  -0.0460  0.1967\n0.2132  -0.1992  0.4257  0.0739\n[  Variable[CPUFloatType]{5,4}  ]\n0.01  *\n3.6861\n-10.1166\n-45.0333\n7.9983\n-20.0705\n[  Variable[CPUFloatType]{5}  ] \n```", "```py\nNet  net(4,  5);\nfor  (const  auto&  pair  :  net.named_parameters())  {\n  std::cout  <<  pair.key()  <<  \": \"  <<  pair.value()  <<  std::endl;\n} \n```", "```py\nroot@fa350df05ecf:/home/build#  make  &&  ./dcgan  11:13:48\nScanning  dependencies  of  target  dcgan\n[  50%]  Building  CXX  object  CMakeFiles/dcgan.dir/dcgan.cpp.o\n[100%]  Linking  CXX  executable  dcgan\n[100%]  Built  target  dcgan\nb:  -0.1863\n-0.8611\n-0.1228\n1.3269\n0.9858\n[  Variable[CPUFloatType]{5}  ]\nlinear.weight:  0.0339  0.2484  0.2035  -0.2103\n-0.0715  -0.2975  -0.4350  -0.1878\n-0.3616  0.1050  -0.4982  0.0335\n-0.1605  0.4963  0.4099  -0.2883\n0.1818  -0.3447  -0.1501  -0.0215\n[  Variable[CPUFloatType]{5,4}  ]\nlinear.bias:  -0.0250\n0.0408\n0.3756\n-0.2149\n-0.3636\n[  Variable[CPUFloatType]{5}  ] \n```", "```py\nint  main()  {\n  Net  net(4,  5);\n  std::cout  <<  net.forward(torch::ones({2,  4}))  <<  std::endl;\n} \n```", "```py\nroot@fa350df05ecf:/home/build#  ./dcgan\n0.8559  1.1572  2.1069  -0.1247  0.8060\n0.8559  1.1572  2.1069  -0.1247  0.8060\n[  Variable[CPUFloatType]{2,5}  ] \n```", "```py\nstruct  Net  :  torch::nn::Module  {  };\n\nvoid  a(Net  net)  {  }\nvoid  b(Net&  net)  {  }\nvoid  c(Net*  net)  {  }\n\nint  main()  {\n  Net  net;\n  a(net);\n  a(std::move(net));\n  b(net);\n  c(&net);\n} \n```", "```py\nstruct  Net  :  torch::nn::Module  {};\n\nvoid  a(std::shared_ptr<Net>  net)  {  }\n\nint  main()  {\n  auto  net  =  std::make_shared<Net>();\n  a(net);\n} \n```", "```py\nstruct  Net  :  torch::nn::Module  {\n  Net(int64_t  N,  int64_t  M)\n  :  linear(register_module(\"linear\",  torch::nn::Linear(N,  M)))\n  {  }\n  torch::nn::Linear  linear;\n}; \n```", "```py\nstruct  LinearImpl  :  torch::nn::Module  {\n  LinearImpl(int64_t  in,  int64_t  out);\n\n  Tensor  forward(const  Tensor&  input);\n\n  Tensor  weight,  bias;\n};\n\nTORCH_MODULE(Linear); \n```", "```py\nstruct  NetImpl  :  torch::nn::Module  {};\nTORCH_MODULE(Net);\n\nvoid  a(Net  net)  {  }\n\nint  main()  {\n  Net  net;\n  a(net);\n} \n```", "```py\nstruct  Net  :  torch::nn::Module  {\n  Net(int64_t  N,  int64_t  M)\n  :  linear(register_module(\"linear\",  torch::nn::Linear(N,  M)))\n  {  }\n  torch::nn::Linear  linear;\n}; \n```", "```py\nstruct  Net  :  torch::nn::Module  {\n  Net(int64_t  N,  int64_t  M)  {\n  linear  =  register_module(\"linear\",  torch::nn::Linear(N,  M));\n  }\n  torch::nn::Linear  linear{nullptr};  // construct an empty holder\n}; \n```", "```py\nstruct  DCGANGeneratorImpl  :  nn::Module  {\n  DCGANGeneratorImpl(int  kNoiseSize)\n  :  conv1(nn::ConvTranspose2dOptions(kNoiseSize,  256,  4)\n  .bias(false)),\n  batch_norm1(256),\n  conv2(nn::ConvTranspose2dOptions(256,  128,  3)\n  .stride(2)\n  .padding(1)\n  .bias(false)),\n  batch_norm2(128),\n  conv3(nn::ConvTranspose2dOptions(128,  64,  4)\n  .stride(2)\n  .padding(1)\n  .bias(false)),\n  batch_norm3(64),\n  conv4(nn::ConvTranspose2dOptions(64,  1,  4)\n  .stride(2)\n  .padding(1)\n  .bias(false))\n  {\n  // register_module() is needed if we want to use the parameters() method later on\n  register_module(\"conv1\",  conv1);\n  register_module(\"conv2\",  conv2);\n  register_module(\"conv3\",  conv3);\n  register_module(\"conv4\",  conv4);\n  register_module(\"batch_norm1\",  batch_norm1);\n  register_module(\"batch_norm2\",  batch_norm2);\n  register_module(\"batch_norm3\",  batch_norm3);\n  }\n\n  torch::Tensor  forward(torch::Tensor  x)  {\n  x  =  torch::relu(batch_norm1(conv1(x)));\n  x  =  torch::relu(batch_norm2(conv2(x)));\n  x  =  torch::relu(batch_norm3(conv3(x)));\n  x  =  torch::tanh(conv4(x));\n  return  x;\n  }\n\n  nn::ConvTranspose2d  conv1,  conv2,  conv3,  conv4;\n  nn::BatchNorm2d  batch_norm1,  batch_norm2,  batch_norm3;\n};\nTORCH_MODULE(DCGANGenerator);\n\nDCGANGenerator  generator(kNoiseSize); \n```", "```py\nnn::Sequential  discriminator(\n  // Layer 1\n  nn::Conv2d(\n  nn::Conv2dOptions(1,  64,  4).stride(2).padding(1).bias(false)),\n  nn::LeakyReLU(nn::LeakyReLUOptions().negative_slope(0.2)),\n  // Layer 2\n  nn::Conv2d(\n  nn::Conv2dOptions(64,  128,  4).stride(2).padding(1).bias(false)),\n  nn::BatchNorm2d(128),\n  nn::LeakyReLU(nn::LeakyReLUOptions().negative_slope(0.2)),\n  // Layer 3\n  nn::Conv2d(\n  nn::Conv2dOptions(128,  256,  4).stride(2).padding(1).bias(false)),\n  nn::BatchNorm2d(256),\n  nn::LeakyReLU(nn::LeakyReLUOptions().negative_slope(0.2)),\n  // Layer 4\n  nn::Conv2d(\n  nn::Conv2dOptions(256,  1,  3).stride(1).padding(0).bias(false)),\n  nn::Sigmoid()); \n```", "```py\nauto  dataset  =  torch::data::datasets::MNIST(\"./mnist\")\n  .map(torch::data::transforms::Normalize<>(0.5,  0.5))\n  .map(torch::data::transforms::Stack<>()); \n```", "```py\nauto  data_loader  =  torch::data::make_data_loader(std::move(dataset)); \n```", "```py\nauto  data_loader  =  torch::data::make_data_loader(\n  std::move(dataset),\n  torch::data::DataLoaderOptions().batch_size(kBatchSize).workers(2)); \n```", "```py\nfor  (torch::data::Example<>&  batch  :  *data_loader)  {\n  std::cout  <<  \"Batch size: \"  <<  batch.data.size(0)  <<  \" | Labels: \";\n  for  (int64_t  i  =  0;  i  <  batch.data.size(0);  ++i)  {\n  std::cout  <<  batch.target[i].item<int64_t>()  <<  \" \";\n  }\n  std::cout  <<  std::endl;\n} \n```", "```py\nroot@fa350df05ecf:/home/build#  make\nScanning  dependencies  of  target  dcgan\n[  50%]  Building  CXX  object  CMakeFiles/dcgan.dir/dcgan.cpp.o\n[100%]  Linking  CXX  executable  dcgan\n[100%]  Built  target  dcgan\nroot@fa350df05ecf:/home/build#  make\n[100%]  Built  target  dcgan\nroot@fa350df05ecf:/home/build#  ./dcgan\nBatch  size:  64  |  Labels:  5  2  6  7  2  1  6  7  0  1  6  2  3  6  9  1  8  4  0  6  5  3  3  0  4  6  6  6  4  0  8  6  0  6  9  2  4  0  2  8  6  3  3  2  9  2  0  1  4  2  3  4  8  2  9  9  3  5  8  0  0  7  9  9\nBatch  size:  64  |  Labels:  2  2  4  7  1  2  8  8  6  9  0  2  2  9  3  6  1  3  8  0  4  4  8  8  8  9  2  6  4  7  1  5  0  9  7  5  4  3  5  4  1  2  8  0  7  1  9  6  1  6  5  3  4  4  1  2  3  2  3  5  0  1  6  2\nBatch  size:  64  |  Labels:  4  5  4  2  1  4  8  3  8  3  6  1  5  4  3  6  2  2  5  1  3  1  5  0  8  2  1  5  3  2  4  4  5  9  7  2  8  9  2  0  6  7  4  3  8  3  5  8  8  3  0  5  8  0  8  7  8  5  5  6  1  7  8  0\nBatch  size:  64  |  Labels:  3  3  7  1  4  1  6  1  0  3  6  4  0  2  5  4  0  4  2  8  1  9  6  5  1  6  3  2  8  9  2  3  8  7  4  5  9  6  0  8  3  0  0  6  4  8  2  5  4  1  8  3  7  8  0  0  8  9  6  7  2  1  4  7\nBatch  size:  64  |  Labels:  3  0  5  5  9  8  3  9  8  9  5  9  5  0  4  1  2  7  7  2  0  0  5  4  8  7  7  6  1  0  7  9  3  0  6  3  2  6  2  7  6  3  3  4  0  5  8  8  9  1  9  2  1  9  4  4  9  2  4  6  2  9  4  0\nBatch  size:  64  |  Labels:  9  6  7  5  3  5  9  0  8  6  6  7  8  2  1  9  8  8  1  1  8  2  0  7  1  4  1  6  7  5  1  7  7  4  0  3  2  9  0  6  6  3  4  4  8  1  2  8  6  9  2  0  3  1  2  8  5  6  4  8  5  8  6  2\nBatch  size:  64  |  Labels:  9  3  0  3  6  5  1  8  6  0  1  9  9  1  6  1  7  7  4  4  4  7  8  8  6  7  8  2  6  0  4  6  8  2  5  3  9  8  4  0  9  9  3  7  0  5  8  2  4  5  6  2  8  2  5  3  7  1  9  1  8  2  2  7\nBatch  size:  64  |  Labels:  9  1  9  2  7  2  6  0  8  6  8  7  7  4  8  6  1  1  6  8  5  7  9  1  3  2  0  5  1  7  3  1  6  1  0  8  6  0  8  1  0  5  4  9  3  8  5  8  4  8  0  1  2  6  2  4  2  7  7  3  7  4  5  3\nBatch  size:  64  |  Labels:  8  8  3  1  8  6  4  2  9  5  8  0  2  8  6  6  7  0  9  8  3  8  7  1  6  6  2  7  7  4  5  5  2  1  7  9  5  4  9  1  0  3  1  9  3  9  8  8  5  3  7  5  3  6  8  9  4  2  0  1  2  5  4  7\nBatch  size:  64  |  Labels:  9  2  7  0  8  4  4  2  7  5  0  0  6  2  0  5  9  5  9  8  8  9  3  5  7  5  4  7  3  0  5  7  6  5  7  1  6  2  8  7  6  3  2  6  5  6  1  2  7  7  0  0  5  9  0  0  9  1  7  8  3  2  9  4\nBatch  size:  64  |  Labels:  7  6  5  7  7  5  2  2  4  9  9  4  8  7  4  8  9  4  5  7  1  2  6  9  8  5  1  2  3  6  7  8  1  1  3  9  8  7  9  5  0  8  5  1  8  7  2  6  5  1  2  0  9  7  4  0  9  0  4  6  0  0  8  6\n... \n```", "```py\ntorch::optim::Adam  generator_optimizer(\n  generator->parameters(),  torch::optim::AdamOptions(2e-4).betas(std::make_tuple(0.5,  0.5)));\ntorch::optim::Adam  discriminator_optimizer(\n  discriminator->parameters(),  torch::optim::AdamOptions(5e-4).betas(std::make_tuple(0.5,  0.5))); \n```", "```py\nfor  (int64_t  epoch  =  1;  epoch  <=  kNumberOfEpochs;  ++epoch)  {\n  int64_t  batch_index  =  0;\n  for  (torch::data::Example<>&  batch  :  *data_loader)  {\n  // Train discriminator with real images.\n  discriminator->zero_grad();\n  torch::Tensor  real_images  =  batch.data;\n  torch::Tensor  real_labels  =  torch::empty(batch.data.size(0)).uniform_(0.8,  1.0);\n  torch::Tensor  real_output  =  discriminator->forward(real_images);\n  torch::Tensor  d_loss_real  =  torch::binary_cross_entropy(real_output,  real_labels);\n  d_loss_real.backward();\n\n  // Train discriminator with fake images.\n  torch::Tensor  noise  =  torch::randn({batch.data.size(0),  kNoiseSize,  1,  1});\n  torch::Tensor  fake_images  =  generator->forward(noise);\n  torch::Tensor  fake_labels  =  torch::zeros(batch.data.size(0));\n  torch::Tensor  fake_output  =  discriminator->forward(fake_images.detach());\n  torch::Tensor  d_loss_fake  =  torch::binary_cross_entropy(fake_output,  fake_labels);\n  d_loss_fake.backward();\n\n  torch::Tensor  d_loss  =  d_loss_real  +  d_loss_fake;\n  discriminator_optimizer.step();\n\n  // Train generator.\n  generator->zero_grad();\n  fake_labels.fill_(1);\n  fake_output  =  discriminator->forward(fake_images);\n  torch::Tensor  g_loss  =  torch::binary_cross_entropy(fake_output,  fake_labels);\n  g_loss.backward();\n  generator_optimizer.step();\n\n  std::printf(\n  \"\\r[%2ld/%2ld][%3ld/%3ld] D_loss: %.4f | G_loss: %.4f\",\n  epoch,\n  kNumberOfEpochs,\n  ++batch_index,\n  batches_per_epoch,\n  d_loss.item<float>(),\n  g_loss.item<float>());\n  }\n} \n```", "```py\nroot@3c0711f20896:/home/build#  make  &&  ./dcgan\nScanning  dependencies  of  target  dcgan\n[  50%]  Building  CXX  object  CMakeFiles/dcgan.dir/dcgan.cpp.o\n[100%]  Linking  CXX  executable  dcgan\n[100%]  Built  target  dcga\n[  1/10][100/938]  D_loss:  0.6876  |  G_loss:  4.1304\n[  1/10][200/938]  D_loss:  0.3776  |  G_loss:  4.3101\n[  1/10][300/938]  D_loss:  0.3652  |  G_loss:  4.6626\n[  1/10][400/938]  D_loss:  0.8057  |  G_loss:  2.2795\n[  1/10][500/938]  D_loss:  0.3531  |  G_loss:  4.4452\n[  1/10][600/938]  D_loss:  0.3501  |  G_loss:  5.0811\n[  1/10][700/938]  D_loss:  0.3581  |  G_loss:  4.5623\n[  1/10][800/938]  D_loss:  0.6423  |  G_loss:  1.7385\n[  1/10][900/938]  D_loss:  0.3592  |  G_loss:  4.7333\n[  2/10][100/938]  D_loss:  0.4660  |  G_loss:  2.5242\n[  2/10][200/938]  D_loss:  0.6364  |  G_loss:  2.0886\n[  2/10][300/938]  D_loss:  0.3717  |  G_loss:  3.8103\n[  2/10][400/938]  D_loss:  1.0201  |  G_loss:  1.3544\n[  2/10][500/938]  D_loss:  0.4522  |  G_loss:  2.6545\n... \n```", "```py\n// Place this somewhere at the top of your training script.\ntorch::Device  device(torch::kCPU); \n```", "```py\ntorch::Tensor  fake_labels  =  torch::zeros(batch.data.size(0)); \n```", "```py\ntorch::Tensor  fake_labels  =  torch::zeros(batch.data.size(0),  device); \n```", "```py\ntorch::Tensor  real_images  =  batch.data; \n```", "```py\ntorch::Tensor  real_images  =  batch.data.to(device); \n```", "```py\ngenerator->to(device);\ndiscriminator->to(device); \n```", "```py\ntorch::Device  device(torch::kCUDA) \n```", "```py\ntorch::Device  device  =  torch::kCPU;\nif  (torch::cuda::is_available())  {\n  std::cout  <<  \"CUDA is available! Training on GPU.\"  <<  std::endl;\n  device  =  torch::kCUDA;\n} \n```", "```py\ntorch::Device  device(torch::cuda::is_available()  ?  torch::kCUDA  :  torch::kCPU); \n```", "```py\nif  (batch_index  %  kCheckpointEvery  ==  0)  {\n  // Checkpoint the model and optimizer state.\n  torch::save(generator,  \"generator-checkpoint.pt\");\n  torch::save(generator_optimizer,  \"generator-optimizer-checkpoint.pt\");\n  torch::save(discriminator,  \"discriminator-checkpoint.pt\");\n  torch::save(discriminator_optimizer,  \"discriminator-optimizer-checkpoint.pt\");\n  // Sample the generator and save the images.\n  torch::Tensor  samples  =  generator->forward(torch::randn({8,  kNoiseSize,  1,  1},  device));\n  torch::save((samples  +  1.0)  /  2.0,  torch::str(\"dcgan-sample-\",  checkpoint_counter,  \".pt\"));\n  std::cout  <<  \"\\n-> checkpoint \"  <<  ++checkpoint_counter  <<  '\\n';\n} \n```", "```py\ntorch::optim::Adam  generator_optimizer(\n  generator->parameters(),  torch::optim::AdamOptions(2e-4).beta1(0.5));\ntorch::optim::Adam  discriminator_optimizer(\n  discriminator->parameters(),  torch::optim::AdamOptions(2e-4).beta1(0.5));\n\nif  (kRestoreFromCheckpoint)  {\n  torch::load(generator,  \"generator-checkpoint.pt\");\n  torch::load(generator_optimizer,  \"generator-optimizer-checkpoint.pt\");\n  torch::load(discriminator,  \"discriminator-checkpoint.pt\");\n  torch::load(\n  discriminator_optimizer,  \"discriminator-optimizer-checkpoint.pt\");\n}\n\nint64_t  checkpoint_counter  =  0;\nfor  (int64_t  epoch  =  1;  epoch  <=  kNumberOfEpochs;  ++epoch)  {\n  int64_t  batch_index  =  0;\n  for  (torch::data::Example<>&  batch  :  *data_loader)  { \n```", "```py\nimport argparse\n\nimport matplotlib.pyplot as plt\nimport torch\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-i\", \"--sample-file\", required=True)\nparser.add_argument(\"-o\", \"--out-file\", default=\"out.png\")\nparser.add_argument(\"-d\", \"--dimension\", type=int, default=3)\noptions = parser.parse_args()\n\nmodule = torch.jit.load(options.sample_file)\nimages = list(module.parameters())[0]\n\nfor index in range(options.dimension * options.dimension):\n  image = images[index].detach().cpu().reshape(28, 28).mul(255).to(torch.uint8)\n  array = image.numpy()\n  axis = plt.subplot(options.dimension, options.dimension, 1 + index)\n  plt.imshow(array, cmap=\"gray\")\n  axis.get_xaxis().set_visible(False)\n  axis.get_yaxis().set_visible(False)\n\nplt.savefig(options.out_file)\nprint(\"Saved \", options.out_file) \n```", "```py\nroot@3c0711f20896:/home/build#  make  &&  ./dcgan  10:17:57\nScanning  dependencies  of  target  dcgan\n[  50%]  Building  CXX  object  CMakeFiles/dcgan.dir/dcgan.cpp.o\n[100%]  Linking  CXX  executable  dcgan\n[100%]  Built  target  dcgan\nCUDA  is  available!  Training  on  GPU.\n[  1/30][200/938]  D_loss:  0.4953  |  G_loss:  4.0195\n->  checkpoint  1\n[  1/30][400/938]  D_loss:  0.3610  |  G_loss:  4.8148\n->  checkpoint  2\n[  1/30][600/938]  D_loss:  0.4072  |  G_loss:  4.36760\n->  checkpoint  3\n[  1/30][800/938]  D_loss:  0.4444  |  G_loss:  4.0250\n->  checkpoint  4\n[  2/30][200/938]  D_loss:  0.3761  |  G_loss:  3.8790\n->  checkpoint  5\n[  2/30][400/938]  D_loss:  0.3977  |  G_loss:  3.3315\n...\n->  checkpoint  120\n[30/30][938/938]  D_loss:  0.3610  |  G_loss:  3.8084 \n```", "```py\nroot@3c0711f20896:/home/build#  python  display.py  -i  dcgan-sample-100.pt\nSaved  out.png \n```"]