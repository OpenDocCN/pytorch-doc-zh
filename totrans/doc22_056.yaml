- en: torch.func
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/docs/stable/func.html](https://pytorch.org/docs/stable/func.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: torch.func, previously known as “functorch”, is [JAX-like](https://github.com/google/jax)
    composable function transforms for PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This library is currently in [beta](https://pytorch.org/blog/pytorch-feature-classification-changes/#beta).
    What this means is that the features generally work (unless otherwise documented)
    and we (the PyTorch team) are committed to bringing this library forward. However,
    the APIs may change under user feedback and we don’t have full coverage over PyTorch
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: If you have suggestions on the API or use-cases you’d like to be covered, please
    open an GitHub issue or reach out. We’d love to hear about how you’re using the
    library.
  prefs: []
  type: TYPE_NORMAL
- en: What are composable function transforms?[](#what-are-composable-function-transforms
    "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A “function transform” is a higher-order function that accepts a numerical function
    and returns a new function that computes a different quantity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`torch.func`](func.api.html#module-torch.func "torch.func") has auto-differentiation
    transforms (`grad(f)` returns a function that computes the gradient of `f`), a
    vectorization/batching transform (`vmap(f)` returns a function that computes `f`
    over batches of inputs), and others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These function transforms can compose with each other arbitrarily. For example,
    composing `vmap(grad(f))` computes a quantity called per-sample-gradients that
    stock PyTorch cannot efficiently compute today.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why composable function transforms?[](#why-composable-function-transforms "Permalink
    to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are a number of use cases that are tricky to do in PyTorch today:'
  prefs: []
  type: TYPE_NORMAL
- en: computing per-sample-gradients (or other per-sample quantities)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: running ensembles of models on a single machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: efficiently batching together tasks in the inner-loop of MAML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: efficiently computing Jacobians and Hessians
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: efficiently computing batched Jacobians and Hessians
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Composing [`vmap()`](generated/torch.func.vmap.html#torch.func.vmap "torch.func.vmap"),
    [`grad()`](generated/torch.func.grad.html#torch.func.grad "torch.func.grad"),
    and [`vjp()`](generated/torch.func.vjp.html#torch.func.vjp "torch.func.vjp") transforms
    allows us to express the above without designing a separate subsystem for each.
    This idea of composable function transforms comes from the [JAX framework](https://github.com/google/jax).
  prefs: []
  type: TYPE_NORMAL
- en: Read More
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[torch.func Whirlwind Tour](func.whirlwind_tour.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is torch.func?](func.whirlwind_tour.html#what-is-torch-func)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why composable function transforms?](func.whirlwind_tour.html#why-composable-function-transforms)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are the transforms?](func.whirlwind_tour.html#what-are-the-transforms)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[torch.func API Reference](func.api.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Function Transforms](func.api.html#function-transforms)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Utilities for working with torch.nn.Modules](func.api.html#utilities-for-working-with-torch-nn-modules)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UX Limitations](func.ux_limitations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[General limitations](func.ux_limitations.html#general-limitations)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[torch.autograd APIs](func.ux_limitations.html#torch-autograd-apis)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[vmap limitations](func.ux_limitations.html#vmap-limitations)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Randomness](func.ux_limitations.html#randomness)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Migrating from functorch to torch.func](func.migrating.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[function transforms](func.migrating.html#function-transforms)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NN module utilities](func.migrating.html#nn-module-utilities)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[functorch.compile](func.migrating.html#functorch-compile)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
