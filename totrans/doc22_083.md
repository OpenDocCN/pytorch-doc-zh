# 基准工具 - torch.utils.benchmark

> [`pytorch.org/docs/stable/benchmark_utils.html`](https://pytorch.org/docs/stable/benchmark_utils.html)

```py
class torch.utils.benchmark.Timer(stmt='pass', setup='pass', global_setup='', timer=<built-in function perf_counter>, globals=None, label=None, sub_label=None, description=None, env=None, num_threads=1, language=Language.PYTHON)¶
```

用于测量 PyTorch 语句执行时间的辅助类。

有关如何使用此类的完整教程，请参见：[`pytorch.org/tutorials/recipes/recipes/benchmark.html`](https://pytorch.org/tutorials/recipes/recipes/benchmark.html)

PyTorch 计时器基于 timeit.Timer（实际上在内部使用 timeit.Timer），但有几个关键区别：

1.  运行时感知:

    计时器将执行预热（因为 PyTorch 的某些元素是惰性初始化的），设置线程池大小以便进行苹果对苹果的比较，并在必要时同步异步 CUDA 函数。

1.  专注于复制品：

    在测量代码时，特别是复杂的内核/模型时，运行到运行的变化是一个重要的混淆因素。预计所有测量都应包括复制品以量化噪声并允许中位数计算，这比平均值更稳健。为此，该类从时间 API 的概念上合并了 timeit.Timer.repeat 和 timeit.Timer.autorange。（确切的算法在方法文档字符串中讨论。）对于不希望使用自适应策略的情况，复制了 timeit 方法。

1.  可选元数据：

    在定义计时器时，可以选择指定标签、子标签、描述和环境。（稍后定义）这些字段包含在结果对象的表示中，并由 Compare 类用于分组和显示比较结果。

1.  指令计数

    除了墙上时间，计时器还可以在 Callgrind 下运行语句并报告执行的指令。

直接类似于 timeit.Timer 构造函数参数：

> stmt、setup、timer、globals

PyTorch 计时器特定的构造函数参数：

> 标签、子标签、描述、环境、线程数

参数

+   **stmt**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")）- 要在循环中运行和计时的代码片段。

+   **设置**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")）- 可选的设置代码。用于定义在 stmt 中使用的变量

+   **全局设置**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")）- （仅限 C++）放置在文件顶层的代码，用于#include 语句等。

+   **计时器**（[*Callable*](https://docs.python.org/3/library/typing.html#typing.Callable "(在 Python v3.12 中)")*[**[**]**,* [*float*](https://docs.python.org/3/library/functions.html#float "(在 Python v3.12 中)")*]*) - 返回当前时间的可调用函数。如果 PyTorch 没有使用 CUDA 构建或没有 GPU 存在，则默认为 timeit.default_timer；否则在测量时间之前将同步 CUDA。

+   **全局**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在 Python v3.12 中)")*[*[*Dict*](https://docs.python.org/3/library/typing.html#typing.Dict "(在 Python v3.12 中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")*,* [*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在 Python v3.12 中)")*]**]*) - 在执行 stmt 时定义全局变量的字典。这是提供 stmt 需要的变量的另一种方法。

+   **标签**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在 Python v3.12 中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")*]*) - 概括 stmt 的字符串。例如，如果 stmt 是“torch.nn.functional.relu(torch.add(x, 1, out=out))”，可以将标签设置为“ReLU(x + 1)”以提高可读性。

+   **子标签**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在 Python v3.12 中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")*]*) - 

    提供额外信息以消除具有相同 stmt 或标签的测量的歧义。例如，在我们上面的示例中，sub_label 可能是“float”或“int”，这样就很容易区分：“ReLU(x + 1): (float)”

    在打印 Measurements 或使用 Compare 进行总结时，“ReLU(x + 1): (int)”。

+   **description**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在 Python v3.12)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12)")*]*) -

    用于区分具有相同标签和 sub_label 的测量的字符串。description 的主要用途是向 Compare 信号数据列。例如，可以基于输入大小设置它以创建以下形式的表：

    ```py
     | n=1 | n=4 | ...
                            ------------- ...
    ReLU(x + 1): (float)    | ... | ... | ...
    ReLU(x + 1): (int)      | ... | ... | ... 
    ```

    使用 Compare。在打印 Measurement 时也包括在内。

+   **env**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在 Python v3.12)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12)")*]*) - 此标记表示在不同环境中运行了相同任务，因此它们不等效，例如在对内核进行 A/B 测试时。当合并复制运行时，Compare 将处理具有不同 env 规范的 Measurements 为不同。

+   **num_threads**（[*int*](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12)")） - 在执行 stmt 时 PyTorch 线程池的大小。单线程性能很重要，既是关键的推理工作负载，也是内在算法效率的良好指标，因此默认设置为 1。这与默认的 PyTorch 线程池大小相反，后者尝试利用所有核心。

```py
adaptive_autorange(threshold=0.1, *, min_run_time=0.01, max_run_time=10.0, callback=None)¶
```

类似于 blocked_autorange，但还检查测量中的变异性，并重复直到 iqr/median 小于阈值或达到 max_run_time。

在高层次上，adaptive_autorange 执行以下伪代码：

```py
`setup`

times = []
while times.sum < max_run_time
    start = timer()
    for _ in range(block_size):
        `stmt`
    times.append(timer() - start)

    enough_data = len(times)>3 and times.sum > min_run_time
    small_iqr=times.iqr/times.mean<threshold

    if enough_data and small_iqr:
        break 
```

参数

+   **threshold**（[*float*](https://docs.python.org/3/library/functions.html#float "(在 Python v3.12)")） - 停止的 iqr/median 阈值的值

+   **min_run_time**（[*float*](https://docs.python.org/3/library/functions.html#float "(在 Python v3.12)")） - 在检查阈值之前所需的总运行时间

+   **max_run_time**（[*float*](https://docs.python.org/3/library/functions.html#float "(在 Python v3.12)")） - 所有测量的总运行时间，无论阈值如何

返回

包含测量运行时间和重复计数的 Measurement 对象，可用于计算统计数据（均值、中位数等）。

返回类型

*Measurement*

```py
blocked_autorange(callback=None, min_run_time=0.2)¶
```

在保持计时器开销最低的情况下测量许多复制品。

在高层次上，blocked_autorange 执行以下伪代码：

```py
`setup`

total_time = 0
while total_time < min_run_time
    start = timer()
    for _ in range(block_size):
        `stmt`
    total_time += (timer() - start) 
```

请注意内部循环中的变量 block_size。块大小的选择对测量质量很重要，必须平衡两个竞争目标：

> 1.  较小的块大小会产生更多的复制品，通常会有更好的统计数据。
> 1.  
> 1.  较大的块大小更好地分摊计时器调用的成本，并导致较少偏倚的测量。这很重要，因为 CUDA 同步时间不容忽视（单个到低双位数微秒的顺序），否则会影响测量结果。

blocked_autorange 通过运行预热期来设置块大小，增加块大小直到计时器开销小于总体计算的 0.1%。然后将此值用于主测量循环。

返回

包含测量运行时间和重复计数的 Measurement 对象，可用于计算统计数据（均值、中位数等）。

返回类型

*Measurement*

```py
collect_callgrind(number: int, *, repeats: None, collect_baseline: bool, retain_out_file: bool) → CallgrindStats¶
```

```py
collect_callgrind(number: int, *, repeats: int, collect_baseline: bool, retain_out_file: bool) → Tuple[CallgrindStats, ...]
```

使用 Callgrind 收集指令计数。

与墙上时间不同，指令计数是确定性的（除了程序本身的非确定性和来自 Python 解释器的少量抖动）。这使它们非常适合进行详细的性能分析。此方法在单独的进程中运行 stmt，以便 Valgrind 可以对程序进行仪器化。由于仪器化，性能会严重下降，但是由于通常少量迭代就足以获得良好的测量结果，这一点得到了改善。

为了使用这种方法，必须安装 valgrind、callgrind_control 和 callgrind_annotate。

由于调用者（此进程）和 stmt 执行之间存在进程边界，全局变量不能包含任意的内存数据结构。（与计时方法不同）相反，全局变量仅限于内置函数、nn.Modules 和 TorchScripted 函数/模块，以减少由于序列化和后续反序列化而引起的意外因素。GlobalsBridge 类提供了更多关于此主题的详细信息。特别注意 nn.Modules：它们依赖 pickle，您可能需要为它们添加一个导入以便正确传输。

默认情况下，将收集并缓存一个空语句的性能分析，以指示有多少指令来自驱动语句的 Python 循环。

返回

一个 CallgrindStats 对象，提供指令计数和一些基本设施用于分析和操作结果。

```py
timeit(number=1000000)¶
```

反映了 timeit.Timer.timeit()的语义。

执行主语句（stmt）的次数。[`docs.python.org/3/library/timeit.html#timeit.Timer.timeit`](https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit)

返回类型

*Measurement*

```py
class torch.utils.benchmark.Measurement(number_per_run, raw_times, task_spec, metadata=None)¶
```

计时器测量的结果。

这个类存储给定语句的一个或多个测量。它是可序列化的，并为下游消费者提供几种便利方法（包括详细的 __repr__）。

```py
static merge(measurements)¶
```

用于合并重复实验的便利方法。

合并将将时间推断为 number_per_run=1，并且不会传输任何元数据。（因为在重复实验之间可能会有差异）

返回类型

[*List*](https://docs.python.org/3/library/typing.html#typing.List "(在 Python v3.12 中)")[*Measurement*]

```py
property significant_figures: int¶
```

近似的显著数字估计。

此属性旨在提供一种方便的方法来估计测量的精度。它仅使用四分位范围来估计统计数据，以尝试减少尾部的偏差，并使用静态 z 值 1.645，因为不希望用于小值 n，所以 z 可以近似于 t。

与 trim_sigfig 方法一起使用的显著数字估计，以提供更易于人类理解的数据摘要。__repr__ 不使用此方法；它只显示原始值。显著数字估计用于 Compare。

```py
class torch.utils.benchmark.CallgrindStats(task_spec, number_per_run, built_with_debug_symbols, baseline_inclusive_stats, baseline_exclusive_stats, stmt_inclusive_stats, stmt_exclusive_stats, stmt_callgrind_out)¶
```

由计时器收集的 Callgrind 结果的顶层容器。

通常使用 FunctionCounts 类进行操作，该类通过调用 CallgrindStats.stats(…)获得。还提供了几种便利方法；最重要的是 CallgrindStats.as_standardized()。

```py
as_standardized()¶
```

从函数字符串中删除库名称和一些前缀。

在比较两组不同的指令计数时，一个障碍可能是路径前缀。Callgrind 在报告函数时包括完整的文件路径（应该如此）。但是，在进行性能分析时，这可能会导致问题。如果两个性能分析中的关键组件（如 Python 或 PyTorch）在不同位置构建，可能会导致类似以下的情况：

```py
23234231 /tmp/first_build_dir/thing.c:foo(...)
 9823794 /tmp/first_build_dir/thing.c:bar(...)
  ...
   53453 .../aten/src/Aten/...:function_that_actually_changed(...)
  ...
 -9823794 /tmp/second_build_dir/thing.c:bar(...)
-23234231 /tmp/second_build_dir/thing.c:foo(...) 
```

通过去除前缀可以改善这个问题，使字符串规范化，并在进行差异比较时更好地取消等效调用点。

返回类型

*CallgrindStats*

```py
counts(*, denoise=False)¶
```

返回执行的指令总数。

查看 FunctionCounts.denoise() 以了解 denoise 参数的解释。

返回类型

[int](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12 中)")

```py
delta(other, inclusive=False)¶
```

比较两组计数。

收集指令计数的一个常见原因是确定某个特定更改对执行某个工作单元所需的指令数量的影响。如果更改增加了该数字，下一个逻辑问题是“为什么”。这通常涉及查看代码的哪个部分增加了指令计数。此函数自动化了该过程，以便可以轻松地在包含和不包含的基础上对计数进行差异。

返回类型

*FunctionCounts*

```py
stats(inclusive=False)¶
```

返回详细的函数计数。

从概念上讲，返回的 FunctionCounts 可以被视为一个元组，其中包含 (计数，路径和函数名称) 元组。

inclusive 匹配 callgrind 的语义。如果为 True，则计数包括子级执行的指令。inclusive=True 用于识别代码中的热点；inclusive=False 用于在比较两次运行的计数时减少噪音。 （有关更多详细信息，请参见 CallgrindStats.delta(…)）

返回类型

*FunctionCounts*

```py
class torch.utils.benchmark.FunctionCounts(_data, inclusive, truncate_rows=True, _linewidth=None)¶
```

用于操作 Callgrind 结果的容器。

它支持：

1.  加法和减法以组合或差异结果。

1.  类似元组索引。

1.  一个去噪函数，用于剥离已知为非确定性且相当嘈杂的 CPython 调用。

1.  两个高阶方法（filter 和 transform）用于自定义操作。

```py
denoise()¶
```

删除已知的嘈杂指令。

CPython 解释器中的几条指令相当嘈杂。这些指令涉及 Python 用于将变量名映射到字典查找的 Unicode。FunctionCounts 通常是一个内容不可知的容器，但这对于获得可靠结果是足够重要的，值得例外。

返回类型

*FunctionCounts*

```py
filter(filter_fn)¶
```

仅保留 filter_fn 应用于函数名称返回 True 的元素。

返回类型

*FunctionCounts*

```py
transform(map_fn)¶
```

将 map_fn 应用于所有函数名称。

这可以用于规范化函数名称（例如剥离文件路径的无关部分），通过将多个函数映射到相同名称来合并条目（在这种情况下，计数将相加），等等。

返回类型

*FunctionCounts*
