# 基准工具 - torch.utils.benchmark

> [https://pytorch.org/docs/stable/benchmark_utils.html](https://pytorch.org/docs/stable/benchmark_utils.html)

```py
class torch.utils.benchmark.Timer(stmt='pass', setup='pass', global_setup='', timer=<built-in function perf_counter>, globals=None, label=None, sub_label=None, description=None, env=None, num_threads=1, language=Language.PYTHON)¶
```

用于测量PyTorch语句执行时间的辅助类。

有关如何使用此类的完整教程，请参见：[https://pytorch.org/tutorials/recipes/recipes/benchmark.html](https://pytorch.org/tutorials/recipes/recipes/benchmark.html)

PyTorch计时器基于timeit.Timer（实际上在内部使用timeit.Timer），但有几个关键区别：

1.  运行时感知:

    计时器将执行预热（因为PyTorch的某些元素是惰性初始化的），设置线程池大小以便进行苹果对苹果的比较，并在必要时同步异步CUDA函数。

1.  专注于复制品：

    在测量代码时，特别是复杂的内核/模型时，运行到运行的变化是一个重要的混淆因素。预计所有测量都应包括复制品以量化噪声并允许中位数计算，这比平均值更稳健。为此，该类从时间API的概念上合并了timeit.Timer.repeat和timeit.Timer.autorange。（确切的算法在方法文档字符串中讨论。）对于不希望使用自适应策略的情况，复制了timeit方法。

1.  可选元数据：

    在定义计时器时，可以选择指定标签、子标签、描述和环境。（稍后定义）这些字段包含在结果对象的表示中，并由Compare类用于分组和显示比较结果。

1.  指令计数

    除了墙上时间，计时器还可以在Callgrind下运行语句并报告执行的指令。

直接类似于timeit.Timer构造函数参数：

> stmt、setup、timer、globals

PyTorch计时器特定的构造函数参数：

> 标签、子标签、描述、环境、线程数

参数

+   **stmt**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)")）- 要在循环中运行和计时的代码片段。

+   **设置**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)")）- 可选的设置代码。用于定义在stmt中使用的变量

+   **全局设置**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)")）- （仅限C++）放置在文件顶层的代码，用于#include语句等。

+   **计时器**（[*Callable*](https://docs.python.org/3/library/typing.html#typing.Callable "(在Python v3.12中)")*[**[**]**,* [*float*](https://docs.python.org/3/library/functions.html#float "(在Python v3.12中)")*]*) - 返回当前时间的可调用函数。如果PyTorch没有使用CUDA构建或没有GPU存在，则默认为timeit.default_timer；否则在测量时间之前将同步CUDA。

+   **全局**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12中)")*[*[*Dict*](https://docs.python.org/3/library/typing.html#typing.Dict "(在Python v3.12中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)")*,* [*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在Python v3.12中)")*]**]*) - 在执行stmt时定义全局变量的字典。这是提供stmt需要的变量的另一种方法。

+   **标签**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)")*]*) - 概括stmt的字符串。例如，如果stmt是“torch.nn.functional.relu(torch.add(x, 1, out=out))”，可以将标签设置为“ReLU(x + 1)”以提高可读性。

+   **子标签**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)")*]*) - 

    提供额外信息以消除具有相同stmt或标签的测量的歧义。例如，在我们上面的示例中，sub_label可能是“float”或“int”，这样就很容易区分：“ReLU(x + 1): (float)”

    在打印Measurements或使用Compare进行总结时，“ReLU(x + 1): (int)”。

+   **description**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12)")*]*) -

    用于区分具有相同标签和sub_label的测量的字符串。description的主要用途是向Compare信号数据列。例如，可以基于输入大小设置它以创建以下形式的表：

    ```py
     | n=1 | n=4 | ...
                            ------------- ...
    ReLU(x + 1): (float)    | ... | ... | ...
    ReLU(x + 1): (int)      | ... | ... | ... 
    ```

    使用Compare。在打印Measurement时也包括在内。

+   **env**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12)")*]*) - 此标记表示在不同环境中运行了相同任务，因此它们不等效，例如在对内核进行A/B测试时。当合并复制运行时，Compare将处理具有不同env规范的Measurements为不同。

+   **num_threads**（[*int*](https://docs.python.org/3/library/functions.html#int "(在Python v3.12)")） - 在执行stmt时PyTorch线程池的大小。单线程性能很重要，既是关键的推理工作负载，也是内在算法效率的良好指标，因此默认设置为1。这与默认的PyTorch线程池大小相反，后者尝试利用所有核心。

```py
adaptive_autorange(threshold=0.1, *, min_run_time=0.01, max_run_time=10.0, callback=None)¶
```

类似于blocked_autorange，但还检查测量中的变异性，并重复直到iqr/median小于阈值或达到max_run_time。

在高层次上，adaptive_autorange执行以下伪代码：

```py
`setup`

times = []
while times.sum < max_run_time
    start = timer()
    for _ in range(block_size):
        `stmt`
    times.append(timer() - start)

    enough_data = len(times)>3 and times.sum > min_run_time
    small_iqr=times.iqr/times.mean<threshold

    if enough_data and small_iqr:
        break 
```

参数

+   **threshold**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python v3.12)")） - 停止的iqr/median阈值的值

+   **min_run_time**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python v3.12)")） - 在检查阈值之前所需的总运行时间

+   **max_run_time**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python v3.12)")） - 所有测量的总运行时间，无论阈值如何

返回

包含测量运行时间和重复计数的Measurement对象，可用于计算统计数据（均值、中位数等）。

返回类型

[*Measurement*](#torch.utils.benchmark.Measurement "torch.utils.benchmark.utils.common.Measurement")

```py
blocked_autorange(callback=None, min_run_time=0.2)¶
```

在保持计时器开销最低的情况下测量许多复制品。

在高层次上，blocked_autorange执行以下伪代码：

```py
`setup`

total_time = 0
while total_time < min_run_time
    start = timer()
    for _ in range(block_size):
        `stmt`
    total_time += (timer() - start) 
```

请注意内部循环中的变量block_size。块大小的选择对测量质量很重要，必须平衡两个竞争目标：

> 1.  较小的块大小会产生更多的复制品，通常会有更好的统计数据。
> 1.  
> 1.  较大的块大小更好地分摊计时器调用的成本，并导致较少偏倚的测量。这很重要，因为CUDA同步时间不容忽视（单个到低双位数微秒的顺序），否则会影响测量结果。

blocked_autorange通过运行预热期来设置块大小，增加块大小直到计时器开销小于总体计算的0.1%。然后将此值用于主测量循环。

返回

包含测量运行时间和重复计数的Measurement对象，可用于计算统计数据（均值、中位数等）。

返回类型

[*Measurement*](#torch.utils.benchmark.Measurement "torch.utils.benchmark.utils.common.Measurement")

```py
collect_callgrind(number: int, *, repeats: None, collect_baseline: bool, retain_out_file: bool) → CallgrindStats¶
```

```py
collect_callgrind(number: int, *, repeats: int, collect_baseline: bool, retain_out_file: bool) → Tuple[CallgrindStats, ...]
```

使用Callgrind收集指令计数。

与墙上时间不同，指令计数是确定性的（除了程序本身的非确定性和来自Python解释器的少量抖动）。这使它们非常适合进行详细的性能分析。此方法在单独的进程中运行stmt，以便Valgrind可以对程序进行仪器化。由于仪器化，性能会严重下降，但是由于通常少量迭代就足以获得良好的测量结果，这一点得到了改善。

为了使用这种方法，必须安装valgrind、callgrind_control和callgrind_annotate。

由于调用者（此进程）和stmt执行之间存在进程边界，全局变量不能包含任意的内存数据结构。（与计时方法不同）相反，全局变量仅限于内置函数、nn.Modules和TorchScripted函数/模块，以减少由于序列化和后续反序列化而引起的意外因素。GlobalsBridge类提供了更多关于此主题的详细信息。特别注意nn.Modules：它们依赖pickle，您可能需要为它们添加一个导入以便正确传输。

默认情况下，将收集并缓存一个空语句的性能分析，以指示有多少指令来自驱动语句的Python循环。

返回

一个CallgrindStats对象，提供指令计数和一些基本设施用于分析和操作结果。

```py
timeit(number=1000000)¶
```

反映了timeit.Timer.timeit()的语义。

执行主语句（stmt）的次数。[https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit](https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit)

返回类型

[*Measurement*](#torch.utils.benchmark.Measurement "torch.utils.benchmark.utils.common.Measurement")

```py
class torch.utils.benchmark.Measurement(number_per_run, raw_times, task_spec, metadata=None)¶
```

计时器测量的结果。

这个类存储给定语句的一个或多个测量。它是可序列化的，并为下游消费者提供几种便利方法（包括详细的__repr__）。

```py
static merge(measurements)¶
```

用于合并重复实验的便利方法。

合并将将时间推断为number_per_run=1，并且不会传输任何元数据。（因为在重复实验之间可能会有差异）

返回类型

[*List*](https://docs.python.org/3/library/typing.html#typing.List "(在Python v3.12中)")[[*Measurement*](#torch.utils.benchmark.Measurement "torch.utils.benchmark.utils.common.Measurement")]

```py
property significant_figures: int¶
```

近似的显著数字估计。

此属性旨在提供一种方便的方法来估计测量的精度。它仅使用四分位范围来估计统计数据，以尝试减少尾部的偏差，并使用静态z值1.645，因为不希望用于小值n，所以z可以近似于t。

与trim_sigfig方法一起使用的显著数字估计，以提供更易于人类理解的数据摘要。__repr__不使用此方法；它只显示原始值。显著数字估计用于Compare。

```py
class torch.utils.benchmark.CallgrindStats(task_spec, number_per_run, built_with_debug_symbols, baseline_inclusive_stats, baseline_exclusive_stats, stmt_inclusive_stats, stmt_exclusive_stats, stmt_callgrind_out)¶
```

由计时器收集的Callgrind结果的顶层容器。

通常使用FunctionCounts类进行操作，该类通过调用CallgrindStats.stats(…)获得。还提供了几种便利方法；最重要的是CallgrindStats.as_standardized()。

```py
as_standardized()¶
```

从函数字符串中删除库名称和一些前缀。

在比较两组不同的指令计数时，一个障碍可能是路径前缀。Callgrind在报告函数时包括完整的文件路径（应该如此）。但是，在进行性能分析时，这可能会导致问题。如果两个性能分析中的关键组件（如Python或PyTorch）在不同位置构建，可能会导致类似以下的情况：

```py
23234231 /tmp/first_build_dir/thing.c:foo(...)
 9823794 /tmp/first_build_dir/thing.c:bar(...)
  ...
   53453 .../aten/src/Aten/...:function_that_actually_changed(...)
  ...
 -9823794 /tmp/second_build_dir/thing.c:bar(...)
-23234231 /tmp/second_build_dir/thing.c:foo(...) 
```

通过去除前缀可以改善这个问题，使字符串规范化，并在进行差异比较时更好地取消等效调用点。

返回类型

[*CallgrindStats*](#torch.utils.benchmark.CallgrindStats "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats")

```py
counts(*, denoise=False)¶
```

返回执行的指令总数。

查看 FunctionCounts.denoise() 以了解 denoise 参数的解释。

返回类型

[int](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12 中)")

```py
delta(other, inclusive=False)¶
```

比较两组计数。

收集指令计数的一个常见原因是确定某个特定更改对执行某个工作单元所需的指令数量的影响。如果更改增加了该数字，下一个逻辑问题是“为什么”。这通常涉及查看代码的哪个部分增加了指令计数。此函数自动化了该过程，以便可以轻松地在包含和不包含的基础上对计数进行差异。

返回类型

[*FunctionCounts*](#torch.utils.benchmark.FunctionCounts "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts")

```py
stats(inclusive=False)¶
```

返回详细的函数计数。

从概念上讲，返回的 FunctionCounts 可以被视为一个元组，其中包含 (计数，路径和函数名称) 元组。

inclusive 匹配 callgrind 的语义。如果为 True，则计数包括子级执行的指令。inclusive=True 用于识别代码中的热点；inclusive=False 用于在比较两次运行的计数时减少噪音。 （有关更多详细信息，请参见 CallgrindStats.delta(…)）

返回类型

[*FunctionCounts*](#torch.utils.benchmark.FunctionCounts "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts")

```py
class torch.utils.benchmark.FunctionCounts(_data, inclusive, truncate_rows=True, _linewidth=None)¶
```

用于操作 Callgrind 结果的容器。

它支持：

1.  加法和减法以组合或差异结果。

1.  类似元组索引。

1.  一个去噪函数，用于剥离已知为非确定性且相当嘈杂的 CPython 调用。

1.  两个高阶方法（filter 和 transform）用于自定义操作。

```py
denoise()¶
```

删除已知的嘈杂指令。

CPython 解释器中的几条指令相当嘈杂。这些指令涉及 Python 用于将变量名映射到字典查找的 Unicode。FunctionCounts 通常是一个内容不可知的容器，但这对于获得可靠结果是足够重要的，值得例外。

返回类型

[*FunctionCounts*](#torch.utils.benchmark.FunctionCounts "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts")

```py
filter(filter_fn)¶
```

仅保留 filter_fn 应用于函数名称返回 True 的元素。

返回类型

[*FunctionCounts*](#torch.utils.benchmark.FunctionCounts "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts")

```py
transform(map_fn)¶
```

将 map_fn 应用于所有函数名称。

这可以用于规范化函数名称（例如剥离文件路径的无关部分），通过将多个函数映射到相同名称来合并条目（在这种情况下，计数将相加），等等。

返回类型

[*FunctionCounts*](#torch.utils.benchmark.FunctionCounts "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts")
