- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/audio/stable/references.html](https://pytorch.org/audio/stable/references.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Yes]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yesno. URL: [http://www.openslr.org/1/](http://www.openslr.org/1/).'
  prefs: []
  type: TYPE_NORMAL
- en: '[AB79]'
  prefs: []
  type: TYPE_NORMAL
- en: Jont B Allen and David A Berkley. Image method for efficiently simulating small-room
    acoustics. *The Journal of the Acoustical Society of America*, 65(4):943–950,
    1979.
  prefs: []
  type: TYPE_NORMAL
- en: '[ABD+20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler,
    Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M. Tyers, and Gregor Weber.
    Common voice: a massively-multilingual speech corpus. 2020\. [arXiv:1912.06670](https://arxiv.org/abs/1912.06670).'
  prefs: []
  type: TYPE_NORMAL
- en: '[BWT+21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman
    Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, and others.
    Xls-r: self-supervised cross-lingual speech representation learning at scale.
    *arXiv preprint arXiv:2111.09296*, 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '[BZMA20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael Auli. Wav2vec
    2.0: a framework for self-supervised learning of speech representations. 2020\.
    [arXiv:2006.11477](https://arxiv.org/abs/2006.11477).'
  prefs: []
  type: TYPE_NORMAL
- en: '[BBL+08]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost,
    Samuel Kim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: interactive
    emotional dyadic motion capture database. *Language Resources and Evaluation*,
    42:335–359, 12 2008\. [doi:10.1007/s10579-008-9076-6](https://doi.org/10.1007/s10579-008-9076-6).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Cap69]'
  prefs: []
  type: TYPE_NORMAL
- en: Jack Capon. High-resolution frequency-wavenumber spectrum analysis. *Proceedings
    of the IEEE*, 57(8):1408–1418, 1969.
  prefs: []
  type: TYPE_NORMAL
- en: '[CDiGangiB+21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Roldano Cattoni, Mattia Antonino Di Gangi, Luisa Bentivogli, Matteo Negri,
    and Marco Turchi. Must-c: a multilingual corpus for end-to-end speech translation.
    *Computer Speech & Language*, 66:101155, 2021\. URL: [https://www.sciencedirect.com/science/article/pii/S0885230820300887](https://www.sciencedirect.com/science/article/pii/S0885230820300887),
    [doi:https://doi.org/10.1016/j.csl.2020.101155](https://doi.org/https://doi.org/10.1016/j.csl.2020.101155).'
  prefs: []
  type: TYPE_NORMAL
- en: '[CCW+21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Guoguo Chen, Shuzhou Chai, Guanbo Wang, Jiayu Du, Wei-Qiang Zhang, Chao Weng,
    Dan Su, Daniel Povey, Jan Trmal, Junbo Zhang, Mingjie Jin, Sanjeev Khudanpur,
    Shinji Watanabe, Shuaijiang Zhao, Wei Zou, Xiangang Li, Xuchen Yao, Yongqing Wang,
    Yujun Wang, Zhao You, and Zhiyong Yan. Gigaspeech: an evolving, multi-domain asr
    corpus with 10,000 hours of transcribed audio. In *Proc. Interspeech 2021*. 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '[CWC+22]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu
    Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, and others. Wavlm: large-scale
    self-supervised pre-training for full stack speech processing. *IEEE Journal of
    Selected Topics in Signal Processing*, 16(6):1505–1518, 2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[CPS16]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ronan Collobert, Christian Puhrsch, and Gabriel Synnaeve. Wav2letter: an end-to-end
    convnet-based speech recognition system. 2016\. [arXiv:1609.03193](https://arxiv.org/abs/1609.03193).'
  prefs: []
  type: TYPE_NORMAL
- en: '[CBC+20]'
  prefs: []
  type: TYPE_NORMAL
- en: Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael
    Auli. Unsupervised cross-lingual representation learning for speech recognition.
    2020\. [arXiv:2006.13979](https://arxiv.org/abs/2006.13979).
  prefs: []
  type: TYPE_NORMAL
- en: '[CY21]'
  prefs: []
  type: TYPE_NORMAL
- en: Erica Cooper and Junichi Yamagishi. How do voices from past speech synthesis
    challenges compare today? *arXiv preprint arXiv:2105.02373*, 2021.
  prefs: []
  type: TYPE_NORMAL
- en: '[CPC+20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Joris Cosentino, Manuel Pariente, Samuele Cornell, Antoine Deleforge, and Emmanuel
    Vincent. Librimix: an open-source dataset for generalizable speech separation.
    2020\. [arXiv:2005.11262](https://arxiv.org/abs/2005.11262).'
  prefs: []
  type: TYPE_NORMAL
- en: '[CSB+18]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alice Coucke, Alaa Saade, Adrien Ball, Théodore Bluche, Alexandre Caulier,
    David Leroy, Clément Doumouro, Thibault Gisselbrecht, Francesco Caltagirone, Thibaut
    Lavril, and others. Snips voice platform: an embedded spoken language understanding
    system for private-by-design voice interfaces. *arXiv preprint arXiv:1805.10190*,
    2018.'
  prefs: []
  type: TYPE_NORMAL
- en: '[DL82]'
  prefs: []
  type: TYPE_NORMAL
- en: DC Dowson and BV666017 Landau. The fréchet distance between multivariate normal
    distributions. *Journal of multivariate analysis*, 12(3):450–455, 1982.
  prefs: []
  type: TYPE_NORMAL
- en: '[Defossez21]'
  prefs: []
  type: TYPE_NORMAL
- en: Alexandre Défossez. Hybrid spectrogram and waveform source separation. In *Proceedings
    of the ISMIR 2021 Workshop on Music Source Separation*. 2021.
  prefs: []
  type: TYPE_NORMAL
- en: '[GKRR14]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mark John Francis Gales, Kate Knill, Anton Ragni, and Shakti Prasad Rath. Speech
    recognition and keyword spotting for low-resource languages: babel project research
    at cued. In *SLTU*. 2014.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gra12]'
  prefs: []
  type: TYPE_NORMAL
- en: Alex Graves. Sequence transduction with recurrent neural networks. 2012\. [arXiv:1211.3711](https://arxiv.org/abs/1211.3711).
  prefs: []
  type: TYPE_NORMAL
- en: '[GL83]'
  prefs: []
  type: TYPE_NORMAL
- en: D. Griffin and Jae Lim. Signal estimation from modified short-time fourier transform.
    In *ICASSP '83\. IEEE International Conference on Acoustics, Speech, and Signal
    Processing*, volume 8, 804–807\. 1983\. [doi:10.1109/ICASSP.1983.1172092](https://doi.org/10.1109/ICASSP.1983.1172092).
  prefs: []
  type: TYPE_NORMAL
- en: '[GQC+20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu,
    Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang. Conformer:
    convolution-augmented transformer for speech recognition. 2020\. [arXiv:2005.08100](https://arxiv.org/abs/2005.08100).'
  prefs: []
  type: TYPE_NORMAL
- en: '[HCC+14]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen,
    Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and Andrew Y. Ng.
    Deep speech: scaling up end-to-end speech recognition. 2014\. [arXiv:1412.5567](https://arxiv.org/abs/1412.5567).'
  prefs: []
  type: TYPE_NORMAL
- en: '[HCE+17]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jort F. Gemmeke, Aren
    Jansen, Channing Moore, Manoj Plakal, Devin Platt, Rif A. Saurous, Bryan Seybold,
    Malcolm Slaney, Ron Weiss, and Kevin Wilson. Cnn architectures for large-scale
    audio classification. In *International Conference on Acoustics, Speech and Signal
    Processing (ICASSP)*. 2017\. URL: [https://arxiv.org/abs/1609.09430](https://arxiv.org/abs/1609.09430).'
  prefs: []
  type: TYPE_NORMAL
- en: '[HIA+17]'
  prefs: []
  type: TYPE_NORMAL
- en: Takuya Higuchi, Nobutaka Ito, Shoko Araki, Takuya Yoshioka, Marc Delcroix, and
    Tomohiro Nakatani. Online mvdr beamformer based on complex gaussian mixture model
    with spatial prior for noise robust asr. *IEEE/ACM Transactions on Audio, Speech,
    and Language Processing*, 25(4):780–793, 2017.
  prefs: []
  type: TYPE_NORMAL
- en: '[HIYN16]'
  prefs: []
  type: TYPE_NORMAL
- en: Takuya Higuchi, Nobutaka Ito, Takuya Yoshioka, and Tomohiro Nakatani. Robust
    mvdr beamforming using time-frequency masks for online/offline asr in noise. In
    *2016 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP)*, 5210–5214\. IEEE, 2016.
  prefs: []
  type: TYPE_NORMAL
- en: '[HBT+21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan
    Salakhutdinov, and Abdelrahman Mohamed. Hubert: self-supervised speech representation
    learning by masked prediction of hidden units. 2021\. [arXiv:2106.07447](https://arxiv.org/abs/2106.07447).'
  prefs: []
  type: TYPE_NORMAL
- en: '[IJ17]'
  prefs: []
  type: TYPE_NORMAL
- en: Keith Ito and Linda Johnson. The lj speech dataset. [https://keithito.com/LJ-Speech-Dataset/](https://keithito.com/LJ-Speech-Dataset/),
    2017.
  prefs: []
  type: TYPE_NORMAL
- en: '[KPL+22]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jacob Kahn, Vineel Pratap, Tatiana Likhomanenko, Qiantong Xu, Awni Hannun,
    Jeff Cai, Paden Tomasello, Ann Lee, Edouard Grave, Gilad Avidov, and others. Flashlight:
    enabling innovation in tools for machine learning. *arXiv preprint arXiv:2201.12465*,
    2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[KES+18a]'
  prefs: []
  type: TYPE_NORMAL
- en: Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande,
    Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, and Koray
    Kavukcuoglu. Efficient neural audio synthesis. 2018\. [arXiv:1802.08435](https://arxiv.org/abs/1802.08435).
  prefs: []
  type: TYPE_NORMAL
- en: '[KES+18b]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande,
    Edward Lockhart, Florian Stimberg, Aäron van den Oord, Sander Dieleman, and Koray
    Kavukcuoglu. Efficient neural audio synthesis. *CoRR*, 2018\. URL: [http://arxiv.org/abs/1802.08435](http://arxiv.org/abs/1802.08435),
    [arXiv:1802.08435](https://arxiv.org/abs/1802.08435).'
  prefs: []
  type: TYPE_NORMAL
- en: '[KPPK15]'
  prefs: []
  type: TYPE_NORMAL
- en: Tom Ko, Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur. Audio augmentation
    for speech recognition. In *Proc. Interspeech 2015*, 3586–3589\. 2015\. [doi:10.21437/Interspeech.2015-711](https://doi.org/10.21437/Interspeech.2015-711).
  prefs: []
  type: TYPE_NORMAL
- en: '[KBV03]'
  prefs: []
  type: TYPE_NORMAL
- en: John Kominek, Alan W Black, and Ver Ver. Cmu arctic databases for speech synthesis.
    Technical Report, 2003.
  prefs: []
  type: TYPE_NORMAL
- en: '[KKB20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae. Hifi-gan: generative adversarial
    networks for efficient and high fidelity speech synthesis. In H. Larochelle, M. Ranzato,
    R. Hadsell, M.F. Balcan, and H. Lin, editors, *Advances in Neural Information
    Processing Systems*, volume 33, 17022–17033\. Curran Associates, Inc., 2020\.
    URL: [https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf](https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: '[KTN+23]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Anurag Kumar, Ke Tan, Zhaoheng Ni, Pranay Manocha, Xiaohui Zhang, Ethan Henderson,
    and Buye Xu. Torchaudio-squim: reference-less speech quality and intelligibility
    measures in torchaudio. *arXiv preprint arXiv:2304.01448*, 2023.'
  prefs: []
  type: TYPE_NORMAL
- en: '[LRI+19]'
  prefs: []
  type: TYPE_NORMAL
- en: Loren Lugosch, Mirco Ravanelli, Patrick Ignoto, Vikrant Singh Tomar, and Yoshua
    Bengio. Speech model pre-training for end-to-end spoken language understanding.
    In Gernot Kubin and Zdravko Kacic, editors, *Proc. of Interspeech*, 814–818\.
    2019.
  prefs: []
  type: TYPE_NORMAL
- en: '[LM19]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yi Luo and Nima Mesgarani. Conv-tasnet: surpassing ideal time–frequency magnitude
    masking for speech separation. *IEEE/ACM Transactions on Audio, Speech, and Language
    Processing*, 27(8):1256–1266, Aug 2019\. URL: [http://dx.doi.org/10.1109/TASLP.2019.2915167](http://dx.doi.org/10.1109/TASLP.2019.2915167),
    [doi:10.1109/taslp.2019.2915167](https://doi.org/10.1109/taslp.2019.2915167).'
  prefs: []
  type: TYPE_NORMAL
- en: '[MK22]'
  prefs: []
  type: TYPE_NORMAL
- en: Pranay Manocha and Anurag Kumar. Speech quality assessment through mos using
    non-matching references. *arXiv preprint arXiv:2206.12285*, 2022.
  prefs: []
  type: TYPE_NORMAL
- en: '[MRFB+15]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Xavier Anguera Miro, Luis Javier Rodriguez-Fuentes, Andi Buzo, Florian Metze,
    Igor Szoke, and Mikel Peñagarikano. Quesst2014: evaluating query-by-example speech
    search in a zero-resource setting with real-life queries. *2015 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*, pages 5833–5837,
    2015.'
  prefs: []
  type: TYPE_NORMAL
- en: '[MPG29]'
  prefs: []
  type: TYPE_NORMAL
- en: RV Mises and Hilda Pollaczek-Geiringer. Praktische verfahren der gleichungsauflösung.
    *ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift für Angewandte
    Mathematik und Mechanik*, 9(1):58–77, 1929.
  prefs: []
  type: TYPE_NORMAL
- en: '[Mys14]'
  prefs: []
  type: TYPE_NORMAL
- en: Gautham J Mysore. Can we automatically transform speech recorded on common consumer
    devices in real-world environments into professional production quality speech?—a
    dataset, insights, and challenges. *IEEE Signal Processing Letters*, 22(8):1006–1010,
    2014.
  prefs: []
  type: TYPE_NORMAL
- en: '[NCZ17]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Arsha Nagrani, Joon Son Chung, and Andrew Zisserman. Voxceleb: a large-scale
    speaker identification dataset. *arXiv preprint arXiv:1706.08612*, 2017.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PCPK15]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech:
    an asr corpus based on public domain audio books. In *2015 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*, volume, 5206–5210\.
    2015\. [doi:10.1109/ICASSP.2015.7178964](https://doi.org/10.1109/ICASSP.2015.7178964).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PCZ+19]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D.
    Cubuk, and Quoc V. Le. Specaugment: a simple data augmentation method for automatic
    speech recognition. *Interspeech 2019*, Sep 2019\. URL: [http://dx.doi.org/10.21437/Interspeech.2019-2680](http://dx.doi.org/10.21437/Interspeech.2019-2680),
    [doi:10.21437/interspeech.2019-2680](https://doi.org/10.21437/interspeech.2019-2680).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PBS13]'
  prefs: []
  type: TYPE_NORMAL
- en: Nathanaël Perraudin, Peter Balazs, and Peter L. Søndergaard. A fast griffin-lim
    algorithm. In *2013 IEEE Workshop on Applications of Signal Processing to Audio
    and Acoustics*, volume, 1–4\. 2013\. [doi:10.1109/WASPAA.2013.6701851](https://doi.org/10.1109/WASPAA.2013.6701851).
  prefs: []
  type: TYPE_NORMAL
- en: '[PTS+23]'
  prefs: []
  type: TYPE_NORMAL
- en: Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani
    Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski,
    Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. Scaling
    speech technology to 1,000+ languages. 2023\. [arXiv:2305.13516](https://arxiv.org/abs/2305.13516).
  prefs: []
  type: TYPE_NORMAL
- en: '[PXS+20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, and Ronan Collobert.
    Mls: a large-scale multilingual dataset for speech research. *Interspeech 2020*,
    Oct 2020\. URL: [http://dx.doi.org/10.21437/Interspeech.2020-2826](http://dx.doi.org/10.21437/Interspeech.2020-2826),
    [doi:10.21437/interspeech.2020-2826](https://doi.org/10.21437/interspeech.2020-2826).'
  prefs: []
  type: TYPE_NORMAL
- en: '[RLStoter+19]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Zafar Rafii, Antoine Liutkus, Fabian-Robert Stöter, Stylianos Ioannis Mimilakis,
    and Rachel Bittner. MUSDB18-HQ - an uncompressed version of musdb18\. December
    2019\. URL: [https://doi.org/10.5281/zenodo.3338373](https://doi.org/10.5281/zenodo.3338373),
    [doi:10.5281/zenodo.3338373](https://doi.org/10.5281/zenodo.3338373).'
  prefs: []
  type: TYPE_NORMAL
- en: '[RGC+20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Chandan KA Reddy, Vishak Gopal, Ross Cutler, Ebrahim Beyrami, Roger Cheng,
    Harishchandra Dubey, Sergiy Matusevych, Robert Aichner, Ashkan Aazami, Sebastian
    Braun, and others. The interspeech 2020 deep noise suppression challenge: datasets,
    subjective testing framework, and challenge results. *arXiv preprint arXiv:2005.13981*,
    2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '[RDelegliseEsteve12]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Anthony Rousseau, Paul Deléglise, and Yannick Estève. Ted-lium: an automatic
    speech recognition dedicated corpus. In *Conference on Language Resources and
    Evaluation (LREC)*, 125–129\. 2012.'
  prefs: []
  type: TYPE_NORMAL
- en: '[SY18]'
  prefs: []
  type: TYPE_NORMAL
- en: Seyyed Saeed Sarfjoo and Junichi Yamagishi. Device recorded vctk (small subset
    version). 2018.
  prefs: []
  type: TYPE_NORMAL
- en: '[SBDokmanic18]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Robin Scheibler, Eric Bezzam, and Ivan Dokmanić. Pyroomacoustics: a python
    package for audio room simulation and array processing algorithms. In *2018 IEEE
    international conference on acoustics, speech and signal processing (ICASSP)*,
    351–355\. IEEE, 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: '[SPW+18]'
  prefs: []
  type: TYPE_NORMAL
- en: Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng
    Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, Rj Skerrv-Ryan, and others. Natural
    tts synthesis by conditioning wavenet on mel spectrogram predictions. In *2018
    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*,
    4779–4783\. IEEE, 2018.
  prefs: []
  type: TYPE_NORMAL
- en: '[SWW+21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yangyang Shi, Yongqiang Wang, Chunyang Wu, Ching-Feng Yeh, Julian Chan, Frank
    Zhang, Duc Le, and Mike Seltzer. Emformer: efficient memory transformer based
    acoustic model for low latency streaming speech recognition. In *ICASSP 2021 -
    2021 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP)*, 6783–6787\. 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '[SWW+22]'
  prefs: []
  type: TYPE_NORMAL
- en: Yangyang Shi, Chunyang Wu, Dilin Wang, Alex Xiao, Jay Mahadeokar, Xiaohui Zhang,
    Chunxi Liu, Ke Li, Yuan Shangguan, Varun Nagaraja, Ozlem Kalinli, and Mike Seltzer.
    Streaming transformer transducer based speech recognition using non-causal convolution.
    In *ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and
    Signal Processing (ICASSP)*, volume, 8277–8281\. 2022\. [doi:10.1109/ICASSP43922.2022.9747706](https://doi.org/10.1109/ICASSP43922.2022.9747706).
  prefs: []
  type: TYPE_NORMAL
- en: '[Smi20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Julius O. Smith. Digital audio resampling home page "theory of ideal bandlimited
    interpolation" section. September 2020\. URL: [https://ccrma.stanford.edu/~jos/resample/Theory_Ideal_Bandlimited_Interpolation.html](https://ccrma.stanford.edu/~jos/resample/Theory_Ideal_Bandlimited_Interpolation.html).'
  prefs: []
  type: TYPE_NORMAL
- en: '[SCP15]'
  prefs: []
  type: TYPE_NORMAL
- en: 'David Snyder, Guoguo Chen, and Daniel Povey. MUSAN: A Music, Speech, and Noise
    Corpus. 2015\. arXiv:1510.08484v1\. [arXiv:1510.08484](https://arxiv.org/abs/1510.08484).'
  prefs: []
  type: TYPE_NORMAL
- en: '[SBA09]'
  prefs: []
  type: TYPE_NORMAL
- en: Mehrez Souden, Jacob Benesty, and Sofiene Affes. On optimal frequency-domain
    multichannel linear filtering for noise reduction. In *IEEE Transactions on audio,
    speech, and language processing*, volume 18, 260–276\. IEEE, 2009.
  prefs: []
  type: TYPE_NORMAL
- en: '[SWT+22]'
  prefs: []
  type: TYPE_NORMAL
- en: Sangeeta Srivastava, Yun Wang, Andros Tjandra, Anurag Kumar, Chunxi Liu, Kritika
    Singh, and Yatharth Saraf. Conformer-based self-supervised learning for non-speech
    audio tasks. In *ICASSP 2022 - 2022 IEEE International Conference on Acoustics,
    Speech and Signal Processing (ICASSP)*, volume, 8862–8866\. 2022\. [doi:10.1109/ICASSP43922.2022.9746490](https://doi.org/10.1109/ICASSP43922.2022.9746490).
  prefs: []
  type: TYPE_NORMAL
- en: '[TEC01]'
  prefs: []
  type: TYPE_NORMAL
- en: 'George Tzanetakis, Georg Essl, and Perry Cook. Automatic musical genre classification
    of audio signals. 2001\. URL: [http://ismir2001.ismir.net/pdf/tzanetakis.pdf](http://ismir2001.ismir.net/pdf/tzanetakis.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: '[VAlumae21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jörgen Valk and Tanel Alumäe. Voxlingua107: a dataset for spoken language recognition.
    In *2021 IEEE Spoken Language Technology Workshop (SLT)*, 652–658\. IEEE, 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '[WRiviereL+21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Changhan Wang, Morgane Rivière, Ann Lee, Anne Wu, Chaitanya Talnikar, Daniel
    Haziza, Mary Williamson, Juan Miguel Pino, and Emmanuel Dupoux. Voxpopuli: A large-scale
    multilingual speech corpus for representation learning, semi-supervised learning
    and interpretation. *CoRR*, 2021\. URL: [https://arxiv.org/abs/2101.00390](https://arxiv.org/abs/2101.00390),
    [arXiv:2101.00390](https://arxiv.org/abs/2101.00390).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Wei98]'
  prefs: []
  type: TYPE_NORMAL
- en: 'R.L. Weide. The carnegie mellon pronuncing dictionary. 1998\. URL: [http://www.speech.cs.cmu.edu/cgi-bin/cmudict](http://www.speech.cs.cmu.edu/cgi-bin/cmudict).'
  prefs: []
  type: TYPE_NORMAL
- en: '[YVM19]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald. CSTR VCTK Corpus:
    english multi-speaker corpus for CSTR voice cloning toolkit (version 0.92). 2019\.
    [doi:10.7488/ds/2645](https://doi.org/10.7488/ds/2645).'
  prefs: []
  type: TYPE_NORMAL
- en: '[ZDC+19]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Heiga Zen, Viet-Trung Dang, Robert A. J. Clark, Yu Zhang, Ron J. Weiss, Ye Jia,
    Z. Chen, and Yonghui Wu. Libritts: a corpus derived from librispeech for text-to-speech.
    *ArXiv*, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[ZSN21]'
  prefs: []
  type: TYPE_NORMAL
- en: Albert Zeyer, Ralf Schlüter, and Hermann Ney. Why does ctc result in peaky behavior?
    2021\. [arXiv:2105.14849](https://arxiv.org/abs/2105.14849).
  prefs: []
  type: TYPE_NORMAL
- en: '[BrianMcFeeColinRaffelDawenLiang+15]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Brian McFee, Colin Raffel, Dawen Liang, Daniel P.W. Ellis, Matt McVicar, Eric
    Battenberg, and Oriol Nieto. Librosa: Audio and Music Signal Analysis in Python.
    In Kathryn Huff and James Bergstra, editors, *Proceedings of the 14th Python in
    Science Conference*, 18 – 24\. 2015\. [doi:10.25080/Majora-7b98e3ed-003](https://doi.org/10.25080/Majora-7b98e3ed-003).'
  prefs: []
  type: TYPE_NORMAL
- en: '[KahnRiviereZheng+20]'
  prefs: []
  type: TYPE_NORMAL
- en: 'J. Kahn, M. Rivière, W. Zheng, E. Kharitonov, Q. Xu, P. E. Mazaré, J. Karadayi,
    V. Liptchinsky, R. Collobert, C. Fuegen, T. Likhomanenko, G. Synnaeve, A. Joulin,
    A. Mohamed, and E. Dupoux. Libri-light: a benchmark for asr with limited or no
    supervision. In *ICASSP 2020 - 2020 IEEE International Conference on Acoustics,
    Speech and Signal Processing (ICASSP)*, 7669–7673\. 2020\. [https://github.com/facebookresearch/libri-light](https://github.com/facebookresearch/libri-light).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Warden18]'
  prefs: []
  type: TYPE_NORMAL
- en: 'P. Warden. Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition.
    *ArXiv e-prints*, April 2018\. URL: [https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209),
    [arXiv:1804.03209](https://arxiv.org/abs/1804.03209).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Wikipediacontributors]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wikipedia contributors. Absorption (acoustics) — Wikipedia, the free encyclopedia.
    [Online]. URL: [https://en.wikipedia.org/wiki/Absorption_(acoustics)](https://en.wikipedia.org/wiki/Absorption_(acoustics)).'
  prefs: []
  type: TYPE_NORMAL
