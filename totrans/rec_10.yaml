- en: torchrec.modules
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: torchrec.modules
- en: 原文：[https://pytorch.org/torchrec/torchrec.modules.html](https://pytorch.org/torchrec/torchrec.modules.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/torchrec/torchrec.modules.html](https://pytorch.org/torchrec/torchrec.modules.html)
- en: Torchrec Common Modules
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Torchrec常见模块
- en: The torchrec modules contain a collection of various modules.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: torchrec模块包含各种模块的集合。
- en: 'These modules include:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模块包括：
- en: extensions of nn.Embedding and nn.EmbeddingBag, called EmbeddingBagCollection
    and EmbeddingCollection respectively.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: nn.Embedding和nn.EmbeddingBag的扩展，分别称为EmbeddingBagCollection和EmbeddingCollection。
- en: established modules such as [DeepFM](https://arxiv.org/pdf/1703.04247.pdf) and
    [CrossNet](https://arxiv.org/abs/1708.05123).
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已建立的模块，如[DeepFM](https://arxiv.org/pdf/1703.04247.pdf)和[CrossNet](https://arxiv.org/abs/1708.05123)。
- en: common module patterns such as MLP and SwishLayerNorm.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的模块模式，如MLP和SwishLayerNorm。
- en: custom modules for TorchRec such as PositionWeightedModule and LazyModuleExtensionMixin.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TorchRec的自定义模块，如PositionWeightedModule和LazyModuleExtensionMixin。
- en: EmbeddingTower and EmbeddingTowerCollection, logical “tower” of embeddings passed
    to provided interaction module.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EmbeddingTower和EmbeddingTowerCollection，逻辑上的“塔”嵌入传递给提供的交互模块。
- en: '## torchrec.modules.activation[](#module-torchrec.modules.activation "Permalink
    to this heading")'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '## torchrec.modules.activation[](#module-torchrec.modules.activation "Permalink
    to this heading")'
- en: Activation Modules
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 激活模块
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Bases: `Module`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: 'Applies the Swish function with layer normalization: Y = X * Sigmoid(LayerNorm(X)).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 应用带有层归一化的Swish函数：Y = X * Sigmoid(LayerNorm(X))。
- en: 'Parameters:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input_dims** (*Union**[**int**,* *List**[**int**]**,* *torch.Size**]*) –
    dimensions to normalize over. If an input tensor has shape [batch_size, d1, d2,
    d3], setting input_dim=[d2, d3] will do the layer normalization on last two dimensions.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**input_dims** (*Union**[**int**,* *List**[**int**]**,* *torch.Size**]*) –
    要进行归一化的维度。如果输入张量的形状为[batch_size, d1, d2, d3]，设置input_dim=[d2, d3]将在最后两个维度上进行层归一化。'
- en: '**device** (*Optional**[**torch.device**]*) – default compute device.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**device** (*Optional**[**torch.device**]*) – 默认计算设备。'
- en: 'Example:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Parameters:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – an input tensor.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*torch.Tensor*) – 输入张量。'
- en: 'Returns:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: an output tensor.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个输出张量。
- en: 'Return type:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE3]  ## torchrec.modules.crossnet[](#module-torchrec.modules.crossnet "Permalink
    to this heading")'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE3]  ## torchrec.modules.crossnet[](#module-torchrec.modules.crossnet "Permalink
    to this heading")'
- en: CrossNet API
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: CrossNet API
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Bases: `Module`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: '[Cross Network](https://arxiv.org/abs/1708.05123):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[交叉网络](https://arxiv.org/abs/1708.05123)：'
- en: Cross Net is a stack of “crossing” operations on a tensor of shape \((*, N)\)
    to the same shape, effectively creating \(N\) learnable polynomical functions
    over the input tensor.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Cross Net是对形状为\((*, N)\)的张量进行一系列“交叉”操作，使其形状相同，有效地创建\(N\)个可学习的多项式函数。
- en: 'In this module, the crossing operations are defined based on a full rank matrix
    (NxN), such that the crossing effect can cover all bits on each layer. On each
    layer l, the tensor is transformed into:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模块中，交叉操作是基于一个满秩矩阵（NxN）定义的，这样交叉效应可以覆盖每一层上的所有位。在每一层l上，张量被转换为：
- en: \[x_{l+1} = x_0 * (W_l \cdot x_l + b_l) + x_l\]
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: \[x_{l+1} = x_0 * (W_l \cdot x_l + b_l) + x_l\]
- en: where \(W_l\) is a square matrix \((NxN)\), \(*\) means element-wise multiplication,
    \(\cdot\) means matrix multiplication.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(W_l\)是一个方阵\((NxN)\)，\(*)表示逐元素乘法，\(\cdot\)表示矩阵乘法。
- en: 'Parameters:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**in_features** (*int*) – the dimension of the input.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**in_features** (*int*) – 输入的维度。'
- en: '**num_layers** (*int*) – the number of layers in the module.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**num_layers** (*int*) – 模块中的层数。'
- en: 'Example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Parameters:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – tensor with shape [batch_size, in_features].'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*torch.Tensor*) – 形状为[batch_size, in_features]的张量。'
- en: 'Returns:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tensor with shape [batch_size, in_features].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为[batch_size, in_features]的张量。
- en: 'Return type:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Bases: `Module`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: Low Rank Cross Net is a highly efficient cross net. Instead of using full rank
    cross matrices (NxN) at each layer, it will use two kernels \(W (N x r)\) and
    \(V (r x N)\), where r << N, to simplify the matrix multiplication.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩交叉网络是一个高效的交叉网络。它不是在每一层使用满秩交叉矩阵（NxN），而是使用两个核\(W (N x r)\)和\(V (r x N)\)，其中r
    << N，以简化矩阵乘法。
- en: 'On each layer l, the tensor is transformed into:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一层l上，张量被转换为：
- en: \[x_{l+1} = x_0 * (W_l \cdot (V_l \cdot x_l) + b_l) + x_l\]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[x_{l+1} = x_0 * (W_l \cdot (V_l \cdot x_l) + b_l) + x_l\]
- en: where \(W_l\) is either a vector, \(*\) means element-wise multiplication, and
    \(\cdot\) means matrix multiplication.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(W_l\)可以是一个向量，\(*)表示逐元素乘法，\(\cdot\)表示矩阵乘法。
- en: Note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Rank r should be chosen smartly. Usually, we expect r < N/2 to have computational
    savings; we should expect \(r ~= N/4\) to preserve the accuracy of the full rank
    cross net.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 秩r应该被聪明地选择。通常，我们期望r < N/2以节省计算；我们应该期望\(r ~= N/4\)以保持完整秩交叉网络的准确性。
- en: 'Parameters:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**in_features** (*int*) – the dimension of the input.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**in_features** (*int*) – 输入的维度。'
- en: '**num_layers** (*int*) – the number of layers in the module.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**num_layers** (*int*) – 模块中的层数。'
- en: '**low_rank** (*int*) – the rank setup of the cross matrix (default = 1). Value
    must be always >= 1.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**low_rank** (*int*) – 交叉矩阵的秩设置（默认为1）。值必须始终 >= 1。'
- en: 'Example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Parameters:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – tensor with shape [batch_size, in_features].'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*torch.Tensor*) – 形状为[batch_size, in_features]的张量。'
- en: 'Returns:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tensor with shape [batch_size, in_features].
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为[batch_size, in_features]的张量。
- en: 'Return type:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Bases: `Module`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: 'Low Rank Mixture Cross Net is a DCN V2 implementation from the [paper](https://arxiv.org/pdf/2008.13535.pdf):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩混合交叉网络是来自[论文](https://arxiv.org/pdf/2008.13535.pdf)的DCN V2实现：
- en: LowRankMixtureCrossNet defines the learnable crossing parameter per layer as
    a low-rank matrix \((N*r)\) together with mixture of experts. Compared to LowRankCrossNet,
    instead of relying on one single expert to learn feature crosses, this module
    leverages such \(K\) experts; each learning feature interactions in different
    subspaces, and adaptively combining the learned crosses using a gating mechanism
    that depends on input \(x\)..
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LowRankMixtureCrossNet将每层的可学习交叉参数定义为一个低秩矩阵\((N*r)\)以及专家混合。与LowRankCrossNet相比，这个模块不依赖于单个专家来学习特征交叉，而是利用这样的\(K\)专家；每个专家在不同子空间中学习特征交互，并通过依赖于输入\(x\)的门控机制自适应地组合学习到的交叉。
- en: 'On each layer l, the tensor is transformed into:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一层l上，张量被转换为：
- en: '\[x_{l+1} = MoE({expert_i : i \in K_{experts}}) + x_l\]'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '\[x_{l+1} = MoE({expert_i : i \in K_{experts}}) + x_l\]'
- en: 'and each \(expert_i\) is defined as:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 每个\(expert_i\)被定义为：
- en: \[expert_i = x_0 * (U_{li} \cdot g(C_{li} \cdot g(V_{li} \cdot x_l)) + b_l)\]
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: \[expert_i = x_0 * (U_{li} \cdot g(C_{li} \cdot g(V_{li} \cdot x_l)) + b_l)\]
- en: where \(U_{li} (N, r)\), \(C_{li} (r, r)\) and \(V_{li} (r, N)\) are low-rank
    matrices, \(*\) means element-wise multiplication, \(x\) means matrix multiplication,
    and \(g()\) is the non-linear activation function.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(U_{li} (N, r)\)，\(C_{li} (r, r)\)和\(V_{li} (r, N)\)是低秩矩阵，\(*)表示逐元素乘法，\(x\)表示矩阵乘法，\(g()\)是非线性激活函数。
- en: When num_expert is 1, the gate evaluation and MOE will be skipped to save computation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当num_expert为1时，门控评估和MOE将被跳过以节省计算。
- en: 'Parameters:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**in_features** (*int*) – the dimension of the input.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**in_features**（*int*）- 输入的维度。'
- en: '**num_layers** (*int*) – the number of layers in the module.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**num_layers**（*int*）- 模块中的层数。'
- en: '**low_rank** (*int*) – the rank setup of the cross matrix (default = 1). Value
    must be always >= 1'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**low_rank**（*int*）- 交叉矩阵的秩设置（默认= 1）。值必须始终>= 1'
- en: '**activation** (*Union**[**torch.nn.Module**,* *Callable**[**[**torch.Tensor**]**,*
    *torch.Tensor**]**]*) – the non-linear activation function, used in defining experts.
    Default is relu.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**activation**（*Union**[**torch.nn.Module**,* *Callable**[**[**torch.Tensor**]**,*
    *torch.Tensor**]**]*)- 非线性激活函数，用于定义专家。默认为relu。'
- en: 'Example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Parameters:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – tensor with shape [batch_size, in_features].'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*torch.Tensor*）- 具有形状[batch_size，in_features]的张量。'
- en: 'Returns:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tensor with shape [batch_size, in_features].
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 具有形状[batch_size，in_features]的张量。
- en: 'Return type:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Bases: `Module`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: Vector Cross Network can be refered as [DCN-V1](https://arxiv.org/pdf/1708.05123.pdf).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 向量交叉网络可以被称为[DCN-V1](https://arxiv.org/pdf/1708.05123.pdf)。
- en: It is also a specialized low rank cross net, where rank=1\. In this version,
    on each layer, instead of keeping two kernels W and V, we only keep one vector
    kernel W (Nx1). We use the dot operation to compute the “crossing” effect of the
    features, thus saving two matrix multiplications to further reduce computational
    cost and cut the number of learnable parameters.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 它也是一个专门的低秩交叉网络，其中rank=1。在这个版本中，在每一层上，我们只保留一个向量核W（Nx1），而不是保留两个核W和V。我们使用点操作来计算特征的“交叉”效应，从而节省两次矩阵乘法以进一步减少计算成本并减少可学习参数的数量。
- en: On each layer l, the tensor is transformed into
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一层l上，张量被转换为
- en: \[x_{l+1} = x_0 * (W_l . x_l + b_l) + x_l\]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \[x_{l+1} = x_0 * (W_l . x_l + b_l) + x_l\]
- en: where \(W_l\) is either a vector, \(*\) means element-wise multiplication; \(.\)
    means dot operations.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(W_l\)是一个向量，\(*)表示逐元素乘法；\(.\)表示点操作。
- en: 'Parameters:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**in_features** (*int*) – the dimension of the input.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**in_features**（*int*）- 输入的维度。'
- en: '**num_layers** (*int*) – the number of layers in the module.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**num_layers**（*int*）- 模块中的层数。'
- en: 'Example:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Parameters:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – tensor with shape [batch_size, in_features].'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*torch.Tensor*）- 具有形状[batch_size，in_features]的张量。'
- en: 'Returns:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tensor with shape [batch_size, in_features].
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 具有形状[batch_size，in_features]的张量。
- en: 'Return type:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE19]  ## torchrec.modules.deepfm[](#module-torchrec.modules.deepfm "Permalink
    to this heading")'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE19]  ## torchrec.modules.deepfm[](#module-torchrec.modules.deepfm "Permalink
    to this heading")'
- en: Deep Factorization-Machine Modules
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 深度因子分解机模块
- en: The following modules are based off the [Deep Factorization-Machine (DeepFM)
    paper](https://arxiv.org/pdf/1703.04247.pdf)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下模块基于[深度因子分解机（DeepFM）论文](https://arxiv.org/pdf/1703.04247.pdf)
- en: Class DeepFM implents the DeepFM Framework
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类DeepFM实现了DeepFM框架
- en: Class FactorizationMachine implements FM as noted in the above paper.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类FactorizationMachine实现了上述论文中提到的FM。
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Bases: `Module`'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: This is the [DeepFM module](https://arxiv.org/pdf/1703.04247.pdf)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[DeepFM模块](https://arxiv.org/pdf/1703.04247.pdf)
- en: This module does not cover the end-end functionality of the published paper.
    Instead, it covers only the deep component of the publication. It is used to learn
    high-order feature interactions. If low-order feature interactions should be learnt,
    please use FactorizationMachine module instead, which will share the same embedding
    input of this module.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模块不涵盖已发表论文的端到端功能。相反，它仅涵盖了出版物的深度组件。它用于学习高阶特征交互。如果应该学习低阶特征交互，请改用FactorizationMachine模块，它将共享此模块的嵌入输入。
- en: 'To support modeling flexibility, we customize the key components as:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持建模的灵活性，我们将关键组件定制为：
- en: Different from the public paper, we change the input from raw sparse features
    to embeddings of the features. It allows flexibility in embedding dimensions and
    the number of embeddings, as long as all embedding tensors have the same batch
    size.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与公开论文不同，我们将输入从原始稀疏特征更改为特征的嵌入。这允许在嵌入维度和嵌入数量方面具有灵活性，只要所有嵌入张量具有相同的批量大小。
- en: On top of the public paper, we allow users to customize the hidden layer to
    be any module, not limited to just MLP.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在公开论文的基础上，我们允许用户自定义隐藏层为任何模块，不仅限于MLP。
- en: 'The general architecture of the module is like:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 模块的一般架构如下：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Parameters:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**dense_module** (*nn.Module*) – any customized module that can be used (such
    as MLP) in DeepFM. The in_features of this module must be equal to the element
    counts. For example, if the input embedding is [randn(3, 2, 3), randn(3, 4, 5)],
    the in_features should be: 2*3+4*5.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**dense_module**（*nn.Module*）– DeepFM中可以使用的任何自定义模块（例如MLP）。此模块的in_features必须等于元素计数。例如，如果输入嵌入是[randn(3,
    2, 3), randn(3, 4, 5)]，则in_features应为：2*3+4*5。'
- en: 'Example:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE22]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Parameters:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**embeddings** (*List**[**torch.Tensor**]*) –'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**embeddings**（*List**[**torch.Tensor**]*）–'
- en: 'The list of all embeddings (e.g. dense, common_sparse, specialized_sparse,
    embedding_features, raw_embedding_features) in the shape of:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 所有嵌入的列表（例如dense、common_sparse、specialized_sparse、embedding_features、raw_embedding_features）的形状为：
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'For the ease of operation, embeddings that have the same embedding dimension
    have the option to be stacked into a single tensor. For example, when we have
    1 trained embedding with dimension=32, 5 native embeddings with dimension=64,
    and 3 dense features with dimension=16, we can prepare the embeddings list to
    be the list of:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便操作，具有相同嵌入维度的嵌入可以选择堆叠到单个张量中。例如，当我们有1个维度为32的训练嵌入，5个维度为64的本地嵌入和3个维度为16的稠密特征时，我们可以准备嵌入列表为：
- en: '[PRE25]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: batch_size of all input tensors need to be identical.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 所有输入张量的批量大小需要相同。
- en: 'Returns:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: output of dense_module with flattened and concatenated embeddings as input.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 带有展平和连接的嵌入的dense_module输出作为输入。
- en: 'Return type:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Bases: `Module`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：`Module`
- en: 'This is the Factorization Machine module, mentioned in the [DeepFM paper](https://arxiv.org/pdf/1703.04247.pdf):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因子分解机模块，在[DeepFM论文](https://arxiv.org/pdf/1703.04247.pdf)中提到：
- en: This module does not cover the end-end functionality of the published paper.
    Instead, it covers only the FM part of the publication, and is used to learn 2nd-order
    feature interactions.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块不涵盖已发表论文的端到端功能。相反，它仅涵盖了出版物的FM部分，并用于学习二阶特征交互。
- en: 'To support modeling flexibility, we customize the key components as different
    from the public paper:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持建模灵活性，我们将关键组件定制为与公共论文不同：
- en: We change the input from raw sparse features to embeddings of the features.
    This allows flexibility in embedding dimensions and the number of embeddings,
    as long as all embedding tensors have the same batch size.
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们将输入从原始稀疏特征更改为特征的嵌入。只要所有嵌入张量具有相同的批量大小，就可以灵活地设置嵌入维度和嵌入数量。
- en: 'The general architecture of the module is like:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块的一般架构如下：
- en: '[PRE28]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Example:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Parameters:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**embeddings** (*List**[**torch.Tensor**]*) –'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**embeddings**（*List**[**torch.Tensor**]*）–'
- en: 'The list of all embeddings (e.g. dense, common_sparse, specialized_sparse,
    embedding_features, raw_embedding_features) in the shape of:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 所有嵌入的列表（例如dense、common_sparse、specialized_sparse、embedding_features、raw_embedding_features）的形状为：
- en: '[PRE31]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'For the ease of operation, embeddings that have the same embedding dimension
    have the option to be stacked into a single tensor. For example, when we have
    1 trained embedding with dimension=32, 5 native embeddings with dimension=64,
    and 3 dense features with dimension=16, we can prepare the embeddings list to
    be the list of:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便操作，具有相同嵌入维度的嵌入可以选择堆叠到单个张量中。例如，当我们有1个维度为32的训练嵌入，5个维度为64的本地嵌入和3个维度为16的稠密特征时，我们可以准备嵌入列表为：
- en: '[PRE32]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: batch_size of all input tensors need to be identical.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 所有输入张量的批量大小需要相同。
- en: 'Returns:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: output of fm with flattened and concatenated embeddings as input. Expected to
    be [B, 1].
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 带有展平和连接的嵌入的FM输出作为输入。预期为[B, 1]。
- en: 'Return type:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE33]  ## torchrec.modules.embedding_configs[](#module-torchrec.modules.embedding_configs
    "Permalink to this heading")'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE33]  ## torchrec.modules.embedding_configs[](#module-torchrec.modules.embedding_configs
    "Permalink to this heading")'
- en: '[PRE34]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Bases: `object`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：`object`
- en: '[PRE35]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Bases: [`BaseEmbeddingConfig`](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：[`BaseEmbeddingConfig`](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")
- en: '[PRE49]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Bases: [`BaseEmbeddingConfig`](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：[`BaseEmbeddingConfig`](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")
- en: '[PRE51]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Bases: [`BaseEmbeddingConfig`](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：[`BaseEmbeddingConfig`](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")
- en: '[PRE55]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Bases: `Enum`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：`Enum`
- en: An enumeration.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 一个枚举。
- en: '[PRE60]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Bases: `tuple`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：`tuple`
- en: '[PRE64]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Alias for field number 0
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 字段编号0的别名
- en: '[PRE65]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Alias for field number 2
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 字段编号2的别名
- en: '[PRE66]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Alias for field number 1
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 字段编号1的别名
- en: '[PRE67]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]  ## torchrec.modules.embedding_modules[](#module-torchrec.modules.embedding_modules
    "Permalink to this heading")'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE71]  ## torchrec.modules.embedding_modules[](#module-torchrec.modules.embedding_modules
    "Permalink to this heading")'
- en: '[PRE72]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Bases: [`EmbeddingBagCollectionInterface`](#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface
    "torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface")'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 继承：[`EmbeddingBagCollectionInterface`](#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface
    "torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface")
- en: EmbeddingBagCollection represents a collection of pooled embeddings (EmbeddingBags).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: EmbeddingBagCollection表示池化嵌入（EmbeddingBags）的集合。
- en: 'It processes sparse data in the form of KeyedJaggedTensor with values of the
    form [F X B X L] where:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 它以KeyedJaggedTensor形式处理稀疏数据，其值形式为[F X B X L]，其中：
- en: 'F: features (keys)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F：特征（键）
- en: 'B: batch size'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B：批量大小
- en: 'L: length of sparse features (jagged)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L：稀疏特征的长度（不规则）
- en: 'and outputs a KeyedTensor with values of the form [B * (F * D)] where:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 并输出形式为[B * (F * D)]的KeyedTensor的值，其中：
- en: 'F: features (keys)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F：特征（键）
- en: 'D: each feature’s (key’s) embedding dimension'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D：每个特征（键）的嵌入维度
- en: 'B: batch size'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B：批量大小
- en: 'Parameters:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**tables** (*List**[*[*EmbeddingBagConfig*](#torchrec.modules.embedding_configs.EmbeddingBagConfig
    "torchrec.modules.embedding_configs.EmbeddingBagConfig")*]*) – list of embedding
    tables.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tables**（*List**[*[*EmbeddingBagConfig*](#torchrec.modules.embedding_configs.EmbeddingBagConfig
    "torchrec.modules.embedding_configs.EmbeddingBagConfig")*]*）– 嵌入表的列表。'
- en: '**is_weighted** (*bool*) – whether input KeyedJaggedTensor is weighted.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**is_weighted**（*bool*）- 输入KeyedJaggedTensor是否加权。'
- en: '**device** (*Optional**[**torch.device**]*) – default compute device.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备**（*可选**[**torch.device**]*）- 默认计算设备。'
- en: 'Example:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE73]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Parameters:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**features** ([*KeyedJaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor
    "torchrec.sparse.jagged_tensor.KeyedJaggedTensor")) – KJT of form [F X B X L].'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征**（[*KeyedJaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor
    "torchrec.sparse.jagged_tensor.KeyedJaggedTensor")）- 形式为[F X B X L]的KJT。'
- en: 'Returns:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: KeyedTensor
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: KeyedTensor
- en: '[PRE77]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Bases: `ABC`, `Module`'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`ABC`，`Module`
- en: Interface for EmbeddingBagCollection.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入袋集合的接口。
- en: '[PRE81]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Define the computation performed at every call.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此之后调用，因为前者负责运行注册的钩子，而后者则默默地忽略它们。
- en: '[PRE83]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Bases: [`EmbeddingCollectionInterface`](#torchrec.modules.embedding_modules.EmbeddingCollectionInterface
    "torchrec.modules.embedding_modules.EmbeddingCollectionInterface")'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`EmbeddingCollectionInterface`](#torchrec.modules.embedding_modules.EmbeddingCollectionInterface
    "torchrec.modules.embedding_modules.EmbeddingCollectionInterface")
- en: EmbeddingCollection represents a collection of non-pooled embeddings.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入集合表示一组非池化嵌入。
- en: 'It processes sparse data in the form of KeyedJaggedTensor of the form [F X
    B X L] where:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 它以形式为[F X B X L]的KeyedJaggedTensor处理稀疏数据，其中：
- en: 'F: features (keys)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F：特征（键）
- en: 'B: batch size'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B：批量大小
- en: 'L: length of sparse features (variable)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L：稀疏特征的长度（可变）
- en: 'and outputs Dict[feature (key), JaggedTensor]. Each JaggedTensor contains values
    of the form (B * L) X D where:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 并输出Dict[特征（键），JaggedTensor]。每个JaggedTensor包含形式为(B * L) X D的值，其中：
- en: 'B: batch size'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B：批量大小
- en: 'L: length of sparse features (jagged)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L：稀疏特征的长度（不规则）
- en: 'D: each feature’s (key’s) embedding dimension and lengths are of the form L'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D：每个特征（键）的嵌入维度和长度的形式为L
- en: 'Parameters:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**tables** (*List**[*[*EmbeddingConfig*](#torchrec.modules.embedding_configs.EmbeddingConfig
    "torchrec.modules.embedding_configs.EmbeddingConfig")*]*) – list of embedding
    tables.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表格**（*列表**[*[*嵌入配置*](#torchrec.modules.embedding_configs.EmbeddingConfig
    "torchrec.modules.embedding_configs.EmbeddingConfig")*]*）- 嵌入表格列表。'
- en: '**device** (*Optional**[**torch.device**]*) – default compute device.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备**（*可选**[**torch.device**]*）- 默认计算设备。'
- en: '**need_indices** (*bool*) – if we need to pass indices to the final lookup
    dict.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**need_indices**（*bool*）- 如果我们需要将索引传递给最终查找字典。'
- en: 'Example:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE86]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Parameters:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**features** ([*KeyedJaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor
    "torchrec.sparse.jagged_tensor.KeyedJaggedTensor")) – KJT of form [F X B X L].'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征**（[*KeyedJaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor
    "torchrec.sparse.jagged_tensor.KeyedJaggedTensor")）- 形式为[F X B X L]的KJT。'
- en: 'Returns:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: Dict[str, JaggedTensor]
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 字典[str, JaggedTensor]
- en: '[PRE92]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Bases: `ABC`, `Module`'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`ABC`，`Module`
- en: Interface for EmbeddingCollection.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入集合的接口。
- en: '[PRE96]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Define the computation performed at every call.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此之后调用，因为前者负责运行注册的钩子，而后者则默默地忽略它们。
- en: '[PRE100]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]  ## torchrec.modules.feature_processor[](#module-torchrec.modules.feature_processor
    "Permalink to this heading")'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE104]  ## torchrec.modules.feature_processor[](#module-torchrec.modules.feature_processor
    "Permalink to this heading")'
- en: '[PRE105]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Bases: `Module`'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: Abstract base class for feature processor.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 特征处理器的抽象基类。
- en: '[PRE106]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: Define the computation performed at every call.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此之后调用，因为前者负责运行注册的钩子，而后者则默默地忽略它们。
- en: '[PRE107]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Bases: `Module`'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: Abstract base class for grouped feature processor
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 分组特征处理器的抽象基类
- en: '[PRE109]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Define the computation performed at every call.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此之后调用，因为前者负责运行注册的钩子，而后者则默默地忽略它们。
- en: '[PRE110]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Bases: [`BaseFeatureProcessor`](#torchrec.modules.feature_processor.BaseFeatureProcessor
    "torchrec.modules.feature_processor.BaseFeatureProcessor")'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`BaseFeatureProcessor`](#torchrec.modules.feature_processor.BaseFeatureProcessor
    "torchrec.modules.feature_processor.BaseFeatureProcessor")
- en: Adds position weights to id list features.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 向id列表特征添加位置权重。
- en: 'Parameters:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**max_feature_lengths** (*Dict**[**str**,* *int**]*) – feature name to max_length
    mapping. max_length, a.k.a truncation size, specifies the maximum number of ids
    each sample has. For each feature, its position weight parameter size is max_length.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '**max_feature_lengths**（*字典**[**str**,* *int**]*）- 特征名称到最大长度的映射。max_length，也称为截断大小，指定每个样本具有的最大id数量。对于每个特征，其位置权重参数大小为max_length。'
- en: '[PRE112]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Parameters:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**features** (*Dict**[**str**,* [*JaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor
    "torchrec.sparse.jagged_tensor.JaggedTensor")*]*) – dictionary of keys to JaggedTensor,
    representing the features.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征**（*字典**[**str**,* [*JaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor
    "torchrec.sparse.jagged_tensor.JaggedTensor")*]*）- 键到JaggedTensor的字典，表示特征。'
- en: 'Returns:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: same as input features with weights field being populated.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 与输入特征相同，权重字段已填充。
- en: 'Return type:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Dict[str, [JaggedTensor](torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor
    "torchrec.sparse.jagged_tensor.JaggedTensor")]
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Dict[str，[JaggedTensor](torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor
    "torchrec.sparse.jagged_tensor.JaggedTensor")]
- en: '[PRE113]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Bases: [`BaseGroupedFeatureProcessor`](#torchrec.modules.feature_processor.BaseGroupedFeatureProcessor
    "torchrec.modules.feature_processor.BaseGroupedFeatureProcessor")'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`BaseGroupedFeatureProcessor`](#torchrec.modules.feature_processor.BaseGroupedFeatureProcessor
    "torchrec.modules.feature_processor.BaseGroupedFeatureProcessor")
- en: PositionWeightedProcessor represents a processor to apply position weight to
    a KeyedJaggedTensor.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: PositionWeightedProcessor表示将位置权重应用于KeyedJaggedTensor的处理器。
- en: It can handle both unsharded and sharded input and output corresponding output
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以处理非分片和分片输入以及相应的输出
- en: 'Parameters:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**max_feature_lengths** (*Dict**[**str**,* *int**]*) – Dict of feature_lengths,
    the key is the feature_name and value is length.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**max_feature_lengths**（*Dict**[**str**，* *int**]）- feature_lengths的字典，键是feature_name，值是长度。'
- en: '**device** (*Optional**[**torch.device**]*) – default compute device.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**device**（*Optional**[**torch.device**]）- 默认计算设备。'
- en: 'Example:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE116]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: In unsharded or non-pipelined model, the input features both contain fp_feature
    and non_fp_features, and the output will filter out non_fp features In sharded
    pipelining model, the input features can only contain either none or all feature_processed
    features, since the input feature comes from the input_dist() of ebc which will
    filter out the keys not in the ebc. And the input size is same as output size
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在非分片或非流水线模型中，输入特征同时包含fp_feature和non_fp_features，输出将过滤掉non_fp特征。在分片流水线模型中，输入特征只能包含所有或所有feature_processed特征，因为输入特征来自ebc的input_dist()，该函数将过滤掉不在ebc中的键。输入大小与输出大小相同
- en: 'Parameters:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**features** ([*KeyedJaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor
    "torchrec.sparse.jagged_tensor.KeyedJaggedTensor")) – input features'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '**features**（[*KeyedJaggedTensor*](torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor
    "torchrec.sparse.jagged_tensor.KeyedJaggedTensor")）- 输入特征'
- en: 'Returns:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: KeyedJaggedTensor
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: KeyedJaggedTensor
- en: '[PRE118]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: Return an iterator over module buffers, yielding both the name of the buffer
    as well as the buffer itself.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个模块缓冲区的迭代器，同时生成缓冲区的名称和缓冲区本身。
- en: 'Parameters:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**prefix** (*str*) – prefix to prepend to all buffer names.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**prefix**（*str*）- 要添加到所有缓冲区名称前面的前缀。'
- en: '**recurse** (*bool**,* *optional*) – if True, then yields buffers of this module
    and all submodules. Otherwise, yields only buffers that are direct members of
    this module. Defaults to True.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**recurse**（*bool**，*可选*）- 如果为True，则生成此模块和所有子模块的缓冲区。否则，仅生成直接属于此模块的缓冲区。默认为True。'
- en: '**remove_duplicate** (*bool**,* *optional*) – whether to remove the duplicated
    buffers in the result. Defaults to True.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**remove_duplicate**（*bool**，*可选*）- 是否在结果中删除重复的缓冲区。默认为True。'
- en: 'Yields:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 产出：
- en: '*(str, torch.Tensor)* – Tuple containing the name and buffer'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '*(str，torch.Tensor)* - 包含名称和缓冲区的元组'
- en: 'Example:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE119]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Return a dictionary containing references to the whole state of the module.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 返回包含模块整个状态的字典。
- en: Both parameters and persistent buffers (e.g. running averages) are included.
    Keys are corresponding parameter and buffer names. Parameters and buffers set
    to `None` are not included.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 包括参数和持久缓冲区（例如运行平均值）。键是相应的参数和缓冲区名称。设置为`None`的参数和缓冲区不包括在内。
- en: Note
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The returned object is a shallow copy. It contains references to the module’s
    parameters and buffers.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的对象是一个浅拷贝。它包含对模块参数和缓冲区的引用。
- en: Warning
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: Currently `state_dict()` also accepts positional arguments for `destination`,
    `prefix` and `keep_vars` in order. However, this is being deprecated and keyword
    arguments will be enforced in future releases.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 当前`state_dict()`还接受`destination`，`prefix`和`keep_vars`的位置参数。但是，这将被弃用，并且将在将来的版本中强制使用关键字参数。
- en: Warning
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: Please avoid the use of argument `destination` as it is not designed for end-users.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 请避免使用参数`destination`，因为它不是为最终用户设计的。
- en: 'Parameters:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**destination** (*dict**,* *optional*) – If provided, the state of module will
    be updated into the dict and the same object is returned. Otherwise, an `OrderedDict`
    will be created and returned. Default: `None`.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**destination**（*dict**，*可选*）- 如果提供，则模块的状态将更新到字典中，并返回相同的对象。否则，将创建并返回一个`OrderedDict`。默认值：`None`。'
- en: '**prefix** (*str**,* *optional*) – a prefix added to parameter and buffer names
    to compose the keys in state_dict. Default: `''''`.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**prefix**（*str**，*可选*）- 添加到state_dict中的参数和缓冲区名称以组成键的前缀。默认值：`''''`。'
- en: '**keep_vars** (*bool**,* *optional*) – by default the `Tensor` s returned in
    the state dict are detached from autograd. If it’s set to `True`, detaching will
    not be performed. Default: `False`.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**keep_vars**（*bool**，*可选*）- 默认情况下，state dict中返回的`Tensor`会与autograd分离。如果设置为`True`，则不会执行分离。默认值：`False`。'
- en: 'Returns:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: a dictionary containing a whole state of the module
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 包含模块整个状态的字典
- en: 'Return type:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: dict
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 字典
- en: 'Example:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE121]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]  ## torchrec.modules.lazy_extension[](#module-torchrec.modules.lazy_extension
    "Permalink to this heading")'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE123]  ## torchrec.modules.lazy_extension[](#module-torchrec.modules.lazy_extension
    "Permalink to this heading")'
- en: '[PRE124]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: 'Bases: `LazyModuleMixin`'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`LazyModuleMixin`
- en: This is a temporary extension of LazyModuleMixin to support passing keyword
    arguments to lazy module’s forward method.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这是LazyModuleMixin的临时扩展，支持将关键字参数传递给惰性模块的前向方法。
- en: The long-term plan is to upstream this feature to LazyModuleMixin. Please see
    [https://github.com/pytorch/pytorch/issues/59923](https://github.com/pytorch/pytorch/issues/59923)
    for details.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 长期计划是将此功能上游到LazyModuleMixin。有关详细信息，请参阅[https://github.com/pytorch/pytorch/issues/59923](https://github.com/pytorch/pytorch/issues/59923)。
- en: 'Please see TestLazyModuleExtensionMixin, which contains unit tests that ensure:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅TestLazyModuleExtensionMixin，其中包含确保的单元测试：
- en: LazyModuleExtensionMixin._infer_parameters has source code parity with torch.nn.modules.lazy.LazyModuleMixin._infer_parameters,
    except that the former can accept keyword arguments.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LazyModuleExtensionMixin._infer_parameters与torch.nn.modules.lazy.LazyModuleMixin._infer_parameters具有源代码的一致性，只是前者可以接受关键字参数。
- en: LazyModuleExtensionMixin._call_impl has source code parity with torch.nn.Module._call_impl,
    except that the former can pass keyword arguments to forward pre hooks.”
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LazyModuleExtensionMixin._call_impl的源代码与torch.nn.Module._call_impl具有相同的代码平等性，只是前者可以将关键字参数传递给forward
    pre hooks。
- en: '[PRE125]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: Applies fn recursively to every submodule (as returned by .children()) as well
    as self. Typical use includes initializing the parameters of a model.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 将fn递归地应用于每个子模块（由.children()返回），以及self。典型用法包括初始化模型的参数。
- en: Note
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Calling apply() on an uninitialized lazy-module will result in an error. User
    is required to initialize a lazy-module (by doing a dummy forward pass) before
    calling apply() on the lazy-module.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在未初始化的懒惰模块上调用apply()将导致错误。用户需要在对懒惰模块调用apply()之前初始化懒惰模块（通过进行虚拟前向传递）。
- en: 'Parameters:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**fn** (*torch.nn.Module -> None*) – function to be applied to each submodule.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '**fn**（*torch.nn.Module -> None*） - 要应用于每个子模块的函数。'
- en: 'Returns:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: self
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: self
- en: 'Return type:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.nn.Module
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: torch.nn.Module
- en: 'Example:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE126]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: Attaches a function to a module, which will be applied recursively to every
    submodule (as returned by .children()) of the module as well as the module itself
    right after the first forward pass (i.e. after all submodules and parameters have
    been initialized).
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个函数附加到一个模块，该函数将递归地应用于模块的每个子模块（由.children()返回）以及模块本身，就在第一次前向传递之后（即在所有子模块和参数初始化之后）。
- en: Typical use includes initializing the numerical value of the parameters of a
    lazy module (i.e. modules inherited from LazyModuleMixin).
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 典型用法包括初始化懒惰模块的参数的数值（即从LazyModuleMixin继承的模块）。
- en: Note
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: lazy_apply() can be used on both lazy and non-lazy modules.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: lazy_apply()可用于懒惰和非懒惰模块。
- en: 'Parameters:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**module** (*torch.nn.Module*) – module to recursively apply fn on.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**module**（*torch.nn.Module*） - 递归应用fn的模块。'
- en: '**fn** (*Callable**[**[**torch.nn.Module**]**,* *None**]*) – function to be
    attached to module and later be applied to each submodule of module and the module
    itself.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**fn**（*Callable**[**[**torch.nn.Module**]**,* *None**]*） - 要附加到模块并稍后应用于模块的每个子模块和模块本身的函数。'
- en: 'Returns:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: module with fn attached.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 附加了fn的模块。
- en: 'Return type:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.nn.Module
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: torch.nn.Module
- en: 'Example:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE128]  ## torchrec.modules.mlp[](#module-torchrec.modules.mlp "Permalink
    to this heading")'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE128]  ## torchrec.modules.mlp[](#module-torchrec.modules.mlp "Permalink
    to this heading")'
- en: '[PRE129]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'Bases: `Module`'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: Applies a stack of Perceptron modules sequentially (i.e. Multi-Layer Perceptron).
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 按顺序应用一堆感知器模块（即多层感知器）。
- en: 'Parameters:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**in_size** (*int*) – in_size of the input.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**in_size**（*int*） - 输入的in_size。'
- en: '**layer_sizes** (*List**[**int**]*) – out_size of each Perceptron module.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**layer_sizes**（*List**[**int**]*） - 每个感知器模块的out_size。'
- en: '**bias** (*bool*) – if set to False, the layer will not learn an additive bias.
    Default: True.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bias**（*bool*） - 如果设置为False，则该层将不会学习附加偏差。默认值：True。'
- en: '**activation** (*str**,* *Union**[**Callable**[**[**]**,* *torch.nn.Module**]**,*
    *torch.nn.Module**,* *Callable**[**[**torch.Tensor**]**,* *torch.Tensor**]**]*)
    – the activation function to apply to the output of linear transformation of each
    Perceptron module. If activation is a str, we currently only support the follow
    strings, as “relu”, “sigmoid”, and “swish_layernorm”. If activation is a Callable[[],
    torch.nn.Module], activation() will be called once per Perceptron module to generate
    the activation module for that Perceptron module, and the parameters won’t be
    shared between those activation modules. One use case is when all the activation
    modules share the same constructor arguments, but don’t share the actual module
    parameters. Default: torch.relu.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**activation**（*str**,* *Union**[**Callable**[**[**]**,* *torch.nn.Module**]**,*
    *torch.nn.Module**,* *Callable**[**[**torch.Tensor**]**,* *torch.Tensor**]**]*）
    - 要应用于每个感知器模块的线性变换输出的激活函数。如果激活是一个str，我们目前只支持以下字符串，如“relu”，“sigmoid”和“swish_layernorm”。如果激活是一个Callable[[],
    torch.nn.Module]，则会为每个感知器模块调用activation()一次，以生成该感知器模块的激活模块，并且这些激活模块之间不会共享参数。一个用例是当所有激活模块共享相同的构造函数参数，但不共享实际的模块参数时。默认值：torch.relu。'
- en: '**device** (*Optional**[**torch.device**]*) – default compute device.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**device**（*Optional**[**torch.device**]*） - 默认计算设备。'
- en: 'Example:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE130]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'Parameters:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – tensor of shape (B, I) where I is number of elements
    in each input sample.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*torch.Tensor*） - 形状为(B, I)的张量，其中I是每个输入样本中的元素数量。'
- en: 'Returns:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tensor of shape (B, O) where O is out_size of the last Perceptron module.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为(B, O)的张量，其中O是最后一个感知器模块的out_size。
- en: 'Return type:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE132]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'Bases: `Module`'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: Applies a linear transformation and activation.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 应用线性变换和激活。
- en: 'Parameters:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**in_size** (*int*) – number of elements in each input sample.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**in_size**（*int*） - 每个输入样本中的元素数量。'
- en: '**out_size** (*int*) – number of elements in each output sample.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**out_size**（*int*） - 每个输出样本中的元素数量。'
- en: '**bias** (*bool*) – if set to `False`, the layer will not learn an additive
    bias. Default: `True`.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bias**（*bool*） - 如果设置为`False`，该层将不会学习附加偏差。默认值：`True`。'
- en: '**activation** (*Union**[**torch.nn.Module**,* *Callable**[**[**torch.Tensor**]**,*
    *torch.Tensor**]**]*) – the activation function to apply to the output of linear
    transformation. Default: torch.relu.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**activation**（*Union**[**torch.nn.Module**,* *Callable**[**[**torch.Tensor**]**,*
    *torch.Tensor**]**]*） - 要应用于线性变换输出的激活函数。默认值：torch.relu。'
- en: '**device** (*Optional**[**torch.device**]*) – default compute device.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**device**（*Optional**[**torch.device**]*） - 默认计算设备。'
- en: 'Example:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE134]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'Parameters:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*torch.Tensor*) – tensor of shape (B, I) where I is number of elements
    in each input sample.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*torch.Tensor*） - 形状为(B, I)的张量，其中I是每个输入样本中的元素数量。'
- en: 'Returns:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tensor of shape (B, O) where O is number of elements per
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为(B, O)的张量，其中O是每个输入样本中的元素数量。
- en: channel in each output sample (i.e. out_size).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 每个输出样本中的通道（即out_size）。
- en: 'Return type:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: torch.Tensor
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: torch.Tensor
- en: '[PRE136]  ## torchrec.modules.utils[](#module-torchrec.modules.utils "Permalink
    to this heading")'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE136]  ## torchrec.modules.utils[](#module-torchrec.modules.utils "Permalink
    to this heading")'
- en: '[PRE137]'
  id: totrans-452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: Verify that the out_features of a given module or a list of modules matches
    the specified number. If a list of modules or a ModuleList is given, recursively
    check all the submodules.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 验证给定模块或模块列表的out_features是否与指定的数字匹配。如果给定模块列表或ModuleList，则递归检查所有子模块。
- en: '[PRE138]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: Given a single module, construct a (nested) ModuleList of size of sizes by making
    copies of the provided module and reinitializing the Linear layers.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 给定单个模块，通过复制提供的模块并重新初始化线性层来构造大小为sizes的（嵌套的）ModuleList。
- en: '[PRE140]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: torchrec.modules.mc_modules[](#torchrec-modules-mc-modules "Permalink to this
    heading")
  id: totrans-461
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: torchrec.modules.mc_modules[](#torchrec-modules-mc-modules "此标题的永久链接")
- en: '[PRE144]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'Bases: [`MCHEvictionPolicy`](#torchrec.modules.mc_modules.MCHEvictionPolicy
    "torchrec.modules.mc_modules.MCHEvictionPolicy")'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`MCHEvictionPolicy`](#torchrec.modules.mc_modules.MCHEvictionPolicy "torchrec.modules.mc_modules.MCHEvictionPolicy")
- en: '[PRE145]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: 'Args: history_metadata (Dict[str, torch.Tensor]): history metadata dict additional_ids
    (torch.Tensor): additional ids to be used as part of history unique_inverse_mapping
    (torch.Tensor): torch.unique inverse mapping generated from'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：history_metadata（Dict[str，torch.Tensor]）：历史元数据字典 additional_ids（torch.Tensor）：要用作历史的一部分的额外ids
    unique_inverse_mapping（torch.Tensor）：从torch.unique生成的逆映射
- en: torch.cat[history_accumulator, additional_ids]. used to map history metadata
    tensor indices to their coalesced tensor indices.
  id: totrans-466
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用torch.cat[history_accumulator, additional_ids]将历史元数据张量索引映射到它们的合并张量索引。
- en: Coalesce metadata history buffers and return dict of processed metadata tensors.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 合并元数据历史缓冲区并返回处理后的元数据张量字典。
- en: '[PRE146]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: 'Args: current_iter (int): current iteration incoming_ids (torch.Tensor): incoming
    ids history_metadata (Dict[str, torch.Tensor]): history metadata dict'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：current_iter（int）：当前迭代 incoming_ids（torch.Tensor）：传入的ids history_metadata（Dict[str，torch.Tensor]）：历史元数据字典
- en: Compute and record metadata based on incoming ids
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 根据传入的ids计算并记录元数据
- en: for the implemented eviction policy.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实现的驱逐策略。
- en: '[PRE148]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'Args:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: 'Returns Tuple of (evicted_indices, selected_new_indices) where:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 返回（被驱逐的索引，选定的新索引）的元组：
- en: evicted_indices are indices in the mch map to be evicted, and selected_new_indices
    are the indices of the ids in the coalesced history that are to be added to the
    mch.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 被驱逐的索引是要被驱逐的mch映射中的索引，而selected_new_indices是要添加到mch中的合并历史中ids的索引。
- en: '[PRE149]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: 'Bases: [`MCHEvictionPolicy`](#torchrec.modules.mc_modules.MCHEvictionPolicy
    "torchrec.modules.mc_modules.MCHEvictionPolicy")'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`MCHEvictionPolicy`](#torchrec.modules.mc_modules.MCHEvictionPolicy "torchrec.modules.mc_modules.MCHEvictionPolicy")
- en: '[PRE150]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: 'Args: history_metadata (Dict[str, torch.Tensor]): history metadata dict additional_ids
    (torch.Tensor): additional ids to be used as part of history unique_inverse_mapping
    (torch.Tensor): torch.unique inverse mapping generated from'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：history_metadata（Dict[str，torch.Tensor]）：历史元数据字典 additional_ids（torch.Tensor）：要用作历史的一部分的额外ids
    unique_inverse_mapping（torch.Tensor）：从torch.unique生成的逆映射
- en: torch.cat[history_accumulator, additional_ids]. used to map history metadata
    tensor indices to their coalesced tensor indices.
  id: totrans-481
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用torch.cat[history_accumulator, additional_ids]将历史元数据张量索引映射到它们的合并张量索引。
- en: Coalesce metadata history buffers and return dict of processed metadata tensors.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 合并元数据历史缓冲区并返回处理后的元数据张量字典。
- en: '[PRE151]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 'Args: current_iter (int): current iteration incoming_ids (torch.Tensor): incoming
    ids history_metadata (Dict[str, torch.Tensor]): history metadata dict'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：current_iter（int）：当前迭代 incoming_ids（torch.Tensor）：传入的ids history_metadata（Dict[str，torch.Tensor]）：历史元数据字典
- en: Compute and record metadata based on incoming ids
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 根据传入的ids计算并记录元数据
- en: for the implemented eviction policy.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实现的驱逐策略。
- en: '[PRE153]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: 'Args:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: 'Returns Tuple of (evicted_indices, selected_new_indices) where:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 返回（被驱逐的索引，选定的新索引）的元组：
- en: evicted_indices are indices in the mch map to be evicted, and selected_new_indices
    are the indices of the ids in the coalesced history that are to be added to the
    mch.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 被驱逐的索引是要被驱逐的mch映射中的索引，而selected_new_indices是要添加到mch中的合并历史中ids的索引。
- en: '[PRE154]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: 'Bases: [`MCHEvictionPolicy`](#torchrec.modules.mc_modules.MCHEvictionPolicy
    "torchrec.modules.mc_modules.MCHEvictionPolicy")'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`MCHEvictionPolicy`](#torchrec.modules.mc_modules.MCHEvictionPolicy "torchrec.modules.mc_modules.MCHEvictionPolicy")
- en: '[PRE155]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: 'Args: history_metadata (Dict[str, torch.Tensor]): history metadata dict additional_ids
    (torch.Tensor): additional ids to be used as part of history unique_inverse_mapping
    (torch.Tensor): torch.unique inverse mapping generated from'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：history_metadata（Dict[str，torch.Tensor]）：历史元数据字典 additional_ids（torch.Tensor）：要用作历史的一部分的额外ids
    unique_inverse_mapping（torch.Tensor）：从torch.unique生成的逆映射
- en: torch.cat[history_accumulator, additional_ids]. used to map history metadata
    tensor indices to their coalesced tensor indices.
  id: totrans-496
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用torch.cat[history_accumulator, additional_ids]将历史元数据张量索引映射到它们的合并张量索引。
- en: Coalesce metadata history buffers and return dict of processed metadata tensors.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 合并元数据历史缓冲区并返回处理后的元数据张量字典。
- en: '[PRE156]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: 'Args: current_iter (int): current iteration incoming_ids (torch.Tensor): incoming
    ids history_metadata (Dict[str, torch.Tensor]): history metadata dict'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：current_iter（int）：当前迭代 incoming_ids（torch.Tensor）：传入的ids history_metadata（Dict[str，torch.Tensor]）：历史元数据字典
- en: Compute and record metadata based on incoming ids
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 根据传入的ids计算并记录元数据
- en: for the implemented eviction policy.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实现的驱逐策略。
- en: '[PRE158]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: 'Args:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: 'Returns Tuple of (evicted_indices, selected_new_indices) where:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 返回（被驱逐的索引，选定的新索引）的元组：
- en: evicted_indices are indices in the mch map to be evicted, and selected_new_indices
    are the indices of the ids in the coalesced history that are to be added to the
    mch.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 被驱逐的索引是要被驱逐的mch映射中的索引，而selected_new_indices是要添加到mch中的合并历史中ids的索引。
- en: '[PRE159]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: 'Bases: `ABC`'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`ABC`
- en: '[PRE160]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: 'Args: history_metadata (Dict[str, torch.Tensor]): history metadata dict additional_ids
    (torch.Tensor): additional ids to be used as part of history unique_inverse_mapping
    (torch.Tensor): torch.unique inverse mapping generated from'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：history_metadata（Dict[str，torch.Tensor]）：历史元数据字典 additional_ids（torch.Tensor）：要用作历史的一部分的额外ids
    unique_inverse_mapping（torch.Tensor）：从torch.unique生成的逆映射
- en: torch.cat[history_accumulator, additional_ids]. used to map history metadata
    tensor indices to their coalesced tensor indices.
  id: totrans-511
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用torch.cat[history_accumulator, additional_ids]将历史元数据张量索引映射到它们的合并张量索引。
- en: Coalesce metadata history buffers and return dict of processed metadata tensors.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 合并元数据历史缓冲区并返回处理后的元数据张量字典。
- en: '[PRE161]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: 'Args: current_iter (int): current iteration incoming_ids (torch.Tensor): incoming
    ids history_metadata (Dict[str, torch.Tensor]): history metadata dict'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：current_iter（int）：当前迭代incoming_ids（torch.Tensor）：传入的ids history_metadata（Dict[str，torch.Tensor]）：历史元数据字典
- en: Compute and record metadata based on incoming ids
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 基于传入的ids计算和记录元数据
- en: for the implemented eviction policy.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 用于实现驱逐策略。
- en: '[PRE163]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: 'Args:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: 'Returns Tuple of (evicted_indices, selected_new_indices) where:'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 返回（驱逐的索引，选择的新索引）的元组，其中：
- en: evicted_indices are indices in the mch map to be evicted, and selected_new_indices
    are the indices of the ids in the coalesced history that are to be added to the
    mch.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 被驱逐的索引是要被驱逐的mch映射中的索引，而选择的新索引是要添加到mch中的合并历史中的id的索引。
- en: '[PRE164]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: 'Bases: `tuple`'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 基础：`tuple`
- en: '[PRE165]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: Alias for field number 2
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 字段编号2的别名
- en: '[PRE166]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: Alias for field number 1
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 字段编号1的别名
- en: '[PRE167]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: Alias for field number 0
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 字段编号0的别名
- en: '[PRE168]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE168]'
- en: 'Bases: [`ManagedCollisionModule`](#torchrec.modules.mc_modules.ManagedCollisionModule
    "torchrec.modules.mc_modules.ManagedCollisionModule")'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 基础：[`ManagedCollisionModule`](#torchrec.modules.mc_modules.ManagedCollisionModule
    "torchrec.modules.mc_modules.ManagedCollisionModule")
- en: ZCH / MCH managed collision module
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: ZCH / MCH管理的碰撞模块
- en: 'Parameters:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**zch_size** (*int*) – range of output ids, within [output_size_offset, output_size_offset
    + zch_size - 1)'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**zch_size**（*int*）-输出id的范围，在[output_size_offset，output_size_offset + zch_size
    - 1]内'
- en: '**device** (*torch.device*) – device on which this module will be executed'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**device**（*torch.device*）-将执行此模块的设备'
- en: '**eviction_policy** (*eviction policy*) – eviction policy to be used'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**eviction_policy**（*驱逐策略*）-要使用的驱逐策略'
- en: '**eviction_interval** (*int*) – interval of eviction policy is triggered'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**eviction_interval**（*int*）-触发驱逐策略的间隔'
- en: '**input_hash_size** (*int*) – input feature id range, will be passed to input_hash_func
    as second arg'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**input_hash_size**（*int*）-输入特征id范围，将作为第二个参数传递给input_hash_func'
- en: '**input_hash_func** (*Optional**[**Callable**]*) – function used to generate
    hashes for input features. This function is typically used to drive uniform distribution
    over range same or greater than input data'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**input_hash_func**（*可选**[**Callable**]）-用于为输入特征生成哈希的函数。此函数通常用于在与输入数据相同或更大的范围内驱动均匀分布'
- en: '**mch_size** (*Optional**[**int**]*) – size of residual output (ie. legacy
    MCH), experimental feature. Ids are internally shifted by output_size_offset +
    zch_output_range'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mch_size**（*可选**[**int**]）-残余输出的大小（即传统MCH），实验性功能。 Ids在内部移位为output_size_offset
    + zch_output_range'
- en: '**mch_hash_func** (*Optional**[**Callable**]*) – function used to generate
    hashes for residual feature. will hash down to mch_size.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mch_hash_func**（*可选**[**Callable**]）-用于为残余特征生成哈希的函数。将哈希降至mch_size。'
- en: '**output_global_offset** (*int*) – offset of the output id for output range,
    typically only used in sharding applications.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**output_global_offset**（*int*）-输出范围的输出id的偏移量，通常仅在分片应用程序中使用。'
- en: '[PRE169]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: Returns None if no eviction should be done this iteration. Otherwise, return
    ids of slots to reset. On eviction, this module should reset its state for those
    slots, with the assumptionn that the downstream module will handle this properly.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 如果此迭代不应进行驱逐，则返回None。否则，返回要重置的插槽的id。在驱逐时，此模块应为这些插槽重置其状态，并假设下游模块将正确处理此操作。
- en: '[PRE170]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: 'Args: feature (JaggedTensor]): feature representation :returns: modified JT
    :rtype: Dict[str, JaggedTensor]'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：feature（JaggedTensor]）：特征表示：返回：修改后的JT：rtype：Dict[str，JaggedTensor]
- en: '[PRE171]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: Returns numerical range of input, for sharding info
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 返回输入的数字范围，用于分片信息
- en: '[PRE172]'
  id: totrans-549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: Returns numerical range of output, for validation vs. downstream embedding lookups
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 返回输出的数字范围，用于验证与下游嵌入查找
- en: '[PRE173]'
  id: totrans-551
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: Used for creating local MC modules for RW sharding, hack for now
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 用于为RW分片创建本地MC模块，现在是一个hack
- en: '[PRE176]'
  id: totrans-555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE178]'
- en: 'Bases: `Module`'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 基础：`Module`
- en: ManagedCollisionCollection represents a collection of managed collision modules.
    The inputs passed to the MCC will be remapped by the managed collision modules
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: ManagedCollisionCollection表示一组受管理的碰撞模块。传递给MCC的输入将由受管理的碰撞模块重新映射
- en: and returned.
  id: totrans-560
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并返回。
- en: 'Parameters:'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**managed_collision_modules** (*Dict**[**str**,* [*ManagedCollisionModule*](#torchrec.modules.mc_modules.ManagedCollisionModule
    "torchrec.modules.mc_modules.ManagedCollisionModule")*]*) – Dict of managed collision
    modules'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**managed_collision_modules**（*Dict**[**str**,* [*ManagedCollisionModule*](#torchrec.modules.mc_modules.ManagedCollisionModule
    "torchrec.modules.mc_modules.ManagedCollisionModule")*]）-受管理的碰撞模块的字典'
- en: '**embedding_confgs** (*List**[*[*BaseEmbeddingConfig*](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")*]*) – List of embedding
    configs, for each table with a managed collsion module'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**embedding_confgs**（*List**[*[*BaseEmbeddingConfig*](#torchrec.modules.embedding_configs.BaseEmbeddingConfig
    "torchrec.modules.embedding_configs.BaseEmbeddingConfig")*]）-每个具有受管理碰撞模块的表的嵌入配置列表'
- en: '[PRE179]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-565
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE181]'
- en: Define the computation performed at every call.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用“Module”实例，而不是这样做，因为前者负责运行注册的钩子，而后者则会默默地忽略它们。
- en: '[PRE182]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-572
  prefs: []
  type: TYPE_PRE
  zh: '[PRE183]'
- en: 'Bases: `Module`'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 基础：`Module`
- en: Abstract base class for ManagedCollisionModule. Maps input ids to range [0,
    max_output_id).
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: ManagedCollisionModule的抽象基类。将输入id映射到范围[0，max_output_id)。
- en: 'Parameters:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**max_output_id** (*int*) – Max output value of remapped ids.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**max_output_id**（*int*）-重新映射的id的最大输出值。'
- en: '**input_hash_size** (*int*) – Max value of input range i.e. [0, input_hash_size)'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**input_hash_size**（*int*）-输入范围的最大值，即[0，input_hash_size]'
- en: '**remapping_range_start_index** (*int*) – Relative start index of remapping
    range'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**remapping_range_start_index**（*int*）-重新映射范围的相对起始索引'
- en: '**device** (*torch.device*) – default compute device.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**device**（*torch.device*）-默认计算设备。'
- en: 'Example::'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: jt = JaggedTensor(…) mcm = ManagedCollisionModule(…) mcm_jt = mcm(fp)
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: jt = JaggedTensor(…) mcm = ManagedCollisionModule(…) mcm_jt = mcm(fp)
- en: '[PRE184]'
  id: totrans-582
  prefs: []
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: Returns None if no eviction should be done this iteration. Otherwise, return
    ids of slots to reset. On eviction, this module should reset its state for those
    slots, with the assumptionn that the downstream module will handle this properly.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 如果本次迭代不应进行驱逐，则返回None。否则，返回要重置的插槽的ID。在驱逐时，此模块应为这些插槽重置其状态，假设下游模块将正确处理此操作。
- en: '[PRE186]'
  id: totrans-585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: Define the computation performed at every call.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行注册的钩子，而后者会默默地忽略它们。
- en: '[PRE187]'
  id: totrans-590
  prefs: []
  type: TYPE_PRE
  zh: '[PRE187]'
- en: Returns numerical range of input, for sharding info
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 返回输入的数值范围，用于分片信息
- en: '[PRE188]'
  id: totrans-592
  prefs: []
  type: TYPE_PRE
  zh: '[PRE188]'
- en: Returns numerical range of output, for validation vs. downstream embedding lookups
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 返回输出的数值范围，用于验证与下游嵌入查找的比较
- en: '[PRE189]'
  id: totrans-594
  prefs: []
  type: TYPE_PRE
  zh: '[PRE189]'
- en: '[PRE190]'
  id: totrans-595
  prefs: []
  type: TYPE_PRE
  zh: '[PRE190]'
- en: Used for creating local MC modules for RW sharding, hack for now
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 用于为RW分片创建本地MC模块，目前是一个hack
- en: '[PRE191]'
  id: totrans-597
  prefs: []
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '[PRE192]'
  id: totrans-598
  prefs: []
  type: TYPE_PRE
  zh: '[PRE192]'
- en: Applies an MC method to a dictionary of JaggedTensors, returning the updated
    dictionary with same ordering
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 将MC方法应用于JaggedTensors字典，返回具有相同顺序的更新字典
- en: '[PRE193]'
  id: totrans-600
  prefs: []
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-601
  prefs: []
  type: TYPE_PRE
  zh: '[PRE194]'
- en: torchrec.modules.mc_embedding_modules[](#torchrec-modules-mc-embedding-modules
    "Permalink to this heading")
  id: totrans-602
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: torchrec.modules.mc_embedding_modules[](#torchrec-modules-mc-embedding-modules
    "Permalink to this heading")
- en: '[PRE195]'
  id: totrans-603
  prefs: []
  type: TYPE_PRE
  zh: '[PRE195]'
- en: 'Bases: `Module`'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：`Module`
- en: BaseManagedCollisionEmbeddingCollection represents a EC/EBC module and a set
    of managed collision modules. The inputs into the MC-EC/EBC will first be modified
    by the managed collision module before being passed into the embedding collection.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: BaseManagedCollisionEmbeddingCollection代表一个EC/EBC模块和一组管理的冲突模块。MC-EC/EBC的输入将首先通过管理的冲突模块进行修改，然后传递到嵌入集合中。
- en: 'Parameters:'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**embedding_module** – EmbeddingCollection to lookup embeddings'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**embedding_module** – 用于查找嵌入的EmbeddingCollection'
- en: '**managed_collision_modules** – Dict of managed collision modules'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**managed_collision_modules** – 管理冲突模块的字典'
- en: '**return_remapped_features** (*bool*) – whether to return remapped input features
    in addition to embeddings'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**return_remapped_features** (*bool*) – 是否返回重新映射的输入特征以及嵌入'
- en: '[PRE196]'
  id: totrans-610
  prefs: []
  type: TYPE_PRE
  zh: '[PRE196]'
- en: Define the computation performed at every call.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 定义每次调用时执行的计算。
- en: Should be overridden by all subclasses.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 应该被所有子类覆盖。
- en: Note
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the registered hooks while the latter silently ignores them.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行注册的钩子，而后者会默默地忽略它们。
- en: '[PRE197]'
  id: totrans-615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE197]'
- en: '[PRE198]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: 'Bases: [`BaseManagedCollisionEmbeddingCollection`](#torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection
    "torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection")'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`BaseManagedCollisionEmbeddingCollection`](#torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection
    "torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection")
- en: ManagedCollisionEmbeddingBagCollection represents a EmbeddingBagCollection module
    and a set of managed collision modules. The inputs into the MC-EBC will first
    be modified by the managed collision module before being passed into the embedding
    bag collection.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: ManagedCollisionEmbeddingBagCollection代表一个EmbeddingBagCollection模块和一组管理的冲突模块。MC-EBC的输入将首先通过管理的冲突模块进行修改，然后传递到嵌入袋集合中。
- en: For details of input and output types, see EmbeddingBagCollection
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 有关输入和输出类型的详细信息，请参见EmbeddingBagCollection
- en: 'Parameters:'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**embedding_module** – EmbeddingBagCollection to lookup embeddings'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**embedding_module** – 用于查找嵌入的EmbeddingBagCollection'
- en: '**managed_collision_modules** – Dict of managed collision modules'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**managed_collision_modules** – 管理冲突模块的字典'
- en: '**return_remapped_features** (*bool*) – whether to return remapped input features
    in addition to embeddings'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**return_remapped_features** (*bool*) – 是否返回重新映射的输入特征以及嵌入'
- en: '[PRE199]'
  id: totrans-624
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: 'Bases: [`BaseManagedCollisionEmbeddingCollection`](#torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection
    "torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection")'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 基类：[`BaseManagedCollisionEmbeddingCollection`](#torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection
    "torchrec.modules.mc_embedding_modules.BaseManagedCollisionEmbeddingCollection")
- en: ManagedCollisionEmbeddingCollection represents a EmbeddingCollection module
    and a set of managed collision modules. The inputs into the MC-EC will first be
    modified by the managed collision module before being passed into the embedding
    collection.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: ManagedCollisionEmbeddingCollection代表一个EmbeddingCollection模块和一组管理的冲突模块。MC-EC的输入将首先通过管理的冲突模块进行修改，然后传递到嵌入集合中。
- en: For details of input and output types, see EmbeddingCollection
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 有关输入和输出类型的详细信息，请参见EmbeddingCollection
- en: 'Parameters:'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**embedding_module** – EmbeddingCollection to lookup embeddings'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**embedding_module** – 用于查找嵌入的EmbeddingCollection'
- en: '**managed_collision_modules** – Dict of managed collision modules'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**managed_collision_modules** – 管理冲突模块的字典'
- en: '**return_remapped_features** (*bool*) – whether to return remapped input features
    in addition to embeddings'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**return_remapped_features** (*bool*) – 是否返回重新映射的输入特征以及嵌入'
- en: '[PRE201]'
  id: totrans-633
  prefs: []
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-634
  prefs: []
  type: TYPE_PRE
  zh: '[PRE202]'
