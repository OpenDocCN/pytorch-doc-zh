["```py\nclass torchtext.transforms.SentencePieceTokenizer(sp_model_path: str)\u00b6\n```", "```py\n>>> from torchtext.transforms import SentencePieceTokenizer\n>>> transform = SentencePieceTokenizer(\"spm_model\")\n>>> transform([\"hello world\", \"attention is all you need!\"]) \n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.GPT2BPETokenizer(encoder_json_path: str, vocab_bpe_path: str, return_tokens: bool = False)\u00b6\n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.CLIPTokenizer(merges_path: str, encoder_json_path: Optional[str] = None, num_merges: Optional[int] = None, return_tokens: bool = False)\u00b6\n```", "```py\n>>> from torchtext.transforms import CLIPTokenizer\n>>> MERGES_FILE = \"http://download.pytorch.org/models/text/clip_merges.bpe\"\n>>> ENCODER_FILE = \"http://download.pytorch.org/models/text/clip_encoder.json\"\n>>> tokenizer = CLIPTokenizer(merges_path=MERGES_FILE, encoder_json_path=ENCODER_FILE)\n>>> tokenizer(\"the quick brown fox jumped over the lazy dog\") \n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.RegexTokenizer(patterns_list)\u00b6\n```", "```py\n>>> import torch\n>>> from torchtext.transforms import RegexTokenizer\n>>> test_sample = 'Basic Regex Tokenization for a Line of Text'\n>>> patterns_list = [\n (r''', ' '  '),\n (r'\"', '')]\n>>> reg_tokenizer = RegexTokenizer(patterns_list)\n>>> jit_reg_tokenizer = torch.jit.script(reg_tokenizer)\n>>> tokens = jit_reg_tokenizer(test_sample) \n```", "```py\n>>> import torch\n>>> from torchtext.transforms import RegexTokenizer\n>>> test_sample = 'Basic.Regex,Tokenization_for+a..Line,,of  Text'\n>>> patterns_list = [\n (r'[,._+ ]+', r' ')]\n>>> reg_tokenizer = RegexTokenizer(patterns_list)\n>>> jit_reg_tokenizer = torch.jit.script(reg_tokenizer)\n>>> tokens = jit_reg_tokenizer(test_sample) \n```", "```py\nforward(line: str) \u2192 List[str]\u00b6\n```", "```py\nclass torchtext.transforms.BERTTokenizer(vocab_path: str, do_lower_case: bool = True, strip_accents: Optional[bool] = None, return_tokens=False, never_split: Optional[List[str]] = None)\u00b6\n```", "```py\n>>> from torchtext.transforms import BERTTokenizer\n>>> VOCAB_FILE = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n>>> tokenizer = BERTTokenizer(vocab_path=VOCAB_FILE, do_lower_case=True, return_tokens=True)\n>>> tokenizer(\"Hello World, How are you!\") # single sentence input\n>>> tokenizer([\"Hello World\",\"How are you!\"]) # batch input \n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.VocabTransform(vocab: Vocab)\u00b6\n```", "```py\n>>> import torch\n>>> from torchtext.vocab import vocab\n>>> from torchtext.transforms import VocabTransform\n>>> from collections import OrderedDict\n>>> vocab_obj = vocab(OrderedDict([('a', 1), ('b', 1), ('c', 1)]))\n>>> vocab_transform = VocabTransform(vocab_obj)\n>>> output = vocab_transform([['a','b'],['a','b','c']])\n>>> jit_vocab_transform = torch.jit.script(vocab_transform) \n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.ToTensor(padding_value: Optional[int] = None, dtype: dtype = torch.int64)\u00b6\n```", "```py\nforward(input: Any) \u2192 Tensor\u00b6\n```", "```py\nclass torchtext.transforms.LabelToIndex(label_names: Optional[List[str]] = None, label_path: Optional[str] = None, sort_names=False)\u00b6\n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.Truncate(max_seq_len: int)\u00b6\n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.AddToken(token: Union[int, str], begin: bool = True)\u00b6\n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.Sequential(*args: Module)\u00b6\n```", "```py\nclass torchtext.transforms.Sequential(arg: OrderedDict[str, Module])\n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.PadTransform(max_length: int, pad_value: int)\u00b6\n```", "```py\nforward(x: Tensor) \u2192 Tensor\u00b6\n```", "```py\nclass torchtext.transforms.StrToIntTransform\u00b6\n```", "```py\nforward(input: Any) \u2192 Any\u00b6\n```", "```py\nclass torchtext.transforms.CharBPETokenizer(bpe_encoder_path: str, bpe_merges_path: str, return_tokens: bool = False, unk_token: Optional[str] = None, suffix: Optional[str] = None, special_tokens: Optional[List[str]] = None)\u00b6\n```", "```py\nforward(input: Union[str, List[str]]) \u2192 Union[List, List[List]]\u00b6\n```"]