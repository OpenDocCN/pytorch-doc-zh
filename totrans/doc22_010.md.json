["```py\n>>> x=torch.empty(5,7,3)\n>>> y=torch.empty(5,7,3)\n# same shapes are always broadcastable (i.e. the above rules always hold)\n\n>>> x=torch.empty((0,))\n>>> y=torch.empty(2,2)\n# x and y are not broadcastable, because x does not have at least 1 dimension\n\n# can line up trailing dimensions\n>>> x=torch.empty(5,3,4,1)\n>>> y=torch.empty(  3,1,1)\n# x and y are broadcastable.\n# 1st trailing dimension: both have size 1\n# 2nd trailing dimension: y has size 1\n# 3rd trailing dimension: x size == y size\n# 4th trailing dimension: y dimension doesn't exist\n\n# but:\n>>> x=torch.empty(5,2,4,1)\n>>> y=torch.empty(  3,1,1)\n# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3 \n```", "```py\n# can line up trailing dimensions to make reading easier\n>>> x=torch.empty(5,1,4,1)\n>>> y=torch.empty(  3,1,1)\n>>> (x+y).size()\ntorch.Size([5, 3, 4, 1])\n\n# but not necessary:\n>>> x=torch.empty(1)\n>>> y=torch.empty(3,1,7)\n>>> (x+y).size()\ntorch.Size([3, 1, 7])\n\n>>> x=torch.empty(5,2,4,1)\n>>> y=torch.empty(3,1,1)\n>>> (x+y).size()\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1 \n```", "```py\n>>> x=torch.empty(5,3,4,1)\n>>> y=torch.empty(3,1,1)\n>>> (x.add_(y)).size()\ntorch.Size([5, 3, 4, 1])\n\n# but:\n>>> x=torch.empty(1,3,1)\n>>> y=torch.empty(3,1,7)\n>>> (x.add_(y)).size()\nRuntimeError: The expanded size of the tensor (1) must match the existing size (7) at non-singleton dimension 2. \n```", "```py\n>>> torch.add(torch.ones(4,1), torch.randn(4)) \n```", "```py\n>>> torch.utils.backcompat.broadcast_warning.enabled=True\n>>> torch.add(torch.ones(4,1), torch.ones(4))\n__main__:1: UserWarning: self and other do not have the same shape, but are broadcastable, and have the same number of elements.\nChanging behavior in a backwards incompatible manner to broadcasting rather than viewing as 1-dimensional. \n```"]