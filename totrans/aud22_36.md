# 使用CUDA CTC解码器进行ASR推理

> 原文：[https://pytorch.org/audio/stable/tutorials/asr_inference_with_cuda_ctc_decoder_tutorial.html](https://pytorch.org/audio/stable/tutorials/asr_inference_with_cuda_ctc_decoder_tutorial.html)

注意

点击这里下载完整示例代码

作者：Yuekai Zhang

本教程展示了如何使用基于CUDA的CTC波束搜索解码器执行语音识别推理。我们在来自[Next-gen Kaldi](https://nadirapovey.com/next-gen-kaldi-what-is-it)项目的预训练[Zipformer](https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless7_ctc)模型上演示了这一点。

## 概述

波束搜索解码通过迭代地扩展文本假设（波束）与下一个可能的字符，并在每个时间步仅保留得分最高的假设来工作。

底层实现使用cuda来加速整个解码过程

解码器的数学公式可以是

在[论文](https://arxiv.org/pdf/1408.2873.pdf)中找到，并且更详细的算法可以在这个[博客](https://distill.pub/2017/ctc/)中找到。

使用CUDA CTC波束搜索解码器运行ASR推理需要以下组件

+   声学模型：从声学特征预测建模单元（本教程中为BPE）的模型

+   BPE模型：字节对编码（BPE）分词器文件

## 声学模型和设置

首先，我们导入必要的工具并获取我们要处理的数据

```py
import torch
import torchaudio

print(torch.__version__)
print([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")) 
```

```py
2.2.0
2.2.0 
```

```py
import time
from pathlib import [Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path "pathlib.Path")

import IPython
import sentencepiece as spm
from torchaudio.models.decoder import cuda_ctc_decoder
from torchaudio.utils import download_asset 
```

我们使用预训练的[Zipformer](https://huggingface.co/Zengwei/icefall-asr-librispeech-pruned-transducer-stateless7-ctc-2022-12-01)模型，该模型在[LibriSpeech数据集](http://www.openslr.org/12)上进行了训练。该模型同时使用CTC和Transducer损失函数进行训练。在本教程中，我们仅使用模型的CTC头部。

```py
def download_asset_external(url, key):
    path = [Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path "pathlib.Path")([torch.hub.get_dir](https://pytorch.org/docs/stable/hub.html#torch.hub.get_dir "torch.hub.get_dir")()) / "torchaudio" / [Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path "pathlib.Path")(key)
    if not path.exists():
        path.parent.mkdir(parents=True, exist_ok=True)
        [torch.hub.download_url_to_file](https://pytorch.org/docs/stable/hub.html#torch.hub.download_url_to_file "torch.hub.download_url_to_file")(url, path)
    return str(path)

[url_prefix](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = "https://huggingface.co/Zengwei/icefall-asr-librispeech-pruned-transducer-stateless7-ctc-2022-12-01"
[model_link](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = f"{[url_prefix](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")}/resolve/main/exp/cpu_jit.pt"
[model_path](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = download_asset_external([model_link](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), "cuda_ctc_decoder/cpu_jit.pt") 
```

```py
 0%|          | 0.00/269M [00:00<?, ?B/s]
  4%|3         | 10.1M/269M [00:00<00:03, 78.9MB/s]
  9%|9         | 25.0M/269M [00:00<00:05, 49.1MB/s]
 18%|#8        | 49.6M/269M [00:00<00:02, 96.3MB/s]
 23%|##3       | 63.0M/269M [00:00<00:03, 67.8MB/s]
 28%|##7       | 74.9M/269M [00:01<00:03, 56.8MB/s]
 31%|###       | 83.4M/269M [00:01<00:03, 59.6MB/s]
 37%|###7      | 99.9M/269M [00:01<00:03, 48.1MB/s]
 39%|###9      | 106M/269M [00:02<00:05, 33.3MB/s]
 46%|####5     | 123M/269M [00:02<00:03, 48.0MB/s]
 48%|####8     | 130M/269M [00:02<00:03, 37.5MB/s]
 54%|#####3    | 145M/269M [00:02<00:02, 51.5MB/s]
 57%|#####6    | 153M/269M [00:03<00:03, 35.0MB/s]
 63%|######3   | 170M/269M [00:03<00:02, 49.3MB/s]
 66%|######6   | 178M/269M [00:04<00:03, 26.8MB/s]
 72%|#######1  | 194M/269M [00:04<00:02, 37.6MB/s]
 75%|#######4  | 201M/269M [00:05<00:02, 30.5MB/s]
 77%|#######6  | 207M/269M [00:05<00:02, 31.4MB/s]
 82%|########2 | 222M/269M [00:05<00:01, 45.5MB/s]
 85%|########5 | 230M/269M [00:05<00:01, 33.0MB/s]
 88%|########7 | 236M/269M [00:05<00:00, 35.8MB/s]
 93%|#########2| 250M/269M [00:06<00:00, 33.8MB/s]
 97%|#########7| 262M/269M [00:06<00:00, 44.9MB/s]
100%|#########9| 269M/269M [00:06<00:00, 34.9MB/s]
100%|##########| 269M/269M [00:06<00:00, 41.1MB/s] 
```

我们将从LibriSpeech测试其他数据集中加载一个样本。

```py
[speech_file](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = download_asset("tutorial-assets/ctc-decoding/1688-142285-0007.wav")
[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [sample_rate](https://docs.python.org/3/library/functions.html#int "builtins.int") = torchaudio.load([speech_file](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
assert [sample_rate](https://docs.python.org/3/library/functions.html#int "builtins.int") == 16000
IPython.display.Audio([speech_file](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")) 
```

```py
 0%|          | 0.00/441k [00:00<?, ?B/s]
100%|##########| 441k/441k [00:00<00:00, 83.3MB/s] 
```

您的浏览器不支持音频元素。

与此音频文件对应的抄本是

```py
[i](https://docs.python.org/3/library/functions.html#int "builtins.int") really was very much afraid of showing him how much shocked [i](https://docs.python.org/3/library/functions.html#int "builtins.int") was at some parts of what he said 
```

## 解码器的文件和数据

接下来，我们从BPE模型中加载我们的标记，这是用于解码的分词器。

### 标记

标记是声学模型可以预测的可能符号，包括CTC中的空白符号。在本教程中，它包括500个BPE标记。它可以作为文件传入，其中每行包含与相同索引对应的标记，或作为标记列表传入，每个标记映射到一个唯一的索引。

```py
# tokens
<blk>
<sos/eos>
<unk>
S
_THE
_A
T
_AND
... 
```

```py
[bpe_link](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = f"{[url_prefix](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")}/resolve/main/data/lang_bpe_500/bpe.model"
[bpe_path](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = download_asset_external([bpe_link](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), "cuda_ctc_decoder/bpe.model")

bpe_model = spm.SentencePieceProcessor()
bpe_model.load([bpe_path](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
[tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [bpe_model.id_to_piece(id) for id in range(bpe_model.get_piece_size())]
print([tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")) 
```

```py
 0%|          | 0.00/239k [00:00<?, ?B/s]
100%|##########| 239k/239k [00:00<00:00, 63.9MB/s]
['<blk>', '<sos/eos>', '<unk>', 'S', '▁THE', '▁A', 'T', '▁AND', 'ED', '▁OF', '▁TO', 'E', 'D', 'N', 'ING', '▁IN', 'Y', 'M', 'C', '▁I', 'A', 'P', '▁HE', 'R', 'O', 'L', 'RE', 'I', 'U', 'ER', '▁IT', 'LY', '▁THAT', '▁WAS', '▁', '▁S', 'AR', '▁BE', 'F', '▁C', 'IN', 'B', '▁FOR', 'OR', 'LE', "'", '▁HIS', '▁YOU', 'AL', '▁RE', 'V', '▁B', 'G', 'RI', '▁E', '▁WITH', '▁T', '▁AS', 'LL', '▁P', '▁HER', 'ST', '▁HAD', '▁SO', '▁F', 'W', 'CE', '▁IS', 'ND', '▁NOT', 'TH', '▁BUT', 'EN', '▁SHE', '▁ON', 'VE', 'ON', 'SE', '▁DE', 'UR', '▁G', 'CH', 'K', 'TER', '▁AT', 'IT', '▁ME', 'RO', 'NE', 'RA', 'ES', 'IL', 'NG', 'IC', '▁NO', '▁HIM', 'ENT', 'IR', '▁WE', 'H', '▁DO', '▁ALL', '▁HAVE', 'LO', '▁BY', '▁MY', '▁MO', '▁THIS', 'LA', '▁ST', '▁WHICH', '▁CON', '▁THEY', 'CK', 'TE', '▁SAID', '▁FROM', '▁GO', '▁WHO', '▁TH', '▁OR', '▁D', '▁W', 'VER', 'LI', '▁SE', '▁ONE', '▁CA', '▁AN', '▁LA', '▁WERE', 'EL', '▁HA', '▁MAN', '▁FA', '▁EX', 'AD', '▁SU', 'RY', '▁MI', 'AT', '▁BO', '▁WHEN', 'AN', 'THER', 'PP', 'ATION', '▁FI', '▁WOULD', '▁PRO', 'OW', 'ET', '▁O', '▁THERE', '▁HO', 'ION', '▁WHAT', '▁FE', '▁PA', 'US', 'MENT', '▁MA', 'UT', '▁OUT', '▁THEIR', '▁IF', '▁LI', '▁K', '▁WILL', '▁ARE', 'ID', '▁RO', 'DE', 'TION', '▁WA', 'PE', '▁UP', '▁SP', '▁PO', 'IGHT', '▁UN', 'RU', '▁LO', 'AS', 'OL', '▁LE', '▁BEEN', '▁SH', '▁RA', '▁SEE', 'KE', 'UL', 'TED', '▁SA', 'UN', 'UND', 'ANT', '▁NE', 'IS', '▁THEM', 'CI', 'GE', '▁COULD', '▁DIS', 'OM', 'ISH', 'HE', 'EST', '▁SOME', 'ENCE', 'ITY', 'IVE', '▁US', '▁MORE', '▁EN', 'ARD', 'ATE', '▁YOUR', '▁INTO', '▁KNOW', '▁CO', 'ANCE', '▁TIME', '▁WI', '▁YE', 'AGE', '▁NOW', 'TI', 'FF', 'ABLE', '▁VERY', '▁LIKE', 'AM', 'HI', 'Z', '▁OTHER', '▁THAN', '▁LITTLE', '▁DID', '▁LOOK', 'TY', 'ERS', '▁CAN', '▁CHA', '▁AR', 'X', 'FUL', 'UGH', '▁BA', '▁DAY', '▁ABOUT', 'TEN', 'IM', '▁ANY', '▁PRE', '▁OVER', 'IES', 'NESS', 'ME', 'BLE', '▁M', 'ROW', '▁HAS', '▁GREAT', '▁VI', 'TA', '▁AFTER', 'PER', '▁AGAIN', 'HO', 'SH', '▁UPON', '▁DI', '▁HAND', '▁COM', 'IST', 'TURE', '▁STA', '▁THEN', '▁SHOULD', '▁GA', 'OUS', 'OUR', '▁WELL', '▁ONLY', 'MAN', '▁GOOD', '▁TWO', '▁MAR', '▁SAY', '▁HU', 'TING', '▁OUR', 'RESS', '▁DOWN', 'IOUS', '▁BEFORE', '▁DA', '▁NA', 'QUI', '▁MADE', '▁EVERY', '▁OLD', '▁EVEN', 'IG', '▁COME', '▁GRA', '▁RI', '▁LONG', 'OT', 'SIDE', 'WARD', '▁FO', '▁WHERE', 'MO', 'LESS', '▁SC', '▁MUST', '▁NEVER', '▁HOW', '▁CAME', '▁SUCH', '▁RU', '▁TAKE', '▁WO', '▁CAR', 'UM', 'AK', '▁THINK', '▁MUCH', '▁MISTER', '▁MAY', '▁JO', '▁WAY', '▁COMP', '▁THOUGHT', '▁STO', '▁MEN', '▁BACK', '▁DON', 'J', '▁LET', '▁TRA', '▁FIRST', '▁JUST', '▁VA', '▁OWN', '▁PLA', '▁MAKE', 'ATED', '▁HIMSELF', '▁WENT', '▁PI', 'GG', 'RING', '▁DU', '▁MIGHT', '▁PART', '▁GIVE', '▁IMP', '▁BU', '▁PER', '▁PLACE', '▁HOUSE', '▁THROUGH', 'IAN', '▁SW', '▁UNDER', 'QUE', '▁AWAY', '▁LOVE', 'QUA', '▁LIFE', '▁GET', '▁WITHOUT', '▁PASS', '▁TURN', 'IGN', '▁HEAD', '▁MOST', '▁THOSE', '▁SHALL', '▁EYES', '▁COL', '▁STILL', '▁NIGHT', '▁NOTHING', 'ITION', 'HA', '▁TELL', '▁WORK', '▁LAST', '▁NEW', '▁FACE', '▁HI', '▁WORD', '▁FOUND', '▁COUNT', '▁OB', '▁WHILE', '▁SHA', '▁MEAN', '▁SAW', '▁PEOPLE', '▁FRIEND', '▁THREE', '▁ROOM', '▁SAME', '▁THOUGH', '▁RIGHT', '▁CHILD', '▁FATHER', '▁ANOTHER', '▁HEART', '▁WANT', '▁TOOK', 'OOK', '▁LIGHT', '▁MISSUS', '▁OPEN', '▁JU', '▁ASKED', 'PORT', '▁LEFT', '▁JA', '▁WORLD', '▁HOME', '▁WHY', '▁ALWAYS', '▁ANSWER', '▁SEEMED', '▁SOMETHING', '▁GIRL', '▁BECAUSE', '▁NAME', '▁TOLD', '▁NI', '▁HIGH', 'IZE', '▁WOMAN', '▁FOLLOW', '▁RETURN', '▁KNEW', '▁EACH', '▁KIND', '▁JE', '▁ACT', '▁LU', '▁CERTAIN', '▁YEARS', '▁QUITE', '▁APPEAR', '▁BETTER', '▁HALF', '▁PRESENT', '▁PRINCE', 'SHIP', '▁ALSO', '▁BEGAN', '▁HAVING', '▁ENOUGH', '▁PERSON', '▁LADY', '▁WHITE', '▁COURSE', '▁VOICE', '▁SPEAK', '▁POWER', '▁MORNING', '▁BETWEEN', '▁AMONG', '▁KEEP', '▁WALK', '▁MATTER', '▁TEA', '▁BELIEVE', '▁SMALL', '▁TALK', '▁FELT', '▁HORSE', '▁MYSELF', '▁SIX', '▁HOWEVER', '▁FULL', '▁HERSELF', '▁POINT', '▁STOOD', '▁HUNDRED', '▁ALMOST', '▁SINCE', '▁LARGE', '▁LEAVE', '▁PERHAPS', '▁DARK', '▁SUDDEN', '▁REPLIED', '▁ANYTHING', '▁WONDER', '▁UNTIL', 'Q'] 
```

## 构建CUDA解码器

在本教程中，我们将构建一个CUDA波束搜索解码器。可以使用工厂函数[`cuda_ctc_decoder()`](../generated/torchaudio.models.decoder.cuda_ctc_decoder.html#torchaudio.models.decoder.cuda_ctc_decoder "torchaudio.models.decoder.cuda_ctc_decoder")来构建解码器。

```py
cuda_decoder = cuda_ctc_decoder([tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), nbest=10, [beam_size](https://docs.python.org/3/library/functions.html#int "builtins.int")=10, blank_skip_threshold=0.95) 
```

## 运行推理

现在我们有了数据、声学模型和解码器，我们可以执行推理。波束搜索解码器的输出类型为[`CUCTCHypothesis`](../generated/torchaudio.models.decoder.CUCTCDecoder.html#torchaudio.models.decoder.CUCTCHypothesis "torchaudio.models.decoder.CUCTCHypothesis")，包括预测的标记ID、单词（与标记ID对应的符号）和假设分数。回想一下与波形对应的抄本是

```py
[i](https://docs.python.org/3/library/functions.html#int "builtins.int") really was very much afraid of showing him how much shocked [i](https://docs.python.org/3/library/functions.html#int "builtins.int") was at some parts of what he said 
```

```py
[actual_transcript](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = "i really was very much afraid of showing him how much shocked i was at some parts of what he said"
[actual_transcript](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [actual_transcript.split](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")()

[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")("cuda", 0)
acoustic_model = [torch.jit.load](https://pytorch.org/docs/stable/generated/torch.jit.load.html#torch.jit.load "torch.jit.load")([model_path](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
[acoustic_model.to](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.to "torch.jit.ScriptModule.to")([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))
[acoustic_model.eval](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.eval "torch.jit.ScriptModule.eval")()

[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))

[feat](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = torchaudio.compliance.kaldi.fbank([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), num_mel_bins=80, snip_edges=False)
[feat](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [feat](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").unsqueeze(0)
[feat_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor "torch.tensor")([feat](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1), [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")).unsqueeze(0)

[encoder_out](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = acoustic_model.encoder([feat](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [feat_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
[nnet_output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = acoustic_model.ctc_output([encoder_out](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
[log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [torch.nn.functional.log_softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax "torch.nn.functional.log_softmax")([nnet_output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), -1)

print(f"The shape of log_prob: {[log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").shape}, the shape of encoder_out_lens: {[encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").shape}") 
```

```py
The shape of log_prob: torch.Size([1, 175, 500]), the shape of encoder_out_lens: torch.Size([1]) 
```

cuda ctc解码器给出以下结果。

```py
[results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = cuda_decoder([log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").to([torch.int32](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype "torch.dtype")))
[beam_search_transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = bpe_model.decode([results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[0][0].[tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")).lower()
[beam_search_wer](https://docs.python.org/3/library/functions.html#float "builtins.float") = torchaudio.functional.edit_distance([actual_transcript](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), [beam_search_transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str").split()) / len(
    [actual_transcript](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")
)

print(f"Transcript: {[beam_search_transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")}")
print(f"WER: {[beam_search_wer](https://docs.python.org/3/library/functions.html#float "builtins.float")}") 
```

```py
Transcript: i really was very much afraid of showing him how much shocked i was at some parts of what he said
WER: 0.0 
```

## 波束搜索解码器参数

在本节中，我们将更深入地讨论一些不同参数和权衡。有关可自定义参数的完整列表，请参考[`文档`](../generated/torchaudio.models.decoder.cuda_ctc_decoder.html#torchaudio.models.decoder.cuda_ctc_decoder "torchaudio.models.decoder.cuda_ctc_decoder")。

### 辅助函数[](#helper-function "跳转到此标题")

```py
def print_decoded(cuda_decoder, bpe_model, [log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), param, param_value):
    start_time = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic "time.monotonic")()
    [results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = cuda_decoder([log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").to([torch.int32](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype "torch.dtype")))
    decode_time = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic "time.monotonic")() - start_time
    [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = bpe_model.decode([results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[0][0].[tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")).lower()
    [score](https://docs.python.org/3/library/functions.html#float "builtins.float") = [results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[0][0].[score](https://docs.python.org/3/library/functions.html#float "builtins.float")
    print(f"{param}  {param_value:<3}: {[transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")} (score: {[score](https://docs.python.org/3/library/functions.html#float "builtins.float"):.2f}; {decode_time:.4f} secs)") 
```

### nbest[](#nbest "跳转到此标题")

此参数表示要返回的最佳假设数量。例如，在之前构建波束搜索解码器时设置 `nbest=10`，现在我们可以访问得分前10名的假设。

```py
for [i](https://docs.python.org/3/library/functions.html#int "builtins.int") in range(10):
    [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = bpe_model.decode([results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[0][[i](https://docs.python.org/3/library/functions.html#int "builtins.int")].[tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")).lower()
    [score](https://docs.python.org/3/library/functions.html#float "builtins.float") = [results](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[0][[i](https://docs.python.org/3/library/functions.html#int "builtins.int")].[score](https://docs.python.org/3/library/functions.html#float "builtins.float")
    print(f"{[transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")} (score: {[score](https://docs.python.org/3/library/functions.html#float "builtins.float")})") 
```

```py
i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.2029460221529007)
i really was very much afraid of showing him how much shocked i was at some part of what he said (score: -1.7402369976043701)
i really was very much afraid of sheowing him how much shocked i was at some parts of what he said (score: -6.679358005523682)
i reallyly very much afraid of showing him how much shocked i was at some parts of what he said (score: -7.596949577331543)
i really was very much afraid of sheowing him how much shocked i was at some part of what he said (score: -8.223165512084961)
i really was very much afraid of shwing him how much shocked i was at some parts of what he said (score: -8.439875602722168)
i really was very much afraid of showing him how much shocked i was in some parts of what he said (score: -8.782379150390625)
i really was very much afraid of showing him how much shocked i was at some parts of what said (score: -8.884151458740234)
i really was very much afraid of showing him how much shocked i was at some partes of what he said (score: -8.999359130859375)
i really was very much afraid of showing him how much shocked i was at some parts of what he say (score: -9.138347625732422) 
```

### 波束大小[](#beam-size "跳转到此标题")

`beam_size`参数确定每个解码步骤后保留的最佳假设数量上限。使用更大的波束大小可以探索更广泛的可能假设范围，这可以产生得分更高的假设，但在一定程度上不会提供额外的收益。我们建议为cuda波束搜索解码器设置`beam_size=10`。

在下面的示例中，我们可以看到随着波束大小从1增加到3，解码质量有所提高，但请注意，使用波束大小为3时提供与波束大小为10相同的输出。

```py
[beam_sizes](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [1, 2, 3, 10]

for [beam_size](https://docs.python.org/3/library/functions.html#int "builtins.int") in [beam_sizes](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    beam_search_decoder = cuda_ctc_decoder(
        [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"),
        nbest=1,
        [beam_size](https://docs.python.org/3/library/functions.html#int "builtins.int")=[beam_size](https://docs.python.org/3/library/functions.html#int "builtins.int"),
        blank_skip_threshold=0.95,
    )
    print_decoded(beam_search_decoder, bpe_model, [log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), "beam size", [beam_size](https://docs.python.org/3/library/functions.html#int "builtins.int")) 
```

```py
beam size 1  : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -1.35; 0.0009 secs)
beam size 2  : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.21; 0.0009 secs)
beam size 3  : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.20; 0.0009 secs)
beam size 10 : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.20; 0.0010 secs) 
```

### blank skip threshold[](#blank-skip-threshold "跳转到此标题")

`blank_skip_threshold`参数用于修剪具有较大空白概率的帧。使用良好的`blank_skip_threshold`修剪这些帧可以大大加快解码过程，而不会降低准确性。根据CTC规则，我们应至少在两个非空白帧之间保留一个空白帧，以避免错误地合并两个连续相同的符号。我们建议为cuda波束搜索解码器设置`blank_skip_threshold=0.95`。

```py
[blank_skip_probs](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [0.25, 0.95, 1.0]

for [blank_skip_prob](https://docs.python.org/3/library/functions.html#float "builtins.float") in [blank_skip_probs](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    beam_search_decoder = cuda_ctc_decoder(
        [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"),
        nbest=10,
        [beam_size](https://docs.python.org/3/library/functions.html#int "builtins.int")=10,
        blank_skip_threshold=[blank_skip_prob](https://docs.python.org/3/library/functions.html#float "builtins.float"),
    )
    print_decoded(beam_search_decoder, bpe_model, [log_prob](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [encoder_out_lens](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), "blank_skip_threshold", [blank_skip_prob](https://docs.python.org/3/library/functions.html#float "builtins.float"))

del cuda_decoder 
```

```py
blank_skip_threshold 0.25: i really was very much afraid of showing him how much shocked i was at some part of what he said (score: -0.01; 0.0009 secs)
blank_skip_threshold 0.95: i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.20; 0.0010 secs)
blank_skip_threshold 1.0: i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.21; 0.0043 secs) 
```

## 使用手电筒CPU解码器进行基准测试[](#benchmark-with-flashlight-cpu-decoder "跳转到此标题")

我们使用librispeech test_other数据集对CUDA解码器和CPU解码器之间的吞吐量和准确性进行基准测试。要重现下面的基准测试结果，您可以参考[这里](https://github.com/pytorch/audio/tree/main/examples/asr/librispeech_cuda_ctc_decoder)。

| 解码器 | 设置 | WER (%) | N-Best Oracle WER (%) | 解码器成本时间 (秒) |
| --- | --- | --- | --- | --- |
| CUDA解码器 | blank_skip_threshold 0.95 | 5.81 | 4.11 | 2.57 |
| CUDA解码器 | blank_skip_threshold 1.0 (无帧跳过) | 5.81 | 4.09 | 6.24 |
| CPU解码器 | beam_size_token 10 | 5.86 | 4.30 | 28.61 |
| CPU解码器 | beam_size_token 500 | 5.86 | 4.30 | 791.80 |

从上表中可以看出，CUDA解码器在WER方面略有改善，并且吞吐量显著增加。

**脚本的总运行时间:** ( 0 分钟 8.752 秒)

[`下载Python源代码: asr_inference_with_cuda_ctc_decoder_tutorial.py`](../_downloads/3956cf493d21711e687e9610c91f9cd1/asr_inference_with_cuda_ctc_decoder_tutorial.py)

[`下载Jupyter笔记本: asr_inference_with_cuda_ctc_decoder_tutorial.ipynb`](../_downloads/96982138e59c541534342222a3f5c69e/asr_inference_with_cuda_ctc_decoder_tutorial.ipynb)

[Sphinx-Gallery生成的图库](https://sphinx-gallery.github.io)
