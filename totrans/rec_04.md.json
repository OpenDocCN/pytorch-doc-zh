["```py\ntorchrec.distributed.collective_utils.invoke_on_rank_and_broadcast_result(pg: ProcessGroup, rank: int, func: Callable[[...], T], *args: Any, **kwargs: Any) \u2192 T\u00b6\n```", "```py\nid = invoke_on_rank_and_broadcast_result(pg, 0, allocate_id) \n```", "```py\ntorchrec.distributed.collective_utils.is_leader(pg: Optional[ProcessGroup], leader_rank: int = 0) \u2192 bool\u00b6\n```", "```py\ntorchrec.distributed.collective_utils.run_on_leader(pg: ProcessGroup, rank: int)\u00b6\n```", "```py\ntorchrec.distributed.comm.get_group_rank(world_size: Optional[int] = None, rank: Optional[int] = None) \u2192 int\u00b6\n```", "```py\ntorchrec.distributed.comm.get_local_rank(world_size: Optional[int] = None, rank: Optional[int] = None) \u2192 int\u00b6\n```", "```py\ntorchrec.distributed.comm.get_local_size(world_size: Optional[int] = None) \u2192 int\u00b6\n```", "```py\ntorchrec.distributed.comm.get_num_groups(world_size: Optional[int] = None) \u2192 int\u00b6\n```", "```py\ntorchrec.distributed.comm.intra_and_cross_node_pg(device: Optional[device] = None, backend: Optional[str] = None) \u2192 Tuple[Optional[ProcessGroup], Optional[ProcessGroup]]\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.All2AllDenseInfo(output_splits: List[int], batch_size: int, input_shape: List[int], input_splits: List[int])\u00b6\n```", "```py\nbatch_size: int\u00b6\n```", "```py\ninput_shape: List[int]\u00b6\n```", "```py\ninput_splits: List[int]\u00b6\n```", "```py\noutput_splits: List[int]\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.All2AllPooledInfo(batch_size_per_rank: List[int], dim_sum_per_rank: List[int], dim_sum_per_rank_tensor: Optional[Tensor], cumsum_dim_sum_per_rank_tensor: Optional[Tensor], codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\nbatch_size_per_rank\u00b6\n```", "```py\ndim_sum_per_rank\u00b6\n```", "```py\ndim_sum_per_rank_tensor\u00b6\n```", "```py\ncumsum_dim_sum_per_rank_tensor\u00b6\n```", "```py\ncodecs\u00b6\n```", "```py\nbatch_size_per_rank: List[int]\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\ncumsum_dim_sum_per_rank_tensor: Optional[Tensor]\u00b6\n```", "```py\ndim_sum_per_rank: List[int]\u00b6\n```", "```py\ndim_sum_per_rank_tensor: Optional[Tensor]\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.All2AllSequenceInfo(embedding_dim: int, lengths_after_sparse_data_all2all: Tensor, forward_recat_tensor: Optional[Tensor], backward_recat_tensor: Tensor, input_splits: List[int], output_splits: List[int], variable_batch_size: bool = False, codecs: Optional[QuantizedCommCodecs] = None, permuted_lengths_after_sparse_data_all2all: Optional[Tensor] = None)\u00b6\n```", "```py\nembedding_dim\u00b6\n```", "```py\nlengths_after_sparse_data_all2all\u00b6\n```", "```py\nforward_recat_tensor\u00b6\n```", "```py\nbackward_recat_tensor\u00b6\n```", "```py\ninput_splits\u00b6\n```", "```py\noutput_splits\u00b6\n```", "```py\nvariable_batch_size\u00b6\n```", "```py\ncodecs\u00b6\n```", "```py\npermuted_lengths_after_sparse_data_all2all\u00b6\n```", "```py\nbackward_recat_tensor: Tensor\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\nembedding_dim: int\u00b6\n```", "```py\nforward_recat_tensor: Optional[Tensor]\u00b6\n```", "```py\ninput_splits: List[int]\u00b6\n```", "```py\nlengths_after_sparse_data_all2all: Tensor\u00b6\n```", "```py\noutput_splits: List[int]\u00b6\n```", "```py\npermuted_lengths_after_sparse_data_all2all: Optional[Tensor] = None\u00b6\n```", "```py\nvariable_batch_size: bool = False\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.All2AllVInfo(dims_sum_per_rank: ~typing.List[int], B_global: int, B_local: int, B_local_list: ~typing.List[int], D_local_list: ~typing.List[int], input_split_sizes: ~typing.List[int] = <factory>, output_split_sizes: ~typing.List[int] = <factory>, codecs: ~typing.Optional[~torchrec.distributed.types.QuantizedCommCodecs] = None)\u00b6\n```", "```py\ndim_sum_per_rank\u00b6\n```", "```py\nB_global\u00b6\n```", "```py\nB_local\u00b6\n```", "```py\nB_local_list\u00b6\n```", "```py\nD_local_list\u00b6\n```", "```py\ninput_split_sizes\u00b6\n```", "```py\noutput_split_sizes\u00b6\n```", "```py\nB_global: int\u00b6\n```", "```py\nB_local: int\u00b6\n```", "```py\nB_local_list: List[int]\u00b6\n```", "```py\nD_local_list: List[int]\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\ndims_sum_per_rank: List[int]\u00b6\n```", "```py\ninput_split_sizes: List[int]\u00b6\n```", "```py\noutput_split_sizes: List[int]\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.All2All_Pooled_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused) \u2192 Tuple[None, None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], a2ai: All2AllPooledInfo, input_embeddings: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.All2All_Pooled_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, grad_output: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.All2All_Seq_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused) \u2192 Tuple[None, None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], a2ai: All2AllSequenceInfo, sharded_input_embeddings: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.All2All_Seq_Req_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, sharded_grad_output: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.All2Allv_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *grad_output)\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], a2ai: All2AllVInfo, inputs: List[Tensor]) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.All2Allv_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *grad_outputs) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tuple[Tensor]\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.AllGatherBaseInfo(input_size: Size, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\ninput_size\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\ninput_size: Size\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.AllGatherBase_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused: Tensor) \u2192 Tuple[Optional[Tensor], ...]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], agi: AllGatherBaseInfo, input: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.AllGatherBase_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, grad_outputs: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterBaseInfo(input_sizes: Size, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\ninput_sizes\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\ninput_sizes: Size\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterBase_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused: Tensor) \u2192 Tuple[Optional[Tensor], ...]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], rsi: ReduceScatterBaseInfo, inputs: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterBase_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, grad_output: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_Tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterInfo(input_sizes: List[Size], codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\ninput_sizes\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\ninput_sizes: List[Size]\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterVInfo(input_sizes: List[Size], input_splits: List[int], equal_splits: bool, total_input_size: List[int], codecs: Optional[QuantizedCommCodecs])\u00b6\n```", "```py\ninput_sizes\u00b6\n```", "```py\ninput_splits\u00b6\n```", "```py\ntotal_input_size\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs]\u00b6\n```", "```py\nequal_splits: bool\u00b6\n```", "```py\ninput_sizes: List[Size]\u00b6\n```", "```py\ninput_splits: List[int]\u00b6\n```", "```py\ntotal_input_size: List[int]\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterV_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused: Tensor) \u2192 Tuple[Optional[Tensor], ...]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], rsi: ReduceScatterVInfo, input: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatterV_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, grad_output: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatter_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused: Tensor) \u2192 Tuple[Optional[Tensor], ...]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], rsi: ReduceScatterInfo, *inputs: Any) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.ReduceScatter_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, grad_output: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.Request(pg: ProcessGroup, device: device)\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.VariableBatchAll2AllPooledInfo(batch_size_per_rank_per_feature: List[List[int]], batch_size_per_feature_pre_a2a: List[int], emb_dim_per_rank_per_feature: List[List[int]], codecs: Optional[QuantizedCommCodecs] = None, input_splits: Optional[List[int]] = None, output_splits: Optional[List[int]] = None)\u00b6\n```", "```py\nbatch_size_per_rank_per_feature\u00b6\n```", "```py\nbatch_size_per_feature_pre_a2a\u00b6\n```", "```py\nemb_dim_per_rank_per_feature\u00b6\n```", "```py\ncodecs\u00b6\n```", "```py\ninput_splits\u00b6\n```", "```py\noutput_splits\u00b6\n```", "```py\nbatch_size_per_feature_pre_a2a: List[int]\u00b6\n```", "```py\nbatch_size_per_rank_per_feature: List[List[int]]\u00b6\n```", "```py\ncodecs: Optional[QuantizedCommCodecs] = None\u00b6\n```", "```py\nemb_dim_per_rank_per_feature: List[List[int]]\u00b6\n```", "```py\ninput_splits: Optional[List[int]] = None\u00b6\n```", "```py\noutput_splits: Optional[List[int]] = None\u00b6\n```", "```py\nclass torchrec.distributed.comm_ops.Variable_Batch_All2All_Pooled_Req(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, *unused) \u2192 Tuple[None, None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], a2ai: VariableBatchAll2AllPooledInfo, input_embeddings: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.comm_ops.Variable_Batch_All2All_Pooled_Wait(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx, grad_output: Tensor) \u2192 Tuple[None, None, Tensor]\u00b6\n```", "```py\nstatic forward(ctx, pg: ProcessGroup, myreq: Request[Tensor], *dummy_tensor: Tensor) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\ntorchrec.distributed.comm_ops.all_gather_base_pooled(input: Tensor, group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.alltoall_pooled(a2a_pooled_embs_tensor: Tensor, batch_size_per_rank: List[int], dim_sum_per_rank: List[int], dim_sum_per_rank_tensor: Optional[Tensor] = None, cumsum_dim_sum_per_rank_tensor: Optional[Tensor] = None, group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.alltoall_sequence(a2a_sequence_embs_tensor: Tensor, forward_recat_tensor: Tensor, backward_recat_tensor: Tensor, lengths_after_sparse_data_all2all: Tensor, input_splits: List[int], output_splits: List[int], variable_batch_size: bool = False, group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.alltoallv(inputs: List[Tensor], out_split: Optional[List[int]] = None, per_rank_split_lengths: Optional[List[int]] = None, group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[List[Tensor]]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.get_gradient_division() \u2192 bool\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.reduce_scatter_base_pooled(input: Tensor, group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.reduce_scatter_pooled(inputs: List[Tensor], group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.reduce_scatter_v_per_feature_pooled(input: Tensor, batch_size_per_rank_per_feature: List[List[int]], embedding_dims: List[int], group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.reduce_scatter_v_pooled(input: Tensor, input_splits: List[int], group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.set_gradient_division(val: bool) \u2192 None\u00b6\n```", "```py\ntorchrec.distributed.comm_ops.variable_batch_alltoall_pooled(a2a_pooled_embs_tensor: Tensor, batch_size_per_rank_per_feature: List[List[int]], batch_size_per_feature_pre_a2a: List[int], emb_dim_per_rank_per_feature: List[List[int]], group: Optional[ProcessGroup] = None, codecs: Optional[QuantizedCommCodecs] = None) \u2192 Awaitable[Tensor]\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.EmbeddingsAllToOne(device: device, world_size: int, cat_dim: int)\u00b6\n```", "```py\nforward(tensors: List[Tensor]) \u2192 Tensor\u00b6\n```", "```py\nset_device(device_str: str) \u2192 None\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.EmbeddingsAllToOneReduce(device: device, world_size: int)\u00b6\n```", "```py\nforward(tensors: List[Tensor]) \u2192 Tensor\u00b6\n```", "```py\nset_device(device_str: str) \u2192 None\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.KJTAllToAll(pg: ProcessGroup, splits: List[int], stagger: int = 1)\u00b6\n```", "```py\nkeys=['A','B','C']\nsplits=[2,1]\nkjtA2A = KJTAllToAll(pg, splits)\nawaitable = kjtA2A(rank0_input)\n\n# where:\n# rank0_input is KeyedJaggedTensor holding\n\n#         0           1           2\n# 'A'    [A.V0]       None        [A.V1, A.V2]\n# 'B'    None         [B.V0]      [B.V1]\n# 'C'    [C.V0]       [C.V1]      None\n\n# rank1_input is KeyedJaggedTensor holding\n\n#         0           1           2\n# 'A'     [A.V3]      [A.V4]      None\n# 'B'     None        [B.V2]      [B.V3, B.V4]\n# 'C'     [C.V2]      [C.V3]      None\n\nrank0_output = awaitable.wait()\n\n# where:\n# rank0_output is KeyedJaggedTensor holding\n\n#         0           1           2           3           4           5\n# 'A'     [A.V0]      None      [A.V1, A.V2]  [A.V3]      [A.V4]      None\n# 'B'     None        [B.V0]    [B.V1]        None        [B.V2]      [B.V3, B.V4]\n\n# rank1_output is KeyedJaggedTensor holding\n#         0           1           2           3           4           5\n# 'C'     [C.V0]      [C.V1]      None        [C.V2]      [C.V3]      None \n```", "```py\nforward(input: KeyedJaggedTensor) \u2192 Awaitable[KJTAllToAllTensorsAwaitable]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.KJTAllToAllSplitsAwaitable(pg: ProcessGroup, input: KeyedJaggedTensor, splits: List[int], labels: List[str], tensor_splits: List[List[int]], input_tensors: List[Tensor], keys: List[str], device: device, stagger: int)\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.KJTAllToAllTensorsAwaitable(pg: ProcessGroup, input: KeyedJaggedTensor, splits: List[int], input_splits: List[List[int]], output_splits: List[List[int]], input_tensors: List[Tensor], labels: List[str], keys: List[str], device: device, stagger: int, stride_per_rank: Optional[List[int]])\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.KJTOneToAll(splits: List[int], world_size: int, device: Optional[device] = None)\u00b6\n```", "```py\nforward(kjt: KeyedJaggedTensor) \u2192 KJTList\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.PooledEmbeddingsAllGather(pg: ProcessGroup, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\ninit_distributed(rank=rank, size=2, backend=\"nccl\")\npg = dist.new_group(backend=\"nccl\")\ninput = torch.randn(2, 2)\nm = PooledEmbeddingsAllGather(pg)\noutput = m(input)\ntensor = output.wait() \n```", "```py\nforward(local_emb: Tensor) \u2192 PooledEmbeddingsAwaitable\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.PooledEmbeddingsAllToAll(pg: ProcessGroup, dim_sum_per_rank: List[int], device: Optional[device] = None, callbacks: Optional[List[Callable[[Tensor], Tensor]]] = None, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\ndim_sum_per_rank = [2, 1]\na2a = PooledEmbeddingsAllToAll(pg, dim_sum_per_rank, device)\n\nt0 = torch.rand((6, 2))\nt1 = torch.rand((6, 1))\nrank0_output = a2a(t0).wait()\nrank1_output = a2a(t1).wait()\nprint(rank0_output.size())\n    # torch.Size([3, 3])\nprint(rank1_output.size())\n    # torch.Size([3, 3]) \n```", "```py\nproperty callbacks: List[Callable[[Tensor], Tensor]]\u00b6\n```", "```py\nforward(local_embs: Tensor, batch_size_per_rank: Optional[List[int]] = None) \u2192 PooledEmbeddingsAwaitable\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.PooledEmbeddingsAwaitable(tensor_awaitable: Awaitable[Tensor])\u00b6\n```", "```py\nproperty callbacks: List[Callable[[Tensor], Tensor]]\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter(pg: ProcessGroup, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\nforward(local_embs: Tensor, input_splits: Optional[List[int]] = None) \u2192 PooledEmbeddingsAwaitable\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.SeqEmbeddingsAllToOne(device: device, world_size: int)\u00b6\n```", "```py\nforward(tensors: List[Tensor]) \u2192 List[Tensor]\u00b6\n```", "```py\nset_device(device_str: str) \u2192 None\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll(pg: ProcessGroup, features_per_rank: List[int], device: Optional[device] = None, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\ninit_distributed(rank=rank, size=2, backend=\"nccl\")\npg = dist.new_group(backend=\"nccl\")\nfeatures_per_rank = [4, 4]\nm = SequenceEmbeddingsAllToAll(pg, features_per_rank)\nlocal_embs = torch.rand((6, 2))\nsharding_ctx: SequenceShardingContext\noutput = m(\n    local_embs=local_embs,\n    lengths=sharding_ctx.lengths_after_input_dist,\n    input_splits=sharding_ctx.input_splits,\n    output_splits=sharding_ctx.output_splits,\n    unbucketize_permute_tensor=None,\n)\ntensor = output.wait() \n```", "```py\nforward(local_embs: Tensor, lengths: Tensor, input_splits: List[int], output_splits: List[int], unbucketize_permute_tensor: Optional[Tensor] = None, batch_size_per_rank: Optional[List[int]] = None, sparse_features_recat: Optional[Tensor] = None) \u2192 SequenceEmbeddingsAwaitable\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.SequenceEmbeddingsAwaitable(tensor_awaitable: Awaitable[Tensor], unbucketize_permute_tensor: Optional[Tensor], embedding_dim: int)\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.SplitsAllToAllAwaitable(input_tensors: List[Tensor], pg: ProcessGroup)\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.VariableBatchPooledEmbeddingsAllToAll(pg: ProcessGroup, emb_dim_per_rank_per_feature: List[List[int]], device: Optional[device] = None, callbacks: Optional[List[Callable[[Tensor], Tensor]]] = None, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\nkjt_split = [1, 2]\nemb_dim_per_rank_per_feature = [[2], [3, 3]]\na2a = VariableBatchPooledEmbeddingsAllToAll(\n    pg, emb_dim_per_rank_per_feature, device\n)\n\nt0 = torch.rand(6) # 2 * (2 + 1)\nt1 = torch.rand(24) # 3 * (1 + 3) + 3 * (2 + 2)\n#        r0_batch_size   r1_batch_size\n#  f_0:              2               1\n-----------------------------------------\n#  f_1:              1               2\n#  f_2:              3               2\nr0_batch_size_per_rank_per_feature = [[2], [1]]\nr1_batch_size_per_rank_per_feature = [[1, 3], [2, 2]]\nr0_batch_size_per_feature_pre_a2a = [2, 1, 3]\nr1_batch_size_per_feature_pre_a2a = [1, 2, 2]\n\nrank0_output = a2a(\n    t0, r0_batch_size_per_rank_per_feature, r0_batch_size_per_feature_pre_a2a\n).wait()\nrank1_output = a2a(\n    t1, r1_batch_size_per_rank_per_feature, r1_batch_size_per_feature_pre_a2a\n).wait()\n\n# input splits:\n#   r0: [2*2, 1*2]\n#   r1: [1*3 + 3*3, 2*3 + 2*3]\n\n# output splits:\n#   r0: [2*2, 1*3 + 3*3]\n#   r1: [1*2, 2*3 + 2*3]\n\nprint(rank0_output.size())\n    # torch.Size([16])\n    # 2*2 + 1*3 + 3*3\nprint(rank1_output.size())\n    # torch.Size([14])\n    # 1*2 + 2*3 + 2*3 \n```", "```py\nproperty callbacks: List[Callable[[Tensor], Tensor]]\u00b6\n```", "```py\nforward(local_embs: Tensor, batch_size_per_rank_per_feature: List[List[int]], batch_size_per_feature_pre_a2a: List[int]) \u2192 PooledEmbeddingsAwaitable\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.dist_data.VariableBatchPooledEmbeddingsReduceScatter(pg: ProcessGroup, codecs: Optional[QuantizedCommCodecs] = None)\u00b6\n```", "```py\nforward(local_embs: Tensor, batch_size_per_rank_per_feature: List[List[int]], embedding_dims: List[int]) \u2192 PooledEmbeddingsAwaitable\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding.EmbeddingCollectionAwaitable(*args, **kwargs)\u00b6\n```", "```py\nclass torchrec.distributed.embedding.EmbeddingCollectionContext(sharding_contexts: List[torchrec.distributed.sharding.sequence_sharding.SequenceShardingContext] = <factory>, input_features: List[torchrec.sparse.jagged_tensor.KeyedJaggedTensor] = <factory>, reverse_indices: List[torch.Tensor] = <factory>)\u00b6\n```", "```py\ninput_features: List[KeyedJaggedTensor]\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nreverse_indices: List[Tensor]\u00b6\n```", "```py\nsharding_contexts: List[SequenceShardingContext]\u00b6\n```", "```py\nclass torchrec.distributed.embedding.EmbeddingCollectionSharder(fused_params: Optional[Dict[str, Any]] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None, use_index_dedup: bool = False)\u00b6\n```", "```py\nproperty module_type: Type[EmbeddingCollection]\u00b6\n```", "```py\nshard(module: EmbeddingCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedEmbeddingCollection\u00b6\n```", "```py\nshardable_parameters(module: EmbeddingCollection) \u2192 Dict[str, Parameter]\u00b6\n```", "```py\nsharding_types(compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nclass torchrec.distributed.embedding.ShardedEmbeddingCollection(module: EmbeddingCollection, table_name_to_parameter_sharding: Dict[str, ParameterSharding], env: ShardingEnv, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None, use_index_dedup: bool = False)\u00b6\n```", "```py\ncompute(ctx: EmbeddingCollectionContext, dist_input: KJTList) \u2192 List[Tensor]\u00b6\n```", "```py\ncompute_and_output_dist(ctx: EmbeddingCollectionContext, input: KJTList) \u2192 LazyAwaitable[Dict[str, JaggedTensor]]\u00b6\n```", "```py\ncreate_context() \u2192 EmbeddingCollectionContext\u00b6\n```", "```py\nproperty fused_optimizer: KeyedOptimizer\u00b6\n```", "```py\ninput_dist(ctx: EmbeddingCollectionContext, features: KeyedJaggedTensor) \u2192 Awaitable[Awaitable[KJTList]]\u00b6\n```", "```py\noutput_dist(ctx: EmbeddingCollectionContext, output: List[Tensor]) \u2192 LazyAwaitable[Dict[str, JaggedTensor]]\u00b6\n```", "```py\nreset_parameters() \u2192 None\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\ntorchrec.distributed.embedding.create_embedding_sharding(sharding_type: str, sharding_infos: List[EmbeddingShardingInfo], env: ShardingEnv, device: Optional[device] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None) \u2192 EmbeddingSharding[SequenceShardingContext, KeyedJaggedTensor, Tensor, Tensor]\u00b6\n```", "```py\ntorchrec.distributed.embedding.create_sharding_infos_by_sharding(module: EmbeddingCollectionInterface, table_name_to_parameter_sharding: Dict[str, ParameterSharding], fused_params: Optional[Dict[str, Any]]) \u2192 Dict[str, List[EmbeddingShardingInfo]]\u00b6\n```", "```py\ntorchrec.distributed.embedding.get_ec_index_dedup() \u2192 bool\u00b6\n```", "```py\ntorchrec.distributed.embedding.set_ec_index_dedup(val: bool) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.CommOpGradientScaling(*args, **kwargs)\u00b6\n```", "```py\nstatic backward(ctx: FunctionCtx, grad_output: Tensor) \u2192 Tuple[Tensor, None]\u00b6\n```", "```py\nstatic forward(ctx: FunctionCtx, input_tensor: Tensor, scale_gradient_factor: int) \u2192 Tensor\u00b6\n```", "```py\n@staticmethod\ndef forward(ctx: Any, *args: Any, **kwargs: Any) -> Any:\n    pass \n```", "```py\n@staticmethod\ndef forward(*args: Any, **kwargs: Any) -> Any:\n    pass\n\n@staticmethod\ndef setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None:\n    pass \n```", "```py\nclass torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup(grouped_configs: List[GroupedEmbeddingConfig], pg: Optional[ProcessGroup] = None, device: Optional[device] = None)\u00b6\n```", "```py\nflush() \u2192 None\u00b6\n```", "```py\nforward(sparse_features: KeyedJaggedTensor) \u2192 Tensor\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, Union[torch.Tensor, ShardedTensor]], strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\nnamed_parameters_by_table() \u2192 Iterator[Tuple[str, TableBatchedEmbeddingSlice]]\u00b6\n```", "```py\nprefetch(sparse_features: KeyedJaggedTensor, forward_stream: Optional[Stream] = None) \u2192 None\u00b6\n```", "```py\npurge() \u2192 None\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup(grouped_configs: List[GroupedEmbeddingConfig], device: Optional[device] = None, pg: Optional[ProcessGroup] = None, feature_processor: Optional[BaseGroupedFeatureProcessor] = None, scale_weight_gradients: bool = True)\u00b6\n```", "```py\nflush() \u2192 None\u00b6\n```", "```py\nforward(sparse_features: KeyedJaggedTensor) \u2192 Tensor\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, Union[ShardedTensor, torch.Tensor]], strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\nnamed_parameters_by_table() \u2192 Iterator[Tuple[str, TableBatchedEmbeddingSlice]]\u00b6\n```", "```py\nprefetch(sparse_features: KeyedJaggedTensor, forward_stream: Optional[Stream] = None) \u2192 None\u00b6\n```", "```py\npurge() \u2192 None\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.InferGroupedEmbeddingsLookup(grouped_configs_per_rank: List[List[GroupedEmbeddingConfig]], world_size: int, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None)\u00b6\n```", "```py\nget_tbes_to_register() \u2192 Dict[IntNBitTableBatchedEmbeddingBagsCodegen, GroupedEmbeddingConfig]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.InferGroupedLookupMixin\u00b6\n```", "```py\nforward(sparse_features: KJTList) \u2192 List[Tensor]\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, torch.Tensor], strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.InferGroupedPooledEmbeddingsLookup(grouped_configs_per_rank: List[List[GroupedEmbeddingConfig]], world_size: int, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None)\u00b6\n```", "```py\nget_tbes_to_register() \u2192 Dict[IntNBitTableBatchedEmbeddingBagsCodegen, GroupedEmbeddingConfig]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup(grouped_configs: List[GroupedEmbeddingConfig], device: Optional[device] = None, fused_params: Optional[Dict[str, Any]] = None)\u00b6\n```", "```py\nflush() \u2192 None\u00b6\n```", "```py\nforward(sparse_features: KeyedJaggedTensor) \u2192 Tensor\u00b6\n```", "```py\nget_tbes_to_register() \u2192 Dict[IntNBitTableBatchedEmbeddingBagsCodegen, GroupedEmbeddingConfig]\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, Union[ShardedTensor, torch.Tensor]], strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\npurge() \u2192 None\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup(grouped_configs: List[GroupedEmbeddingConfig], device: Optional[device] = None, feature_processor: Optional[BaseGroupedFeatureProcessor] = None, fused_params: Optional[Dict[str, Any]] = None)\u00b6\n```", "```py\nflush() \u2192 None\u00b6\n```", "```py\nforward(sparse_features: KeyedJaggedTensor) \u2192 Tensor\u00b6\n```", "```py\nget_tbes_to_register() \u2192 Dict[IntNBitTableBatchedEmbeddingBagsCodegen, GroupedEmbeddingConfig]\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, Union[ShardedTensor, torch.Tensor]], strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\npurge() \u2192 None\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\ntorchrec.distributed.embedding_lookup.embeddings_cat_empty_rank_handle(embeddings: List[Tensor], dummy_embs_tensor: Tensor, dim: int = 0) \u2192 Tensor\u00b6\n```", "```py\ntorchrec.distributed.embedding_lookup.fx_wrap_tensor_view2d(x: Tensor, dim0: int, dim1: int) \u2192 Tensor\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.BaseEmbeddingDist(*args, **kwargs)\u00b6\n```", "```py\nabstract forward(local_embs: T, sharding_ctx: Optional[C] = None) \u2192 Union[Awaitable[W], W]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.BaseSparseFeaturesDist(*args, **kwargs)\u00b6\n```", "```py\nabstract forward(sparse_features: KeyedJaggedTensor) \u2192 Union[Awaitable[Awaitable[F]], F]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.EmbeddingSharding(qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nabstract create_input_dist(device: Optional[device] = None) \u2192 BaseSparseFeaturesDist[F]\u00b6\n```", "```py\nabstract create_lookup(device: Optional[device] = None, fused_params: Optional[Dict[str, Any]] = None, feature_processor: Optional[BaseGroupedFeatureProcessor] = None) \u2192 BaseEmbeddingLookup[F, T]\u00b6\n```", "```py\nabstract create_output_dist(device: Optional[device] = None) \u2192 BaseEmbeddingDist[C, T, W]\u00b6\n```", "```py\nabstract embedding_dims() \u2192 List[int]\u00b6\n```", "```py\nabstract embedding_names() \u2192 List[str]\u00b6\n```", "```py\nabstract embedding_names_per_rank() \u2192 List[List[str]]\u00b6\n```", "```py\nabstract embedding_shard_metadata() \u2192 List[Optional[ShardMetadata]]\u00b6\n```", "```py\nembedding_tables() \u2192 List[ShardedEmbeddingTable]\u00b6\n```", "```py\nproperty qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]]\u00b6\n```", "```py\nuncombined_embedding_dims() \u2192 List[int]\u00b6\n```", "```py\nuncombined_embedding_names() \u2192 List[str]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.EmbeddingShardingContext(batch_size_per_rank: List[int] = <factory>, batch_size_per_rank_per_feature: List[List[int]] = <factory>, batch_size_per_feature_pre_a2a: List[int] = <factory>, variable_batch_per_feature: bool = False)\u00b6\n```", "```py\nbatch_size_per_feature_pre_a2a: List[int]\u00b6\n```", "```py\nbatch_size_per_rank: List[int]\u00b6\n```", "```py\nbatch_size_per_rank_per_feature: List[List[int]]\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nvariable_batch_per_feature: bool = False\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.EmbeddingShardingInfo(embedding_config: torchrec.modules.embedding_configs.EmbeddingTableConfig, param_sharding: torchrec.distributed.types.ParameterSharding, param: torch.Tensor, fused_params: Union[Dict[str, Any], NoneType] = None)\u00b6\n```", "```py\nembedding_config: EmbeddingTableConfig\u00b6\n```", "```py\nfused_params: Optional[Dict[str, Any]] = None\u00b6\n```", "```py\nparam: Tensor\u00b6\n```", "```py\nparam_sharding: ParameterSharding\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.FusedKJTListSplitsAwaitable(requests: List[KJTListSplitsAwaitable[C]], contexts: List[C], pg: Optional[ProcessGroup])\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.KJTListAwaitable(awaitables: List[Awaitable[KeyedJaggedTensor]], ctx: C)\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.KJTListSplitsAwaitable(awaitables: List[Awaitable[Awaitable[KeyedJaggedTensor]]], ctx: C)\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.KJTSplitsAllToAllMeta(pg: torch.distributed.distributed_c10d.ProcessGroup, _input: torchrec.sparse.jagged_tensor.KeyedJaggedTensor, splits: List[int], splits_tensors: List[torch.Tensor], input_splits: List[List[int]], input_tensors: List[torch.Tensor], labels: List[str], keys: List[str], device: torch.device, stagger: int, splits_cumsum: List[int])\u00b6\n```", "```py\ndevice: device\u00b6\n```", "```py\ninput_splits: List[List[int]]\u00b6\n```", "```py\ninput_tensors: List[Tensor]\u00b6\n```", "```py\nkeys: List[str]\u00b6\n```", "```py\nlabels: List[str]\u00b6\n```", "```py\npg: ProcessGroup\u00b6\n```", "```py\nsplits: List[int]\u00b6\n```", "```py\nsplits_cumsum: List[int]\u00b6\n```", "```py\nsplits_tensors: List[Tensor]\u00b6\n```", "```py\nstagger: int\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.ListOfKJTListAwaitable(awaitables: List[Awaitable[KJTList]])\u00b6\n```", "```py\nclass torchrec.distributed.embedding_sharding.ListOfKJTListSplitsAwaitable(awaitables: List[Awaitable[Awaitable[KJTList]]])\u00b6\n```", "```py\ntorchrec.distributed.embedding_sharding.bucketize_kjt_before_all2all(kjt: KeyedJaggedTensor, num_buckets: int, block_sizes: Tensor, output_permute: bool = False, bucketize_pos: bool = False, block_bucketize_row_pos: Optional[List[Tensor]] = None) \u2192 Tuple[KeyedJaggedTensor, Optional[Tensor]]\u00b6\n```", "```py\ntorchrec.distributed.embedding_sharding.group_tables(tables_per_rank: List[List[ShardedEmbeddingTable]]) \u2192 List[List[GroupedEmbeddingConfig]]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.BaseEmbeddingLookup(*args, **kwargs)\u00b6\n```", "```py\nabstract forward(sparse_features: F) \u2192 T\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.BaseEmbeddingSharder(fused_params: Optional[Dict[str, Any]] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\ncompute_kernels(sharding_type: str, compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nproperty fused_params: Optional[Dict[str, Any]]\u00b6\n```", "```py\nsharding_types(compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nstorage_usage(tensor: Tensor, compute_device_type: str, compute_kernel: str) \u2192 Dict[str, int]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.BaseGroupedFeatureProcessor(*args, **kwargs)\u00b6\n```", "```py\nabstract forward(features: KeyedJaggedTensor) \u2192 KeyedJaggedTensor\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder(fused_params: Optional[Dict[str, Any]] = None, shardable_params: Optional[List[str]] = None)\u00b6\n```", "```py\ncompute_kernels(sharding_type: str, compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nproperty fused_params: Optional[Dict[str, Any]]\u00b6\n```", "```py\nshardable_parameters(module: M) \u2192 Dict[str, Parameter]\u00b6\n```", "```py\nsharding_types(compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nstorage_usage(tensor: Tensor, compute_device_type: str, compute_kernel: str) \u2192 Dict[str, int]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.EmbeddingAttributes(compute_kernel: torchrec.distributed.embedding_types.EmbeddingComputeKernel = <EmbeddingComputeKernel.DENSE: 'dense'>)\u00b6\n```", "```py\ncompute_kernel: EmbeddingComputeKernel = 'dense'\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.EmbeddingComputeKernel(value)\u00b6\n```", "```py\nDENSE = 'dense'\u00b6\n```", "```py\nFUSED = 'fused'\u00b6\n```", "```py\nFUSED_UVM = 'fused_uvm'\u00b6\n```", "```py\nFUSED_UVM_CACHING = 'fused_uvm_caching'\u00b6\n```", "```py\nQUANT = 'quant'\u00b6\n```", "```py\nQUANT_UVM = 'quant_uvm'\u00b6\n```", "```py\nQUANT_UVM_CACHING = 'quant_uvm_caching'\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.FeatureShardingMixIn\u00b6\n```", "```py\nfeature_names() \u2192 List[str]\u00b6\n```", "```py\nfeature_names_per_rank() \u2192 List[List[str]]\u00b6\n```", "```py\nfeatures_per_rank() \u2192 List[int]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.GroupedEmbeddingConfig(data_type: torchrec.types.DataType, pooling: torchrec.modules.embedding_configs.PoolingType, is_weighted: bool, has_feature_processor: bool, compute_kernel: torchrec.distributed.embedding_types.EmbeddingComputeKernel, embedding_tables: List[torchrec.distributed.embedding_types.ShardedEmbeddingTable], fused_params: Union[Dict[str, Any], NoneType] = None)\u00b6\n```", "```py\ncompute_kernel: EmbeddingComputeKernel\u00b6\n```", "```py\ndata_type: DataType\u00b6\n```", "```py\ndim_sum() \u2192 int\u00b6\n```", "```py\nembedding_dims() \u2192 List[int]\u00b6\n```", "```py\nembedding_names() \u2192 List[str]\u00b6\n```", "```py\nembedding_shard_metadata() \u2192 List[Optional[ShardMetadata]]\u00b6\n```", "```py\nembedding_tables: List[ShardedEmbeddingTable]\u00b6\n```", "```py\nfeature_hash_sizes() \u2192 List[int]\u00b6\n```", "```py\nfeature_names() \u2192 List[str]\u00b6\n```", "```py\nfused_params: Optional[Dict[str, Any]] = None\u00b6\n```", "```py\nhas_feature_processor: bool\u00b6\n```", "```py\nis_weighted: bool\u00b6\n```", "```py\nnum_features() \u2192 int\u00b6\n```", "```py\npooling: PoolingType\u00b6\n```", "```py\ntable_names() \u2192 List[str]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.KJTList(features: List[KeyedJaggedTensor])\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.ListOfKJTList(features: List[KJTList])\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.ModuleShardingMixIn\u00b6\n```", "```py\nproperty shardings: Dict[str, FeatureShardingMixIn]\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.OptimType(value)\u00b6\n```", "```py\nADAGRAD = 'ADAGRAD'\u00b6\n```", "```py\nADAM = 'ADAM'\u00b6\n```", "```py\nADAMW = 'ADAMW'\u00b6\n```", "```py\nLAMB = 'LAMB'\u00b6\n```", "```py\nLARS_SGD = 'LARS_SGD'\u00b6\n```", "```py\nLION = 'LION'\u00b6\n```", "```py\nPARTIAL_ROWWISE_ADAM = 'PARTIAL_ROWWISE_ADAM'\u00b6\n```", "```py\nPARTIAL_ROWWISE_LAMB = 'PARTIAL_ROWWISE_LAMB'\u00b6\n```", "```py\nROWWISE_ADAGRAD = 'ROWWISE_ADAGRAD'\u00b6\n```", "```py\nSGD = 'SGD'\u00b6\n```", "```py\nSHAMPOO = 'SHAMPOO'\u00b6\n```", "```py\nSHAMPOO_V2 = 'SHAMPOO_V2'\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.ShardedConfig(local_rows: int = 0, local_cols: int = 0)\u00b6\n```", "```py\nlocal_cols: int = 0\u00b6\n```", "```py\nlocal_rows: int = 0\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.ShardedEmbeddingModule(qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nextra_repr() \u2192 str\u00b6\n```", "```py\nprefetch(dist_input: KJTList, forward_stream: Optional[Stream] = None) \u2192 None\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.ShardedEmbeddingTable(num_embeddings: int, embedding_dim: int, name: str = '', data_type: torchrec.types.DataType = <DataType.FP32: 'FP32'>, feature_names: List[str] = <factory>, weight_init_max: Union[float, NoneType] = None, weight_init_min: Union[float, NoneType] = None, pruning_indices_remapping: Union[torch.Tensor, NoneType] = None, init_fn: Union[Callable[[torch.Tensor], Union[torch.Tensor, NoneType]], NoneType] = None, need_pos: bool = False, pooling: torchrec.modules.embedding_configs.PoolingType = <PoolingType.SUM: 'SUM'>, is_weighted: bool = False, has_feature_processor: bool = False, embedding_names: List[str] = <factory>, compute_kernel: torchrec.distributed.embedding_types.EmbeddingComputeKernel = <EmbeddingComputeKernel.DENSE: 'dense'>, local_rows: int = 0, local_cols: int = 0, local_metadata: Union[torch.distributed._shard.metadata.ShardMetadata, NoneType] = None, global_metadata: Union[torch.distributed._shard.sharded_tensor.metadata.ShardedTensorMetadata, NoneType] = None, fused_params: Union[Dict[str, Any], NoneType] = None)\u00b6\n```", "```py\nfused_params: Optional[Dict[str, Any]] = None\u00b6\n```", "```py\nclass torchrec.distributed.embedding_types.ShardedMetaConfig(local_rows: int = 0, local_cols: int = 0, local_metadata: Union[torch.distributed._shard.metadata.ShardMetadata, NoneType] = None, global_metadata: Union[torch.distributed._shard.sharded_tensor.metadata.ShardedTensorMetadata, NoneType] = None)\u00b6\n```", "```py\nglobal_metadata: Optional[ShardedTensorMetadata] = None\u00b6\n```", "```py\nlocal_metadata: Optional[ShardMetadata] = None\u00b6\n```", "```py\ntorchrec.distributed.embedding_types.compute_kernel_to_embedding_location(compute_kernel: EmbeddingComputeKernel) \u2192 EmbeddingLocation\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.EmbeddingAwaitable(*args, **kwargs)\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.EmbeddingBagCollectionAwaitable(*args, **kwargs)\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.EmbeddingBagCollectionContext(sharding_contexts: List[Union[torchrec.distributed.embedding_sharding.EmbeddingShardingContext, NoneType]] = <factory>, inverse_indices: Union[Tuple[List[str], torch.Tensor], NoneType] = None, variable_batch_per_feature: bool = False)\u00b6\n```", "```py\ninverse_indices: Optional[Tuple[List[str], Tensor]] = None\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nsharding_contexts: List[Optional[EmbeddingShardingContext]]\u00b6\n```", "```py\nvariable_batch_per_feature: bool = False\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder(fused_params: Optional[Dict[str, Any]] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nproperty module_type: Type[EmbeddingBagCollection]\u00b6\n```", "```py\nshard(module: EmbeddingBagCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedEmbeddingBagCollection\u00b6\n```", "```py\nshardable_parameters(module: EmbeddingBagCollection) \u2192 Dict[str, Parameter]\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.EmbeddingBagSharder(fused_params: Optional[Dict[str, Any]] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nproperty module_type: Type[EmbeddingBag]\u00b6\n```", "```py\nshard(module: EmbeddingBag, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedEmbeddingBag\u00b6\n```", "```py\nshardable_parameters(module: EmbeddingBag) \u2192 Dict[str, Parameter]\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.ShardedEmbeddingBag(module: EmbeddingBag, table_name_to_parameter_sharding: Dict[str, ParameterSharding], env: ShardingEnv, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None)\u00b6\n```", "```py\ncompute(ctx: NullShardedModuleContext, dist_input: KeyedJaggedTensor) \u2192 Tensor\u00b6\n```", "```py\ncreate_context() \u2192 NullShardedModuleContext\u00b6\n```", "```py\nproperty fused_optimizer: KeyedOptimizer\u00b6\n```", "```py\ninput_dist(ctx: NullShardedModuleContext, input: Tensor, offsets: Optional[Tensor] = None, per_sample_weights: Optional[Tensor] = None) \u2192 Awaitable[Awaitable[KeyedJaggedTensor]]\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, torch.Tensor], strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_modules(memo: Optional[Set[Module]] = None, prefix: str = '', remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Module]]\u00b6\n```", "```py\n>>> l = nn.Linear(2, 2)\n>>> net = nn.Sequential(l, l)\n>>> for idx, m in enumerate(net.named_modules()):\n...     print(idx, '->', m)\n\n0 -> ('', Sequential(\n (0): Linear(in_features=2, out_features=2, bias=True)\n (1): Linear(in_features=2, out_features=2, bias=True)\n))\n1 -> ('0', Linear(in_features=2, out_features=2, bias=True)) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\noutput_dist(ctx: NullShardedModuleContext, output: Tensor) \u2192 LazyAwaitable[Tensor]\u00b6\n```", "```py\nsharded_parameter_names(prefix: str = '') \u2192 Iterator[str]\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection(module: EmbeddingBagCollectionInterface, table_name_to_parameter_sharding: Dict[str, ParameterSharding], env: ShardingEnv, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\ncompute(ctx: EmbeddingBagCollectionContext, dist_input: KJTList) \u2192 List[Tensor]\u00b6\n```", "```py\ncompute_and_output_dist(ctx: EmbeddingBagCollectionContext, input: KJTList) \u2192 LazyAwaitable[KeyedTensor]\u00b6\n```", "```py\ncreate_context() \u2192 EmbeddingBagCollectionContext\u00b6\n```", "```py\nproperty fused_optimizer: KeyedOptimizer\u00b6\n```", "```py\ninput_dist(ctx: EmbeddingBagCollectionContext, features: KeyedJaggedTensor) \u2192 Awaitable[Awaitable[KJTList]]\u00b6\n```", "```py\noutput_dist(ctx: EmbeddingBagCollectionContext, output: List[Tensor]) \u2192 LazyAwaitable[KeyedTensor]\u00b6\n```", "```py\nreset_parameters() \u2192 None\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.embeddingbag.VariableBatchEmbeddingBagCollectionAwaitable(*args, **kwargs)\u00b6\n```", "```py\ntorchrec.distributed.embeddingbag.construct_output_kt(embeddings: List[Tensor], embedding_names: List[str], embedding_dims: List[int]) \u2192 KeyedTensor\u00b6\n```", "```py\ntorchrec.distributed.embeddingbag.create_embedding_bag_sharding(sharding_type: str, sharding_infos: List[EmbeddingShardingInfo], env: ShardingEnv, device: Optional[device] = None, permute_embeddings: bool = False, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None) \u2192 EmbeddingSharding[EmbeddingShardingContext, KeyedJaggedTensor, Tensor, Tensor]\u00b6\n```", "```py\ntorchrec.distributed.embeddingbag.create_sharding_infos_by_sharding(module: EmbeddingBagCollectionInterface, table_name_to_parameter_sharding: Dict[str, ParameterSharding], prefix: str, fused_params: Optional[Dict[str, Any]], suffix: Optional[str] = 'weight') \u2192 Dict[str, List[EmbeddingShardingInfo]]\u00b6\n```", "```py\ntorchrec.distributed.embeddingbag.replace_placement_with_meta_device(sharding_infos: List[EmbeddingShardingInfo]) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule(max_feature_lengths: Dict[str, int], device: Optional[device] = None)\u00b6\n```", "```py\nforward(features: KeyedJaggedTensor) \u2192 KeyedJaggedTensor\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.model_parallel.DataParallelWrapper\u00b6\n```", "```py\nabstract wrap(dmp: DistributedModelParallel, env: ShardingEnv, device: device) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.model_parallel.DefaultDataParallelWrapper(bucket_cap_mb: int = 25, static_graph: bool = True, find_unused_parameters: bool = False, allreduce_comm_precision: Optional[str] = None)\u00b6\n```", "```py\nwrap(dmp: DistributedModelParallel, env: ShardingEnv, device: device) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.model_parallel.DistributedModelParallel(module: Module, env: Optional[ShardingEnv] = None, device: Optional[device] = None, plan: Optional[ShardingPlan] = None, sharders: Optional[List[ModuleSharder[Module]]] = None, init_data_parallel: bool = True, init_parameters: bool = True, data_parallel_wrapper: Optional[DataParallelWrapper] = None)\u00b6\n```", "```py\n@torch.no_grad()\ndef init_weights(m):\n    if isinstance(m, nn.Linear):\n        m.weight.fill_(1.0)\n    elif isinstance(m, EmbeddingBagCollection):\n        for param in m.parameters():\n            init.kaiming_normal_(param)\n\nm = MyModel(device='meta')\nm = DistributedModelParallel(m)\nm.apply(init_weights) \n```", "```py\nbare_named_parameters(prefix: str = '', recurse: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\ncopy(device: device) \u2192 DistributedModelParallel\u00b6\n```", "```py\nforward(*args, **kwargs) \u2192 Any\u00b6\n```", "```py\nproperty fused_optimizer: KeyedOptimizer\u00b6\n```", "```py\ninit_data_parallel() \u2192 None\u00b6\n```", "```py\nload_state_dict(state_dict: OrderedDict[str, torch.Tensor], prefix: str = '', strict: bool = True) \u2192 _IncompatibleKeys\u00b6\n```", "```py\nproperty module: Module\u00b6\n```", "```py\nnamed_buffers(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Tensor]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, buf in self.named_buffers():\n>>>     if name in ['running_var']:\n>>>         print(buf.size()) \n```", "```py\nnamed_parameters(prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) \u2192 Iterator[Tuple[str, Parameter]]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> for name, param in self.named_parameters():\n>>>     if name in ['bias']:\n>>>         print(param.size()) \n```", "```py\nproperty plan: ShardingPlan\u00b6\n```", "```py\nsparse_grad_parameter_names(destination: Optional[List[str]] = None, prefix: str = '') \u2192 List[str]\u00b6\n```", "```py\nstate_dict(destination: Optional[Dict[str, Any]] = None, prefix: str = '', keep_vars: bool = False) \u2192 Dict[str, Any]\u00b6\n```", "```py\n>>> # xdoctest: +SKIP(\"undefined vars\")\n>>> module.state_dict().keys()\n['bias', 'weight'] \n```", "```py\ntraining: bool\u00b6\n```", "```py\ntorchrec.distributed.model_parallel.get_module(module: Module) \u2192 Module\u00b6\n```", "```py\ntorchrec.distributed.model_parallel.get_unwrapped_module(module: Module) \u2192 Module\u00b6\n```", "```py\nclass torchrec.distributed.quant_embeddingbag.QuantEmbeddingBagCollectionSharder(fused_params: Optional[Dict[str, Any]] = None, shardable_params: Optional[List[str]] = None)\u00b6\n```", "```py\nproperty module_type: Type[EmbeddingBagCollection]\u00b6\n```", "```py\nshard(module: EmbeddingBagCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedQuantEmbeddingBagCollection\u00b6\n```", "```py\nclass torchrec.distributed.quant_embeddingbag.QuantFeatureProcessedEmbeddingBagCollectionSharder(fused_params: Optional[Dict[str, Any]] = None, shardable_params: Optional[List[str]] = None)\u00b6\n```", "```py\ncompute_kernels(sharding_type: str, compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nproperty module_type: Type[FeatureProcessedEmbeddingBagCollection]\u00b6\n```", "```py\nshard(module: FeatureProcessedEmbeddingBagCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedQuantEmbeddingBagCollection\u00b6\n```", "```py\nsharding_types(compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nclass torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection(module: EmbeddingBagCollectionInterface, table_name_to_parameter_sharding: Dict[str, ParameterSharding], env: ShardingEnv, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None)\u00b6\n```", "```py\ncompute(ctx: NullShardedModuleContext, dist_input: ListOfKJTList) \u2192 List[List[Tensor]]\u00b6\n```", "```py\ncompute_and_output_dist(ctx: NullShardedModuleContext, input: ListOfKJTList) \u2192 KeyedTensor\u00b6\n```", "```py\ncopy(device: device) \u2192 Module\u00b6\n```", "```py\ncreate_context() \u2192 NullShardedModuleContext\u00b6\n```", "```py\nembedding_bag_configs() \u2192 List[EmbeddingBagConfig]\u00b6\n```", "```py\nforward(*input, **kwargs) \u2192 KeyedTensor\u00b6\n```", "```py\ninput_dist(ctx: NullShardedModuleContext, features: KeyedJaggedTensor) \u2192 ListOfKJTList\u00b6\n```", "```py\noutput_dist(ctx: NullShardedModuleContext, output: List[List[Tensor]]) \u2192 KeyedTensor\u00b6\n```", "```py\nsharding_type_to_sharding_infos() \u2192 Dict[str, List[EmbeddingShardingInfo]]\u00b6\n```", "```py\nproperty shardings: Dict[str, FeatureShardingMixIn]\u00b6\n```", "```py\ntbes_configs() \u2192 Dict[IntNBitTableBatchedEmbeddingBagsCodegen, GroupedEmbeddingConfig]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.quant_embeddingbag.ShardedQuantFeatureProcessedEmbeddingBagCollection(module: EmbeddingBagCollectionInterface, table_name_to_parameter_sharding: Dict[str, ParameterSharding], env: ShardingEnv, fused_params: Optional[Dict[str, Any]] = None, device: Optional[device] = None, feature_processor: Optional[FeatureProcessorsCollection] = None)\u00b6\n```", "```py\napply_feature_processor(kjt_list: KJTList) \u2192 KJTList\u00b6\n```", "```py\ncompute(ctx: NullShardedModuleContext, dist_input: ListOfKJTList) \u2192 List[List[Tensor]]\u00b6\n```", "```py\nembedding_bags: nn.ModuleDict\u00b6\n```", "```py\ntbes: torch.nn.ModuleList\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\ntorchrec.distributed.quant_embeddingbag.create_infer_embedding_bag_sharding(sharding_type: str, sharding_infos: List[EmbeddingShardingInfo], env: ShardingEnv) \u2192 EmbeddingSharding[NullShardingContext, KJTList, List[Tensor], Tensor]\u00b6\n```", "```py\ntorchrec.distributed.quant_embeddingbag.flatten_feature_lengths(features: KeyedJaggedTensor) \u2192 KeyedJaggedTensor\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.ArgInfo(input_attrs: List[str], is_getitems: List[bool], name: Optional[str])\u00b6\n```", "```py\ninput_attrs\u00b6\n```", "```py\nis_getitems\u00b6\n```", "```py\nname\u00b6\n```", "```py\ninput_attrs: List[str]\u00b6\n```", "```py\nis_getitems: List[bool]\u00b6\n```", "```py\nname: Optional[str]\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.BaseForward(name: str, args: List[ArgInfo], module: ShardedModule, context: TrainPipelineContext, stream: Optional[Stream])\u00b6\n```", "```py\nproperty args: List[ArgInfo]\u00b6\n```", "```py\nproperty name: str\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.FusedKJTListSplitsAwaitable(requests: List[KJTListSplitsAwaitable[C]], contexts: List[C], pg: Optional[ProcessGroup])\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.KJTAllToAllForward(pg: ProcessGroup, splits: List[int], stagger: int = 1)\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.KJTSplitsAllToAllMeta(pg: torch.distributed.distributed_c10d.ProcessGroup, _input: torchrec.sparse.jagged_tensor.KeyedJaggedTensor, splits: List[int], splits_tensors: List[torch.Tensor], input_splits: List[List[int]], input_tensors: List[torch.Tensor], labels: List[str], keys: List[str], device: torch.device, stagger: int)\u00b6\n```", "```py\ndevice: device\u00b6\n```", "```py\ninput_splits: List[List[int]]\u00b6\n```", "```py\ninput_tensors: List[Tensor]\u00b6\n```", "```py\nkeys: List[str]\u00b6\n```", "```py\nlabels: List[str]\u00b6\n```", "```py\npg: ProcessGroup\u00b6\n```", "```py\nsplits: List[int]\u00b6\n```", "```py\nsplits_tensors: List[Tensor]\u00b6\n```", "```py\nstagger: int\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.PipelinedForward(name: str, args: List[ArgInfo], module: ShardedModule, context: TrainPipelineContext, stream: Optional[Stream])\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.PrefetchPipelinedForward(name: str, args: List[ArgInfo], module: ShardedModule, context: PrefetchTrainPipelineContext, prefetch_stream: Optional[Stream])\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.PrefetchTrainPipelineContext(input_dist_splits_requests: Dict[str, torchrec.distributed.types.Awaitable[Any]] = <factory>, input_dist_tensors_requests: Dict[str, torchrec.distributed.types.Awaitable[Any]] = <factory>, module_contexts: Dict[str, torchrec.streamable.Multistreamable] = <factory>, module_contexts_next_batch: Dict[str, torchrec.streamable.Multistreamable] = <factory>, fused_splits_awaitables: List[Tuple[List[str], torchrec.distributed.train_pipeline.FusedKJTListSplitsAwaitable]] = <factory>, module_input_post_prefetch: Dict[str, torchrec.streamable.Multistreamable] = <factory>, module_contexts_post_prefetch: Dict[str, torchrec.streamable.Multistreamable] = <factory>)\u00b6\n```", "```py\nmodule_contexts_post_prefetch: Dict[str, Multistreamable]\u00b6\n```", "```py\nmodule_input_post_prefetch: Dict[str, Multistreamable]\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.PrefetchTrainPipelineSparseDist(model: Module, optimizer: Optimizer, device: device, execute_all_batches: bool = True, apply_jit: bool = False)\u00b6\n```", "```py\nprogress(dataloader_iter: Iterator[In]) \u2192 Out\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.SplitsAllToAllAwaitable(input_tensors: List[Tensor], pg: ProcessGroup)\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.Tracer(leaf_modules: Optional[List[str]] = None)\u00b6\n```", "```py\ngraph: Graph\u00b6\n```", "```py\nis_leaf_module(m: Module, module_qualified_name: str) \u2192 bool\u00b6\n```", "```py\nmodule_stack: OrderedDict[str, Tuple[str, Any]]\u00b6\n```", "```py\nnode_name_to_scope: Dict[str, Tuple[str, type]]\u00b6\n```", "```py\nproxy_buffer_attributes: bool = False\u00b6\n```", "```py\nscope: Scope\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.TrainPipeline(*args, **kwds)\u00b6\n```", "```py\nabstract progress(dataloader_iter: Iterator[In]) \u2192 Out\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.TrainPipelineBase(model: Module, optimizer: Optimizer, device: device)\u00b6\n```", "```py\nprogress(dataloader_iter: Iterator[In]) \u2192 Out\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.TrainPipelineContext(input_dist_splits_requests: ~typing.Dict[str, ~torchrec.distributed.types.Awaitable[~typing.Any]] = <factory>, input_dist_tensors_requests: ~typing.Dict[str, ~torchrec.distributed.types.Awaitable[~typing.Any]] = <factory>, module_contexts: ~typing.Dict[str, ~torchrec.streamable.Multistreamable] = <factory>, module_contexts_next_batch: ~typing.Dict[str, ~torchrec.streamable.Multistreamable] = <factory>, fused_splits_awaitables: ~typing.List[~typing.Tuple[~typing.List[str], ~torchrec.distributed.train_pipeline.FusedKJTListSplitsAwaitable]] = <factory>)\u00b6\n```", "```py\ninput_dist_splits_requests\u00b6\n```", "```py\ninput_dist_tensors_requests\u00b6\n```", "```py\nmodule_contexts\u00b6\n```", "```py\nmodule_contexts_next_batch\u00b6\n```", "```py\nfused_splits_awaitables\u00b6\n```", "```py\nfused_splits_awaitables: List[Tuple[List[str], FusedKJTListSplitsAwaitable]]\u00b6\n```", "```py\ninput_dist_splits_requests: Dict[str, Awaitable[Any]]\u00b6\n```", "```py\ninput_dist_tensors_requests: Dict[str, Awaitable[Any]]\u00b6\n```", "```py\nmodule_contexts: Dict[str, Multistreamable]\u00b6\n```", "```py\nmodule_contexts_next_batch: Dict[str, Multistreamable]\u00b6\n```", "```py\nclass torchrec.distributed.train_pipeline.TrainPipelineSparseDist(model: Module, optimizer: Optimizer, device: device, execute_all_batches: bool = True, apply_jit: bool = False)\u00b6\n```", "```py\nprogress(dataloader_iter: Iterator[In]) \u2192 Out\u00b6\n```", "```py\nclass torchrec.distributed.types.Awaitable\u00b6\n```", "```py\nproperty callbacks: List[Callable[[W], W]]\u00b6\n```", "```py\nwait() \u2192 W\u00b6\n```", "```py\nclass torchrec.distributed.types.CacheParams(algorithm: Union[fbgemm_gpu.split_table_batched_embeddings_ops_common.CacheAlgorithm, NoneType] = None, load_factor: Union[float, NoneType] = None, reserved_memory: Union[float, NoneType] = None, precision: Union[torchrec.types.DataType, NoneType] = None, prefetch_pipeline: Union[bool, NoneType] = None, stats: Union[torchrec.distributed.types.CacheStatistics, NoneType] = None)\u00b6\n```", "```py\nalgorithm: Optional[CacheAlgorithm] = None\u00b6\n```", "```py\nload_factor: Optional[float] = None\u00b6\n```", "```py\nprecision: Optional[DataType] = None\u00b6\n```", "```py\nprefetch_pipeline: Optional[bool] = None\u00b6\n```", "```py\nreserved_memory: Optional[float] = None\u00b6\n```", "```py\nstats: Optional[CacheStatistics] = None\u00b6\n```", "```py\nclass torchrec.distributed.types.CacheStatistics\u00b6\n```", "```py\nabstract property cacheability: float\u00b6\n```", "```py\nabstract property expected_lookups: float\u00b6\n```", "```py\nabstract expected_miss_rate(clf: float) \u2192 float\u00b6\n```", "```py\nclass torchrec.distributed.types.CommOp(value)\u00b6\n```", "```py\nPOOLED_EMBEDDINGS_ALL_TO_ALL = 'pooled_embeddings_all_to_all'\u00b6\n```", "```py\nPOOLED_EMBEDDINGS_REDUCE_SCATTER = 'pooled_embeddings_reduce_scatter'\u00b6\n```", "```py\nSEQUENCE_EMBEDDINGS_ALL_TO_ALL = 'sequence_embeddings_all_to_all'\u00b6\n```", "```py\nclass torchrec.distributed.types.ComputeKernel(value)\u00b6\n```", "```py\nDEFAULT = 'default'\u00b6\n```", "```py\nclass torchrec.distributed.types.EmbeddingModuleShardingPlan\u00b6\n```", "```py\nclass torchrec.distributed.types.GenericMeta\u00b6\n```", "```py\nclass torchrec.distributed.types.LazyAwaitable(*args, **kwargs)\u00b6\n```", "```py\nclass torchrec.distributed.types.LazyNoWait(*args, **kwargs)\u00b6\n```", "```py\nclass torchrec.distributed.types.ModuleSharder(qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\ncompute_kernels(sharding_type: str, compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nabstract property module_type: Type[M]\u00b6\n```", "```py\nproperty qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]]\u00b6\n```", "```py\nabstract classmethod shard(module: M, params: EmbeddingModuleShardingPlan, env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedModule[Any, Any, Any, Any]\u00b6\n```", "```py\nshardable_parameters(module: M) \u2192 Dict[str, Parameter]\u00b6\n```", "```py\nsharding_types(compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nstorage_usage(tensor: Tensor, compute_device_type: str, compute_kernel: str) \u2192 Dict[str, int]\u00b6\n```", "```py\nclass torchrec.distributed.types.ModuleShardingPlan\u00b6\n```", "```py\nclass torchrec.distributed.types.NoOpQuantizedCommCodec(*args, **kwds)\u00b6\n```", "```py\ncalc_quantized_size(input_len: int, ctx: Optional[QuantizationContext] = None) \u2192 int\u00b6\n```", "```py\ncreate_context() \u2192 Optional[QuantizationContext]\u00b6\n```", "```py\ndecode(input_grad: Tensor, ctx: Optional[QuantizationContext] = None) \u2192 Tensor\u00b6\n```", "```py\nencode(input_tensor: Tensor, ctx: Optional[QuantizationContext] = None) \u2192 Tensor\u00b6\n```", "```py\nquantized_dtype() \u2192 dtype\u00b6\n```", "```py\nclass torchrec.distributed.types.NoWait(obj: W)\u00b6\n```", "```py\nclass torchrec.distributed.types.NullShardedModuleContext\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.types.NullShardingContext\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nclass torchrec.distributed.types.ParameterSharding(sharding_type: str, compute_kernel: str, ranks: Optional[List[int]] = None, sharding_spec: Optional[ShardingSpec] = None, cache_params: Optional[CacheParams] = None, enforce_hbm: Optional[bool] = None, stochastic_rounding: Optional[bool] = None, bounds_check_mode: Optional[BoundsCheckMode] = None)\u00b6\n```", "```py\nbounds_check_mode: Optional[BoundsCheckMode] = None\u00b6\n```", "```py\ncache_params: Optional[CacheParams] = None\u00b6\n```", "```py\ncompute_kernel: str\u00b6\n```", "```py\nenforce_hbm: Optional[bool] = None\u00b6\n```", "```py\nranks: Optional[List[int]] = None\u00b6\n```", "```py\nsharding_spec: Optional[ShardingSpec] = None\u00b6\n```", "```py\nsharding_type: str\u00b6\n```", "```py\nstochastic_rounding: Optional[bool] = None\u00b6\n```", "```py\nclass torchrec.distributed.types.ParameterStorage(value)\u00b6\n```", "```py\nDDR = 'ddr'\u00b6\n```", "```py\nHBM = 'hbm'\u00b6\n```", "```py\nclass torchrec.distributed.types.QuantizedCommCodec(*args, **kwds)\u00b6\n```", "```py\n>>>\n quantized_tensor = quantized_comm_codec.encode(input_tensor)\n quantized_tensor.dtype == quantized_comm_codec.quantized_dtype\n collective_call(output_tensors, input_tensors=tensor)\n output_tensor = decode(output_tensors) \n```", "```py\ncalc_quantized_size(input_len: int, ctx: Optional[QuantizationContext] = None) \u2192 int\u00b6\n```", "```py\ncreate_context() \u2192 Optional[QuantizationContext]\u00b6\n```", "```py\ndecode(input_grad: Tensor, ctx: Optional[QuantizationContext] = None) \u2192 Tensor\u00b6\n```", "```py\nencode(input_tensor: Tensor, ctx: Optional[QuantizationContext] = None) \u2192 Tensor\u00b6\n```", "```py\nproperty quantized_dtype: dtype\u00b6\n```", "```py\nclass torchrec.distributed.types.QuantizedCommCodecs(forward: ~torchrec.distributed.types.QuantizedCommCodec = <torchrec.distributed.types.NoOpQuantizedCommCodec object>, backward: ~torchrec.distributed.types.QuantizedCommCodec = <torchrec.distributed.types.NoOpQuantizedCommCodec object>)\u00b6\n```", "```py\nbackward: QuantizedCommCodec = <torchrec.distributed.types.NoOpQuantizedCommCodec object>\u00b6\n```", "```py\nforward: QuantizedCommCodec = <torchrec.distributed.types.NoOpQuantizedCommCodec object>\u00b6\n```", "```py\nclass torchrec.distributed.types.ShardedModule(qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nabstract compute(ctx: ShrdCtx, dist_input: CompIn) \u2192 DistOut\u00b6\n```", "```py\ncompute_and_output_dist(ctx: ShrdCtx, input: CompIn) \u2192 LazyAwaitable[Out]\u00b6\n```", "```py\nabstract create_context() \u2192 ShrdCtx\u00b6\n```", "```py\nforward(*input, **kwargs) \u2192 LazyAwaitable[Out]\u00b6\n```", "```py\nabstract input_dist(ctx: ShrdCtx, *input, **kwargs) \u2192 Awaitable[Awaitable[CompIn]]\u00b6\n```", "```py\nabstract output_dist(ctx: ShrdCtx, output: DistOut) \u2192 LazyAwaitable[Out]\u00b6\n```", "```py\nproperty qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]]\u00b6\n```", "```py\nsharded_parameter_names(prefix: str = '') \u2192 Iterator[str]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.types.ShardingEnv(world_size: int, rank: int, pg: Optional[ProcessGroup] = None)\u00b6\n```", "```py\nclassmethod from_local(world_size: int, rank: int) \u2192 ShardingEnv\u00b6\n```", "```py\nclassmethod from_process_group(pg: ProcessGroup) \u2192 ShardingEnv\u00b6\n```", "```py\nclass torchrec.distributed.types.ShardingPlan(plan: Dict[str, ModuleShardingPlan])\u00b6\n```", "```py\nplan\u00b6\n```", "```py\nget_plan_for_module(module_path: str) \u2192 Optional[ModuleShardingPlan]\u00b6\n```", "```py\nplan: Dict[str, ModuleShardingPlan]\u00b6\n```", "```py\nclass torchrec.distributed.types.ShardingPlanner\u00b6\n```", "```py\nabstract collective_plan(module: Module, sharders: List[ModuleSharder[Module]]) \u2192 ShardingPlan\u00b6\n```", "```py\nabstract plan(module: Module, sharders: List[ModuleSharder[Module]]) \u2192 ShardingPlan\u00b6\n```", "```py\nclass torchrec.distributed.types.ShardingType(value)\u00b6\n```", "```py\nCOLUMN_WISE = 'column_wise'\u00b6\n```", "```py\nDATA_PARALLEL = 'data_parallel'\u00b6\n```", "```py\nROW_WISE = 'row_wise'\u00b6\n```", "```py\nTABLE_COLUMN_WISE = 'table_column_wise'\u00b6\n```", "```py\nTABLE_ROW_WISE = 'table_row_wise'\u00b6\n```", "```py\nTABLE_WISE = 'table_wise'\u00b6\n```", "```py\ntorchrec.distributed.types.get_tensor_size_bytes(t: Tensor) \u2192 int\u00b6\n```", "```py\ntorchrec.distributed.types.scope(method)\u00b6\n```", "```py\nclass torchrec.distributed.utils.CopyableMixin(*args, **kwargs)\u00b6\n```", "```py\nclass MyModule(CopyableMixin):\n    ... \n```", "```py\ncopy(device: device) \u2192 Module\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.utils.PermutePooledEmbeddings(embs_dims: List[int], permute: List[int], device: Optional[device] = None)\u00b6\n```", "```py\ntorchrec.distributed.utils.add_params_from_parameter_sharding(fused_params: Optional[Dict[str, Any]], parameter_sharding: ParameterSharding) \u2192 Dict[str, Any]\u00b6\n```", "```py\ntorchrec.distributed.utils.add_prefix_to_state_dict(state_dict: Dict[str, Any], prefix: str) \u2192 None\u00b6\n```", "```py\ntorchrec.distributed.utils.append_prefix(prefix: str, name: str) \u2192 str\u00b6\n```", "```py\ntorchrec.distributed.utils.convert_to_fbgemm_types(fused_params: Dict[str, Any]) \u2192 Dict[str, Any]\u00b6\n```", "```py\ntorchrec.distributed.utils.copy_to_device(module: Module, current_device: device, to_device: device) \u2192 Module\u00b6\n```", "```py\ntorchrec.distributed.utils.filter_state_dict(state_dict: OrderedDict[str, torch.Tensor], name: str) \u2192 OrderedDict[str, torch.Tensor]\u00b6\n```", "```py\ntorchrec.distributed.utils.get_unsharded_module_names(model: Module) \u2192 List[str]\u00b6\n```", "```py\ntorchrec.distributed.utils.init_parameters(module: Module, device: device) \u2192 None\u00b6\n```", "```py\ntorchrec.distributed.utils.merge_fused_params(fused_params: Optional[Dict[str, Any]] = None, param_fused_params: Optional[Dict[str, Any]] = None) \u2192 Dict[str, Any]\u00b6\n```", "```py\ntorchrec.distributed.utils.none_throws(optional: Optional[_T], message: str = 'Unexpected `None`') \u2192 _T\u00b6\n```", "```py\ntorchrec.distributed.utils.optimizer_type_to_emb_opt_type(optimizer_class: Type[Optimizer]) \u2192 Optional[EmbOptimType]\u00b6\n```", "```py\nclass torchrec.distributed.utils.sharded_model_copy(device: Optional[Union[str, int, device]])\u00b6\n```", "```py\n# Copying model to CPU.\n\nm = DistributedModelParallel(m)\nwith sharded_model_copy(\"cpu\"):\n    m_cpu = copy.deepcopy(m) \n```", "```py\nclass torchrec.distributed.mc_modules.ManagedCollisionCollectionAwaitable(*args, **kwargs)\u00b6\n```", "```py\nclass torchrec.distributed.mc_modules.ManagedCollisionCollectionContext(sharding_contexts: List[torchrec.distributed.sharding.sequence_sharding.SequenceShardingContext] = <factory>, input_features: List[torchrec.sparse.jagged_tensor.KeyedJaggedTensor] = <factory>, reverse_indices: List[torch.Tensor] = <factory>)\u00b6\n```", "```py\ninput_features: List[KeyedJaggedTensor]\u00b6\n```", "```py\nreverse_indices: List[Tensor]\u00b6\n```", "```py\nsharding_contexts: List[SequenceShardingContext]\u00b6\n```", "```py\nclass torchrec.distributed.mc_modules.ManagedCollisionCollectionSharder(qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nproperty module_type: Type[ManagedCollisionCollection]\u00b6\n```", "```py\nshard(module: ManagedCollisionCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, sharding_type_to_sharding: Dict[str, EmbeddingSharding[EmbeddingShardingContext, KeyedJaggedTensor, Tensor, Tensor]], device: Optional[device] = None) \u2192 ShardedManagedCollisionCollection\u00b6\n```", "```py\nshardable_parameters(module: ManagedCollisionCollection) \u2192 Dict[str, Parameter]\u00b6\n```", "```py\nsharding_types(compute_device_type: str) \u2192 List[str]\u00b6\n```", "```py\nclass torchrec.distributed.mc_modules.ShardedManagedCollisionCollection(module: ManagedCollisionCollection, table_name_to_parameter_sharding: Dict[str, ParameterSharding], env: ShardingEnv, device: device, sharding_type_to_sharding: Dict[str, EmbeddingSharding[EmbeddingShardingContext, KeyedJaggedTensor, Tensor, Tensor]], qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\ncompute(ctx: ManagedCollisionCollectionContext, dist_input: KJTList) \u2192 KJTList\u00b6\n```", "```py\ncreate_context() \u2192 ManagedCollisionCollectionContext\u00b6\n```", "```py\nevict() \u2192 Dict[str, Optional[Tensor]]\u00b6\n```", "```py\ninput_dist(ctx: ManagedCollisionCollectionContext, features: KeyedJaggedTensor) \u2192 Awaitable[Awaitable[KJTList]]\u00b6\n```", "```py\noutput_dist(ctx: ManagedCollisionCollectionContext, output: KJTList) \u2192 LazyAwaitable[KeyedJaggedTensor]\u00b6\n```", "```py\nsharded_parameter_names(prefix: str = '') \u2192 Iterator[str]\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\ntorchrec.distributed.mc_modules.create_mc_sharding(sharding_type: str, sharding_infos: List[EmbeddingShardingInfo], env: ShardingEnv, device: Optional[device] = None) \u2192 EmbeddingSharding[SequenceShardingContext, KeyedJaggedTensor, Tensor, Tensor]\u00b6\n```", "```py\nclass torchrec.distributed.mc_embeddingbag.ManagedCollisionEmbeddingBagCollectionContext(sharding_contexts: List[Union[torchrec.distributed.embedding_sharding.EmbeddingShardingContext, NoneType]] = <factory>, inverse_indices: Union[Tuple[List[str], torch.Tensor], NoneType] = None, variable_batch_per_feature: bool = False, evictions_per_table: Union[Dict[str, Union[torch.Tensor, NoneType]], NoneType] = None, remapped_kjt: Union[torchrec.distributed.embedding_types.KJTList, NoneType] = None)\u00b6\n```", "```py\nevictions_per_table: Optional[Dict[str, Optional[Tensor]]] = None\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nremapped_kjt: Optional[KJTList] = None\u00b6\n```", "```py\nclass torchrec.distributed.mc_embeddingbag.ManagedCollisionEmbeddingBagCollectionSharder(ebc_sharder: Optional[EmbeddingBagCollectionSharder] = None, mc_sharder: Optional[ManagedCollisionCollectionSharder] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nproperty module_type: Type[ManagedCollisionEmbeddingBagCollection]\u00b6\n```", "```py\nshard(module: ManagedCollisionEmbeddingBagCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedManagedCollisionEmbeddingBagCollection\u00b6\n```", "```py\nclass torchrec.distributed.mc_embeddingbag.ShardedManagedCollisionEmbeddingBagCollection(module: ManagedCollisionEmbeddingBagCollection, table_name_to_parameter_sharding: Dict[str, ParameterSharding], ebc_sharder: EmbeddingBagCollectionSharder, mc_sharder: ManagedCollisionCollectionSharder, env: ShardingEnv, device: device)\u00b6\n```", "```py\ncreate_context() \u2192 ManagedCollisionEmbeddingBagCollectionContext\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.distributed.mc_embedding.ManagedCollisionEmbeddingCollectionContext(sharding_contexts: List[torchrec.distributed.sharding.sequence_sharding.SequenceShardingContext] = <factory>, input_features: List[torchrec.sparse.jagged_tensor.KeyedJaggedTensor] = <factory>, reverse_indices: List[torch.Tensor] = <factory>, evictions_per_table: Union[Dict[str, Union[torch.Tensor, NoneType]], NoneType] = None, remapped_kjt: Union[torchrec.distributed.embedding_types.KJTList, NoneType] = None)\u00b6\n```", "```py\nevictions_per_table: Optional[Dict[str, Optional[Tensor]]] = None\u00b6\n```", "```py\nrecord_stream(stream: Stream) \u2192 None\u00b6\n```", "```py\nremapped_kjt: Optional[KJTList] = None\u00b6\n```", "```py\nclass torchrec.distributed.mc_embedding.ManagedCollisionEmbeddingCollectionSharder(ec_sharder: Optional[EmbeddingCollectionSharder] = None, mc_sharder: Optional[ManagedCollisionCollectionSharder] = None, qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None)\u00b6\n```", "```py\nproperty module_type: Type[ManagedCollisionEmbeddingCollection]\u00b6\n```", "```py\nshard(module: ManagedCollisionEmbeddingCollection, params: Dict[str, ParameterSharding], env: ShardingEnv, device: Optional[device] = None) \u2192 ShardedManagedCollisionEmbeddingCollection\u00b6\n```", "```py\nclass torchrec.distributed.mc_embedding.ShardedManagedCollisionEmbeddingCollection(module: ManagedCollisionEmbeddingCollection, table_name_to_parameter_sharding: Dict[str, ParameterSharding], ec_sharder: EmbeddingCollectionSharder, mc_sharder: ManagedCollisionCollectionSharder, env: ShardingEnv, device: device)\u00b6\n```", "```py\ncreate_context() \u2192 ManagedCollisionEmbeddingCollectionContext\u00b6\n```", "```py\ntraining: bool\u00b6\n```"]