["```py\nconda  install  pytorch  torchvision  -c  pytorch\nconda  install  matplotlib  tensorboard \n```", "```py\npip  install  torch  torchvision  matplotlib  tensorboard \n```", "```py\n# PyTorch model and training necessities\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# Image datasets and image manipulation\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Image display\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# PyTorch TensorBoard support\nfrom torch.utils.tensorboard import [SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\")\n\n# In case you are using an environment that has TensorFlow installed,\n# such as Google Colab, uncomment the following code to avoid\n# a bug with saving embeddings to your TensorBoard directory\n\n# import tensorflow as tf\n# import tensorboard as tb\n# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile \n```", "```py\n# Gather datasets and prepare them for consumption\n[transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\") = [transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")(\n    [[transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")(),\n    [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")((0.5,), (0.5,))])\n\n# Store separate training and validations splits in ./data\n[training_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\") = [torchvision.datasets.FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\")('./data',\n    download=True,\n    train=True,\n    [transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")=[transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\"))\n[validation_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\") = [torchvision.datasets.FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\")('./data',\n    download=True,\n    train=False,\n    [transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")=[transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\"))\n\n[training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")([training_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\"),\n                                              batch_size=4,\n                                              shuffle=True,\n                                              num_workers=2)\n\n[validation_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")([validation_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\"),\n                                                batch_size=4,\n                                                shuffle=False,\n                                                num_workers=2)\n\n# Class labels\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# Helper function for inline image display\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# Extract a batch of 4 images\ndataiter = iter([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"))\n[images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = next(dataiter)\n\n# Create a grid from the images and show them\n[img_grid](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torchvision.utils.make_grid](https://pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid \"torchvision.utils.make_grid\")([images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nmatplotlib_imshow([img_grid](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), one_channel=True) \n```", "```py\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n\n  0%|          | 0/26421880 [00:00<?, ?it/s]\n  0%|          | 65536/26421880 [00:00<01:09, 378414.86it/s]\n  1%|          | 229376/26421880 [00:00<00:37, 693250.36it/s]\n  4%|3         | 950272/26421880 [00:00<00:11, 2219214.26it/s]\n 15%|#4        | 3833856/26421880 [00:00<00:02, 7688687.97it/s]\n 35%|###5      | 9273344/26421880 [00:00<00:01, 15802443.73it/s]\n 58%|#####7    | 15204352/26421880 [00:01<00:00, 21640902.59it/s]\n 80%|#######9  | 21102592/26421880 [00:01<00:00, 25246743.30it/s]\n100%|##########| 26421880/26421880 [00:01<00:00, 19515987.25it/s]\nExtracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n\n  0%|          | 0/29515 [00:00<?, ?it/s]\n100%|##########| 29515/29515 [00:00<00:00, 329627.44it/s]\nExtracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n\n  0%|          | 0/4422102 [00:00<?, ?it/s]\n  1%|1         | 65536/4422102 [00:00<00:11, 363060.61it/s]\n  5%|5         | 229376/4422102 [00:00<00:06, 683092.95it/s]\n 19%|#8        | 819200/4422102 [00:00<00:01, 1861301.92it/s]\n 64%|######4   | 2850816/4422102 [00:00<00:00, 5548383.23it/s]\n100%|##########| 4422102/4422102 [00:00<00:00, 6080037.27it/s]\nExtracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n\n  0%|          | 0/5148 [00:00<?, ?it/s]\n100%|##########| 5148/5148 [00:00<00:00, 39618856.87it/s]\nExtracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw \n```", "```py\n# Default log_dir argument is \"runs\" - but it's good to be specific\n# torch.utils.tensorboard.SummaryWriter is imported above\n[writer](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\") = [SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\")('runs/fashion_mnist_experiment_1')\n\n# Write image data to TensorBoard log dir\n[writer.add_image](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image \"torch.utils.tensorboard.writer.SummaryWriter.add_image\")('Four Fashion-MNIST Images', [img_grid](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[writer.flush](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush \"torch.utils.tensorboard.writer.SummaryWriter.flush\")()\n\n# To view, start TensorBoard on the command line with:\n#   tensorboard --logdir=runs\n# ...and open a browser tab to http://localhost:6006/ \n```", "```py\nclass Net([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self):\n        super([Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(1, 6, 5)\n        self.pool = [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d \"torch.nn.MaxPool2d\")(2, 2)\n        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(6, 16, 5)\n        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(16 * 4 * 4, 120)\n        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(120, 84)\n        self.fc3 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(84, 10)\n\n    def forward(self, x):\n        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.conv1(x)))\n        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.fc1(x))\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")()\n[criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\") = [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")()\n[optimizer](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\") = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\")([net.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")(), lr=0.001, momentum=0.9) \n```", "```py\nprint(len([validation_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")))\nfor epoch in range(1):  # loop over the dataset multiple times\n    running_loss = 0.0\n\n    for i, data in enumerate([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), 0):\n        # basic training loop\n        [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = data\n        [optimizer.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.zero_grad \"torch.optim.SGD.zero_grad\")()\n        [outputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = net([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")([outputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        [loss.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward \"torch.Tensor.backward\")()\n        [optimizer.step](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.step \"torch.optim.SGD.step\")()\n\n        running_loss += [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").item()\n        if i % 1000 == 999:    # Every 1000 mini-batches...\n            print('Batch {}'.format(i + 1))\n            # Check against the validation set\n            running_vloss = 0.0\n\n            # In evaluation mode some model specific operations can be omitted eg. dropout layer\n            [net.train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train \"torch.nn.Module.train\")(False) # Switching to evaluation mode, eg. turning off regularisation\n            for j, vdata in enumerate([validation_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), 0):\n                [vinputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [vlabels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = vdata\n                [voutputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = net([vinputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n                [vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")([voutputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [vlabels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n                running_vloss += [vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").item()\n            [net.train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train \"torch.nn.Module.train\")(True) # Switching back to training mode, eg. turning on regularisation\n\n            avg_loss = running_loss / 1000\n            avg_vloss = running_vloss / len([validation_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"))\n\n            # Log the running loss averaged per batch\n            [writer.add_scalars](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars \"torch.utils.tensorboard.writer.SummaryWriter.add_scalars\")('Training vs. Validation Loss',\n                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n                            epoch * len([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")) + i)\n\n            running_loss = 0.0\nprint('Finished Training')\n\n[writer.flush](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush \"torch.utils.tensorboard.writer.SummaryWriter.flush\")() \n```", "```py\n2500\nBatch 1000\nBatch 2000\nBatch 3000\nBatch 4000\nBatch 5000\nBatch 6000\nBatch 7000\nBatch 8000\nBatch 9000\nBatch 10000\nBatch 11000\nBatch 12000\nBatch 13000\nBatch 14000\nBatch 15000\nFinished Training \n```", "```py\n# Again, grab a single mini-batch of images\ndataiter = iter([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"))\n[images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = next(dataiter)\n\n# add_graph() will trace the sample input through your model,\n# and render it as a graph.\n[writer.add_graph](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph \"torch.utils.tensorboard.writer.SummaryWriter.add_graph\")(net, [images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[writer.flush](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush \"torch.utils.tensorboard.writer.SummaryWriter.flush\")() \n```", "```py\n# Select a random subset of data and corresponding labels\ndef select_n_random(data, [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), n=100):\n    assert len(data) == len([labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\n    perm = [torch.randperm](https://pytorch.org/docs/stable/generated/torch.randperm.html#torch.randperm \"torch.randperm\")(len(data))\n    return data[perm][:n], [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[perm][:n]\n\n# Extract a random subset of data\n[images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = select_n_random([training_set.data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [training_set.targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\n# get the class labels for each image\nclass_labels = [classes[label] for label in [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")]\n\n# log embeddings\n[features](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").view(-1, 28 * 28)\n[writer.add_embedding](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_embedding \"torch.utils.tensorboard.writer.SummaryWriter.add_embedding\")([features](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"),\n                    metadata=class_labels,\n                    label_img=[images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").unsqueeze(1))\n[writer.flush](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush \"torch.utils.tensorboard.writer.SummaryWriter.flush\")()\n[writer.close](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.close \"torch.utils.tensorboard.writer.SummaryWriter.close\")() \n```"]