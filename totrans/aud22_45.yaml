- en: 'Torchaudio-Squim: Non-intrusive Speech Assessment in TorchAudio'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/audio/stable/tutorials/squim_tutorial.html](https://pytorch.org/audio/stable/tutorials/squim_tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Click [here](#sphx-glr-download-tutorials-squim-tutorial-py) to download the
    full example code
  prefs: []
  type: TYPE_NORMAL
- en: 'Author: [Anurag Kumar](mailto:anuragkr90%40meta.com), [Zhaoheng Ni](mailto:zni%40meta.com)'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Overview[](#overview "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This tutorial shows uses of Torchaudio-Squim to estimate objective and subjective
    metrics for assessment of speech quality and intelligibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'TorchAudio-Squim enables speech assessment in Torchaudio. It provides interface
    and pre-trained models to estimate various speech quality and intelligibility
    metrics. Currently, Torchaudio-Squim [1] supports reference-free estimation 3
    widely used objective metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Wideband Perceptual Estimation of Speech Quality (PESQ) [2]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Short-Time Objective Intelligibility (STOI) [3]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) [4]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also supports estimation of subjective Mean Opinion Score (MOS) for a given
    audio waveform using Non-Matching References [1, 5].
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] Kumar, Anurag, et al. “TorchAudio-Squim: Reference-less Speech Quality
    and Intelligibility measures in TorchAudio.” ICASSP 2023-2023 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2023.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] I. Rec, “P.862.2: Wideband extension to recommendation P.862 for the assessment
    of wideband telephone networks and speech codecs,” International Telecommunication
    Union, CH–Geneva, 2005.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Taal, C. H., Hendriks, R. C., Heusdens, R., & Jensen, J. (2010, March).
    A short-time objective intelligibility measure for time-frequency weighted noisy
    speech. In 2010 IEEE international conference on acoustics, speech and signal
    processing (pp. 4214-4217). IEEE.'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Le Roux, Jonathan, et al. “SDR–half-baked or well done?.” ICASSP 2019-2019
    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).
    IEEE, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Manocha, Pranay, and Anurag Kumar. “Speech quality assessment through MOS
    using non-matching references.” Interspeech, 2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 2\. Preparation[](#preparation "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First import the modules and define the helper functions.
  prefs: []
  type: TYPE_NORMAL
- en: We will need torch, torchaudio to use Torchaudio-squim, Matplotlib to plot data,
    pystoi, pesq for computing reference metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Load Speech and Noise Sample[](#load-speech-and-noise-sample "Permalink
    to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Currently, Torchaudio-Squim model only supports 16000 Hz sampling rate. Resample
    the waveforms if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Trim waveforms so that they have the same number of frames.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Play speech sample
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: Play noise sample
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Create distorted (noisy) speech samples[](#create-distorted-noisy-speech-samples
    "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Play distorted speech with 20dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: Play distorted speech with -5dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Visualize the waveforms[](#visualize-the-waveforms "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Visualize speech sample
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Clean Speech](../Images/1a1bff08b20cbd26590cca35888077e0.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize noise sample
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![Noise](../Images/cf255965754a39d367fd8c4d7cc5021b.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize distorted speech with 20dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![Distorted Speech with 20dB SNR](../Images/c0d401a9d6195aa0fd526c9507f14b87.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize distorted speech with -5dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![Distorted Speech with -5dB SNR](../Images/f71c3c56743ba5d56f22d8064d2e12ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 6\. Predict Objective Metrics[](#predict-objective-metrics "Permalink to this
    heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Get the pre-trained `SquimObjective`model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Compare model outputs with ground truths for distorted speech with 20dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Compare model outputs with ground truths for distorted speech with -5dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 7\. Predict Mean Opinion Scores (Subjective) Metric[](#predict-mean-opinion-scores-subjective-metric
    "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Get the pre-trained `SquimSubjective` model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Load a non-matching reference (NMR)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Compute MOS metric for distorted speech with 20dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Compute MOS metric for distorted speech with -5dB SNR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 8\. Comparison with ground truths and baselines[](#comparison-with-ground-truths-and-baselines
    "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Visualizing the estimated metrics by the `SquimObjective` and `SquimSubjective`
    models can help users better understand how the models can be applicable in real
    scenario. The graph below shows scatter plots of three different systems: MOSA-Net
    [1], AMSA [2], and the `SquimObjective` model, where y axis represents the estimated
    STOI, PESQ, and Si-SDR scores, and x axis represents the corresponding ground
    truth.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![https://download.pytorch.org/torchaudio/tutorial-assets/objective_plot.png](../Images/beab25bd56b59ea05c29a2fee467b3a7.png)](https://download.pytorch.org/torchaudio/tutorial-assets/objective_plot.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] Zezario, Ryandhimas E., Szu-Wei Fu, Fei Chen, Chiou-Shann Fuh, Hsin-Min
    Wang, and Yu Tsao. “Deep learning-based non-intrusive multi-objective speech assessment
    model with cross-domain features.” IEEE/ACM Transactions on Audio, Speech, and
    Language Processing 31 (2022): 54-70.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Dong, Xuan, and Donald S. Williamson. “An attention enhanced multi-task
    model for objective speech assessment in real-world environments.” In ICASSP 2020-2020
    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),
    pp. 911-915\. IEEE, 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: The graph below shows scatter plot of the `SquimSubjective` model, where y axis
    represents the estimated MOS metric score, and x axis represents the corresponding
    ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: '[![https://download.pytorch.org/torchaudio/tutorial-assets/subjective_plot.png](../Images/6f51f5b6f641de3a35830b1d0e9a0d57.png)](https://download.pytorch.org/torchaudio/tutorial-assets/subjective_plot.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Total running time of the script:** ( 0 minutes 6.527 seconds)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Python source code: squim_tutorial.py`](../_downloads/c943e35bc7cad6e8d9b1df2a7034a8fc/squim_tutorial.py)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Jupyter notebook: squim_tutorial.ipynb`](../_downloads/242b4f86f5d51a9a90d3080d8ce32681/squim_tutorial.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  prefs: []
  type: TYPE_NORMAL
