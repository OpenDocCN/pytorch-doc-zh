# torch.Storage

> 原文：[`pytorch.org/docs/stable/storage.html`](https://pytorch.org/docs/stable/storage.html)

`torch.Storage` 是与默认数据类型对应的存储类的别名（`torch.get_default_dtype()`）。例如，如果默认数据类型是 `torch.float`，`torch.Storage` 解析为 `torch.FloatStorage`。

`torch.<type>Storage` 和 `torch.cuda.<type>Storage` 类，如 `torch.FloatStorage`、`torch.IntStorage` 等，实际上从未被实例化。调用它们的构造函数会创建一个具有适当 `torch.dtype` 和 `torch.device` 的 `torch.TypedStorage`。`torch.<type>Storage` 类具有与 `torch.TypedStorage` 相同的所有类方法。

`torch.TypedStorage` 是一个连续的、一维的特定 `torch.dtype` 元素数组。它可以给定任何 `torch.dtype`，内部数据将被适当解释。`torch.TypedStorage` 包含一个 `torch.UntypedStorage`，它将数据保存为字节的无类型数组。

每个分步的 `torch.Tensor` 包含一个 `torch.TypedStorage`，它存储了 `torch.Tensor` 视图的所有数据。

警告

除了 `torch.UntypedStorage` 外，所有存储类将来将被移除，而 `torch.UntypedStorage` 将在所有情况下使用。

```py
class torch.TypedStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
bfloat16()
```

将此存储转换为 bfloat16 类型。

```py
bool()
```

将此存储转换为布尔类型。

```py
byte()
```

将此存储转换为字节类型。

```py
char()
```

将此存储转换为字符类型。

```py
clone()
```

返回此存储的副本。

```py
complex_double()
```

将此存储转换为复数双精度类型。

```py
complex_float()
```

将此存储转换为复数浮点类型。

```py
copy_(source, non_blocking=None)
```

```py
cpu()
```

如果尚未在 CPU 上，则返回此存储的 CPU 副本。

```py
cuda(device=None, non_blocking=False, **kwargs)
```

返回此对象在 CUDA 内存中的副本。

如果此对象已经在 CUDA 内存中且在正确的设备上，则不执行复制并返回原始对象。

参数

+   **device** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")) – 目标 GPU id。默认为当前设备。

+   **non_blocking** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.12)")) – 如果为 `True` 并且源位于固定内存中，则复制将与主机异步进行。否则，参数不起作用。

+   ****kwargs** – 为了兼容性，可能包含 `async` 键代替 `non_blocking` 参数。

返回类型

*T*

```py
data_ptr()
```

```py
property device
```

```py
double()
```

将此存储转换为双精度类型。

```py
dtype: dtype
```

```py
element_size()
```

```py
property filename: Optional[str]
```

如果存储是从文件内存映射而来，则返回与此存储关联的文件名。如果存储不是通过内存映射文件创建的，则返回 `None`。

```py
fill_(value)
```

```py
float()
```

将此存储转换为浮点类型。

```py
float8_e4m3fn()
```

将此存储转换为 float8_e4m3fn 类型

```py
float8_e5m2()
```

将此存储转换为 float8_e5m2 类型

```py
classmethod from_buffer(*args, **kwargs)
```

```py
classmethod from_file(filename, shared=False, size=0) → Storage
```

创建由内存映射文件支持的 CPU 存储。

如果 `shared` 是 `True`，则内存在所有进程之间共享。所有更改都将写入文件。如果 `shared` 是 `False`，则对存储的更改不会影响文件。

`size` 是存储中元素的数量。如果 `shared` 是 `False`，那么文件必须至少包含 `size * sizeof(Type)` 字节（`Type` 是存储的类型）。如果 `shared` 是 `True`，则文件将在需要时创建。

参数

+   **filename**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）- 要映射的文件名

+   **shared**（[*bool*](https://docs.python.org/3/library/functions.html#bool)）- 是否共享内存（是否传递`MAP_SHARED`或`MAP_PRIVATE`到底层的[mmap(2)调用](https://man7.org/linux/man-pages/man2/mmap.2.html)）

+   **size**（[*int*](https://docs.python.org/3/library/functions.html#int)）- 存储中的元素数

```py
get_device()
```

返回类型

[*int*](https://docs.python.org/3/library/functions.html#int)

```py
half()
```

将此存储转换为半精度类型。

```py
hpu(device=None, non_blocking=False, **kwargs)
```

在 HPU 内存中返回此对象的副本。

如果此对象已经在 HPU 内存中且在正确的设备上，则不执行复制操作，并返回原始对象。

参数

+   **device**（[*int*](https://docs.python.org/3/library/functions.html#int)）- 目标 HPU id。默认为当前设备。

+   **non_blocking**（[*bool*](https://docs.python.org/3/library/functions.html#bool)）- 如果为`True`且源在固定内存中，则复制将与主机异步进行。否则，参数无效。

+   ****kwargs** - 为了兼容性，可能包含`async`键代替`non_blocking`参数。

返回类型

*T*

```py
int()
```

将此存储转换为整型。

```py
property is_cuda
```

```py
property is_hpu
```

```py
is_pinned(device='cuda')
```

确定 CPU TypedStorage 是否已经固定在设备上。

参数

**device**（[*str*](https://docs.python.org/3/library/stdtypes.html#str) *或* *torch.device*）- 要在其上固定内存的设备。默认：`'cuda'`

返回

一个布尔变量。

```py
is_shared()
```

```py
is_sparse = False
```

```py
long()
```

将此存储转换为长整型。

```py
nbytes()
```

```py
pickle_storage_type()
```

```py
pin_memory(device='cuda')
```

将 CPU TypedStorage 复制到固定内存，如果尚未固定。

参数

**device**（[*str*](https://docs.python.org/3/library/stdtypes.html#str) *或* *torch.device*）- 要在其上固定内存的设备。默认：`'cuda'`。

返回

固定的 CPU 存储。

```py
resize_(size)
```

```py
share_memory_()
```

参见`torch.UntypedStorage.share_memory_()`。

```py
short()
```

将此存储转换为短整型。

```py
size()
```

```py
tolist()
```

返回包含此存储元素的列表。

```py
type(dtype=None, non_blocking=False)
```

如果未提供 dtype，则返回类型，否则将此对象转换为指定类型。

如果已经是正确类型，则不执行复制操作，并返回原始对象。

参数

+   **dtype**（[*type*](https://docs.python.org/3/library/functions.html#type) *或* *string*）- 所需类型

+   **non_blocking**（[*bool*](https://docs.python.org/3/library/functions.html#bool)）- 如果为`True`，且源在固定内存中且目的地在 GPU 上或反之，则复制将与主机异步进行。否则，参数无效。

+   ****kwargs** - 为了兼容性，可能包含`async`键代替`non_blocking`参数。`async`参数已被弃用。

返回类型

[*Union*](https://docs.python.org/3/library/typing.html#typing.Union)[*T*, [*str*](https://docs.python.org/3/library/stdtypes.html#str)]

```py
untyped()
```

返回内部`torch.UntypedStorage`。

```py
class torch.UntypedStorage(*args, **kwargs)
```

```py
bfloat16()
```

将此存储转换为 bfloat16 类型。

```py
bool()
```

将此存储转换为布尔类型。

```py
byte()
```

将此存储转换为字节类型。

```py
byteswap(dtype)
```

交换底层数据中的字节。

```py
char()
```

将此存储转换为字符类型。

```py
clone()
```

返回此存储的副本。

```py
complex_double()
```

将此存储转换为复数双精度类型。

```py
complex_float()
```

将此存储转换为复数浮点类型。

```py
copy_()
```

```py
cpu()
```

如果尚未在 CPU 上，则返回此存储的 CPU 副本。

```py
cuda(device=None, non_blocking=False, **kwargs)
```

在 CUDA 内存中返回此对象的副本。

如果此对象已经在 CUDA 内存中且在正确的设备上，则不执行复制操作，并返回原始对象。

参数

+   **device**（[*int*](https://docs.python.org/3/library/functions.html#int)）- 目标 GPU id。默认为当前设备。

+   **non_blocking**（[*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.12)")） - 如果为`True`且源位于固定内存中，则复制将与主机异步进行。否则，该参数不起作用。

+   ****kwargs** - 为了兼容性，可能包含`async`键，而不是`non_blocking`参数。

```py
data_ptr()
```

```py
device: device
```

```py
double()
```

将此存储转换为 double 类型。

```py
element_size()
```

```py
property filename: Optional[str]
```

如果存储是从文件内存映射而来，则返回与此存储关联的文件名。如果存储不是通过内存映射文件创建的，则返回`None`。

```py
fill_()
```

```py
float()
```

将此存储转换为 float 类型。

```py
float8_e4m3fn()
```

将此存储转换为 float8_e4m3fn 类型

```py
float8_e5m2()
```

将此存储转换为 float8_e5m2 类型

```py
static from_buffer()
```

```py
static from_file(filename, shared=False, size=0) → Storage
```

创建由内存映射文件支持的 CPU 存储。

如果`shared`为`True`，则内存在所有进程之间共享。所有更改都将写入文件。如果`shared`为`False`，则存储上的更改不会影响文件。

`size`是存储中的元素数量。如果`shared`为`False`，则文件必须至少包含`size * sizeof(Type)`字节（`Type`是存储类型，在`UnTypedStorage`情况下，文件必须至少包含`size`字节）。如果`shared`为`True`，则将根据需要创建文件。

参数

+   **filename**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")） - 要映射的文件名

+   **shared**（[*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.12)")） -

    是否共享内存（是否将`MAP_SHARED`或`MAP_PRIVATE`传递给底层的[mmap(2)调用](https://man7.org/linux/man-pages/man2/mmap.2.html)）

+   **size**（[*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")） - 存储中的元素数量

```py
get_device()
```

返回类型

[*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")

```py
half()
```

将此存储转换为 half 类型。

```py
hpu(device=None, non_blocking=False, **kwargs)
```

在 HPU 内存中返回此对象的副本。

如果此对象已经在 HPU 内存中且在正确的设备上，则不执行复制，并返回原始对象。

参数

+   **device**（[*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")） - 目标 HPU id。默认为当前设备。

+   **non_blocking**（[*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.12)")） - 如果为`True`且源位于固定内存中，则复制将与主机异步进行。否则，该参数不起作用。

+   ****kwargs** - 为了兼容性，可能包含`async`键，而不是`non_blocking`参数。

```py
int()
```

将此存储转换为 int 类型。

```py
property is_cuda
```

```py
property is_hpu
```

```py
is_pinned(device='cuda')
```

确定 CPU 存储是否已固定在设备上。

参数

**device**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)") *或* *torch.device*） - 要固定内存的设备。默认值：`'cuda'`。

返回

一个布尔变量。

```py
is_shared()
```

```py
is_sparse: bool = False
```

```py
is_sparse_csr: bool = False
```

```py
long()
```

将此存储转换为 long 类型。

```py
mps()
```

如果尚未在 MPS 上，则返回此存储的 MPS 副本。

```py
nbytes()
```

```py
new()
```

```py
pin_memory(device='cuda')
```

将 CPU 存储复制到固定内存，如果尚未固定。

参数

**device**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)") *或* *torch.device*） - 要固定内存的设备。默认值：`'cuda'`。

返回

一个固定的 CPU 存储。

```py
resize_()
```

```py
share_memory_(*args, **kwargs)
```

将存储移动到共享内存。

对于已经在共享内存中的存储和不需要移动以在进程间共享的 CUDA 存储，这是一个无操作。共享内存中的存储无法调整大小。

请注意，为了缓解诸如[此](https://github.com/pytorch/pytorch/issues/95606)等问题，可以安全地从同一对象的多个线程调用此函数。但是，在没有适当同步的情况下调用 self 上的任何其他函数是不安全的。有关更多详细信息，请参阅多进程最佳实践。

注意

当删除共享内存中对存储的所有引用时，相关的共享内存对象也将被删除。PyTorch 具有特殊的清理过程，以确保即使当前进程意外退出也会发生这种情况。

值得注意的是`share_memory_()`和`from_file()`之间的区别，其中`shared = True`

1.  `share_memory_`使用[shm_open(3)](https://man7.org/linux/man-pages/man3/shm_open.3.html)创建 POSIX 共享内存对象，而`from_file()`使用[open(2)](https://man7.org/linux/man-pages/man2/open.2.html)打开用户传递的文件名。

1.  两者都使用[mmap(2)调用](https://man7.org/linux/man-pages/man2/mmap.2.html)与`MAP_SHARED`将文件/对象映射到当前虚拟地址空间

1.  `share_memory_`将在将对象映射后调用`shm_unlink(3)`，以确保在没有进程打开对象时释放共享内存对象。`torch.from_file(shared=True)`不会取消链接文件。该文件是持久的，直到用户删除为止。

返回

`self`

```py
short()
```

将此存储转换为 short 类型。

```py
size()
```

返回类型

[int](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")

```py
tolist()
```

返回包含此存储元素的列表。

```py
type(dtype=None, non_blocking=False, **kwargs)
```

如果未提供 dtype，则返回类型，否则将此对象转换为指定类型。

如果已经是正确类型，则不执行复制操作，返回原始对象。

参数

+   **dtype**（[*type*](https://docs.python.org/3/library/functions.html#type "(in Python v3.12)") *或* *string*）- 所需类型

+   **non_blocking**（[*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.12)")）- 如果为`True`，且源位于固定内存中，目标位于 GPU 上或反之，则复制操作将异步执行，与主机无关。否则，该参数无效。

+   ****kwargs** - 为了兼容性，可能包含`async`键代替`non_blocking`参数。`async`参数已被弃用。

```py
untyped()
```

```py
class torch.DoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.float64
```

```py
class torch.FloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.float32
```

```py
class torch.HalfStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.float16
```

```py
class torch.LongStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.int64
```

```py
class torch.IntStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.int32
```

```py
class torch.ShortStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.int16
```

```py
class torch.CharStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.int8
```

```py
class torch.ByteStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.uint8
```

```py
class torch.BoolStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.bool
```

```py
class torch.BFloat16Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.bfloat16
```

```py
class torch.ComplexDoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.complex128
```

```py
class torch.ComplexFloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.complex64
```

```py
class torch.QUInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.quint8
```

```py
class torch.QInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.qint8
```

```py
class torch.QInt32Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.qint32
```

```py
class torch.QUInt4x2Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.quint4x2
```

```py
class torch.QUInt2x4Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
```

```py
dtype: dtype = torch.quint2x4
```
