- en: Transforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Click [here](#sphx-glr-download-beginner-basics-transforms-tutorial-py) to download
    the full example code
  prefs: []
  type: TYPE_NORMAL
- en: '[Learn the Basics](intro.html) || [Quickstart](quickstart_tutorial.html) ||
    [Tensors](tensorqs_tutorial.html) || [Datasets & DataLoaders](data_tutorial.html)
    || **Transforms** || [Build Model](buildmodel_tutorial.html) || [Autograd](autogradqs_tutorial.html)
    || [Optimization](optimization_tutorial.html) || [Save & Load Model](saveloadrun_tutorial.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Data does not always come in its final processed form that is required for training
    machine learning algorithms. We use **transforms** to perform some manipulation
    of the data and make it suitable for training.
  prefs: []
  type: TYPE_NORMAL
- en: All TorchVision datasets have two parameters -`transform` to modify the features
    and `target_transform` to modify the labels - that accept callables containing
    the transformation logic. The [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)
    module offers several commonly-used transforms out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: The FashionMNIST features are in PIL Image format, and the labels are integers.
    For training, we need the features as normalized tensors, and the labels as one-hot
    encoded tensors. To make these transformations, we use `ToTensor` and `Lambda`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ToTensor()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)
    converts a PIL image or NumPy `ndarray` into a `FloatTensor`. and scales the image’s
    pixel intensity values in the range [0., 1.]'
  prefs: []
  type: TYPE_NORMAL
- en: Lambda Transforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lambda transforms apply any user-defined lambda function. Here, we define a
    function to turn the integer into a one-hot encoded tensor. It first creates a
    zero tensor of size 10 (the number of labels in our dataset) and calls [scatter_](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html)
    which assigns a `value=1` on the index as given by the label `y`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[torchvision.transforms API](https://pytorch.org/vision/stable/transforms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total running time of the script:** ( 0 minutes 4.410 seconds)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Python source code: transforms_tutorial.py`](../../_downloads/2f1ec3031a7101e25403c5d53a40a401/transforms_tutorial.py)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Jupyter notebook: transforms_tutorial.ipynb`](../../_downloads/9bdb71ef4a637dc36fb461904ccb7056/transforms_tutorial.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  prefs: []
  type: TYPE_NORMAL
