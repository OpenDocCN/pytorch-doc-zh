["```py\nimport torch\nimport torchaudio\n\nprint(torch.__version__)\nprint([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n2.2.0\n2.2.0 \n```", "```py\nimport time\nfrom typing import [List](https://docs.python.org/3/library/typing.html#typing.List \"typing.List\")\n\nimport IPython\nimport matplotlib.pyplot as plt\nfrom torchaudio.models.decoder import ctc_decoder\nfrom torchaudio.utils import download_asset \n```", "```py\nbundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_10M\nacoustic_model = bundle.get_model() \n```", "```py\nDownloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ll10m.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ll10m.pth\n\n  0%|          | 0.00/360M [00:00<?, ?B/s]\n  8%|8         | 29.4M/360M [00:00<00:01, 308MB/s]\n 19%|#9        | 68.9M/360M [00:00<00:00, 371MB/s]\n 30%|##9       | 108M/360M [00:00<00:00, 387MB/s]\n 42%|####2     | 152M/360M [00:00<00:00, 417MB/s]\n 55%|#####4    | 198M/360M [00:00<00:00, 441MB/s]\n 67%|######6   | 240M/360M [00:00<00:00, 438MB/s]\n 78%|#######8  | 282M/360M [00:00<00:00, 424MB/s]\n 91%|######### | 327M/360M [00:00<00:00, 440MB/s]\n100%|##########| 360M/360M [00:00<00:00, 409MB/s] \n```", "```py\n[speech_file](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/ctc-decoding/1688-142285-0007.wav\")\n\nIPython.display.Audio([speech_file](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") really was very much afraid of showing him how much shocked [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") was at some parts of what he said \n```", "```py\n[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([speech_file](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\nif [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") != bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):\n    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = torchaudio.functional.resample([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\n# tokens.txt\n_\n|\ne\n[t](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n... \n```", "```py\n[tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [label.lower() for label in bundle.get_labels()]\nprint([tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) \n```", "```py\n['-', '|', 'e', 't', 'a', 'o', 'n', 'i', 'h', 's', 'r', 'd', 'l', 'u', 'm', 'w', 'c', 'f', 'g', 'y', 'p', 'b', 'v', 'k', \"'\", 'x', 'j', 'q', 'z'] \n```", "```py\n# lexcion.txt\na a |\nable a b l e |\nabout a b o u [t](https://docs.python.org/3/library/functions.html#int \"builtins.int\") |\n...\n... \n```", "```py\nfrom torchaudio.models.decoder import CTCDecoderLM, CTCDecoderLMState\n\nclass CustomLM(CTCDecoderLM):\n  \"\"\"Create a Python wrapper around `language_model` to feed to the decoder.\"\"\"\n\n    def __init__(self, language_model: [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n        CTCDecoderLM.__init__(self)\n        self.language_model = language_model\n        self.sil = -1  # index for silent token in the language model\n        self.states = {}\n\n        language_model.eval()\n\n    def start(self, start_with_nothing: bool = False):\n        state = CTCDecoderLMState()\n        with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n            [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = self.language_model(self.sil)\n\n        self.states[state] = [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")\n        return state\n\n    def score(self, state: CTCDecoderLMState, token_index: int):\n        outstate = state.child(token_index)\n        if outstate not in self.states:\n            [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = self.language_model(token_index)\n            self.states[outstate] = [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")\n        [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = self.states[outstate]\n\n        return outstate, [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")\n\n    def finish(self, state: CTCDecoderLMState):\n        return self.[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")(state, self.sil) \n```", "```py\nfrom torchaudio.models.decoder import download_pretrained_files\n\nfiles = download_pretrained_files(\"librispeech-4-gram\")\n\nprint(files) \n```", "```py\n 0%|          | 0.00/4.97M [00:00<?, ?B/s]\n100%|##########| 4.97M/4.97M [00:00<00:00, 62.7MB/s]\n\n  0%|          | 0.00/57.0 [00:00<?, ?B/s]\n100%|##########| 57.0/57.0 [00:00<00:00, 124kB/s]\n\n  0%|          | 0.00/2.91G [00:00<?, ?B/s]\n  0%|          | 11.6M/2.91G [00:00<00:25, 121MB/s]\n  1%|          | 25.1M/2.91G [00:00<00:23, 134MB/s]\n  2%|1         | 58.1M/2.91G [00:00<00:13, 228MB/s]\n  3%|2         | 79.8M/2.91G [00:00<00:14, 203MB/s]\n  4%|3         | 109M/2.91G [00:00<00:12, 239MB/s]\n  5%|4         | 136M/2.91G [00:00<00:11, 252MB/s]\n  6%|5         | 173M/2.91G [00:00<00:09, 296MB/s]\n  7%|7         | 211M/2.91G [00:00<00:08, 326MB/s]\n  8%|8         | 243M/2.91G [00:00<00:09, 317MB/s]\n  9%|9         | 274M/2.91G [00:01<00:08, 320MB/s]\n 10%|#         | 312M/2.91G [00:01<00:08, 343MB/s]\n 12%|#1        | 345M/2.91G [00:01<00:08, 331MB/s]\n 13%|#2        | 377M/2.91G [00:01<00:09, 302MB/s]\n 14%|#3        | 406M/2.91G [00:01<00:08, 302MB/s]\n 15%|#4        | 437M/2.91G [00:01<00:08, 310MB/s]\n 16%|#5        | 467M/2.91G [00:01<00:09, 292MB/s]\n 17%|#7        | 510M/2.91G [00:01<00:07, 335MB/s]\n 19%|#8        | 552M/2.91G [00:01<00:07, 363MB/s]\n 20%|#9        | 589M/2.91G [00:02<00:06, 372MB/s]\n 21%|##        | 625M/2.91G [00:02<00:06, 353MB/s]\n 22%|##2       | 659M/2.91G [00:02<00:07, 344MB/s]\n 23%|##3       | 695M/2.91G [00:02<00:06, 353MB/s]\n 24%|##4       | 730M/2.91G [00:02<00:06, 355MB/s]\n 26%|##5       | 764M/2.91G [00:02<00:06, 343MB/s]\n 27%|##6       | 804M/2.91G [00:02<00:06, 367MB/s]\n 28%|##8       | 840M/2.91G [00:02<00:06, 366MB/s]\n 29%|##9       | 876M/2.91G [00:02<00:05, 370MB/s]\n 31%|###       | 915M/2.91G [00:02<00:05, 382MB/s]\n 32%|###1      | 952M/2.91G [00:03<00:05, 380MB/s]\n 33%|###3      | 989M/2.91G [00:03<00:05, 383MB/s]\n 34%|###4      | 1.00G/2.91G [00:03<00:05, 378MB/s]\n 36%|###5      | 1.04G/2.91G [00:03<00:05, 371MB/s]\n 37%|###7      | 1.08G/2.91G [00:03<00:04, 403MB/s]\n 39%|###8      | 1.13G/2.91G [00:03<00:04, 433MB/s]\n 40%|####      | 1.17G/2.91G [00:03<00:04, 419MB/s]\n 41%|####1     | 1.21G/2.91G [00:03<00:04, 411MB/s]\n 43%|####3     | 1.25G/2.91G [00:03<00:04, 435MB/s]\n 45%|####4     | 1.30G/2.91G [00:03<00:03, 448MB/s]\n 46%|####6     | 1.34G/2.91G [00:04<00:04, 385MB/s]\n 48%|####7     | 1.38G/2.91G [00:04<00:04, 403MB/s]\n 49%|####8     | 1.43G/2.91G [00:04<00:03, 419MB/s]\n 50%|#####     | 1.47G/2.91G [00:04<00:03, 434MB/s]\n 52%|#####1    | 1.51G/2.91G [00:04<00:03, 435MB/s]\n 53%|#####3    | 1.55G/2.91G [00:04<00:03, 428MB/s]\n 55%|#####4    | 1.59G/2.91G [00:04<00:03, 385MB/s]\n 56%|#####6    | 1.63G/2.91G [00:04<00:03, 397MB/s]\n 57%|#####7    | 1.67G/2.91G [00:04<00:03, 398MB/s]\n 59%|#####8    | 1.71G/2.91G [00:05<00:03, 384MB/s]\n 60%|######    | 1.75G/2.91G [00:05<00:02, 419MB/s]\n 62%|######1   | 1.79G/2.91G [00:05<00:03, 398MB/s]\n 63%|######2   | 1.83G/2.91G [00:05<00:02, 401MB/s]\n 64%|######4   | 1.87G/2.91G [00:05<00:02, 416MB/s]\n 66%|######5   | 1.91G/2.91G [00:05<00:02, 387MB/s]\n 67%|######7   | 1.95G/2.91G [00:05<00:02, 382MB/s]\n 68%|######8   | 1.99G/2.91G [00:05<00:02, 390MB/s]\n 70%|######9   | 2.02G/2.91G [00:05<00:02, 377MB/s]\n 71%|#######   | 2.06G/2.91G [00:06<00:02, 371MB/s]\n 72%|#######2  | 2.10G/2.91G [00:06<00:02, 382MB/s]\n 73%|#######3  | 2.13G/2.91G [00:06<00:02, 382MB/s]\n 75%|#######4  | 2.18G/2.91G [00:06<00:01, 411MB/s]\n 76%|#######6  | 2.22G/2.91G [00:06<00:01, 403MB/s]\n 77%|#######7  | 2.25G/2.91G [00:06<00:01, 393MB/s]\n 79%|#######8  | 2.29G/2.91G [00:06<00:01, 389MB/s]\n 80%|#######9  | 2.33G/2.91G [00:06<00:01, 372MB/s]\n 81%|########1 | 2.36G/2.91G [00:06<00:01, 332MB/s]\n 83%|########2 | 2.40G/2.91G [00:07<00:01, 353MB/s]\n 84%|########3 | 2.44G/2.91G [00:07<00:01, 362MB/s]\n 85%|########5 | 2.47G/2.91G [00:07<00:01, 374MB/s]\n 86%|########6 | 2.51G/2.91G [00:07<00:01, 385MB/s]\n 88%|########7 | 2.56G/2.91G [00:07<00:00, 405MB/s]\n 89%|########9 | 2.59G/2.91G [00:07<00:00, 377MB/s]\n 90%|######### | 2.63G/2.91G [00:07<00:00, 385MB/s]\n 92%|#########1| 2.67G/2.91G [00:07<00:00, 368MB/s]\n 93%|#########2| 2.70G/2.91G [00:07<00:00, 373MB/s]\n 94%|#########4| 2.74G/2.91G [00:08<00:00, 386MB/s]\n 95%|#########5| 2.78G/2.91G [00:08<00:00, 385MB/s]\n 97%|#########6| 2.82G/2.91G [00:08<00:00, 389MB/s]\n 98%|#########8| 2.85G/2.91G [00:08<00:00, 391MB/s]\n 99%|#########9| 2.89G/2.91G [00:08<00:00, 405MB/s]\n100%|##########| 2.91G/2.91G [00:08<00:00, 369MB/s]\nPretrainedFiles(lexicon='/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lexicon.txt', tokens='/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/tokens.txt', lm='/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lm.bin') \n```", "```py\n[LM_WEIGHT](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = 3.23\n[WORD_SCORE](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = -0.26\n\nbeam_search_decoder = ctc_decoder(\n    lexicon=[files.lexicon](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n    [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")=[files.tokens](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n    lm=[files.lm](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n    nbest=3,\n    [beam_size](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=1500,\n    [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[LM_WEIGHT](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n    word_score=[WORD_SCORE](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n) \n```", "```py\nclass GreedyCTCDecoder([torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, labels, blank=0):\n        super().__init__()\n        self.labels = labels\n        self.blank = blank\n\n    def forward(self, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"): [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) -> [List](https://docs.python.org/3/library/typing.html#typing.List \"typing.List\")[str]:\n  \"\"\"Given a sequence emission over labels, get the best path\n Args:\n emission (Tensor): Logit tensors. Shape `[num_seq, num_label]`.\n\n Returns:\n List[str]: The resulting transcript\n \"\"\"\n        indices = [torch.argmax](https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax \"torch.argmax\")([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), dim=-1)  # [num_seq,]\n        indices = [torch.unique_consecutive](https://pytorch.org/docs/stable/generated/torch.unique_consecutive.html#torch.unique_consecutive \"torch.unique_consecutive\")(indices, dim=-1)\n        indices = [[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") for [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in indices if [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") != self.blank]\n        joined = \"\".join([self.labels[[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")] for [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in indices])\n        return joined.replace(\"|\", \" \").strip().split()\n\ngreedy_decoder = [GreedyCTCDecoder](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")([tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) \n```", "```py\n[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") really was very much afraid of showing him how much shocked [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") was at some parts of what he said \n```", "```py\n[actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = \"i really was very much afraid of showing him how much shocked i was at some parts of what he said\"\n[actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [actual_transcript.split](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")()\n\n[emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), _ = acoustic_model([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\n[greedy_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = greedy_decoder([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0])\n[greedy_transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \" \".join([greedy_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n[greedy_wer](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = torchaudio.functional.edit_distance([actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [greedy_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")) / len([actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n\nprint(f\"Transcript: {[greedy_transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")}\")\nprint(f\"WER: {[greedy_wer](https://docs.python.org/3/library/functions.html#float \"builtins.float\")}\") \n```", "```py\nTranscript: i reily was very much affrayd of showing him howmuch shoktd i wause at some parte of what he seid\nWER: 0.38095238095238093 \n```", "```py\n[beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = beam_search_decoder([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[beam_search_transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \" \".join([beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].words).strip()\n[beam_search_wer](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = torchaudio.functional.edit_distance([actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].words) / len(\n    [actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")\n)\n\nprint(f\"Transcript: {[beam_search_transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")}\")\nprint(f\"WER: {[beam_search_wer](https://docs.python.org/3/library/functions.html#float \"builtins.float\")}\") \n```", "```py\nTranscript: i really was very much afraid of showing him how much shocked i was at some part of what he said\nWER: 0.047619047619047616 \n```", "```py\ntokens_str = \"\".join(beam_search_decoder.idxs_to_tokens([beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].[tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")))\n[transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \" \".join(tokens_str.split(\"|\")) \n```", "```py\nbeam_search_decoder.decode_begin() \n```", "```py\nfor [t](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in range([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1)):\n    beam_search_decoder.decode_step([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0, [t](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):[t](https://docs.python.org/3/library/functions.html#int \"builtins.int\") + 1, :]) \n```", "```py\nbeam_search_decoder.decode_end()\n[beam_search_result_inc](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = beam_search_decoder.get_final_hypothesis() \n```", "```py\n[beam_search_transcript_inc](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \" \".join([beam_search_result_inc](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0].words).strip()\n[beam_search_wer_inc](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = torchaudio.functional.edit_distance(\n    [actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [beam_search_result_inc](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0].words) / len([actual_transcript](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n\nprint(f\"Transcript: {[beam_search_transcript_inc](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")}\")\nprint(f\"WER: {[beam_search_wer_inc](https://docs.python.org/3/library/functions.html#float \"builtins.float\")}\")\n\nassert [beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].words == [beam_search_result_inc](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0].words\nassert [beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") == [beam_search_result_inc](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0].[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")\n[torch.testing.assert_close](https://pytorch.org/docs/stable/testing.html#torch.testing.assert_close \"torch.testing.assert_close\")([beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].[timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [beam_search_result_inc](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0].[timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nTranscript: i really was very much afraid of showing him how much shocked i was at some part of what he said\nWER: 0.047619047619047616 \n```", "```py\n[timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].[timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n[predicted_tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = beam_search_decoder.idxs_to_tokens([beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][0].[tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n\nprint([predicted_tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), len([predicted_tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")))\nprint([timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").shape[0]) \n```", "```py\n['|', 'i', '|', 'r', 'e', 'a', 'l', 'l', 'y', '|', 'w', 'a', 's', '|', 'v', 'e', 'r', 'y', '|', 'm', 'u', 'c', 'h', '|', 'a', 'f', 'r', 'a', 'i', 'd', '|', 'o', 'f', '|', 's', 'h', 'o', 'w', 'i', 'n', 'g', '|', 'h', 'i', 'm', '|', 'h', 'o', 'w', '|', 'm', 'u', 'c', 'h', '|', 's', 'h', 'o', 'c', 'k', 'e', 'd', '|', 'i', '|', 'w', 'a', 's', '|', 'a', 't', '|', 's', 'o', 'm', 'e', '|', 'p', 'a', 'r', 't', '|', 'o', 'f', '|', 'w', 'h', 'a', 't', '|', 'h', 'e', '|', 's', 'a', 'i', 'd', '|', '|'] 99\ntensor([  0,  31,  33,  36,  39,  41,  42,  44,  46,  48,  49,  52,  54,  58,\n         64,  66,  69,  73,  74,  76,  80,  82,  84,  86,  88,  94,  97, 107,\n        111, 112, 116, 134, 136, 138, 140, 142, 146, 148, 151, 153, 155, 157,\n        159, 161, 162, 166, 170, 176, 177, 178, 179, 182, 184, 186, 187, 191,\n        193, 198, 201, 202, 203, 205, 207, 212, 213, 216, 222, 224, 230, 250,\n        251, 254, 256, 261, 262, 264, 267, 270, 276, 277, 281, 284, 288, 289,\n        292, 295, 297, 299, 300, 303, 305, 307, 310, 311, 324, 325, 329, 331,\n        353], dtype=torch.int32) 99 \n```", "```py\ndef plot_alignments([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")):\n\n    [t](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = [torch.arange](https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange \"torch.arange\")([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0)) / [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n    ratio = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0) / [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(1) / [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n\n    chars = []\n    words = []\n    word_start = None\n    for token, timestep in zip([tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") * ratio):\n        if token == \"|\":\n            if word_start is not None:\n                words.append((word_start, timestep))\n            word_start = None\n        else:\n            chars.append((token, timestep))\n            if word_start is None:\n                word_start = timestep\n\n    fig, axes = plt.subplots(3, 1)\n\n    def _plot(ax, xlim):\n        ax.plot([t](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        for token, timestep in chars:\n            ax.annotate(token.upper(), (timestep, 0.5))\n        for word_start, word_end in words:\n            ax.axvspan(word_start, word_end, alpha=0.1, color=\"red\")\n        ax.set_ylim(-0.6, 0.7)\n        ax.set_yticks([0])\n        ax.grid(True, axis=\"y\")\n        ax.set_xlim(xlim)\n\n    _plot(axes[0], (0.3, 2.5))\n    _plot(axes[1], (2.5, 4.7))\n    _plot(axes[2], (4.7, 6.9))\n    axes[2].set_xlabel(\"time (sec)\")\n    fig.tight_layout()\n\nplot_alignments([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0], [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [predicted_tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [timesteps](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\ndef print_decoded(decoder, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), param, param_value):\n    start_time = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")()\n    result = decoder([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n    decode_time = [time.monotonic](https://docs.python.org/3/library/time.html#time.monotonic \"time.monotonic\")() - start_time\n\n    [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \" \".join(result[0][0].words).lower().strip()\n    [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = result[0][0].[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")\n    print(f\"{param}  {param_value:<3}: {[transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")} (score: {[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\"):.2f}; {decode_time:.4f} secs)\") \n```", "```py\nfor [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in range(3):\n    [transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \" \".join([beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].words).strip()\n    [score](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = [beam_search_result](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")[0][[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")\n    print(f\"{[transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")} (score: {[score](https://docs.python.org/3/library/functions.html#float \"builtins.float\")})\") \n```", "```py\ni really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.8247656512226)\ni really was very much afraid of showing him how much shocked i was at some parts of what he said (score: 3697.8590263593164)\ni reply was very much afraid of showing him how much shocked i was at some part of what he said (score: 3695.0164135098426) \n```", "```py\n[beam_sizes](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [1, 5, 50, 500]\n\nfor [beam_size](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in [beam_sizes](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    beam_search_decoder = ctc_decoder(\n        lexicon=[files.lexicon](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")=[files.tokens](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        lm=[files.lm](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [beam_size](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[beam_size](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n        [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[LM_WEIGHT](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n        word_score=[WORD_SCORE](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n    )\n\n    print_decoded(beam_search_decoder, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"beam size\", [beam_size](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\nbeam size 1  : i you ery much afra of shongut shot i was at some arte what he sad (score: 3144.93; 0.0476 secs)\nbeam size 5  : i rely was very much afraid of showing him how much shot i was at some parts of what he said (score: 3688.02; 0.0513 secs)\nbeam size 50 : i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.82; 0.1665 secs)\nbeam size 500: i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.82; 0.5454 secs) \n```", "```py\n[num_tokens](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = len([tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n[beam_size_tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [1, 5, 10, [num_tokens](https://docs.python.org/3/library/functions.html#int \"builtins.int\")]\n\nfor [beam_size_token](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in [beam_size_tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    beam_search_decoder = ctc_decoder(\n        lexicon=[files.lexicon](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")=[files.tokens](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        lm=[files.lm](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [beam_size_token](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[beam_size_token](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n        [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[LM_WEIGHT](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n        word_score=[WORD_SCORE](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n    )\n\n    print_decoded(beam_search_decoder, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"beam size token\", [beam_size_token](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\nbeam size token 1  : i rely was very much affray of showing him hoch shot i was at some part of what he sed (score: 3584.80; 0.1582 secs)\nbeam size token 5  : i rely was very much afraid of showing him how much shocked i was at some part of what he said (score: 3694.83; 0.1784 secs)\nbeam size token 10 : i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3696.25; 0.1977 secs)\nbeam size token 29 : i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.82; 0.2287 secs) \n```", "```py\n[beam_thresholds](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [1, 5, 10, 25]\n\nfor [beam_threshold](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in [beam_thresholds](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    beam_search_decoder = ctc_decoder(\n        lexicon=[files.lexicon](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")=[files.tokens](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        lm=[files.lm](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [beam_threshold](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[beam_threshold](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n        [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[LM_WEIGHT](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n        word_score=[WORD_SCORE](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n    )\n\n    print_decoded(beam_search_decoder, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"beam threshold\", [beam_threshold](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\nbeam threshold 1  : i ila ery much afraid of shongut shot i was at some parts of what he said (score: 3316.20; 0.0281 secs)\nbeam threshold 5  : i rely was very much afraid of showing him how much shot i was at some parts of what he said (score: 3682.23; 0.0506 secs)\nbeam threshold 10 : i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.82; 0.2118 secs)\nbeam threshold 25 : i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.82; 0.2319 secs) \n```", "```py\n[lm_weights](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [0, [LM_WEIGHT](https://docs.python.org/3/library/functions.html#float \"builtins.float\"), 15]\n\nfor [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in [lm_weights](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"):\n    beam_search_decoder = ctc_decoder(\n        lexicon=[files.lexicon](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [tokens](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")=[files.tokens](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        lm=[files.lm](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n        [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n        word_score=[WORD_SCORE](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n    )\n\n    print_decoded(beam_search_decoder, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"lm weight\", [lm_weight](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\nlm weight 0  : i rely was very much affraid of showing him ho much shoke i was at some parte of what he seid (score: 3834.06; 0.2554 secs)\nlm weight 3.23: i really was very much afraid of showing him how much shocked i was at some part of what he said (score: 3699.82; 0.2617 secs)\nlm weight 15 : was there in his was at some of what he said (score: 2918.99; 0.2414 secs) \n```"]