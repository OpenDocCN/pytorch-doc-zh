["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt \n```", "```py\nepsilons = [0, .05, .1, .15, .2, .25, .3]\npretrained_model = \"data/lenet_mnist_model.pth\"\nuse_cuda=True\n# Set random seed for reproducibility\n[torch.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed \"torch.manual_seed\")(42) \n```", "```py\n<torch._C.Generator object at 0x7f6b149d3070> \n```", "```py\n# LeNet Model definition\nclass Net([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self):\n        super([Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(1, 32, 3, 1)\n        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(32, 64, 3, 1)\n        self.dropout1 = [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")(0.25)\n        self.dropout2 = [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")(0.5)\n        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(9216, 128)\n        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = self.conv2(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = [F.max_pool2d](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d \"torch.nn.functional.max_pool2d\")(x, 2)\n        x = self.dropout1(x)\n        x = [torch.flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten \"torch.flatten\")(x, 1)\n        x = self.fc1(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = [F.log_softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax \"torch.nn.functional.log_softmax\")(x, dim=1)\n        return output\n\n# MNIST Test dataset and dataloader declaration\n[test_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")(\n    [datasets.MNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST \"torchvision.datasets.MNIST\")('../data', train=False, download=True, transform=[transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")([\n            [transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")(),\n            [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")((0.1307,), (0.3081,)),\n            ])),\n        batch_size=1, shuffle=True)\n\n# Define what device we are using\nprint(\"CUDA Available: \",[torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")())\n[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\" if use_cuda and [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\")\n\n# Initialize the network\nmodel = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")().to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n# Load the pretrained model\n[model.load_state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict \"torch.nn.Module.load_state_dict\")([torch.load](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load \"torch.load\")(pretrained_model, map_location=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")))\n\n# Set the model in evaluation mode. In this case this is for the Dropout layers\n[model.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval \"torch.nn.Module.eval\")() \n```", "```py\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|##########| 9912422/9912422 [00:00<00:00, 436275131.90it/s]\nExtracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n\n  0%|          | 0/28881 [00:00<?, ?it/s]\n100%|##########| 28881/28881 [00:00<00:00, 35440518.97it/s]\nExtracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n\n  0%|          | 0/1648877 [00:00<?, ?it/s]\n100%|##########| 1648877/1648877 [00:00<00:00, 251450385.28it/s]\nExtracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\n  0%|          | 0/4542 [00:00<?, ?it/s]\n100%|##########| 4542/4542 [00:00<00:00, 36286721.46it/s]\nExtracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\nCUDA Available:  True\n\nNet(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n  (dropout1): Dropout(p=0.25, inplace=False)\n  (dropout2): Dropout(p=0.5, inplace=False)\n  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n) \n```", "```py\n# FGSM attack code\ndef fgsm_attack(image, epsilon, data_grad):\n    # Collect the element-wise sign of the data gradient\n    sign_data_grad = data_grad.sign()\n    # Create the perturbed image by adjusting each pixel of the input image\n    perturbed_image = image + epsilon*sign_data_grad\n    # Adding clipping to maintain [0,1] range\n    perturbed_image = [torch.clamp](https://pytorch.org/docs/stable/generated/torch.clamp.html#torch.clamp \"torch.clamp\")(perturbed_image, 0, 1)\n    # Return the perturbed image\n    return perturbed_image\n\n# restores the tensors to their original scale\ndef denorm(batch, mean=[0.1307], std=[0.3081]):\n  \"\"\"\n Convert a batch of tensors to their original scale.\n\n Args:\n batch (torch.Tensor): Batch of normalized tensors.\n mean (torch.Tensor or list): Mean used for normalization.\n std (torch.Tensor or list): Standard deviation used for normalization.\n\n Returns:\n torch.Tensor: batch of tensors without normalization applied to them.\n \"\"\"\n    if isinstance(mean, list):\n        mean = [torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor \"torch.tensor\")(mean).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n    if isinstance(std, list):\n        std = [torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor \"torch.tensor\")(std).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1) \n```", "```py\ndef test( model, [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"), [test_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), epsilon ):\n\n    # Accuracy counter\n    correct = 0\n    adv_examples = []\n\n    # Loop over all examples in test set\n    for data, target in [test_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"):\n\n        # Send the data and label to the device\n        data, target = data.to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")), target.to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n        # Set requires_grad attribute of tensor. Important for Attack\n        data.requires_grad = True\n\n        # Forward pass the data through the model\n        output = model(data)\n        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n\n        # If the initial prediction is wrong, don't bother attacking, just move on\n        if init_pred.item() != target.item():\n            continue\n\n        # Calculate the loss\n        loss = [F.nll_loss](https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss \"torch.nn.functional.nll_loss\")(output, target)\n\n        # Zero all existing gradients\n        [model.zero_grad](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.zero_grad \"torch.nn.Module.zero_grad\")()\n\n        # Calculate gradients of model in backward pass\n        loss.backward()\n\n        # Collect ``datagrad``\n        data_grad = data.grad.data\n\n        # Restore the data to its original scale\n        data_denorm = denorm(data)\n\n        # Call FGSM Attack\n        perturbed_data = fgsm_attack(data_denorm, epsilon, data_grad)\n\n        # Reapply normalization\n        perturbed_data_normalized = [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")((0.1307,), (0.3081,))(perturbed_data)\n\n        # Re-classify the perturbed image\n        output = model(perturbed_data_normalized)\n\n        # Check for success\n        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n        if final_pred.item() == target.item():\n            correct += 1\n            # Special case for saving 0 epsilon examples\n            if epsilon == 0 and len(adv_examples) < 5:\n                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n        else:\n            # Save some adv examples for visualization later\n            if len(adv_examples) < 5:\n                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n\n    # Calculate final accuracy for this epsilon\n    final_acc = correct/float(len([test_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")))\n    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {len([test_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"))} = {final_acc}\")\n\n    # Return the accuracy and an adversarial example\n    return final_acc, adv_examples \n```", "```py\naccuracies = []\nexamples = []\n\n# Run test for each epsilon\nfor eps in epsilons:\n    acc, ex = test(model, [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"), [test_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), eps)\n    accuracies.append(acc)\n    examples.append(ex) \n```", "```py\nEpsilon: 0      Test Accuracy = 9912 / 10000 = 0.9912\nEpsilon: 0.05   Test Accuracy = 9605 / 10000 = 0.9605\nEpsilon: 0.1    Test Accuracy = 8743 / 10000 = 0.8743\nEpsilon: 0.15   Test Accuracy = 7111 / 10000 = 0.7111\nEpsilon: 0.2    Test Accuracy = 4877 / 10000 = 0.4877\nEpsilon: 0.25   Test Accuracy = 2717 / 10000 = 0.2717\nEpsilon: 0.3    Test Accuracy = 1418 / 10000 = 0.1418 \n```", "```py\nplt.figure(figsize=(5,5))\nplt.plot(epsilons, accuracies, \"*-\")\nplt.yticks(np.arange(0, 1.1, step=0.1))\nplt.xticks(np.arange(0, .35, step=0.05))\nplt.title(\"Accuracy vs Epsilon\")\nplt.xlabel(\"Epsilon\")\nplt.ylabel(\"Accuracy\")\nplt.show() \n```", "```py\n# Plot several examples of adversarial samples at each epsilon\ncnt = 0\nplt.figure(figsize=(8,10))\nfor i in range(len(epsilons)):\n    for j in range(len(examples[i])):\n        cnt += 1\n        plt.subplot(len(epsilons),len(examples[0]),cnt)\n        plt.xticks([], [])\n        plt.yticks([], [])\n        if j == 0:\n            plt.ylabel(f\"Eps: {epsilons[i]}\", fontsize=14)\n        orig,adv,ex = examples[i][j]\n        plt.title(f\"{orig} -> {adv}\")\n        plt.imshow(ex, cmap=\"gray\")\nplt.tight_layout()\nplt.show() \n```"]