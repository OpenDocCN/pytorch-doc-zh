["```py\nDataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n           batch_sampler=None, num_workers=0, collate_fn=None,\n           pin_memory=False, drop_last=False, timeout=0,\n           worker_init_fn=None, *, prefetch_factor=2,\n           persistent_workers=False) \n```", "```py\nfor indices in batch_sampler:\n    yield collate_fn([dataset[i] for i in indices]) \n```", "```py\ndataset_iter = iter(dataset)\nfor indices in batch_sampler:\n    yield collate_fn([next(dataset_iter) for _ in indices]) \n```", "```py\nfor index in sampler:\n    yield collate_fn(dataset[index]) \n```", "```py\nfor data in iter(dataset):\n    yield collate_fn(data) \n```", "```py\nclass SimpleCustomBatch:\n    def __init__(self, data):\n        transposed_data = list(zip(*data))\n        self.inp = torch.stack(transposed_data[0], 0)\n        self.tgt = torch.stack(transposed_data[1], 0)\n\n    # custom memory pinning method on custom type\n    def pin_memory(self):\n        self.inp = self.inp.pin_memory()\n        self.tgt = self.tgt.pin_memory()\n        return self\n\ndef collate_wrapper(batch):\n    return SimpleCustomBatch(batch)\n\ninps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\ntgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\ndataset = TensorDataset(inps, tgts)\n\nloader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n                    pin_memory=True)\n\nfor batch_ndx, sample in enumerate(loader):\n    print(sample.inp.is_pinned())\n    print(sample.tgt.is_pinned()) \n```", "```py\nclass torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=None, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=None, persistent_workers=False, pin_memory_device='')\u00b6\n```", "```py\nclass torch.utils.data.Dataset(*args, **kwds)\u00b6\n```", "```py\nclass torch.utils.data.IterableDataset(*args, **kwds)\u00b6\n```", "```py\n>>> class MyIterableDataset(torch.utils.data.IterableDataset):\n...     def __init__(self, start, end):\n...         super(MyIterableDataset).__init__()\n...         assert end > start, \"this example code only works with end >= start\"\n...         self.start = start\n...         self.end = end\n...\n...     def __iter__(self):\n...         worker_info = torch.utils.data.get_worker_info()\n...         if worker_info is None:  # single-process data loading, return the full iterator\n...             iter_start = self.start\n...             iter_end = self.end\n...         else:  # in a worker process\n...             # split workload\n...             per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))\n...             worker_id = worker_info.id\n...             iter_start = self.start + worker_id * per_worker\n...             iter_end = min(iter_start + per_worker, self.end)\n...         return iter(range(iter_start, iter_end))\n...\n>>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n>>> ds = MyIterableDataset(start=3, end=7)\n\n>>> # Single-process loading\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n[tensor([3]), tensor([4]), tensor([5]), tensor([6])]\n\n>>> # Mult-process loading with two worker processes\n>>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n[tensor([3]), tensor([5]), tensor([4]), tensor([6])]\n\n>>> # With even more workers\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=12)))\n[tensor([3]), tensor([5]), tensor([4]), tensor([6])] \n```", "```py\n>>> class MyIterableDataset(torch.utils.data.IterableDataset):\n...     def __init__(self, start, end):\n...         super(MyIterableDataset).__init__()\n...         assert end > start, \"this example code only works with end >= start\"\n...         self.start = start\n...         self.end = end\n...\n...     def __iter__(self):\n...         return iter(range(self.start, self.end))\n...\n>>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n>>> ds = MyIterableDataset(start=3, end=7)\n\n>>> # Single-process loading\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n[3, 4, 5, 6]\n>>>\n>>> # Directly doing multi-process loading yields duplicate data\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n[3, 3, 4, 4, 5, 5, 6, 6]\n\n>>> # Define a `worker_init_fn` that configures each dataset copy differently\n>>> def worker_init_fn(worker_id):\n...     worker_info = torch.utils.data.get_worker_info()\n...     dataset = worker_info.dataset  # the dataset copy in this worker process\n...     overall_start = dataset.start\n...     overall_end = dataset.end\n...     # configure the dataset to only process the split workload\n...     per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))\n...     worker_id = worker_info.id\n...     dataset.start = overall_start + worker_id * per_worker\n...     dataset.end = min(dataset.start + per_worker, overall_end)\n...\n\n>>> # Mult-process loading with the custom `worker_init_fn`\n>>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=2, worker_init_fn=worker_init_fn)))\n[3, 5, 4, 6]\n\n>>> # With even more workers\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=12, worker_init_fn=worker_init_fn)))\n[3, 4, 5, 6] \n```", "```py\nclass torch.utils.data.TensorDataset(*tensors)\u00b6\n```", "```py\nclass torch.utils.data.StackDataset(*args, **kwargs)\u00b6\n```", "```py\n>>> images = ImageDataset()\n>>> texts = TextDataset()\n>>> tuple_stack = StackDataset(images, texts)\n>>> tuple_stack[0] == (images[0], texts[0])\n>>> dict_stack = StackDataset(image=images, text=texts)\n>>> dict_stack[0] == {'image': images[0], 'text': texts[0]} \n```", "```py\nclass torch.utils.data.ConcatDataset(datasets)\u00b6\n```", "```py\nclass torch.utils.data.ChainDataset(datasets)\u00b6\n```", "```py\nclass torch.utils.data.Subset(dataset, indices)\u00b6\n```", "```py\ntorch.utils.data._utils.collate.collate(batch, *, collate_fn_map=None)\u00b6\n```", "```py\n>>> def collate_tensor_fn(batch, *, collate_fn_map):\n>>> # Extend this function to handle batch of tensors\n...     return torch.stack(batch, 0)\n>>> def custom_collate(batch):\n...     collate_map = {torch.Tensor: collate_tensor_fn}\n...     return collate(batch, collate_fn_map=collate_map)\n>>> # Extend `default_collate` by in-place modifying `default_collate_fn_map`\n>>> default_collate_fn_map.update({torch.Tensor: collate_tensor_fn}) \n```", "```py\ntorch.utils.data.default_collate(batch)\u00b6\n```", "```py\n>>> # Example with a batch of `int`s:\n>>> default_collate([0, 1, 2, 3])\ntensor([0, 1, 2, 3])\n>>> # Example with a batch of `str`s:\n>>> default_collate(['a', 'b', 'c'])\n['a', 'b', 'c']\n>>> # Example with `Map` inside the batch:\n>>> default_collate([{'A': 0, 'B': 1}, {'A': 100, 'B': 100}])\n{'A': tensor([  0, 100]), 'B': tensor([  1, 100])}\n>>> # Example with `NamedTuple` inside the batch:\n>>> Point = namedtuple('Point', ['x', 'y'])\n>>> default_collate([Point(0, 0), Point(1, 1)])\nPoint(x=tensor([0, 1]), y=tensor([0, 1]))\n>>> # Example with `Tuple` inside the batch:\n>>> default_collate([(0, 1), (2, 3)])\n[tensor([0, 2]), tensor([1, 3])]\n>>> # Example with `List` inside the batch:\n>>> default_collate([[0, 1], [2, 3]])\n[tensor([0, 2]), tensor([1, 3])]\n>>> # Two options to extend `default_collate` to handle specific type\n>>> # Option 1: Write custom collate function and invoke `default_collate`\n>>> def custom_collate(batch):\n...     elem = batch[0]\n...     if isinstance(elem, CustomType):  # Some custom condition\n...         return ...\n...     else:  # Fall back to `default_collate`\n...         return default_collate(batch)\n>>> # Option 2: In-place modify `default_collate_fn_map`\n>>> def collate_customtype_fn(batch, *, collate_fn_map=None):\n...     return ...\n>>> default_collate_fn_map.update(CustoType, collate_customtype_fn)\n>>> default_collate(batch)  # Handle `CustomType` automatically \n```", "```py\ntorch.utils.data.default_convert(data)\u00b6\n```", "```py\n>>> # Example with `int`\n>>> default_convert(0)\n0\n>>> # Example with NumPy array\n>>> default_convert(np.array([0, 1]))\ntensor([0, 1])\n>>> # Example with NamedTuple\n>>> Point = namedtuple('Point', ['x', 'y'])\n>>> default_convert(Point(0, 0))\nPoint(x=0, y=0)\n>>> default_convert(Point(np.array(0), np.array(0)))\nPoint(x=tensor(0), y=tensor(0))\n>>> # Example with List\n>>> default_convert([np.array([0, 1]), np.array([2, 3])])\n[tensor([0, 1]), tensor([2, 3])] \n```", "```py\ntorch.utils.data.get_worker_info()\u00b6\n```", "```py\ntorch.utils.data.random_split(dataset, lengths, generator=<torch._C.Generator object>)\u00b6\n```", "```py\n>>> generator1 = torch.Generator().manual_seed(42)\n>>> generator2 = torch.Generator().manual_seed(42)\n>>> random_split(range(10), [3, 7], generator=generator1)\n>>> random_split(range(30), [0.3, 0.3, 0.4], generator=generator2) \n```", "```py\nclass torch.utils.data.Sampler(data_source=None)\u00b6\n```", "```py\n>>> class AccedingSequenceLengthSampler(Sampler[int]):\n>>>     def __init__(self, data: List[str]) -> None:\n>>>         self.data = data\n>>>\n>>>     def __len__(self) -> int:\n>>>         return len(self.data)\n>>>\n>>>     def __iter__(self) -> Iterator[int]:\n>>>         sizes = torch.tensor([len(x) for x in self.data])\n>>>         yield from torch.argsort(sizes).tolist()\n>>>\n>>> class AccedingSequenceLengthBatchSampler(Sampler[List[int]]):\n>>>     def __init__(self, data: List[str], batch_size: int) -> None:\n>>>         self.data = data\n>>>         self.batch_size = batch_size\n>>>\n>>>     def __len__(self) -> int:\n>>>         return (len(self.data) + self.batch_size - 1) // self.batch_size\n>>>\n>>>     def __iter__(self) -> Iterator[List[int]]:\n>>>         sizes = torch.tensor([len(x) for x in self.data])\n>>>         for batch in torch.chunk(torch.argsort(sizes), len(self)):\n>>>             yield batch.tolist() \n```", "```py\nclass torch.utils.data.SequentialSampler(data_source)\u00b6\n```", "```py\nclass torch.utils.data.RandomSampler(data_source, replacement=False, num_samples=None, generator=None)\u00b6\n```", "```py\nclass torch.utils.data.SubsetRandomSampler(indices, generator=None)\u00b6\n```", "```py\nclass torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None)\u00b6\n```", "```py\n>>> list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True))\n[4, 4, 1, 4, 5]\n>>> list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False))\n[0, 1, 4, 3, 2] \n```", "```py\nclass torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\u00b6\n```", "```py\n>>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n>>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8]] \n```", "```py\nclass torch.utils.data.distributed.DistributedSampler(dataset, num_replicas=None, rank=None, shuffle=True, seed=0, drop_last=False)\u00b6\n```", "```py\n>>> sampler = DistributedSampler(dataset) if is_distributed else None\n>>> loader = DataLoader(dataset, shuffle=(sampler is None),\n...                     sampler=sampler)\n>>> for epoch in range(start_epoch, n_epochs):\n...     if is_distributed:\n...         sampler.set_epoch(epoch)\n...     train(loader) \n```"]