["```py\ncuda = torch.device('cuda')     # Default CUDA device\ncuda0 = torch.device('cuda:0')\ncuda2 = torch.device('cuda:2')  # GPU 2 (these are 0-indexed)\n\nx = torch.tensor([1., 2.], device=cuda0)\n# x.device is device(type='cuda', index=0)\ny = torch.tensor([1., 2.]).cuda()\n# y.device is device(type='cuda', index=0)\n\nwith torch.cuda.device(1):\n    # allocates a tensor on GPU 1\n    a = torch.tensor([1., 2.], device=cuda)\n\n    # transfers a tensor from CPU to GPU 1\n    b = torch.tensor([1., 2.]).cuda()\n    # a.device and b.device are device(type='cuda', index=1)\n\n    # You can also use ``Tensor.to`` to transfer a tensor:\n    b2 = torch.tensor([1., 2.]).to(device=cuda)\n    # b.device and b2.device are device(type='cuda', index=1)\n\n    c = a + b\n    # c.device is device(type='cuda', index=1)\n\n    z = x + y\n    # z.device is device(type='cuda', index=0)\n\n    # even within a context, you can specify the device\n    # (or give a GPU index to the .cuda call)\n    d = torch.randn(2, device=cuda2)\n    e = torch.randn(2).to(cuda2)\n    f = torch.randn(2).cuda(cuda2)\n    # d.device, e.device, and f.device are all device(type='cuda', index=2) \n```", "```py\n# The flag below controls whether to allow TF32 on matmul. This flag defaults to False\n# in PyTorch 1.12 and later.\ntorch.backends.cuda.matmul.allow_tf32 = True\n\n# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\ntorch.backends.cudnn.allow_tf32 = True \n```", "```py\na_full = torch.randn(10240, 10240, dtype=torch.double, device='cuda')\nb_full = torch.randn(10240, 10240, dtype=torch.double, device='cuda')\nab_full = a_full @ b_full\nmean = ab_full.abs().mean()  # 80.7277\n\na = a_full.float()\nb = b_full.float()\n\n# Do matmul at TF32 mode.\ntorch.backends.cuda.matmul.allow_tf32 = True\nab_tf32 = a @ b  # takes 0.016s on GA100\nerror = (ab_tf32 - ab_full).abs().max()  # 0.1747\nrelative_error = error / mean  # 0.0022\n\n# Do matmul with TF32 disabled.\ntorch.backends.cuda.matmul.allow_tf32 = False\nab_fp32 = a @ b  # takes 0.11s on GA100\nerror = (ab_fp32 - ab_full).abs().max()  # 0.0031\nrelative_error = error / mean  # 0.000039 \n```", "```py\ntorch.backends.cuda.matmul.allow_tf32 = False\ntorch.backends.cudnn.allow_tf32 = False \n```", "```py\nat::globalContext().setAllowTF32CuBLAS(false);\nat::globalContext().setAllowTF32CuDNN(false); \n```", "```py\n[--------------------------- bench_gemm_transformer --------------------------]\n      [  m ,  k  ,  n  ]    |  allow_fp16_reduc=True  |  allow_fp16_reduc=False\n1 threads: --------------------------------------------------------------------\n      [4096, 4048, 4096]    |           1634.6        |           1639.8\n      [4096, 4056, 4096]    |           1670.8        |           1661.9\n      [4096, 4080, 4096]    |           1664.2        |           1658.3\n      [4096, 4096, 4096]    |           1639.4        |           1651.0\n      [4096, 4104, 4096]    |           1677.4        |           1674.9\n      [4096, 4128, 4096]    |           1655.7        |           1646.0\n      [4096, 4144, 4096]    |           1796.8        |           2519.6\n      [4096, 5096, 4096]    |           2094.6        |           3190.0\n      [4096, 5104, 4096]    |           2144.0        |           2663.5\n      [4096, 5112, 4096]    |           2149.1        |           2766.9\n      [4096, 5120, 4096]    |           2142.8        |           2631.0\n      [4096, 9728, 4096]    |           3875.1        |           5779.8\n      [4096, 16384, 4096]   |           6182.9        |           9656.5\n(times in microseconds). \n```", "```py\ntorch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = False \n```", "```py\nat::globalContext().setAllowFP16ReductionCuBLAS(false); \n```", "```py\ntorch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction = False \n```", "```py\nat::globalContext().setAllowBF16ReductionCuBLAS(true); \n```", "```py\nstart_event = torch.cuda.Event(enable_timing=True)\nend_event = torch.cuda.Event(enable_timing=True)\nstart_event.record()\n\n# Run some things here\n\nend_event.record()\ntorch.cuda.synchronize()  # Wait for the events to be recorded!\nelapsed_time_ms = start_event.elapsed_time(end_event) \n```", "```py\ncuda = torch.device('cuda')\ns = torch.cuda.Stream()  # Create a new stream.\nA = torch.empty((100, 100), device=cuda).normal_(0.0, 1.0)\nwith torch.cuda.stream(s):\n    # sum() may start execution before normal_() finishes!\n    B = torch.sum(A) \n```", "```py\ncuda = torch.device('cuda')\ns = torch.cuda.Stream()  # Create a new stream.\nA = torch.empty((100, 100), device=cuda).normal_(0.0, 1.0)\ns.wait_stream(torch.cuda.default_stream(cuda))  # NEW!\nwith torch.cuda.stream(s):\n    B = torch.sum(A)\nA.record_stream(s)  # NEW! \n```", "```py\ncuda = torch.device('cuda')\ns = torch.cuda.Stream()  # Create a new stream.\nA = torch.empty((100, 100), device=cuda)\ns.wait_stream(torch.cuda.default_stream(cuda))  # STILL REQUIRED!\nwith torch.cuda.stream(s):\n    A.normal_(0.0, 1.0)\n    A.record_stream(s) \n```", "```py\ns = torch.cuda.Stream()\n\n# Safe, grads are used in the same stream context as backward()\nwith torch.cuda.stream(s):\n    loss.backward()\n    use grads\n\n# Unsafe\nwith torch.cuda.stream(s):\n    loss.backward()\nuse grads\n\n# Safe, with synchronization\nwith torch.cuda.stream(s):\n    loss.backward()\ntorch.cuda.current_stream().wait_stream(s)\nuse grads\n\n# Safe, populating initial grad and invoking backward are in the same stream context\nwith torch.cuda.stream(s):\n    loss.backward(gradient=torch.ones_like(loss))\n\n# Unsafe, populating initial_grad and invoking backward are in different stream contexts,\n# without synchronization\ninitial_grad = torch.ones_like(loss)\nwith torch.cuda.stream(s):\n    loss.backward(gradient=initial_grad)\n\n# Safe, with synchronization\ninitial_grad = torch.ones_like(loss)\ns.wait_stream(torch.cuda.current_stream())\nwith torch.cuda.stream(s):\n    initial_grad.record_stream(s)\n    loss.backward(gradient=initial_grad) \n```", "```py\nwith torch.cuda.stream(s):\n    loss.backward()\nuse grads \n```", "```py\nwith torch.cuda.stream(s):\n    loss.backward()\ntorch.cuda.current_stream().wait_stream(s)\nuse grads \n```", "```py\n#include  <sys/types.h>\n#include  <cuda_runtime_api.h>\n#include  <iostream>\n// Compile with g++ alloc.cc -o alloc.so -I/usr/local/cuda/include -shared -fPIC\nextern  \"C\"  {\nvoid*  my_malloc(ssize_t  size,  int  device,  cudaStream_t  stream)  {\n  void  *ptr;\n  cudaMalloc(&ptr,  size);\n  std::cout<<\"alloc \"<<ptr<<size<<std::endl;\n  return  ptr;\n}\n\nvoid  my_free(void*  ptr,  ssize_t  size,  int  device,  cudaStream_t  stream)  {\n  std::cout<<\"free \"<<ptr<<  \" \"<<stream<<std::endl;\n  cudaFree(ptr);\n}\n} \n```", "```py\nimport torch\n\n# Load the allocator\nnew_alloc = torch.cuda.memory.CUDAPluggableAllocator(\n    'alloc.so', 'my_malloc', 'my_free')\n# Swap the current allocator\ntorch.cuda.memory.change_current_allocator(new_alloc)\n# This will allocate memory in the device using the new allocator\nb = torch.zeros(10, device='cuda') \n```", "```py\nimport torch\n\n# Do an initial memory allocator\nb = torch.zeros(10, device='cuda')\n# Load the allocator\nnew_alloc = torch.cuda.memory.CUDAPluggableAllocator(\n    'alloc.so', 'my_malloc', 'my_free')\n# This will error since the current allocator was already instantiated\ntorch.cuda.memory.change_current_allocator(new_alloc) \n```", "```py\nimport argparse\nimport torch\n\nparser = argparse.ArgumentParser(description='PyTorch Example')\nparser.add_argument('--disable-cuda', action='store_true',\n                    help='Disable CUDA')\nargs = parser.parse_args()\nargs.device = None\nif not args.disable_cuda and torch.cuda.is_available():\n    args.device = torch.device('cuda')\nelse:\n    args.device = torch.device('cpu') \n```", "```py\nx = torch.empty((8, 42), device=args.device)\nnet = Network().to(device=args.device) \n```", "```py\ncuda0 = torch.device('cuda:0')  # CUDA GPU 0\nfor i, x in enumerate(train_loader):\n    x = x.to(cuda0) \n```", "```py\nprint(\"Outside device is 0\")  # On device 0 (default in most scenarios)\nwith torch.cuda.device(1):\n    print(\"Inside device is 1\")  # On device 1\nprint(\"Outside device is still 0\")  # On device 0 \n```", "```py\ncuda = torch.device('cuda')\nx_cpu = torch.empty(2)\nx_gpu = torch.empty(2, device=cuda)\nx_cpu_long = torch.empty(2, dtype=torch.int64)\n\ny_cpu = x_cpu.new_full([3, 2], fill_value=0.3)\nprint(y_cpu)\n\n    tensor([[ 0.3000,  0.3000],\n            [ 0.3000,  0.3000],\n            [ 0.3000,  0.3000]])\n\ny_gpu = x_gpu.new_full([3, 2], fill_value=-5)\nprint(y_gpu)\n\n    tensor([[-5.0000, -5.0000],\n            [-5.0000, -5.0000],\n            [-5.0000, -5.0000]], device='cuda:0')\n\ny_cpu_long = x_cpu_long.new_tensor([[1, 2, 3]])\nprint(y_cpu_long)\n\n    tensor([[ 1,  2,  3]]) \n```", "```py\nx_cpu = torch.empty(2, 3)\nx_gpu = torch.empty(2, 3)\n\ny_cpu = torch.ones_like(x_cpu)\ny_gpu = torch.zeros_like(x_gpu) \n```", "```py\ng = torch.cuda.CUDAGraph()\n\n# Placeholder input used for capture\nstatic_input = torch.empty((5,), device=\"cuda\")\n\n# Warmup before capture\ns = torch.cuda.Stream()\ns.wait_stream(torch.cuda.current_stream())\nwith torch.cuda.stream(s):\n    for _ in range(3):\n        static_output = static_input * 2\ntorch.cuda.current_stream().wait_stream(s)\n\n# Captures the graph\n# To allow capture, automatically sets a side stream as the current stream in the context\nwith torch.cuda.graph(g):\n    static_output = static_input * 2\n\n# Fills the graph's input memory with new data to compute on\nstatic_input.copy_(torch.full((5,), 3, device=\"cuda\"))\ng.replay()\n# static_output holds the results\nprint(static_output)  # full of 3 * 2 = 6\n\n# Fills the graph's input memory with more data to compute on\nstatic_input.copy_(torch.full((5,), 4, device=\"cuda\"))\ng.replay()\nprint(static_output)  # full of 4 * 2 = 8 \n```", "```py\nN, D_in, H, D_out = 640, 4096, 2048, 1024\nmodel = torch.nn.Sequential(torch.nn.Linear(D_in, H),\n                            torch.nn.Dropout(p=0.2),\n                            torch.nn.Linear(H, D_out),\n                            torch.nn.Dropout(p=0.1)).cuda()\nloss_fn = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n\n# Placeholders used for capture\nstatic_input = torch.randn(N, D_in, device='cuda')\nstatic_target = torch.randn(N, D_out, device='cuda')\n\n# warmup\n# Uses static_input and static_target here for convenience,\n# but in a real setting, because the warmup includes optimizer.step()\n# you must use a few batches of real data.\ns = torch.cuda.Stream()\ns.wait_stream(torch.cuda.current_stream())\nwith torch.cuda.stream(s):\n    for i in range(3):\n        optimizer.zero_grad(set_to_none=True)\n        y_pred = model(static_input)\n        loss = loss_fn(y_pred, static_target)\n        loss.backward()\n        optimizer.step()\ntorch.cuda.current_stream().wait_stream(s)\n\n# capture\ng = torch.cuda.CUDAGraph()\n# Sets grads to None before capture, so backward() will create\n# .grad attributes with allocations from the graph's private pool\noptimizer.zero_grad(set_to_none=True)\nwith torch.cuda.graph(g):\n    static_y_pred = model(static_input)\n    static_loss = loss_fn(static_y_pred, static_target)\n    static_loss.backward()\n    optimizer.step()\n\nreal_inputs = [torch.rand_like(static_input) for _ in range(10)]\nreal_targets = [torch.rand_like(static_target) for _ in range(10)]\n\nfor data, target in zip(real_inputs, real_targets):\n    # Fills the graph's input memory with new data to compute on\n    static_input.copy_(data)\n    static_target.copy_(target)\n    # replay() includes forward, backward, and step.\n    # You don't even need to call optimizer.zero_grad() between iterations\n    # because the captured backward refills static .grad tensors in place.\n    g.replay()\n    # Params have been updated. static_y_pred, static_loss, and .grad\n    # attributes hold values from computing on this iteration's data. \n```", "```py\nN, D_in, H, D_out = 640, 4096, 2048, 1024\n\nmodule1 = torch.nn.Linear(D_in, H).cuda()\nmodule2 = torch.nn.Linear(H, D_out).cuda()\nmodule3 = torch.nn.Linear(H, D_out).cuda()\n\nloss_fn = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(chain(module1.parameters(),\n                                  module2.parameters(),\n                                  module3.parameters()),\n                            lr=0.1)\n\n# Sample inputs used for capture\n# requires_grad state of sample inputs must match\n# requires_grad state of real inputs each callable will see.\nx = torch.randn(N, D_in, device='cuda')\nh = torch.randn(N, H, device='cuda', requires_grad=True)\n\nmodule1 = torch.cuda.make_graphed_callables(module1, (x,))\nmodule2 = torch.cuda.make_graphed_callables(module2, (h,))\nmodule3 = torch.cuda.make_graphed_callables(module3, (h,))\n\nreal_inputs = [torch.rand_like(x) for _ in range(10)]\nreal_targets = [torch.randn(N, D_out, device=\"cuda\") for _ in range(10)]\n\nfor data, target in zip(real_inputs, real_targets):\n    optimizer.zero_grad(set_to_none=True)\n\n    tmp = module1(data)  # forward ops run as a graph\n\n    if tmp.sum().item() > 0:\n        tmp = module2(tmp)  # forward ops run as a graph\n    else:\n        tmp = module3(tmp)  # forward ops run as a graph\n\n    loss = loss_fn(tmp, target)\n    # module2's or module3's (whichever was chosen) backward ops,\n    # as well as module1's backward ops, run as graphs\n    loss.backward()\n    optimizer.step() \n```", "```py\n# warmup\n# In a real setting, use a few batches of real data.\ns = torch.cuda.Stream()\ns.wait_stream(torch.cuda.current_stream())\nwith torch.cuda.stream(s):\n    for i in range(3):\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast():\n            y_pred = model(static_input)\n            loss = loss_fn(y_pred, static_target)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\ntorch.cuda.current_stream().wait_stream(s)\n\n# capture\ng = torch.cuda.CUDAGraph()\noptimizer.zero_grad(set_to_none=True)\nwith torch.cuda.graph(g):\n    with torch.cuda.amp.autocast():\n        static_y_pred = model(static_input)\n        static_loss = loss_fn(static_y_pred, static_target)\n    scaler.scale(static_loss).backward()\n    # don't capture scaler.step(optimizer) or scaler.update()\n\nreal_inputs = [torch.rand_like(static_input) for _ in range(10)]\nreal_targets = [torch.rand_like(static_target) for _ in range(10)]\n\nfor data, target in zip(real_inputs, real_targets):\n    static_input.copy_(data)\n    static_target.copy_(target)\n    g.replay()\n    # Runs scaler.step and scaler.update eagerly\n    scaler.step(optimizer)\n    scaler.update() \n```", "```py\nwith torch.cuda.graph(g):\n    # at context manager entrance, torch.cuda.current_stream()\n    # is the initial capturing stream\n\n    # INCORRECT (does not branch out from or rejoin initial stream)\n    with torch.cuda.stream(s):\n        cuda_work()\n\n    # CORRECT:\n    # branches out from initial stream\n    s.wait_stream(torch.cuda.current_stream())\n    with torch.cuda.stream(s):\n        cuda_work()\n    # rejoins initial stream before capture ends\n    torch.cuda.current_stream().wait_stream(s) \n```", "```py\n    os.environ[\"NCCL_ASYNC_ERROR_HANDLING\"] = \"0\"\n    torch.distributed.init_process_group(...) \n    ```", "```py\n    with torch.cuda.stream(s):\n        model = DistributedDataParallel(model) \n    ```", "```py\ng1 = torch.cuda.CUDAGraph()\ng2 = torch.cuda.CUDAGraph()\n\n# (create static inputs for g1 and g2, run warmups of their workloads...)\n\n# Captures g1\nwith torch.cuda.graph(g1):\n    static_out_1 = g1_workload(static_in_1)\n\n# Captures g2, hinting that g2 may share a memory pool with g1\nwith torch.cuda.graph(g2, pool=g1.pool()):\n    static_out_2 = g2_workload(static_in_2)\n\nstatic_in_1.copy_(real_data_1)\nstatic_in_2.copy_(real_data_2)\ng1.replay()\ng2.replay() \n```"]