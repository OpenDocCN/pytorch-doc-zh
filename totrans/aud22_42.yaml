- en: Text-to-Speech with Tacotron2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/audio/stable/tutorials/tacotron2_pipeline_tutorial.html](https://pytorch.org/audio/stable/tutorials/tacotron2_pipeline_tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Click [here](#sphx-glr-download-tutorials-tacotron2-pipeline-tutorial-py) to
    download the full example code
  prefs: []
  type: TYPE_NORMAL
- en: '**Author**: [Yao-Yuan Yang](https://github.com/yangarbiter), [Moto Hira](mailto:moto%40meta.com)'
  prefs: []
  type: TYPE_NORMAL
- en: Overview[](#overview "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This tutorial shows how to build text-to-speech pipeline, using the pretrained
    Tacotron2 in torchaudio.
  prefs: []
  type: TYPE_NORMAL
- en: 'The text-to-speech pipeline goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Text preprocessing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, the input text is encoded into a list of symbols. In this tutorial, we
    will use English characters and phonemes as the symbols.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Spectrogram generation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the encoded text, a spectrogram is generated. We use `Tacotron2` model
    for this.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Time-domain conversion
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The last step is converting the spectrogram into the waveform. The process to
    generate speech from spectrogram is also called Vocoder. In this tutorial, three
    different vocoders are used, [`WaveRNN`](../generated/torchaudio.models.WaveRNN.html#torchaudio.models.WaveRNN
    "torchaudio.models.WaveRNN"), [`GriffinLim`](../generated/torchaudio.transforms.GriffinLim.html#torchaudio.transforms.GriffinLim
    "torchaudio.transforms.GriffinLim"), and [Nvidia’s WaveGlow](https://pytorch.org/hub/nvidia_deeplearningexamples_tacotron2/).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The following figure illustrates the whole process.
  prefs: []
  type: TYPE_NORMAL
- en: '![https://download.pytorch.org/torchaudio/tutorial-assets/tacotron2_tts_pipeline.png](../Images/209f5b44836c4b1fdfb15fbfce7fd7f0.png)'
  prefs: []
  type: TYPE_IMG
- en: All the related components are bundled in [`torchaudio.pipelines.Tacotron2TTSBundle`](../generated/torchaudio.pipelines.Tacotron2TTSBundle.html#torchaudio.pipelines.Tacotron2TTSBundle
    "torchaudio.pipelines.Tacotron2TTSBundle"), but this tutorial will also cover
    the process under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: Preparation[](#preparation "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we install the necessary dependencies. In addition to `torchaudio`, `DeepPhonemizer`
    is required to perform phoneme-based encoding.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Text Processing[](#text-processing "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Character-based encoding[](#character-based-encoding "Permalink to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will go through how the character-based encoding works.
  prefs: []
  type: TYPE_NORMAL
- en: Since the pre-trained Tacotron2 model expects specific set of symbol tables,
    the same functionalities available in `torchaudio`. This section is more for the
    explanation of the basis of encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we define the set of symbols. For example, we can use `'_-!\'(),.:;?
    abcdefghijklmnopqrstuvwxyz'`. Then, we will map the each character of the input
    text into the index of the corresponding symbol in the table.
  prefs: []
  type: TYPE_NORMAL
- en: The following is an example of such processing. In the example, symbols that
    are not in the table are ignored.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned in the above, the symbol table and indices must match what the
    pretrained Tacotron2 model expects. `torchaudio` provides the transform along
    with the pretrained model. For example, you can instantiate and use such transform
    as follow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `processor` object takes either a text or list of texts as inputs. When
    a list of texts are provided, the returned `lengths` variable represents the valid
    length of each processed tokens in the output batch.
  prefs: []
  type: TYPE_NORMAL
- en: The intermediate representation can be retrieved as follow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Phoneme-based encoding[](#phoneme-based-encoding "Permalink to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Phoneme-based encoding is similar to character-based encoding, but it uses a
    symbol table based on phonemes and a G2P (Grapheme-to-Phoneme) model.
  prefs: []
  type: TYPE_NORMAL
- en: The detail of the G2P model is out of scope of this tutorial, we will just look
    at what the conversion looks like.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the case of character-based encoding, the encoding process is expected
    to match what a pretrained Tacotron2 model is trained on. `torchaudio` has an
    interface to create the process.
  prefs: []
  type: TYPE_NORMAL
- en: The following code illustrates how to make and use the process. Behind the scene,
    a G2P model is created using `DeepPhonemizer` package, and the pretrained weights
    published by the author of `DeepPhonemizer` is fetched.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the encoded values are different from the example of character-based
    encoding.
  prefs: []
  type: TYPE_NORMAL
- en: The intermediate representation looks like the following.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Spectrogram Generation[](#spectrogram-generation "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Tacotron2` is the model we use to generate spectrogram from the encoded text.
    For the detail of the model, please refer to [the paper](https://arxiv.org/abs/1712.05884).'
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to instantiate a Tacotron2 model with pretrained weight, however,
    note that the input to Tacotron2 models need to be processed by the matching text
    processor.
  prefs: []
  type: TYPE_NORMAL
- en: '[`torchaudio.pipelines.Tacotron2TTSBundle`](../generated/torchaudio.pipelines.Tacotron2TTSBundle.html#torchaudio.pipelines.Tacotron2TTSBundle
    "torchaudio.pipelines.Tacotron2TTSBundle") bundles the matching models and processors
    together so that it is easy to create the pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: For the available bundles, and its usage, please refer to [`Tacotron2TTSBundle`](../generated/torchaudio.pipelines.Tacotron2TTSBundle.html#torchaudio.pipelines.Tacotron2TTSBundle
    "torchaudio.pipelines.Tacotron2TTSBundle").
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![tacotron2 pipeline tutorial](../Images/caf2a228b2d54421e1c3fc64dd482393.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that `Tacotron2.infer` method perfoms multinomial sampling, therefor, the
    process of generating the spectrogram incurs randomness.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![tacotron2 pipeline tutorial](../Images/b4898a614b73264775a6c5201f2e1bc3.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Waveform Generation[](#waveform-generation "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the spectrogram is generated, the last process is to recover the waveform
    from the spectrogram.
  prefs: []
  type: TYPE_NORMAL
- en: '`torchaudio` provides vocoders based on `GriffinLim` and `WaveRNN`.'
  prefs: []
  type: TYPE_NORMAL
- en: WaveRNN[](#wavernn "Permalink to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Continuing from the previous section, we can instantiate the matching WaveRNN
    model from the same bundle.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![tacotron2 pipeline tutorial](../Images/d81f4591e9faa8f9a00d0a4eb78e505d.png)'
  prefs: []
  type: TYPE_IMG
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: Griffin-Lim[](#griffin-lim "Permalink to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the Griffin-Lim vocoder is same as WaveRNN. You can instantiate the vocode
    object with [`get_vocoder()`](../generated/torchaudio.pipelines.Tacotron2TTSBundle.html#torchaudio.pipelines.Tacotron2TTSBundle.get_vocoder
    "torchaudio.pipelines.Tacotron2TTSBundle.get_vocoder") method and pass the spectrogram.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![tacotron2 pipeline tutorial](../Images/3ce8674d89c25493f24e575fd2377a53.png)'
  prefs: []
  type: TYPE_IMG
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: Waveglow[](#waveglow "Permalink to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Waveglow is a vocoder published by Nvidia. The pretrained weights are published
    on Torch Hub. One can instantiate the model using `torch.hub` module.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![tacotron2 pipeline tutorial](../Images/d981c34fe89af30a4e994e3d10e2dad4.png)'
  prefs: []
  type: TYPE_IMG
- en: 
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the audio element.
  prefs: []
  type: TYPE_NORMAL
- en: '**Total running time of the script:** ( 1 minutes 41.941 seconds)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Python source code: tacotron2_pipeline_tutorial.py`](../_downloads/9772cbd0af96f57f17a2da758b365a43/tacotron2_pipeline_tutorial.py)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Jupyter notebook: tacotron2_pipeline_tutorial.ipynb`](../_downloads/63ad2005fc24f143f3f078cd2c6b0d60/tacotron2_pipeline_tutorial.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  prefs: []
  type: TYPE_NORMAL
