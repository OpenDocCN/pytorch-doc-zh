- en: torchtext.data.utils¶
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/text/stable/data_utils.html](https://pytorch.org/text/stable/data_utils.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '## get_tokenizer[¶](#get-tokenizer "Permalink to this heading")'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Generate tokenizer function for a string sentence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**tokenizer** – the name of tokenizer function. If None, it returns split()
    function, which splits the string sentence by space. If basic_english, it returns
    _basic_english_normalize() function, which normalize the string first and split
    by space. If a callable function, it will return the function. If a tokenizer
    library (e.g. spacy, moses, toktok, revtok, subword), it returns the corresponding
    library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**language** – Default en'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ngrams_iterator[¶](#ngrams-iterator "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Return an iterator that yields the given tokens and their ngrams.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**token_list** – A list of tokens'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ngrams** – the number of ngrams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
