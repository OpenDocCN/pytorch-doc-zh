# torch.masked

> [`pytorch.org/docs/stable/masked.html`](https://pytorch.org/docs/stable/masked.html)

## 介绍

### 动机

警告

Masked 张量的 PyTorch API 处于原型阶段，未来可能会发生变化。

MaskedTensor 作为`torch.Tensor`的扩展，为用户提供以下功能：

+   使用任何掩码语义（例如，可变长度张量，nan*运算符等）。

+   区分 0 和 NaN 梯度

+   各种稀疏应用（请参见下面的教程）

“指定”和“未指定”在 PyTorch 中有着悠久的历史，没有正式的语义，当然也没有一致性；事实上，MaskedTensor 是在积累了一系列问题之后诞生的，这些问题普通的`torch.Tensor`类无法正确解决。因此，MaskedTensor 的主要目标是成为 PyTorch 中“指定”和“未指定”值的真相来源，使其成为一等公民而不是一个事后想法。这应该进一步释放[稀疏性](https://pytorch.org/docs/stable/sparse.html)的潜力，实现更安全和更一致的运算符，并为用户和开发人员提供更流畅、更直观的体验。

### 什么是 MaskedTensor？

MaskedTensor 是一个张量子类，由 1）输入（数据）和 2）掩码组成。掩码告诉我们应该包含或忽略输入中的哪些条目。

举例来说，假设我们想要掩盖所有等于 0 的值（用灰色表示）并取最大值：

![_images/tensor_comparison.jpg](img/tensor_comparison.jpg)

顶部是普通张量示例，底部是 MaskedTensor，其中所有的 0 都被掩盖了。这显然会产生不同的结果，取决于我们是否有掩码，但这种灵活的结构允许用户在计算过程中系统地忽略任何他们想要的元素。

我们已经撰写了许多现有的教程，以帮助用户入门，例如：

+   [概述 - 新用户的起点，讨论如何使用 MaskedTensors 以及它们的用处](https://pytorch.org/tutorials/prototype/maskedtensor_overview)

+   [稀疏性 - MaskedTensor 支持稀疏的 COO 和 CSR 数据以及掩码张量](https://pytorch.org/tutorials/prototype/maskedtensor_sparsity)

+   [Adagrad 稀疏语义 - 一个实际示例，展示了 MaskedTensor 如何简化稀疏语义和实现](https://pytorch.org/tutorials/prototype/maskedtensor_adagrad)

+   [高级语义 - 讨论为什么做出某些决定（例如，要求掩码匹配二进制/缩减操作，与 NumPy 的 MaskedArray 的区别以及缩减语义）](https://pytorch.org/tutorials/prototype/maskedtensor_advanced_semantics)

## 支持的运算符

### 一元运算符

一元运算符是只包含单个输入的运算符。将它们应用于 MaskedTensors 相对简单：如果在给定索引处数据被掩盖，我们应用运算符，否则我们将继续掩盖数据。

可用的一元运算符有：

| `abs` | 计算`input`中每个元素的绝对值。 |
| --- | --- |
| `absolute` | `torch.abs()`的别名 |
| `acos` | 计算`input`中每个元素的反余弦。 |
| `arccos` | `torch.acos()`的别名。 |
| `acosh` | 返回一个新的张量，其中包含`input`元素的反双曲余弦。 |
| `arccosh` | `torch.acosh()`的别名。 |
| `angle` | 计算给定`input`张量的逐元素角度（弧度）。 |
| `asin` | 返回一个新张量，其中元素是`input`的反正弦。 |
| `arcsin` | `torch.asin()`的别名。 |
| `asinh` | 返回一个新张量，其中元素是`input`的反双曲正弦。 |
| `arcsinh` | `torch.asinh()`的别名。 |
| `atan` | 返回一个新张量，其中元素是`input`的反正切。 |
| `arctan` | `torch.atan()`的别名。 |
| `atanh` | 返回一个新张量，其中元素是`input`的反双曲正切。 |
| `arctanh` | `torch.atanh()`的别名。 |
| `bitwise_not` | 计算给定输入张量的按位取反。 |
| `ceil` | 返回一个新张量，其中元素是`input`的上取整，即大于或等于每个元素的最小整数。 |
| `clamp` | 将`input`中的所有元素夹紧到 [`min`, `max` ]范围内。 |
| `clip` | `torch.clamp()`的别名。 |
| `conj_physical` | 计算给定`input`张量的逐元素共轭。 |
| `cos` | 返回一个新张量，其中元素是`input`的余弦。 |
| `cosh` | 返回一个新张量，其中元素是`input`的双曲余弦。 |
| `deg2rad` | 返回一个新张量，其中`input`的每个元素从角度转换为弧度。 |
| `digamma` | `torch.special.digamma()`的别名。 |
| `erf` | `torch.special.erf()`的别名。 |
| `erfc` | `torch.special.erfc()`的别名。 |
| `erfinv` | `torch.special.erfinv()`的别名。 |
| `exp` | 返回一个新张量，其中元素是输入张量`input`的指数。 |
| `exp2` | `torch.special.exp2()`的别名。 |
| `expm1` | `torch.special.expm1()`的别名。 |
| `fix` | `torch.trunc()`的别名。 |
| `floor` | 返回一个新的张量，其中每个元素的下限，即小于或等于每个元素的最大整数。 |
| `frac` | 计算`input`中每个元素的小数部分。 |
| `lgamma` | 计算`input`上伽玛函数的绝对值的自然对数。 |
| `log` | 返回一个新的张量，其中每个元素的自然对数。 |
| `log10` | 返回一个新的张量，其中每个元素的以 10 为底的对数。 |
| `log1p` | 返回一个新的张量，其中每个元素的自然对数(1 + `input`)。 |
| `log2` | 返回一个新的张量，其中每个元素的以 2 为底的对数。 |
| `logit` | `torch.special.logit()`的别名。 |
| `i0` | `torch.special.i0()`的别名。 |
| `isnan` | 返回一个新的张量，其中布尔元素表示`input`的每个元素是否为 NaN。 |
| `nan_to_num` | 用`nan`、`posinf`和`neginf`指定的值替换`input`中的`NaN`、正无穷大和负无穷大值。 |
| `neg` | 返回一个新的张量，其中每个元素的负值。 |
| `negative` | `torch.neg()`的别名。 |
| `positive` | 返回`input`。 |
| `pow` | 将`input`中的每个元素与`exponent`的幂相乘，并返回结果张量。 |
| `rad2deg` | 返回一个新的张量，其中`input`的每个元素从弧度转换为角度。 |
| `reciprocal` | 返回一个新的张量，其中每个元素的倒数。 |
| `round` | 将`input`的元素四舍五入到最近的整数。 |
| `rsqrt` | 返回一个新的张量，其中每个元素的倒数的平方根。 |
| `sigmoid` | `torch.special.expit()`的别名。 |
| `sign` | 返回一个新的张量，其中每个元素的符号。 |
| `sgn` | 这个函数是对复数张量的 torch.sign()的扩展。 |
| `signbit` | 检查`input`的每个元素是否设置了符号位。 |
| `sin` | 返回一个新的张量，其中每个元素的正弦值。 |
| `sinc` | `torch.special.sinc()`的别名。 |
| `sinh` | 返回一个新的张量，其中包含`input`元素的双曲正弦。 |
| `sqrt` | 返回一个新的张量，其中包含`input`元素的平方根。 |
| `square` | 返回一个新的张量，其中包含`input`元素的平方。 |
| `tan` | 返回一个新的张量，其中包含`input`元素的正切。 |
| `tanh` | 返回一个新的张量，其中包含`input`元素的双曲正切。 |
| `trunc` | 返回一个新的张量，其中包含`input`元素的截断整数值。 |

可用的就地一元运算符是上述所有内容**除外**：

| `angle` | 计算给定`input`张量的逐元素角度（弧度）。 |
| --- | --- |
| `positive` | 返回`input`。 |
| `signbit` | 检查`input`的每个元素是否设置了符号位。 |
| `isnan` | 返回一个新的张量，其中的布尔元素表示`input`的每个元素是否为 NaN。 |

### 二元运算符

正如您在教程中看到的，`MaskedTensor`也实现了二元操作，但需要注意的是，两个 MaskedTensor 中的掩码必须匹配，否则将引发错误。正如错误中所指出的，如果您需要支持特定运算符或提出了它们应该如何行为的语义，请在 GitHub 上提出问题。目前，我们决定采用最保守的实现方式，以确保用户完全了解正在发生的情况，并且在使用掩码语义时是有意识的。

可用的二元运算符有：

| `add` | 将`other`按`alpha`缩放后加到`input`上。 |
| --- | --- |
| `atan2` | 考虑象限的$\text{input}_{i} / \text{other}_{i}$​的逐元素反正切。 |
| `arctan2` | `torch.atan2()`的别名。 |
| `bitwise_and` | 计算`input`和`other`的按位与。 |
| `bitwise_or` | 计算`input`和`other`的按位或。 |
| `bitwise_xor` | 计算`input`和`other`的按位异或。 |
| `bitwise_left_shift` | 计算`input`左移`other`位的算术左移。 |
| `bitwise_right_shift` | 计算`input`右移`other`位的算术右移。 |
| `div` | 将输入`input`的每个元素除以对应的`other`元素。 |
| `divide` | `torch.div()`的别名。 |
| `floor_divide` |  |
| `fmod` | 应用 C++的[std::fmod](https://en.cppreference.com/w/cpp/numeric/math/fmod)逐元素。 |
| `logaddexp` | 输入指数的和的对数。 |
| `logaddexp2` | 以 2 为底的输入指数的和的对数。 |
| `mul` | 将`input`乘以`other`。 |
| `multiply` | `torch.mul()`的别名。 |
| `nextafter` | 返回`input`向`other`方向的下一个浮点值，逐元素。 |
| `remainder` | 逐个计算[Python 的模运算](https://docs.python.org/3/reference/expressions.html#binary-arithmetic-operations)。 |
| `sub` | 从`input`中减去`other`，乘以`alpha`。 |
| `subtract` | `torch.sub()`的别名。 |
| `true_divide` | `torch.div()`的别名，`rounding_mode=None`。 |
| `eq` | 逐元素计算相等性。 |
| `ne` | 逐元素计算 $\text{input} \neq \text{other}$。 |
| `le` | 逐元素计算 $\text{input} \leq \text{other}$。 |
| `ge` | 逐元素计算 $\text{input} \geq \text{other}$。 |
| `greater` | `torch.gt()`的别名。 |
| `greater_equal` | `torch.ge()`的别名。 |
| `gt` | 逐元素计算 $\text{input} > \text{other}$。 |
| `less_equal` | `torch.le()`的别名。 |
| `lt` | 逐元素计算 $\text{input} < \text{other}$。 |
| `less` | `torch.lt()`的别名。 |
| `maximum` | 计算`input`和`other`的逐元素最大值。 |
| `minimum` | 计算`input`和`other`的逐元素最小值。 |
| `fmax` | 计算`input`和`other`的逐元素最大值。 |
| `fmin` | 计算`input`和`other`的逐元素最小值。 |
| `not_equal` | `torch.ne()`的别名。 |

除以下所有可用的就地二元运算符之外：

| `logaddexp` | 输入指数的和的对数。 |
| --- | --- |
| `logaddexp2` | 以 2 为底的输入指数的和的对数。 |
| `equal` | 如果两个张量大小和元素相同，则为`True`，否则为`False`。 |
| `fmin` | 计算`input`和`other`的逐元素最小值。 |
| `minimum` | 计算`input`和`other`的逐元素最小值。 |
| `fmax` | 计算`input`和`other`的逐元素最大值。 |

### 缩减

以下缩减操作可用（支持自动微分）。有关更多信息，请参阅[概述](https://pytorch.org/tutorials/prototype/maskedtensor_overview.html)教程详细介绍了一些缩减的示例，而[高级语义](https://pytorch.org/tutorials/prototype/maskedtensor_advanced_semantics.html)教程则对我们如何决定某些缩减语义进行了更深入的讨论。

| `sum` | 返回`input`张量中所有元素的总和。 |
| --- | --- |
| `mean` | 返回`input`张量中所有元素的平均值。 |
| `amin` | 返回给定维度`dim`中`input`张量的每个切片的最小值。 |
| `amax` | 返回给定维度`dim`中`input`张量的每个切片的最大值。 |
| `argmin` | 返回展平张量的最小值的索引或沿某个维度的最小值的索引。 |
| `argmax` | 返回`input`张量中所有元素的最大值的索引。 |
| `prod` | 返回`input`张量中所有元素的乘积。 |
| `all` | 测试`input`中的所有元素是否都为 True。 |
| `norm` | 返回给定张量的矩阵范数或向量范数。 |
| `var` | 计算由`dim`指定的维度上的方差。 |
| `std` | 计算由`dim`指定的维度上的标准差。 |

### 视图和选择函数

我们还包括了一些视图和选择函数；直观地说，这些运算符将同时应用于数据和掩码，然后将结果包装在`MaskedTensor`中。举个快速的例子，考虑`select()`：

```py
>>> data = torch.arange(12, dtype=torch.float).reshape(3, 4)
>>> data
tensor([[ 0.,  1.,  2.,  3.],
 [ 4.,  5.,  6.,  7.],
 [ 8.,  9., 10., 11.]])
>>> mask = torch.tensor([[True, False, False, True], [False, True, False, False], [True, True, True, True]])
>>> mt = masked_tensor(data, mask)
>>> data.select(0, 1)
tensor([4., 5., 6., 7.])
>>> mask.select(0, 1)
tensor([False,  True, False, False])
>>> mt.select(0, 1)
MaskedTensor(
 [      --,   5.0000,       --,       --]
) 
```

目前支持以下操作：

| `atleast_1d` | 返回每个输入张量的零维度的一维视图。 |
| --- | --- |
| `broadcast_tensors` | 根据广播语义广播给定的张量。 |
| `broadcast_to` | 将`input`广播到形状`shape`。 |
| `cat` | 在给定维度中连接给定序列`seq`的张量。 |
| `chunk` | 尝试将张量分割为指定数量的块。 |
| `column_stack` | 通过水平堆叠`tensors`中的张量创建一个新张量。 |
| `dsplit` | 根据`indices_or_sections`将具有三个或更多维度的`input`张量沿深度方向分割为多个张量。 |
| `flatten` | 通过将其重塑为一维张量来展平`input`。 |
| `hsplit` | 根据`indices_or_sections`在水平方向上将具有一个或多个维度的`input`张量分割成多个张量。 |
| `hstack` | 水平（列方向）顺序堆叠张量。 |
| `kron` | 计算`input`和`other`的 Kronecker 积，用$\otimes$⊗表示。 |
| `meshgrid` | 创建由 attr:tensors 中的 1D 输入指定的坐标网格。 |
| `narrow` | 返回一个`input`张量的缩小版本的新张量。 |
| `ravel` | 返回一个连续的扁平化张量。 |
| `select` | 沿着给定索引在所选维度上切片`input`张量。 |
| `split` | 将张量分割成块。 |
| `t` | 期望`input`是<= 2-D 张量，并转置维度 0 和 1。 |
| `transpose` | 返回一个`input`的转置版本的张量。 |
| `vsplit` | 根据`indices_or_sections`在垂直方向上将具有两个或更多维度的`input`张量分割成多个张量。 |
| `vstack` | 垂直（行方向）顺序堆叠张量。 |
| `Tensor.expand` | 返回一个视图，将`self`张量中的单例维度扩展到更大的尺寸。 |
| `Tensor.expand_as` | 将此张量扩展到与`other`相同的大小。 |
| `Tensor.reshape` | 返回一个与`self`具有相同数据和元素数量但具有指定形状的张量。 |
| `Tensor.reshape_as` | 将此张量重塑为与`other`相同的形状。 |
| `Tensor.view` | 返回一个与`self`张量具有相同数据但形状不同的新张量。 |
