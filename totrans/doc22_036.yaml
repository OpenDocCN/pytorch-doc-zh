- en: Tensor Views
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tensor Views
- en: 原文：[https://pytorch.org/docs/stable/tensor_view.html](https://pytorch.org/docs/stable/tensor_view.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/docs/stable/tensor_view.html](https://pytorch.org/docs/stable/tensor_view.html)
- en: PyTorch allows a tensor to be a `View` of an existing tensor. View tensor shares
    the same underlying data with its base tensor. Supporting `View` avoids explicit
    data copy, thus allows us to do fast and memory efficient reshaping, slicing and
    element-wise operations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 允许一个张量是现有张量的 `View`。视图张量与其基本张量共享相同的基础数据。支持 `View` 避免了显式数据复制，因此允许我们进行快速和内存高效的重塑、切片和逐元素操作。
- en: For example, to get a view of an existing tensor `t`, you can call `t.view(...)`.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要获取现有张量 `t` 的视图，可以调用 `t.view(...)`。
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Since views share underlying data with its base tensor, if you edit the data
    in the view, it will be reflected in the base tensor as well.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于视图与其基本张量共享基础数据，如果在视图中编辑数据，将会反映在基本张量中。
- en: Typically a PyTorch op returns a new tensor as output, e.g. [`add()`](generated/torch.Tensor.add.html#torch.Tensor.add
    "torch.Tensor.add"). But in case of view ops, outputs are views of input tensors
    to avoid unnecessary data copy. No data movement occurs when creating a view,
    view tensor just changes the way it interprets the same data. Taking a view of
    contiguous tensor could potentially produce a non-contiguous tensor. Users should
    pay additional attention as contiguity might have implicit performance impact.
    [`transpose()`](generated/torch.Tensor.transpose.html#torch.Tensor.transpose "torch.Tensor.transpose")
    is a common example.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，PyTorch 操作会返回一个新的张量作为输出，例如 [`add()`](generated/torch.Tensor.add.html#torch.Tensor.add
    "torch.Tensor.add")。但是在视图操作中，输出是输入张量的视图，以避免不必要的数据复制。创建视图时不会发生数据移动，视图张量只是改变了解释相同数据的方式。对连续张量进行视图操作可能会产生非连续张量。用户应额外注意，因为连续性可能会对性能产生隐含影响。[`transpose()`](generated/torch.Tensor.transpose.html#torch.Tensor.transpose
    "torch.Tensor.transpose") 是一个常见示例。
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For reference, here’s a full list of view ops in PyTorch:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作为参考，以下是 PyTorch 中所有视图操作的完整列表：
- en: Basic slicing and indexing op, e.g. `tensor[0, 2:, 1:7:2]` returns a view of
    base `tensor`, see note below.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本的切片和索引操作，例如 `tensor[0, 2:, 1:7:2]` 返回基本 `tensor` 的视图，请参见下面的说明。
- en: '[`adjoint()`](generated/torch.Tensor.adjoint.html#torch.Tensor.adjoint "torch.Tensor.adjoint")'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`adjoint()`](generated/torch.Tensor.adjoint.html#torch.Tensor.adjoint "torch.Tensor.adjoint")'
- en: '[`as_strided()`](generated/torch.Tensor.as_strided.html#torch.Tensor.as_strided
    "torch.Tensor.as_strided")'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`as_strided()`](generated/torch.Tensor.as_strided.html#torch.Tensor.as_strided
    "torch.Tensor.as_strided")'
- en: '[`detach()`](generated/torch.Tensor.detach.html#torch.Tensor.detach "torch.Tensor.detach")'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`detach()`](generated/torch.Tensor.detach.html#torch.Tensor.detach "torch.Tensor.detach")'
- en: '[`diagonal()`](generated/torch.Tensor.diagonal.html#torch.Tensor.diagonal "torch.Tensor.diagonal")'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`diagonal()`](generated/torch.Tensor.diagonal.html#torch.Tensor.diagonal "torch.Tensor.diagonal")'
- en: '[`expand()`](generated/torch.Tensor.expand.html#torch.Tensor.expand "torch.Tensor.expand")'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`expand()`](generated/torch.Tensor.expand.html#torch.Tensor.expand "torch.Tensor.expand")'
- en: '[`expand_as()`](generated/torch.Tensor.expand_as.html#torch.Tensor.expand_as
    "torch.Tensor.expand_as")'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`expand_as()`](generated/torch.Tensor.expand_as.html#torch.Tensor.expand_as
    "torch.Tensor.expand_as")'
- en: '[`movedim()`](generated/torch.Tensor.movedim.html#torch.Tensor.movedim "torch.Tensor.movedim")'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`movedim()`](generated/torch.Tensor.movedim.html#torch.Tensor.movedim "torch.Tensor.movedim")'
- en: '[`narrow()`](generated/torch.Tensor.narrow.html#torch.Tensor.narrow "torch.Tensor.narrow")'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`narrow()`](generated/torch.Tensor.narrow.html#torch.Tensor.narrow "torch.Tensor.narrow")'
- en: '[`permute()`](generated/torch.Tensor.permute.html#torch.Tensor.permute "torch.Tensor.permute")'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`permute()`](generated/torch.Tensor.permute.html#torch.Tensor.permute "torch.Tensor.permute")'
- en: '[`select()`](generated/torch.Tensor.select.html#torch.Tensor.select "torch.Tensor.select")'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`select()`](generated/torch.Tensor.select.html#torch.Tensor.select "torch.Tensor.select")'
- en: '[`squeeze()`](generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze "torch.Tensor.squeeze")'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`squeeze()`](generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze "torch.Tensor.squeeze")'
- en: '[`transpose()`](generated/torch.Tensor.transpose.html#torch.Tensor.transpose
    "torch.Tensor.transpose")'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`transpose()`](generated/torch.Tensor.transpose.html#torch.Tensor.transpose
    "torch.Tensor.transpose")'
- en: '[`t()`](generated/torch.Tensor.t.html#torch.Tensor.t "torch.Tensor.t")'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`t()`](generated/torch.Tensor.t.html#torch.Tensor.t "torch.Tensor.t")'
- en: '[`T`](tensors.html#torch.Tensor.T "torch.Tensor.T")'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`T`](tensors.html#torch.Tensor.T "torch.Tensor.T")'
- en: '[`H`](tensors.html#torch.Tensor.H "torch.Tensor.H")'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`H`](tensors.html#torch.Tensor.H "torch.Tensor.H")'
- en: '[`mT`](tensors.html#torch.Tensor.mT "torch.Tensor.mT")'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`mT`](tensors.html#torch.Tensor.mT "torch.Tensor.mT")'
- en: '[`mH`](tensors.html#torch.Tensor.mH "torch.Tensor.mH")'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`mH`](tensors.html#torch.Tensor.mH "torch.Tensor.mH")'
- en: '[`real`](generated/torch.Tensor.real.html#torch.Tensor.real "torch.Tensor.real")'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`real`](generated/torch.Tensor.real.html#torch.Tensor.real "torch.Tensor.real")'
- en: '[`imag`](generated/torch.Tensor.imag.html#torch.Tensor.imag "torch.Tensor.imag")'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`imag`](generated/torch.Tensor.imag.html#torch.Tensor.imag "torch.Tensor.imag")'
- en: '`view_as_real()`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`view_as_real()`'
- en: '[`unflatten()`](generated/torch.Tensor.unflatten.html#torch.Tensor.unflatten
    "torch.Tensor.unflatten")'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`unflatten()`](generated/torch.Tensor.unflatten.html#torch.Tensor.unflatten
    "torch.Tensor.unflatten")'
- en: '[`unfold()`](generated/torch.Tensor.unfold.html#torch.Tensor.unfold "torch.Tensor.unfold")'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`unfold()`](generated/torch.Tensor.unfold.html#torch.Tensor.unfold "torch.Tensor.unfold")'
- en: '[`unsqueeze()`](generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze
    "torch.Tensor.unsqueeze")'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`unsqueeze()`](generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze
    "torch.Tensor.unsqueeze")'
- en: '[`view()`](generated/torch.Tensor.view.html#torch.Tensor.view "torch.Tensor.view")'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`view()`](generated/torch.Tensor.view.html#torch.Tensor.view "torch.Tensor.view")'
- en: '[`view_as()`](generated/torch.Tensor.view_as.html#torch.Tensor.view_as "torch.Tensor.view_as")'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`view_as()`](generated/torch.Tensor.view_as.html#torch.Tensor.view_as "torch.Tensor.view_as")'
- en: '[`unbind()`](generated/torch.Tensor.unbind.html#torch.Tensor.unbind "torch.Tensor.unbind")'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`unbind()`](generated/torch.Tensor.unbind.html#torch.Tensor.unbind "torch.Tensor.unbind")'
- en: '[`split()`](generated/torch.Tensor.split.html#torch.Tensor.split "torch.Tensor.split")'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`split()`](generated/torch.Tensor.split.html#torch.Tensor.split "torch.Tensor.split")'
- en: '[`hsplit()`](generated/torch.Tensor.hsplit.html#torch.Tensor.hsplit "torch.Tensor.hsplit")'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`hsplit()`](generated/torch.Tensor.hsplit.html#torch.Tensor.hsplit "torch.Tensor.hsplit")'
- en: '[`vsplit()`](generated/torch.Tensor.vsplit.html#torch.Tensor.vsplit "torch.Tensor.vsplit")'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`vsplit()`](generated/torch.Tensor.vsplit.html#torch.Tensor.vsplit "torch.Tensor.vsplit")'
- en: '[`tensor_split()`](generated/torch.Tensor.tensor_split.html#torch.Tensor.tensor_split
    "torch.Tensor.tensor_split")'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`tensor_split()`](generated/torch.Tensor.tensor_split.html#torch.Tensor.tensor_split
    "torch.Tensor.tensor_split")'
- en: '`split_with_sizes()`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split_with_sizes()`'
- en: '[`swapaxes()`](generated/torch.Tensor.swapaxes.html#torch.Tensor.swapaxes "torch.Tensor.swapaxes")'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`swapaxes()`](generated/torch.Tensor.swapaxes.html#torch.Tensor.swapaxes "torch.Tensor.swapaxes")'
- en: '[`swapdims()`](generated/torch.Tensor.swapdims.html#torch.Tensor.swapdims "torch.Tensor.swapdims")'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`swapdims()`](generated/torch.Tensor.swapdims.html#torch.Tensor.swapdims "torch.Tensor.swapdims")'
- en: '[`chunk()`](generated/torch.Tensor.chunk.html#torch.Tensor.chunk "torch.Tensor.chunk")'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`chunk()`](generated/torch.Tensor.chunk.html#torch.Tensor.chunk "torch.Tensor.chunk")'
- en: '[`indices()`](generated/torch.Tensor.indices.html#torch.Tensor.indices "torch.Tensor.indices")
    (sparse tensor only)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`indices()`](generated/torch.Tensor.indices.html#torch.Tensor.indices "torch.Tensor.indices")（仅适用于稀疏张量）'
- en: '[`values()`](generated/torch.Tensor.values.html#torch.Tensor.values "torch.Tensor.values")
    (sparse tensor only)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`values()`](generated/torch.Tensor.values.html#torch.Tensor.values "torch.Tensor.values")（仅适用于稀疏张量）'
- en: Note
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When accessing the contents of a tensor via indexing, PyTorch follows Numpy
    behaviors that basic indexing returns views, while advanced indexing returns a
    copy. Assignment via either basic or advanced indexing is in-place. See more examples
    in [Numpy indexing documentation](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过索引访问张量的内容时，PyTorch遵循Numpy的行为，基本索引返回视图，而高级索引返回副本。通过基本或高级索引进行赋值是原地的。在[Numpy索引文档](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)中查看更多示例。
- en: 'It’s also worth mentioning a few ops with special behaviors:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得一提的是一些具有特殊行为的操作：
- en: '[`reshape()`](generated/torch.Tensor.reshape.html#torch.Tensor.reshape "torch.Tensor.reshape"),
    [`reshape_as()`](generated/torch.Tensor.reshape_as.html#torch.Tensor.reshape_as
    "torch.Tensor.reshape_as") and [`flatten()`](generated/torch.Tensor.flatten.html#torch.Tensor.flatten
    "torch.Tensor.flatten") can return either a view or new tensor, user code shouldn’t
    rely on whether it’s view or not.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`reshape()`](generated/torch.Tensor.reshape.html#torch.Tensor.reshape "torch.Tensor.reshape")、[`reshape_as()`](generated/torch.Tensor.reshape_as.html#torch.Tensor.reshape_as
    "torch.Tensor.reshape_as")和[`flatten()`](generated/torch.Tensor.flatten.html#torch.Tensor.flatten
    "torch.Tensor.flatten")可能返回视图或新张量，用户代码不应该依赖于它是视图还是不是。'
- en: '[`contiguous()`](generated/torch.Tensor.contiguous.html#torch.Tensor.contiguous
    "torch.Tensor.contiguous") returns **itself** if input tensor is already contiguous,
    otherwise it returns a new contiguous tensor by copying data.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`contiguous()`](generated/torch.Tensor.contiguous.html#torch.Tensor.contiguous
    "torch.Tensor.contiguous")如果输入张量已经是连续的，则返回**自身**，否则通过复制数据返回一个新的连续张量。'
- en: For a more detailed walk-through of PyTorch internal implementation, please
    refer to [ezyang’s blogpost about PyTorch Internals](http://blog.ezyang.com/2019/05/pytorch-internals/).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有关PyTorch内部实现的更详细介绍，请参考[ezyang关于PyTorch内部的博文](http://blog.ezyang.com/2019/05/pytorch-internals/)。
