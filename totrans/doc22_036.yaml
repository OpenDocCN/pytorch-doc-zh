- en: Tensor Views
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/docs/stable/tensor_view.html](https://pytorch.org/docs/stable/tensor_view.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PyTorch allows a tensor to be a `View` of an existing tensor. View tensor shares
    the same underlying data with its base tensor. Supporting `View` avoids explicit
    data copy, thus allows us to do fast and memory efficient reshaping, slicing and
    element-wise operations.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to get a view of an existing tensor `t`, you can call `t.view(...)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Since views share underlying data with its base tensor, if you edit the data
    in the view, it will be reflected in the base tensor as well.
  prefs: []
  type: TYPE_NORMAL
- en: Typically a PyTorch op returns a new tensor as output, e.g. [`add()`](generated/torch.Tensor.add.html#torch.Tensor.add
    "torch.Tensor.add"). But in case of view ops, outputs are views of input tensors
    to avoid unnecessary data copy. No data movement occurs when creating a view,
    view tensor just changes the way it interprets the same data. Taking a view of
    contiguous tensor could potentially produce a non-contiguous tensor. Users should
    pay additional attention as contiguity might have implicit performance impact.
    [`transpose()`](generated/torch.Tensor.transpose.html#torch.Tensor.transpose "torch.Tensor.transpose")
    is a common example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For reference, here’s a full list of view ops in PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic slicing and indexing op, e.g. `tensor[0, 2:, 1:7:2]` returns a view of
    base `tensor`, see note below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`adjoint()`](generated/torch.Tensor.adjoint.html#torch.Tensor.adjoint "torch.Tensor.adjoint")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`as_strided()`](generated/torch.Tensor.as_strided.html#torch.Tensor.as_strided
    "torch.Tensor.as_strided")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`detach()`](generated/torch.Tensor.detach.html#torch.Tensor.detach "torch.Tensor.detach")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`diagonal()`](generated/torch.Tensor.diagonal.html#torch.Tensor.diagonal "torch.Tensor.diagonal")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`expand()`](generated/torch.Tensor.expand.html#torch.Tensor.expand "torch.Tensor.expand")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`expand_as()`](generated/torch.Tensor.expand_as.html#torch.Tensor.expand_as
    "torch.Tensor.expand_as")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`movedim()`](generated/torch.Tensor.movedim.html#torch.Tensor.movedim "torch.Tensor.movedim")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`narrow()`](generated/torch.Tensor.narrow.html#torch.Tensor.narrow "torch.Tensor.narrow")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`permute()`](generated/torch.Tensor.permute.html#torch.Tensor.permute "torch.Tensor.permute")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`select()`](generated/torch.Tensor.select.html#torch.Tensor.select "torch.Tensor.select")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`squeeze()`](generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze "torch.Tensor.squeeze")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`transpose()`](generated/torch.Tensor.transpose.html#torch.Tensor.transpose
    "torch.Tensor.transpose")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`t()`](generated/torch.Tensor.t.html#torch.Tensor.t "torch.Tensor.t")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`T`](tensors.html#torch.Tensor.T "torch.Tensor.T")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`H`](tensors.html#torch.Tensor.H "torch.Tensor.H")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`mT`](tensors.html#torch.Tensor.mT "torch.Tensor.mT")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`mH`](tensors.html#torch.Tensor.mH "torch.Tensor.mH")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`real`](generated/torch.Tensor.real.html#torch.Tensor.real "torch.Tensor.real")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`imag`](generated/torch.Tensor.imag.html#torch.Tensor.imag "torch.Tensor.imag")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`view_as_real()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`unflatten()`](generated/torch.Tensor.unflatten.html#torch.Tensor.unflatten
    "torch.Tensor.unflatten")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`unfold()`](generated/torch.Tensor.unfold.html#torch.Tensor.unfold "torch.Tensor.unfold")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`unsqueeze()`](generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze
    "torch.Tensor.unsqueeze")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`view()`](generated/torch.Tensor.view.html#torch.Tensor.view "torch.Tensor.view")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`view_as()`](generated/torch.Tensor.view_as.html#torch.Tensor.view_as "torch.Tensor.view_as")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`unbind()`](generated/torch.Tensor.unbind.html#torch.Tensor.unbind "torch.Tensor.unbind")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`split()`](generated/torch.Tensor.split.html#torch.Tensor.split "torch.Tensor.split")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`hsplit()`](generated/torch.Tensor.hsplit.html#torch.Tensor.hsplit "torch.Tensor.hsplit")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`vsplit()`](generated/torch.Tensor.vsplit.html#torch.Tensor.vsplit "torch.Tensor.vsplit")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`tensor_split()`](generated/torch.Tensor.tensor_split.html#torch.Tensor.tensor_split
    "torch.Tensor.tensor_split")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`split_with_sizes()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`swapaxes()`](generated/torch.Tensor.swapaxes.html#torch.Tensor.swapaxes "torch.Tensor.swapaxes")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`swapdims()`](generated/torch.Tensor.swapdims.html#torch.Tensor.swapdims "torch.Tensor.swapdims")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`chunk()`](generated/torch.Tensor.chunk.html#torch.Tensor.chunk "torch.Tensor.chunk")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`indices()`](generated/torch.Tensor.indices.html#torch.Tensor.indices "torch.Tensor.indices")
    (sparse tensor only)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`values()`](generated/torch.Tensor.values.html#torch.Tensor.values "torch.Tensor.values")
    (sparse tensor only)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When accessing the contents of a tensor via indexing, PyTorch follows Numpy
    behaviors that basic indexing returns views, while advanced indexing returns a
    copy. Assignment via either basic or advanced indexing is in-place. See more examples
    in [Numpy indexing documentation](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s also worth mentioning a few ops with special behaviors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[`reshape()`](generated/torch.Tensor.reshape.html#torch.Tensor.reshape "torch.Tensor.reshape"),
    [`reshape_as()`](generated/torch.Tensor.reshape_as.html#torch.Tensor.reshape_as
    "torch.Tensor.reshape_as") and [`flatten()`](generated/torch.Tensor.flatten.html#torch.Tensor.flatten
    "torch.Tensor.flatten") can return either a view or new tensor, user code shouldn’t
    rely on whether it’s view or not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`contiguous()`](generated/torch.Tensor.contiguous.html#torch.Tensor.contiguous
    "torch.Tensor.contiguous") returns **itself** if input tensor is already contiguous,
    otherwise it returns a new contiguous tensor by copying data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a more detailed walk-through of PyTorch internal implementation, please
    refer to [ezyang’s blogpost about PyTorch Internals](http://blog.ezyang.com/2019/05/pytorch-internals/).
  prefs: []
  type: TYPE_NORMAL
