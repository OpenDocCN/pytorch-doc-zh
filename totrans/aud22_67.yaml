- en: torchaudio.prototype.models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/audio/stable/prototype.models.html](https://pytorch.org/audio/stable/prototype.models.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The `torchaudio.prototype.models` subpackage contains definitions of models
    for addressing common audio tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For models with pre-trained parameters, please refer to [`torchaudio.prototype.pipelines`](prototype.pipelines.html#module-torchaudio.prototype.pipelines
    "torchaudio.prototype.pipelines") module.
  prefs: []
  type: TYPE_NORMAL
- en: Model defintions are responsible for constructing computation graphs and executing
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Some models have complex structure and variations. For such models, factory
    functions are provided.
  prefs: []
  type: TYPE_NORMAL
- en: '| [`ConformerWav2Vec2PretrainModel`](generated/torchaudio.prototype.models.ConformerWav2Vec2PretrainModel.html#torchaudio.prototype.models.ConformerWav2Vec2PretrainModel
    "torchaudio.prototype.models.ConformerWav2Vec2PretrainModel") | Conformer Wav2Vec2
    pre-train model for training from scratch. |'
  prefs: []
  type: TYPE_TB
- en: '| [`ConvEmformer`](generated/torchaudio.prototype.models.ConvEmformer.html#torchaudio.prototype.models.ConvEmformer
    "torchaudio.prototype.models.ConvEmformer") | Implements the convolution-augmented
    streaming transformer architecture introduced in *Streaming Transformer Transducer
    based Speech Recognition Using Non-Causal Convolution* [[Shi *et al.*, 2022](references.html#id31
    "Yangyang Shi, Chunyang Wu, Dilin Wang, Alex Xiao, Jay Mahadeokar, Xiaohui Zhang,
    Chunxi Liu, Ke Li, Yuan Shangguan, Varun Nagaraja, Ozlem Kalinli, and Mike Seltzer.
    Streaming transformer transducer based speech recognition using non-causal convolution.
    In ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP), volume, 8277-8281\. 2022\. doi:10.1109/ICASSP43922.2022.9747706.")].
    |'
  prefs: []
  type: TYPE_TB
- en: '| [`HiFiGANVocoder`](generated/torchaudio.prototype.models.HiFiGANVocoder.html#torchaudio.prototype.models.HiFiGANVocoder
    "torchaudio.prototype.models.HiFiGANVocoder") | Generator part of *HiFi GAN* [[Kong
    *et al.*, 2020](references.html#id57 "Jungil Kong, Jaehyeon Kim, and Jaekyoung
    Bae. Hifi-gan: generative adversarial networks for efficient and high fidelity
    speech synthesis. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H.
    Lin, editors, Advances in Neural Information Processing Systems, volume 33, 17022–17033\.
    Curran Associates, Inc., 2020\. URL: https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf.")].
    |'
  prefs: []
  type: TYPE_TB
- en: Prototype Factory Functions of Beta Models[](#prototype-factory-functions-of-beta-models
    "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some model definitions are in beta, but there are new factory functions that
    are still in prototype. Please check “Prototype Factory Functions” section in
    each model.
  prefs: []
  type: TYPE_NORMAL
- en: '| [`Wav2Vec2Model`](generated/torchaudio.models.Wav2Vec2Model.html#torchaudio.models.Wav2Vec2Model
    "torchaudio.models.Wav2Vec2Model") | Acoustic model used in *wav2vec 2.0* [[Baevski
    *et al.*, 2020](references.html#id15 "Alexei Baevski, Henry Zhou, Abdelrahman
    Mohamed, and Michael Auli. Wav2vec 2.0: a framework for self-supervised learning
    of speech representations. 2020\. arXiv:2006.11477.")]. |'
  prefs: []
  type: TYPE_TB
- en: '| [`RNNT`](generated/torchaudio.models.RNNT.html#torchaudio.models.RNNT "torchaudio.models.RNNT")
    | Recurrent neural network transducer (RNN-T) model. |'
  prefs: []
  type: TYPE_TB
