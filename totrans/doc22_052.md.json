["```py\ntorch.distributed.checkpoint.load(state_dict, storage_reader, *, process_group=None, coordinator_rank=0, no_dist=False, planner=None)\u00b6\n```", "```py\n>>> my_model = MyModule()\n>>> optimizer = Adagrad(my_model.parameters())\n>>> model_state_dict = my_model.state_dict()\n>>> fs_storage_reader = torch.distributed.checkpoint.FileSystemReader(\"/checkpoint/1\") \n```", "```py\n>>> torch.distributed.checkpoint.load_state_dict(\n>>>     state_dict=model_state_dict,\n>>>     storage_reader=fs_storage_reader,\n>>> ) \n```", "```py\n>>> # module.load_state_dict() function might have customized steps\n>>> # to flush the state_dict, must call it to\n>>> # ensure correct behavior.\n>>> my_model.load_state_dict(model_state_dict) \n```", "```py\ntorch.distributed.checkpoint.save(state_dict, storage_writer, *, process_group=None, coordinator_rank=0, no_dist=False, planner=None)\u00b6\n```", "```py\n>>> my_model = MyModule() \n```", "```py\n>>> model_state_dict = my_model.state_dict() \n```", "```py\n>>> fs_storage_writer = torch.distributed.checkpoint.FileSystemWriter(\"/checkpoint/1\")\n>>> torch.distributed.checkpoint.save_state_dict(\n>>>     state_dict=model_state_dict,\n>>>     storage_writer=fs_storage_writer,\n>>> ) \n```", "```py\ntorch.distributed.checkpoint.load_state_dict(state_dict, storage_reader, process_group=None, coordinator_rank=0, no_dist=False, planner=None)\u00b6\n```", "```py\ntorch.distributed.checkpoint.save_state_dict(state_dict, storage_writer, process_group=None, coordinator_rank=0, no_dist=False, planner=None)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.stateful.Stateful(*args, **kwargs)\u00b6\n```", "```py\nload_state_dict(state_dict)\u00b6\n```", "```py\nstate_dict()\u00b6\n```", "```py\nclass torch.distributed.checkpoint.StorageReader\u00b6\n```", "```py\nabstract prepare_global_plan(plans)\u00b6\n```", "```py\nabstract prepare_local_plan(plan)\u00b6\n```", "```py\nabstract read_data(plan, planner)\u00b6\n```", "```py\nabstract read_metadata()\u00b6\n```", "```py\nabstract set_up_storage_reader(metadata, is_coordinator)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.StorageWriter\u00b6\n```", "```py\nabstract finish(metadata, results)\u00b6\n```", "```py\nabstract prepare_global_plan(plans)\u00b6\n```", "```py\nabstract prepare_local_plan(plan)\u00b6\n```", "```py\nabstract set_up_storage_writer(is_coordinator)\u00b6\n```", "```py\nabstract write_data(plan, planner)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.LoadPlanner\u00b6\n```", "```py\n>>> class RenamePlanner(DefaultLoadPlanner):\n>>>     def set_up_planner(self, state_dict, metadata, is_coordinator):\n>>>         self.original_state_dict = state_dict\n>>>         state_dict = {\"foo_\" + k: v for k, v in state_dict.items()}\n>>>\n>>>         if self.flatten_sharded_tensors:\n>>>             state_dict = _flatten_sharded_tensors(state_dict)\n>>>\n>>>         if self.flatten_state_dict:\n>>>             state_dict, self.mappings = flatten_state_dict(state_dict)\n>>>\n>>>         self.state_dict = state_dict\n>>>         self.metadata = metadata\n>>>         self.is_coordinator = is_coordinator\n>>>\n>>>     def load_bytes(self, read_item, value):\n>>>         # Remove the \"foo_\" prefix\n>>>         self.original_state_dict[read_item.dest_index.fqn[4:]] = torch.load(value) \n```", "```py\n>>> class MetaModelMaterialize(DefaultSavePlanner):\n>>>     def resolve_tensor(self, read_item):\n>>>         tensor = super().resolve_tensor(read_item)\n>>>         return torch.empty_like(tensor, device=\"cpu\")\n>>>\n>>>     def commit_tensor(self, read_item, tensor):\n>>>         self.state_dict[read_item.dest_index.fqn] = tensor \n```", "```py\nabstract commit_tensor(read_item, tensor)\u00b6\n```", "```py\nabstract create_global_plan(global_plan)\u00b6\n```", "```py\nabstract create_local_plan()\u00b6\n```", "```py\nabstract finish_plan(central_plan)\u00b6\n```", "```py\nabstract load_bytes(read_item, value)\u00b6\n```", "```py\nabstract resolve_tensor(read_item)\u00b6\n```", "```py\nabstract set_up_planner(state_dict, metadata, is_coordinator)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.LoadPlan(items: List[torch.distributed.checkpoint.planner.ReadItem], storage_data: Any = None, planner_data: Any = None)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.ReadItem(type: torch.distributed.checkpoint.planner.LoadItemType, dest_index: torch.distributed.checkpoint.metadata.MetadataIndex, dest_offsets: torch.Size, storage_index: torch.distributed.checkpoint.metadata.MetadataIndex, storage_offsets: torch.Size, lengths: torch.Size)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.SavePlanner\u00b6\n```", "```py\n>>> class RenamePlanner(DefaultSavePlanner):\n>>>     def set_up_planner(self, state_dict, is_coordinator):\n>>>         # prefix all keys with `foo_``\n>>>         super().set_up_planner({\"foo_\" + k: v for k, v in state_dict.items()}, is_coordinator) \n```", "```py\n>>> class FP16Planner(DefaultSavePlanner):\n>>>     def create_local_plan(self):\n>>>         plan = super().create_local_plan()\n>>>         for p in plan:\n>>>             if p.tensor_data is not None:\n>>>                 p.tensor_data.properties.dtype = torch.float16\n>>>         return plan\n>>>\n>>>     def resolve_data(self, write_item):\n>>>         item = super().resolve_data(write_item)\n>>>         return item if write_item.type == WriteItemType.BYTE_IO else item.to(torch.float16) \n```", "```py\n>>> from itertools import islice\n>>> from dataclasses import replace\n>>> class DDPLoadBalancingPlanner(DefaultSavePlanner):\n>>>     # This uses the default local plan behavior of having all non-sharded writes in rank 0\n>>>     # This sample doesn't handle ShardedTensors\n>>>     def create_global_plan(self, all_plans):\n>>>         def chunk(it, size):\n>>>             it = iter(it)\n>>>         return list(iter(lambda: tuple(islice(it, size)), ()))\n>>>         all_plans = [\n>>>             replace(plan, items=items) for plan, items in\n>>>                 zip(all_plans, chunk(all_plans[0].items, len(all_plans)))\n>>>         ]\n>>>         return super().create_global_plan(all_plans) \n```", "```py\n>>> class SaveExtraDataPlanner(DefaultSavePlanner):\n>>>     def create_local_plan(self) -> SavePlan:\n>>>         plan = super().create_local_plan()\n>>>         return replace(plan, planner_data=\"per-rank-data\")\n>>>\n>>>     def create_global_plan(self, all_plans: List[SavePlan]) -> Tuple[List[SavePlan], Metadata]:\n>>>         global_plan, metadata = super().create_global_plan(all_plans)\n>>>         merged_data = [p.planner_data for p in global_plan]\n>>>         metadata = replace(metadata, planner_data=merged_data)\n>>>         return global_plan, metadata \n```", "```py\nabstract create_global_plan(all_plans)\u00b6\n```", "```py\nabstract create_local_plan()\u00b6\n```", "```py\nabstract finish_plan(new_plan)\u00b6\n```", "```py\nabstract resolve_data(write_item)\u00b6\n```", "```py\nabstract set_up_planner(state_dict, is_coordinator)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.SavePlan(items: List[torch.distributed.checkpoint.planner.WriteItem], storage_data: Any = None, planner_data: Any = None)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.WriteItem(index: torch.distributed.checkpoint.metadata.MetadataIndex, type: torch.distributed.checkpoint.planner.WriteItemType, tensor_data: Union[torch.distributed.checkpoint.planner.TensorWriteData, NoneType] = None)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.FileSystemReader(path)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.FileSystemWriter(path, single_file_per_rank=True, sync_files=True, thread_count=1, per_thread_copy_ahead=10000000)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.DefaultSavePlanner(flatten_state_dict=True, flatten_sharded_tensors=True, dedup_replicated_tensors=True)\u00b6\n```", "```py\nlookup_object(index)\u00b6\n```", "```py\ntransform_object(write_item, object)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.DefaultLoadPlanner(flatten_state_dict=True, flatten_sharded_tensors=True)\u00b6\n```", "```py\nlookup_tensor(index)\u00b6\n```", "```py\ntransform_tensor(read_item, tensor)\u00b6\n```", "```py\ntorch.distributed.checkpoint.state_dict.get_state_dict(model, optimizers, *, submodules=None, options=None)\u00b6\n```", "```py\ntorch.distributed.checkpoint.state_dict.get_model_state_dict(model, *, submodules=None, options=None)\u00b6\n```", "```py\ntorch.distributed.checkpoint.state_dict.get_optimizer_state_dict(model, optimizers, *, submodules=None, options=None)\u00b6\n```", "```py\ntorch.distributed.checkpoint.state_dict.set_state_dict(model, optimizers, *, model_state_dict, optim_state_dict, options=None)\u00b6\n```", "```py\ntorch.distributed.checkpoint.state_dict.set_model_state_dict(model, model_state_dict, *, options=None)\u00b6\n```", "```py\ntorch.distributed.checkpoint.state_dict.set_optimizer_state_dict(model, optimizers, *, optim_state_dict, options=None)\u00b6\n```", "```py\nclass torch.distributed.checkpoint.state_dict.StateDictOptions(full_state_dict=False, cpu_offload=False, ignore_frozen_params=False, keep_submodule_prefixes=True, strict=True)\u00b6\n```"]