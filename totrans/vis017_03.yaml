- en: TVTensors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/vision/stable/tv_tensors.html](https://pytorch.org/vision/stable/tv_tensors.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: TVTensors are [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor
    "(in PyTorch v2.2)") subclasses which the v2 [transforms](transforms.html#transforms)
    use under the hood to dispatch their inputs to the appropriate lower-level kernels.
    Most users do not need to manipulate TVTensors directly.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to [Getting started with transforms v2](auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py)
    for an introduction to TVTensors, or [TVTensors FAQ](auto_examples/transforms/plot_tv_tensors.html#sphx-glr-auto-examples-transforms-plot-tv-tensors-py)
    for more advanced info.
  prefs: []
  type: TYPE_NORMAL
- en: '| [`Image`](generated/torchvision.tv_tensors.Image.html#torchvision.tv_tensors.Image
    "torchvision.tv_tensors.Image")(data, *[, dtype, device, requires_grad]) | [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor
    "(in PyTorch v2.2)") subclass for images. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Video`](generated/torchvision.tv_tensors.Video.html#torchvision.tv_tensors.Video
    "torchvision.tv_tensors.Video")(data, *[, dtype, device, requires_grad]) | [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor
    "(in PyTorch v2.2)") subclass for videos. |'
  prefs: []
  type: TYPE_TB
- en: '| [`BoundingBoxFormat`](generated/torchvision.tv_tensors.BoundingBoxFormat.html#torchvision.tv_tensors.BoundingBoxFormat
    "torchvision.tv_tensors.BoundingBoxFormat")(value) | Coordinate format of a bounding
    box. |'
  prefs: []
  type: TYPE_TB
- en: '| [`BoundingBoxes`](generated/torchvision.tv_tensors.BoundingBoxes.html#torchvision.tv_tensors.BoundingBoxes
    "torchvision.tv_tensors.BoundingBoxes")(data, *, format, canvas_size) | [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor
    "(in PyTorch v2.2)") subclass for bounding boxes. |'
  prefs: []
  type: TYPE_TB
- en: '| [`Mask`](generated/torchvision.tv_tensors.Mask.html#torchvision.tv_tensors.Mask
    "torchvision.tv_tensors.Mask")(data, *[, dtype, device, requires_grad]) | [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor
    "(in PyTorch v2.2)") subclass for segmentation and detection masks. |'
  prefs: []
  type: TYPE_TB
- en: '| [`TVTensor`](generated/torchvision.tv_tensors.TVTensor.html#torchvision.tv_tensors.TVTensor
    "torchvision.tv_tensors.TVTensor") | Base class for all TVTensors. |'
  prefs: []
  type: TYPE_TB
- en: '| [`set_return_type`](generated/torchvision.tv_tensors.set_return_type.html#torchvision.tv_tensors.set_return_type
    "torchvision.tv_tensors.set_return_type")(return_type) | Set the return type of
    torch operations on [`TVTensor`](generated/torchvision.tv_tensors.TVTensor.html#torchvision.tv_tensors.TVTensor
    "torchvision.tv_tensors.TVTensor"). |'
  prefs: []
  type: TYPE_TB
- en: '| [`wrap`](generated/torchvision.tv_tensors.wrap.html#torchvision.tv_tensors.wrap
    "torchvision.tv_tensors.wrap")(wrappee, *, like, **kwargs) | Convert a [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor
    "(in PyTorch v2.2)") (`wrappee`) into the same [`TVTensor`](generated/torchvision.tv_tensors.TVTensor.html#torchvision.tv_tensors.TVTensor
    "torchvision.tv_tensors.TVTensor") subclass as `like`. |'
  prefs: []
  type: TYPE_TB
