["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n[torch.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed \"torch.manual_seed\")(0)\n\n# Here's a simple MLP\nclass SimpleMLP([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self):\n        super([SimpleMLP](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(784, 128)\n        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(128, 128)\n        self.fc3 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(128, 10)\n\n    def forward(self, x):\n        x = x.flatten(1)\n        x = self.fc1(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = self.fc2(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = self.fc3(x)\n        return x \n```", "```py\ndevice = 'cuda'\nnum_models = 10\n\n[data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.randn](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn \"torch.randn\")(100, 64, 1, 28, 28, device=device)\n[targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.randint](https://pytorch.org/docs/stable/generated/torch.randint.html#torch.randint \"torch.randint\")(10, (6400,), device=device)\n\nmodels = [[SimpleMLP](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")().to(device) for _ in range(num_models)] \n```", "```py\n[minibatches](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[:num_models]\npredictions_diff_minibatch_loop = [model([minibatch](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) for model, [minibatch](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") in zip(models, [minibatches](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))] \n```", "```py\n[minibatch](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0]\npredictions2 = [model([minibatch](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) for model in models] \n```", "```py\nfrom torch.func import [stack_module_state](https://pytorch.org/docs/stable/generated/torch.func.stack_module_state.html#torch.func.stack_module_state \"torch.func.stack_module_state\")\n\nparams, buffers = [stack_module_state](https://pytorch.org/docs/stable/generated/torch.func.stack_module_state.html#torch.func.stack_module_state \"torch.func.stack_module_state\")(models) \n```", "```py\nfrom torch.func import [functional_call](https://pytorch.org/docs/stable/generated/torch.func.functional_call.html#torch.func.functional_call \"torch.func.functional_call\")\nimport copy\n\n# Construct a \"stateless\" version of one of the models. It is \"stateless\" in\n# the sense that the parameters are meta Tensors and do not have storage.\nbase_model = copy.deepcopy(models[0])\nbase_model = [base_model.to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to \"torch.nn.Module.to\")('meta')\n\ndef fmodel(params, buffers, x):\n    return [functional_call](https://pytorch.org/docs/stable/generated/torch.func.functional_call.html#torch.func.functional_call \"torch.func.functional_call\")(base_model, (params, buffers), (x,)) \n```", "```py\nprint([p.size(0) for p in params.values()]) # show the leading 'num_models' dimension\n\nassert [minibatches](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").shape == (num_models, 64, 1, 28, 28) # verify minibatch has leading dimension of size 'num_models'\n\nfrom torch import [vmap](https://pytorch.org/docs/stable/generated/torch.vmap.html#torch.vmap \"torch.vmap\")\n\n[predictions1_vmap](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [vmap](https://pytorch.org/docs/stable/generated/torch.vmap.html#torch.vmap \"torch.vmap\")(fmodel)(params, buffers, [minibatches](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\n# verify the ``vmap`` predictions match the\nassert [torch.allclose](https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose \"torch.allclose\")([predictions1_vmap](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack \"torch.stack\")(predictions_diff_minibatch_loop), atol=1e-3, rtol=1e-5) \n```", "```py\n[10, 10, 10, 10, 10, 10] \n```", "```py\n[predictions2_vmap](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [vmap](https://pytorch.org/docs/stable/generated/torch.vmap.html#torch.vmap \"torch.vmap\")(fmodel, in_dims=(0, 0, None))(params, buffers, [minibatch](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\nassert [torch.allclose](https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose \"torch.allclose\")([predictions2_vmap](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack \"torch.stack\")(predictions2), atol=1e-3, rtol=1e-5) \n```", "```py\nfrom torch.utils.benchmark import [Timer](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\")\n[without_vmap](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\") = [Timer](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\")(\n    stmt=\"[model(minibatch) for model, minibatch in zip(models, minibatches)]\",\n    globals=globals())\n[with_vmap](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\") = [Timer](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\")(\n    stmt=\"vmap(fmodel)(params, buffers, minibatches)\",\n    globals=globals())\nprint(f'Predictions without vmap {[without_vmap.timeit](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer.timeit \"torch.utils.benchmark.Timer.timeit\")(100)}')\nprint(f'Predictions with vmap {[with_vmap.timeit](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer.timeit \"torch.utils.benchmark.Timer.timeit\")(100)}') \n```", "```py\nPredictions without vmap <torch.utils.benchmark.utils.common.Measurement object at 0x7f48efb85b40>\n[model(minibatch) for model, minibatch in zip(models, minibatches)]\n  2.26 ms\n  1 measurement, 100 runs , 1 thread\nPredictions with vmap <torch.utils.benchmark.utils.common.Measurement object at 0x7f48efb85ea0>\nvmap(fmodel)(params, buffers, minibatches)\n  791.58 us\n  1 measurement, 100 runs , 1 thread \n```"]