["```py\n# License: BSD\n# Author: Sasank Chilamkurthy\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\n[cudnn.benchmark](https://pytorch.org/docs/stable/backends.html#torch.backends.cudnn.benchmark \"torch.backends.cudnn.benchmark\") = True\nplt.ion()   # interactive mode \n```", "```py\n<contextlib.ExitStack object at 0x7f6aede85450> \n```", "```py\n# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': [transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")([\n        [transforms.RandomResizedCrop](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomResizedCrop.html#torchvision.transforms.RandomResizedCrop \"torchvision.transforms.RandomResizedCrop\")(224),\n        [transforms.RandomHorizontalFlip](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip \"torchvision.transforms.RandomHorizontalFlip\")(),\n        [transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")(),\n        [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': [transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")([\n        [transforms.Resize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize \"torchvision.transforms.Resize\")(256),\n        [transforms.CenterCrop](https://pytorch.org/vision/stable/generated/torchvision.transforms.CenterCrop.html#torchvision.transforms.CenterCrop \"torchvision.transforms.CenterCrop\")(224),\n        [transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")(),\n        [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data/hymenoptera_data'\nimage_datasets = {x: [datasets.ImageFolder](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder \"torchvision.datasets.ImageFolder\")(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].[classes](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n\n[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda:0\" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\") \n```", "```py\ndef imshow(inp, title=None):\n  \"\"\"Display image for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n# Get a batch of training data\n[inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [classes](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = next(iter(dataloaders['train']))\n\n# Make a grid from batch\n[out](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torchvision.utils.make_grid](https://pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid \"torchvision.utils.make_grid\")([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\nimshow([out](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), title=[class_names[x] for x in [classes](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")]) \n```", "```py\ndef train_model(model, [criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\"), optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        [torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save \"torch.save\")(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs  -  1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), labels in dataloaders[phase]:\n                    [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n                    labels = labels.to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with [torch.set_grad_enabled](https://pytorch.org/docs/stable/generated/torch.set_grad_enabled.html#torch.set_grad_enabled \"torch.set_grad_enabled\")(phase == 'train'):\n                        outputs = model([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n                        _, preds = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max \"torch.max\")(outputs, 1)\n                        loss = [criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss.item() * [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(0)\n                    running_corrects += [torch.sum](https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum \"torch.sum\")(preds == labels.data)\n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # deep copy the model\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    [torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save \"torch.save\")(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed  //  60:.0f}m {time_elapsed  %  60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # load best model weights\n        model.load_state_dict([torch.load](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load \"torch.load\")(best_model_params_path))\n    return model \n```", "```py\ndef visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n        for i, ([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), labels) in enumerate(dataloaders['val']):\n            [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n            labels = labels.to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n            outputs = model([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n            _, preds = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max \"torch.max\")(outputs, 1)\n\n            for j in range([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow([inputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training) \n```", "```py\nmodel_ft = [models.resnet18](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18 \"torchvision.models.resnet18\")(weights='IMAGENET1K_V1')\nnum_ftrs = [model_ft.fc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\").in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n[model_ft.fc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\") = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(num_ftrs, 2)\n\nmodel_ft = [model_ft.to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to \"torch.nn.Module.to\")([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n[criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\") = [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")()\n\n# Observe that all parameters are being optimized\n[optimizer_ft](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\") = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\")([model_ft.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\n[exp_lr_scheduler](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR \"torch.optim.lr_scheduler.StepLR\") = [lr_scheduler.StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR \"torch.optim.lr_scheduler.StepLR\")([optimizer_ft](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\"), step_size=7, gamma=0.1) \n```", "```py\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /var/lib/jenkins/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n  0%|          | 0.00/44.7M [00:00<?, ?B/s]\n 31%|###       | 13.7M/44.7M [00:00<00:00, 143MB/s]\n 62%|######2   | 27.8M/44.7M [00:00<00:00, 146MB/s]\n 94%|#########3| 41.9M/44.7M [00:00<00:00, 147MB/s]\n100%|##########| 44.7M/44.7M [00:00<00:00, 146MB/s] \n```", "```py\nmodel_ft = train_model(model_ft, [criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\"), [optimizer_ft](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\"), [exp_lr_scheduler](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR \"torch.optim.lr_scheduler.StepLR\"),\n                       num_epochs=25) \n```", "```py\nEpoch 0/24\n----------\ntrain Loss: 0.4785 Acc: 0.7582\nval Loss: 0.2864 Acc: 0.8758\n\nEpoch 1/24\n----------\ntrain Loss: 0.5262 Acc: 0.8074\nval Loss: 0.5643 Acc: 0.7778\n\nEpoch 2/24\n----------\ntrain Loss: 0.4336 Acc: 0.8156\nval Loss: 0.2852 Acc: 0.9020\n\nEpoch 3/24\n----------\ntrain Loss: 0.6358 Acc: 0.7582\nval Loss: 0.4226 Acc: 0.8627\n\nEpoch 4/24\n----------\ntrain Loss: 0.4319 Acc: 0.8525\nval Loss: 0.3289 Acc: 0.8824\n\nEpoch 5/24\n----------\ntrain Loss: 0.4856 Acc: 0.7869\nval Loss: 0.3162 Acc: 0.8758\n\nEpoch 6/24\n----------\ntrain Loss: 0.3984 Acc: 0.8197\nval Loss: 0.4864 Acc: 0.8235\n\nEpoch 7/24\n----------\ntrain Loss: 0.3621 Acc: 0.8238\nval Loss: 0.2516 Acc: 0.8889\n\nEpoch 8/24\n----------\ntrain Loss: 0.2331 Acc: 0.9016\nval Loss: 0.2395 Acc: 0.9085\n\nEpoch 9/24\n----------\ntrain Loss: 0.2571 Acc: 0.9016\nval Loss: 0.2579 Acc: 0.9281\n\nEpoch 10/24\n----------\ntrain Loss: 0.3528 Acc: 0.8320\nval Loss: 0.2281 Acc: 0.9150\n\nEpoch 11/24\n----------\ntrain Loss: 0.3108 Acc: 0.8320\nval Loss: 0.2832 Acc: 0.9020\n\nEpoch 12/24\n----------\ntrain Loss: 0.2189 Acc: 0.8975\nval Loss: 0.2734 Acc: 0.8824\n\nEpoch 13/24\n----------\ntrain Loss: 0.2872 Acc: 0.8648\nval Loss: 0.2274 Acc: 0.9281\n\nEpoch 14/24\n----------\ntrain Loss: 0.2745 Acc: 0.8689\nval Loss: 0.2712 Acc: 0.8954\n\nEpoch 15/24\n----------\ntrain Loss: 0.3152 Acc: 0.8689\nval Loss: 0.3225 Acc: 0.8954\n\nEpoch 16/24\n----------\ntrain Loss: 0.2069 Acc: 0.9016\nval Loss: 0.2486 Acc: 0.9085\n\nEpoch 17/24\n----------\ntrain Loss: 0.2447 Acc: 0.9016\nval Loss: 0.2282 Acc: 0.9281\n\nEpoch 18/24\n----------\ntrain Loss: 0.2709 Acc: 0.8811\nval Loss: 0.2590 Acc: 0.9020\n\nEpoch 19/24\n----------\ntrain Loss: 0.1959 Acc: 0.9139\nval Loss: 0.2282 Acc: 0.9150\n\nEpoch 20/24\n----------\ntrain Loss: 0.2432 Acc: 0.8852\nval Loss: 0.2623 Acc: 0.9150\n\nEpoch 21/24\n----------\ntrain Loss: 0.2643 Acc: 0.8770\nval Loss: 0.2776 Acc: 0.9150\n\nEpoch 22/24\n----------\ntrain Loss: 0.2973 Acc: 0.8770\nval Loss: 0.2362 Acc: 0.9020\n\nEpoch 23/24\n----------\ntrain Loss: 0.2859 Acc: 0.8648\nval Loss: 0.2551 Acc: 0.9085\n\nEpoch 24/24\n----------\ntrain Loss: 0.3264 Acc: 0.8811\nval Loss: 0.2317 Acc: 0.9150\n\nTraining complete in 1m 3s\nBest val Acc: 0.928105 \n```", "```py\nvisualize_model(model_ft) \n```", "```py\nmodel_conv = [torchvision.models.resnet18](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18 \"torchvision.models.resnet18\")(weights='IMAGENET1K_V1')\nfor [param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\") in [model_conv.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")():\n    [param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\").requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = [model_conv.fc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\").in_features\n[model_conv.fc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\") = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(num_ftrs, 2)\n\nmodel_conv = [model_conv.to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to \"torch.nn.Module.to\")([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n[criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\") = [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\n[optimizer_conv](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\") = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\")([model_conv.fc.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\n[exp_lr_scheduler](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR \"torch.optim.lr_scheduler.StepLR\") = [lr_scheduler.StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR \"torch.optim.lr_scheduler.StepLR\")([optimizer_conv](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\"), step_size=7, gamma=0.1) \n```", "```py\nmodel_conv = train_model(model_conv, [criterion](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\"), [optimizer_conv](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\"),\n                         [exp_lr_scheduler](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR \"torch.optim.lr_scheduler.StepLR\"), num_epochs=25) \n```", "```py\nEpoch 0/24\n----------\ntrain Loss: 0.6996 Acc: 0.6516\nval Loss: 0.2014 Acc: 0.9346\n\nEpoch 1/24\n----------\ntrain Loss: 0.4233 Acc: 0.8033\nval Loss: 0.2656 Acc: 0.8758\n\nEpoch 2/24\n----------\ntrain Loss: 0.4603 Acc: 0.7869\nval Loss: 0.1847 Acc: 0.9477\n\nEpoch 3/24\n----------\ntrain Loss: 0.3096 Acc: 0.8566\nval Loss: 0.1747 Acc: 0.9477\n\nEpoch 4/24\n----------\ntrain Loss: 0.4427 Acc: 0.8156\nval Loss: 0.1630 Acc: 0.9477\n\nEpoch 5/24\n----------\ntrain Loss: 0.5505 Acc: 0.7828\nval Loss: 0.1643 Acc: 0.9477\n\nEpoch 6/24\n----------\ntrain Loss: 0.3004 Acc: 0.8607\nval Loss: 0.1744 Acc: 0.9542\n\nEpoch 7/24\n----------\ntrain Loss: 0.4083 Acc: 0.8361\nval Loss: 0.1892 Acc: 0.9412\n\nEpoch 8/24\n----------\ntrain Loss: 0.4483 Acc: 0.7910\nval Loss: 0.1984 Acc: 0.9477\n\nEpoch 9/24\n----------\ntrain Loss: 0.3335 Acc: 0.8279\nval Loss: 0.1942 Acc: 0.9412\n\nEpoch 10/24\n----------\ntrain Loss: 0.2413 Acc: 0.8934\nval Loss: 0.2001 Acc: 0.9477\n\nEpoch 11/24\n----------\ntrain Loss: 0.3107 Acc: 0.8689\nval Loss: 0.1801 Acc: 0.9412\n\nEpoch 12/24\n----------\ntrain Loss: 0.3032 Acc: 0.8689\nval Loss: 0.1669 Acc: 0.9477\n\nEpoch 13/24\n----------\ntrain Loss: 0.3587 Acc: 0.8525\nval Loss: 0.1900 Acc: 0.9477\n\nEpoch 14/24\n----------\ntrain Loss: 0.2771 Acc: 0.8893\nval Loss: 0.2317 Acc: 0.9216\n\nEpoch 15/24\n----------\ntrain Loss: 0.3064 Acc: 0.8852\nval Loss: 0.1909 Acc: 0.9477\n\nEpoch 16/24\n----------\ntrain Loss: 0.4243 Acc: 0.8238\nval Loss: 0.2227 Acc: 0.9346\n\nEpoch 17/24\n----------\ntrain Loss: 0.3297 Acc: 0.8238\nval Loss: 0.1916 Acc: 0.9412\n\nEpoch 18/24\n----------\ntrain Loss: 0.4235 Acc: 0.8238\nval Loss: 0.1766 Acc: 0.9477\n\nEpoch 19/24\n----------\ntrain Loss: 0.2500 Acc: 0.8934\nval Loss: 0.2003 Acc: 0.9477\n\nEpoch 20/24\n----------\ntrain Loss: 0.2413 Acc: 0.8934\nval Loss: 0.1821 Acc: 0.9477\n\nEpoch 21/24\n----------\ntrain Loss: 0.3762 Acc: 0.8115\nval Loss: 0.1842 Acc: 0.9412\n\nEpoch 22/24\n----------\ntrain Loss: 0.3485 Acc: 0.8566\nval Loss: 0.2166 Acc: 0.9281\n\nEpoch 23/24\n----------\ntrain Loss: 0.3625 Acc: 0.8361\nval Loss: 0.1747 Acc: 0.9412\n\nEpoch 24/24\n----------\ntrain Loss: 0.3840 Acc: 0.8320\nval Loss: 0.1768 Acc: 0.9412\n\nTraining complete in 0m 31s\nBest val Acc: 0.954248 \n```", "```py\nvisualize_model(model_conv)\n\nplt.ioff()\nplt.show() \n```", "```py\ndef visualize_model_predictions(model,img_path):\n    was_training = model.training\n    model.eval()\n\n    img = Image.open(img_path)\n    img = data_transforms['val'](img)\n    img = img.unsqueeze(0)\n    img = img.to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n    with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n        outputs = model(img)\n        _, preds = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max \"torch.max\")(outputs, 1)\n\n        ax = plt.subplot(2,2,1)\n        ax.axis('off')\n        ax.set_title(f'Predicted: {class_names[preds[0]]}')\n        imshow(img.cpu().data[0])\n\n        model.train(mode=was_training) \n```", "```py\nvisualize_model_predictions(\n    model_conv,\n    img_path='data/hymenoptera_data/val/bees/72100438_73de9f17af.jpg'\n)\n\nplt.ioff()\nplt.show() \n```"]