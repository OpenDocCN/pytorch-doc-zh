- en: TorchServe¶
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/serve](https://pytorch.org/serve)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: TorchServe is a performant, flexible and easy to use tool for serving PyTorch
    models in production.
  prefs: []
  type: TYPE_NORMAL
- en: What’s going on in TorchServe?
  prefs: []
  type: TYPE_NORMAL
- en: '[High performance Llama 2 deployments with AWS Inferentia2 using TorchServe](https://pytorch.org/blog/high-performance-llama/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Naver Case Study: Transition From High-Cost GPUs to Intel CPUs and oneAPI
    powered Software with performance](https://pytorch.org/blog/ml-model-server-resource-saving/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Run multiple generative AI models on GPU using Amazon SageMaker multi-model
    endpoints with TorchServe and save up to 75% in inference costs](https://aws.amazon.com/blogs/machine-learning/run-multiple-generative-ai-models-on-gpu-using-amazon-sagemaker-multi-model-endpoints-with-torchserve-and-save-up-to-75-in-inference-costs/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deploying your Generative AI model in only four steps with Vertex AI and PyTorch](https://cloud.google.com/blog/products/ai-machine-learning/get-your-genai-model-going-in-four-easy-steps)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch Model Serving on Google Cloud TPUv5](https://cloud.google.com/tpu/docs/v5e-inference#pytorch-model-inference-and-serving)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Monitoring using Datadog](https://www.datadoghq.com/blog/ai-integrations/#model-serving-and-deployment-vertex-ai-amazon-sagemaker-torchserve)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Torchserve Performance Tuning, Animated Drawings Case-Study](https://pytorch.org/blog/torchserve-performance-tuning/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Walmart Search: Serving Models at a Scale on TorchServe](https://medium.com/walmartglobaltech/search-model-serving-using-pytorch-and-torchserve-6caf9d1c5f4d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Scaling inference on CPU with TorchServe](https://www.youtube.com/watch?v=066_Jd6cwZg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TorchServe C++ backend](https://www.youtube.com/watch?v=OSmGGDpaesc)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Grokking Intel CPU PyTorch performance from first principles: a TorchServe
    case study](https://pytorch.org/tutorials/intermediate/torchserve_with_ipex.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Grokking Intel CPU PyTorch performance from first principles( Part 2): a TorchServe
    case study](https://pytorch.org/tutorials/intermediate/torchserve_with_ipex_2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Case Study: Amazon Ads Uses PyTorch and AWS Inferentia to Scale Models for
    Ads Processing](https://pytorch.org/blog/amazon-ads-case-study/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Optimize your inference jobs using dynamic batch inference with TorchServe
    on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/optimize-your-inference-jobs-using-dynamic-batch-inference-with-torchserve-on-amazon-sagemaker/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using AI to bring children’s drawings to life](https://ai.facebook.com/blog/using-ai-to-bring-childrens-drawings-to-life/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Model Serving in PyTorch](https://www.youtube.com/watch?v=2A17ZtycsPw)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Evolution of Cresta’s machine learning architecture: Migration to AWS and
    PyTorch](https://aws.amazon.com/blogs/machine-learning/evolution-of-crestas-machine-learning-architecture-migration-to-aws-and-pytorch/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explain Like I’m 5: TorchServe](https://www.youtube.com/watch?v=NEdZbkfHQCk)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Serve PyTorch Models with TorchServe](https://www.youtube.com/watch?v=XlO7iQMV3Ik)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to deploy PyTorch models on Vertex AI](https://cloud.google.com/blog/topics/developers-practitioners/pytorch-google-cloud-how-deploy-pytorch-models-vertex-ai)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Quantitative Comparison of Serving Platforms](https://biano-ai.github.io/research/2021/08/16/quantitative-comparison-of-serving-platforms-for-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '[#### TorchServe Quick Start'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Quick Start'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to install TorchServe and serve models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e44a4dab4c1bd5cde13eaa681343e78.png)](getting_started.html)
    [#### Running TorchServe'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Running TorchServe'
  prefs: []
  type: TYPE_NORMAL
- en: Indepth explanation of how to run TorchServe
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/661e92286b91a04a664aa0dd434223f4.png)](server.html) [#### Why
    TorchServe'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Examples'
  prefs: []
  type: TYPE_NORMAL
- en: Various TorchServe use cases
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0507eb3112fdbfd24e3e2ba13aa3e3fa.png)](use_cases.html) [####
    Performance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Performance,Troubleshooting'
  prefs: []
  type: TYPE_NORMAL
- en: Guides and best practices on how to improve perfromance when working with TorchServe
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a115bf3860d7637d64025cdabc4de95b.png)](performance_guide.html)
    [#### Metrics'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Metrics,Performance,Troubleshooting'
  prefs: []
  type: TYPE_NORMAL
- en: Collecting and viewing Torcherve metrics
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eab661f8c4941205ffdc566aced9bccf.png)](metrics.html) [#### Large
    Model Inference'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Large-Models,Performance'
  prefs: []
  type: TYPE_NORMAL
- en: Serving Large Models with TorchServe
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6afe69d86ffcf863cd832ed3698732f.png)](large_model_inference.html)
    [#### Troubleshooting'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Troubleshooting,Performance'
  prefs: []
  type: TYPE_NORMAL
- en: Various updates on Torcherve and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d23903f23b5705cc9f1d9bdca6ce6bbb.png)](Troubleshooting.html)
    [#### TorchServe Security Policy'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: Security'
  prefs: []
  type: TYPE_NORMAL
- en: Security Policy
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e44a4dab4c1bd5cde13eaa681343e78.png)](security.html) [#### FAQs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics: FAQS'
  prefs: []
  type: TYPE_NORMAL
- en: Various frequently asked questions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ccfac0b40fe2fac42582244489f0da4.png)](FAQs.html)'
  prefs: []
  type: TYPE_IMG
