["```py\nclass torchtext.models.RobertaBundle(_params: torchtext.models.RobertaEncoderParams, _path: Optional[str] = None, _head: Optional[torch.nn.Module] = None, transform: Optional[Callable] = None)\u00b6\n```", "```py\n>>> import torch, torchtext\n>>> from torchtext.functional import to_tensor\n>>> xlmr_base = torchtext.models.XLMR_BASE_ENCODER\n>>> model = xlmr_base.get_model()\n>>> transform = xlmr_base.transform()\n>>> input_batch = [\"Hello world\", \"How are you!\"]\n>>> model_input = to_tensor(transform(input_batch), padding_value=1)\n>>> output = model(model_input)\n>>> output.shape\ntorch.Size([2, 6, 768]) \n```", "```py\n>>> import torch, torchtext\n>>> from torchtext.models import RobertaClassificationHead\n>>> from torchtext.functional import to_tensor\n>>> xlmr_large = torchtext.models.XLMR_LARGE_ENCODER\n>>> classifier_head = torchtext.models.RobertaClassificationHead(num_classes=2, input_dim = 1024)\n>>> model = xlmr_large.get_model(head=classifier_head)\n>>> transform = xlmr_large.transform()\n>>> input_batch = [\"Hello world\", \"How are you!\"]\n>>> model_input = to_tensor(transform(input_batch), padding_value=1)\n>>> output = model(model_input)\n>>> output.shape\ntorch.Size([1, 2]) \n```", "```py\n>>> from torchtext.models import RobertaEncoderConf, RobertaBundle, RobertaClassificationHead\n>>> model_weights_path = \"https://download.pytorch.org/models/text/xlmr.base.encoder.pt\"\n>>> encoder_conf = RobertaEncoderConf(vocab_size=250002)\n>>> classifier_head = RobertaClassificationHead(num_classes=2, input_dim=768)\n>>> model = RobertaBundle.build_model(encoder_conf=encoder_conf, head=classifier_head, checkpoint=model_weights_path) \n```", "```py\nget_model(head: Optional[torch.nn.Module] = None, load_weights: bool = True, freeze_encoder: bool = False, *, dl_kwargs=None) \u2192 torchtext.models.RobertaModel\u00b6\n```", "```py\ntorchtext.models.XLMR_BASE_ENCODER\u00b6\n```", "```py\ntorchtext.models.XLMR_LARGE_ENCODER\u00b6\n```", "```py\ntorchtext.models.ROBERTA_BASE_ENCODER\u00b6\n```", "```py\ntorchtext.models.ROBERTA_LARGE_ENCODER\u00b6\n```"]