- en: torch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: torch
- en: 原文：[https://pytorch.org/docs/stable/torch.html](https://pytorch.org/docs/stable/torch.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/docs/stable/torch.html](https://pytorch.org/docs/stable/torch.html)
- en: The torch package contains data structures for multi-dimensional tensors and
    defines mathematical operations over these tensors. Additionally, it provides
    many utilities for efficient serialization of Tensors and arbitrary types, and
    other useful utilities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: torch包含用于多维张量的数据结构，并定义了这些张量上的数学操作。此外，它还提供了许多用于高效序列化张量和任意类型的工具，以及其他有用的实用程序。
- en: It has a CUDA counterpart, that enables you to run your tensor computations
    on an NVIDIA GPU with compute capability >= 3.0.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 它有一个CUDA对应项，可以让您在具有计算能力>= 3.0的NVIDIA GPU上运行张量计算。
- en: Tensors
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量
- en: '| [`is_tensor`](generated/torch.is_tensor.html#torch.is_tensor "torch.is_tensor")
    | Returns True if obj is a PyTorch tensor. |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| [`is_tensor`](generated/torch.is_tensor.html#torch.is_tensor "torch.is_tensor")
    | 如果obj是PyTorch张量，则返回True。 |'
- en: '| [`is_storage`](generated/torch.is_storage.html#torch.is_storage "torch.is_storage")
    | Returns True if obj is a PyTorch storage object. |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| [`is_storage`](generated/torch.is_storage.html#torch.is_storage "torch.is_storage")
    | 如果obj是PyTorch存储对象，则返回True。 |'
- en: '| [`is_complex`](generated/torch.is_complex.html#torch.is_complex "torch.is_complex")
    | Returns True if the data type of `input` is a complex data type i.e., one of
    `torch.complex64`, and `torch.complex128`. |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| [`is_complex`](generated/torch.is_complex.html#torch.is_complex "torch.is_complex")
    | 如果`input`的数据类型是复数数据类型，即`torch.complex64`和`torch.complex128`之一，则返回True。 |'
- en: '| [`is_conj`](generated/torch.is_conj.html#torch.is_conj "torch.is_conj") |
    Returns True if the `input` is a conjugated tensor, i.e. its conjugate bit is
    set to True. |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| [`is_conj`](generated/torch.is_conj.html#torch.is_conj "torch.is_conj") |
    如果`input`是一个共轭张量，即其共轭位设置为True，则返回True。 |'
- en: '| [`is_floating_point`](generated/torch.is_floating_point.html#torch.is_floating_point
    "torch.is_floating_point") | Returns True if the data type of `input` is a floating
    point data type i.e., one of `torch.float64`, `torch.float32`, `torch.float16`,
    and `torch.bfloat16`. |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| [`is_floating_point`](generated/torch.is_floating_point.html#torch.is_floating_point
    "torch.is_floating_point") | 如果`input`的数据类型是浮点数据类型，即`torch.float64`、`torch.float32`、`torch.float16`和`torch.bfloat16`之一，则返回True。
    |'
- en: '| [`is_nonzero`](generated/torch.is_nonzero.html#torch.is_nonzero "torch.is_nonzero")
    | Returns True if the `input` is a single element tensor which is not equal to
    zero after type conversions. |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [`is_nonzero`](generated/torch.is_nonzero.html#torch.is_nonzero "torch.is_nonzero")
    | 如果`input`是一个经过类型转换后不等于零的单个元素张量，则返回True。 |'
- en: '| [`set_default_dtype`](generated/torch.set_default_dtype.html#torch.set_default_dtype
    "torch.set_default_dtype") | Sets the default floating point dtype to `d`. |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [`set_default_dtype`](generated/torch.set_default_dtype.html#torch.set_default_dtype
    "torch.set_default_dtype") | 将默认的浮点dtype设置为`d`。 |'
- en: '| [`get_default_dtype`](generated/torch.get_default_dtype.html#torch.get_default_dtype
    "torch.get_default_dtype") | Get the current default floating point [`torch.dtype`](tensor_attributes.html#torch.dtype
    "torch.dtype"). |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [`get_default_dtype`](generated/torch.get_default_dtype.html#torch.get_default_dtype
    "torch.get_default_dtype") | 获取当前默认的浮点[`torch.dtype`](tensor_attributes.html#torch.dtype
    "torch.dtype")。 |'
- en: '| [`set_default_device`](generated/torch.set_default_device.html#torch.set_default_device
    "torch.set_default_device") | Sets the default `torch.Tensor` to be allocated
    on `device`. |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [`set_default_device`](generated/torch.set_default_device.html#torch.set_default_device
    "torch.set_default_device") | 将默认的`torch.Tensor`分配到`device`上。 |'
- en: '| [`set_default_tensor_type`](generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type
    "torch.set_default_tensor_type") | Sets the default `torch.Tensor` type to floating
    point tensor type `t`. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [`set_default_tensor_type`](generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type
    "torch.set_default_tensor_type") | 将默认的`torch.Tensor`类型设置为浮点张量类型`t`。 |'
- en: '| [`numel`](generated/torch.numel.html#torch.numel "torch.numel") | Returns
    the total number of elements in the `input` tensor. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [`numel`](generated/torch.numel.html#torch.numel "torch.numel") | 返回`input`张量中的总元素数。
    |'
- en: '| [`set_printoptions`](generated/torch.set_printoptions.html#torch.set_printoptions
    "torch.set_printoptions") | Set options for printing. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [`set_printoptions`](generated/torch.set_printoptions.html#torch.set_printoptions
    "torch.set_printoptions") | 设置打印选项。 |'
- en: '| [`set_flush_denormal`](generated/torch.set_flush_denormal.html#torch.set_flush_denormal
    "torch.set_flush_denormal") | Disables denormal floating numbers on CPU. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [`set_flush_denormal`](generated/torch.set_flush_denormal.html#torch.set_flush_denormal
    "torch.set_flush_denormal") | 禁用CPU上的非规格化浮点数。 |'
- en: '### Creation Ops'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '### 创建操作'
- en: Note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Random sampling creation ops are listed under [Random sampling](#random-sampling)
    and include: [`torch.rand()`](generated/torch.rand.html#torch.rand "torch.rand")
    [`torch.rand_like()`](generated/torch.rand_like.html#torch.rand_like "torch.rand_like")
    [`torch.randn()`](generated/torch.randn.html#torch.randn "torch.randn") [`torch.randn_like()`](generated/torch.randn_like.html#torch.randn_like
    "torch.randn_like") [`torch.randint()`](generated/torch.randint.html#torch.randint
    "torch.randint") [`torch.randint_like()`](generated/torch.randint_like.html#torch.randint_like
    "torch.randint_like") [`torch.randperm()`](generated/torch.randperm.html#torch.randperm
    "torch.randperm") You may also use [`torch.empty()`](generated/torch.empty.html#torch.empty
    "torch.empty") with the [In-place random sampling](#inplace-random-sampling) methods
    to create [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") s with values
    sampled from a broader range of distributions.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 随机抽样创建操作列在[随机抽样](#random-sampling)下，包括：[`torch.rand()`](generated/torch.rand.html#torch.rand
    "torch.rand") [`torch.rand_like()`](generated/torch.rand_like.html#torch.rand_like
    "torch.rand_like") [`torch.randn()`](generated/torch.randn.html#torch.randn "torch.randn")
    [`torch.randn_like()`](generated/torch.randn_like.html#torch.randn_like "torch.randn_like")
    [`torch.randint()`](generated/torch.randint.html#torch.randint "torch.randint")
    [`torch.randint_like()`](generated/torch.randint_like.html#torch.randint_like
    "torch.randint_like") [`torch.randperm()`](generated/torch.randperm.html#torch.randperm
    "torch.randperm") 您还可以使用[`torch.empty()`](generated/torch.empty.html#torch.empty
    "torch.empty")与[原地随机抽样](#inplace-random-sampling)方法一起创建从更广泛的分布中抽样值的[`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor")。
- en: '| [`tensor`](generated/torch.tensor.html#torch.tensor "torch.tensor") | Constructs
    a tensor with no autograd history (also known as a "leaf tensor", see [Autograd
    mechanics](notes/autograd.html)) by copying `data`. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [`tensor`](generated/torch.tensor.html#torch.tensor "torch.tensor") | 通过复制`data`构建一个没有自动求导历史的张量（也称为“叶子张量”，参见[自动求导机制](notes/autograd.html)）。
    |'
- en: '| [`sparse_coo_tensor`](generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor
    "torch.sparse_coo_tensor") | Constructs a [sparse tensor in COO(rdinate) format](sparse.html#sparse-coo-docs)
    with specified values at the given `indices`. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [`sparse_coo_tensor`](generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor
    "torch.sparse_coo_tensor") | 使用给定的`indices`构建一个COO（坐标）格式的稀疏张量。 |'
- en: '| [`sparse_csr_tensor`](generated/torch.sparse_csr_tensor.html#torch.sparse_csr_tensor
    "torch.sparse_csr_tensor") | Constructs a [sparse tensor in CSR (Compressed Sparse
    Row)](sparse.html#sparse-csr-docs) with specified values at the given `crow_indices`
    and `col_indices`. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [`sparse_csr_tensor`](generated/torch.sparse_csr_tensor.html#torch.sparse_csr_tensor
    "torch.sparse_csr_tensor") | 使用给定的`crow_indices`和`col_indices`构建一个CSR（压缩稀疏行）格式的稀疏张量。
    |'
- en: '| [`sparse_csc_tensor`](generated/torch.sparse_csc_tensor.html#torch.sparse_csc_tensor
    "torch.sparse_csc_tensor") | Constructs a [sparse tensor in CSC (Compressed Sparse
    Column)](sparse.html#sparse-csc-docs) with specified values at the given `ccol_indices`
    and `row_indices`. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| [`sparse_csc_tensor`](generated/torch.sparse_csc_tensor.html#torch.sparse_csc_tensor
    "torch.sparse_csc_tensor") | 使用给定的`ccol_indices`和`row_indices`构建一个CSC（压缩稀疏列）格式的稀疏张量。
    |'
- en: '| [`sparse_bsr_tensor`](generated/torch.sparse_bsr_tensor.html#torch.sparse_bsr_tensor
    "torch.sparse_bsr_tensor") | Constructs a [sparse tensor in BSR (Block Compressed
    Sparse Row))](sparse.html#sparse-bsr-docs) with specified 2-dimensional blocks
    at the given `crow_indices` and `col_indices`. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| [`sparse_bsr_tensor`](generated/torch.sparse_bsr_tensor.html#torch.sparse_bsr_tensor
    "torch.sparse_bsr_tensor") | 使用给定的`crow_indices`和`col_indices`构建一个BSR（块压缩稀疏行）格式的稀疏张量。
    |'
- en: '| [`sparse_bsc_tensor`](generated/torch.sparse_bsc_tensor.html#torch.sparse_bsc_tensor
    "torch.sparse_bsc_tensor") | Constructs a [sparse tensor in BSC (Block Compressed
    Sparse Column))](sparse.html#sparse-bsc-docs) with specified 2-dimensional blocks
    at the given `ccol_indices` and `row_indices`. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| [`sparse_bsc_tensor`](generated/torch.sparse_bsc_tensor.html#torch.sparse_bsc_tensor
    "torch.sparse_bsc_tensor") | 使用给定的`ccol_indices`和`row_indices`构建一个BSC（块压缩稀疏列）格式的稀疏张量。
    |'
- en: '| [`asarray`](generated/torch.asarray.html#torch.asarray "torch.asarray") |
    Converts `obj` to a tensor. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| [`asarray`](generated/torch.asarray.html#torch.asarray "torch.asarray") |
    将`obj`转换为张量。 |'
- en: '| [`as_tensor`](generated/torch.as_tensor.html#torch.as_tensor "torch.as_tensor")
    | Converts `data` into a tensor, sharing data and preserving autograd history
    if possible. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| [`as_tensor`](generated/torch.as_tensor.html#torch.as_tensor "torch.as_tensor")
    | 将`data`转换为张量，如果可能的话共享数据并保留自动求导历史。 |'
- en: '| [`as_strided`](generated/torch.as_strided.html#torch.as_strided "torch.as_strided")
    | Create a view of an existing torch.Tensor `input` with specified `size`, `stride`
    and `storage_offset`. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| [`as_strided`](generated/torch.as_strided.html#torch.as_strided "torch.as_strided")
    | 使用指定的`size`、`stride`和`storage_offset`创建一个现有torch.Tensor `input`的视图。 |'
- en: '| [`from_file`](generated/torch.from_file.html#torch.from_file "torch.from_file")
    | Creates a CPU tensor with a storage backed by a memory-mapped file. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| [`from_file`](generated/torch.from_file.html#torch.from_file "torch.from_file")
    | 创建一个由内存映射文件支持的CPU张量。 |'
- en: '| [`from_numpy`](generated/torch.from_numpy.html#torch.from_numpy "torch.from_numpy")
    | Creates a [`Tensor`](tensors.html#torch.Tensor "torch.Tensor") from a [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray
    "(in NumPy v1.26)"). |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| [`from_numpy`](generated/torch.from_numpy.html#torch.from_numpy "torch.from_numpy")
    | 从一个[`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)创建一个[`Tensor`](tensors.html#torch.Tensor)。
    |'
- en: '| [`from_dlpack`](generated/torch.from_dlpack.html#torch.from_dlpack "torch.from_dlpack")
    | Converts a tensor from an external library into a `torch.Tensor`. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| [`from_dlpack`](generated/torch.from_dlpack.html#torch.from_dlpack "torch.from_dlpack")
    | 将来自外部库的张量转换为`torch.Tensor`。 |'
- en: '| [`frombuffer`](generated/torch.frombuffer.html#torch.frombuffer "torch.frombuffer")
    | Creates a 1-dimensional [`Tensor`](tensors.html#torch.Tensor "torch.Tensor")
    from an object that implements the Python buffer protocol. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| [`frombuffer`](generated/torch.frombuffer.html#torch.frombuffer "torch.frombuffer")
    | 从实现Python缓冲区协议的对象创建一个1维张量。 |'
- en: '| [`zeros`](generated/torch.zeros.html#torch.zeros "torch.zeros") | Returns
    a tensor filled with the scalar value 0, with the shape defined by the variable
    argument `size`. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| [`zeros`](generated/torch.zeros.html#torch.zeros "torch.zeros") | 返回一个填充了标量值0且形状由可变参数`size`定义的张量。
    |'
- en: '| [`zeros_like`](generated/torch.zeros_like.html#torch.zeros_like "torch.zeros_like")
    | Returns a tensor filled with the scalar value 0, with the same size as `input`.
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| [`zeros_like`](generated/torch.zeros_like.html#torch.zeros_like "torch.zeros_like")
    | 返回一个与`input`相同大小且填充了标量值0的张量。 |'
- en: '| [`ones`](generated/torch.ones.html#torch.ones "torch.ones") | Returns a tensor
    filled with the scalar value 1, with the shape defined by the variable argument
    `size`. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| [`ones`](generated/torch.ones.html#torch.ones "torch.ones") | 返回一个填充了标量值1且形状由可变参数`size`定义的张量。
    |'
- en: '| [`ones_like`](generated/torch.ones_like.html#torch.ones_like "torch.ones_like")
    | Returns a tensor filled with the scalar value 1, with the same size as `input`.
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| [`ones_like`](generated/torch.ones_like.html#torch.ones_like "torch.ones_like")
    | 返回一个与`input`相同大小且填充了标量值1的张量。 |'
- en: '| [`arange`](generated/torch.arange.html#torch.arange "torch.arange") | Returns
    a 1-D tensor of size $\left\lceil \frac{\text{end} - \text{start}}{\text{step}}
    \right\rceil$⌈stepend−start​⌉ with values from the interval `[start, end)` taken
    with common difference `step` beginning from start. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| [`arange`](generated/torch.arange.html#torch.arange "torch.arange") | 返回一个大小为$\left\lceil
    \frac{\text{end} - \text{start}}{\text{step}} \right\rceil$的一维张量，其值来自区间`[start,
    end)`，以`step`为公差从`start`开始。 |'
- en: '| [`range`](generated/torch.range.html#torch.range "torch.range") | Returns
    a 1-D tensor of size $\left\lfloor \frac{\text{end} - \text{start}}{\text{step}}
    \right\rfloor + 1$⌊stepend−start​⌋+1 with values from `start` to `end` with step
    `step`. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| [`range`](生成/torch.range.html#torch.range "torch.range") | 返回一个大小为$\left\lfloor
    \frac{\text{end} - \text{start}}{\text{step}} \right\rfloor + 1$的一维张量，其值从`start`到`end`，步长为`step`。
    |'
- en: '| [`linspace`](generated/torch.linspace.html#torch.linspace "torch.linspace")
    | Creates a one-dimensional tensor of size `steps` whose values are evenly spaced
    from `start` to `end`, inclusive. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| [`linspace`](生成/torch.linspace.html#torch.linspace "torch.linspace") | 创建一个大小为`steps`的一维张量，其值从`start`到`end`均匀间隔。
    |'
- en: '| [`logspace`](generated/torch.logspace.html#torch.logspace "torch.logspace")
    | Creates a one-dimensional tensor of size `steps` whose values are evenly spaced
    from ${{\text{{base}}}}^{{\text{{start}}}}$basestart to ${{\text{{base}}}}^{{\text{{end}}}}$baseend,
    inclusive, on a logarithmic scale with base `base`. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| [`logspace`](生成/torch.logspace.html#torch.logspace "torch.logspace") | 创建一个大小为`steps`的一维张量，其值在对数刻度上从${{\text{{base}}}}^{{\text{{start}}}}$basestart到${{\text{{base}}}}^{{\text{{end}}}}$baseend均匀间隔。
    |'
- en: '| [`eye`](generated/torch.eye.html#torch.eye "torch.eye") | Returns a 2-D tensor
    with ones on the diagonal and zeros elsewhere. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| [`eye`](生成/torch.eye.html#torch.eye "torch.eye") | 返回一个对角线为1，其他位置为0的二维张量。
    |'
- en: '| [`empty`](generated/torch.empty.html#torch.empty "torch.empty") | Returns
    a tensor filled with uninitialized data. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| [`empty`](生成/torch.empty.html#torch.empty "torch.empty") | 返回一个填充未初始化数据的张量。
    |'
- en: '| [`empty_like`](generated/torch.empty_like.html#torch.empty_like "torch.empty_like")
    | Returns an uninitialized tensor with the same size as `input`. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| [`empty_like`](生成/torch.empty_like.html#torch.empty_like "torch.empty_like")
    | 返回一个与`input`大小相同的未初始化张量。 |'
- en: '| [`empty_strided`](generated/torch.empty_strided.html#torch.empty_strided
    "torch.empty_strided") | Creates a tensor with the specified `size` and `stride`
    and filled with undefined data. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| [`empty_strided`](生成/torch.empty_strided.html#torch.empty_strided "torch.empty_strided")
    | 创建一个指定`size`和`stride`的张量，并填充未定义数据。 |'
- en: '| [`full`](generated/torch.full.html#torch.full "torch.full") | Creates a tensor
    of size `size` filled with `fill_value`. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| [`full`](生成/torch.full.html#torch.full "torch.full") | 创建一个大小为`size`且填充为`fill_value`的张量。
    |'
- en: '| [`full_like`](generated/torch.full_like.html#torch.full_like "torch.full_like")
    | Returns a tensor with the same size as `input` filled with `fill_value`. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| [`full_like`](生成/torch.full_like.html#torch.full_like "torch.full_like")
    | 返回一个与`input`大小相同且填充为`fill_value`的张量。 |'
- en: '| [`quantize_per_tensor`](generated/torch.quantize_per_tensor.html#torch.quantize_per_tensor
    "torch.quantize_per_tensor") | Converts a float tensor to a quantized tensor with
    given scale and zero point. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| [`quantize_per_tensor`](生成/torch.quantize_per_tensor.html#torch.quantize_per_tensor
    "torch.quantize_per_tensor") | 将浮点张量转换为具有给定比例和零点的量化张量。 |'
- en: '| [`quantize_per_channel`](generated/torch.quantize_per_channel.html#torch.quantize_per_channel
    "torch.quantize_per_channel") | Converts a float tensor to a per-channel quantized
    tensor with given scales and zero points. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| [`quantize_per_channel`](生成/torch.quantize_per_channel.html#torch.quantize_per_channel
    "torch.quantize_per_channel") | 将浮点张量转换为具有给定比例和零点的按通道量化张量。 |'
- en: '| [`dequantize`](generated/torch.dequantize.html#torch.dequantize "torch.dequantize")
    | Returns an fp32 Tensor by dequantizing a quantized Tensor |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| [`dequantize`](生成/torch.dequantize.html#torch.dequantize "torch.dequantize")
    | 通过去量化一个量化张量返回一个fp32张量。 |'
- en: '| [`complex`](generated/torch.complex.html#torch.complex "torch.complex") |
    Constructs a complex tensor with its real part equal to [`real`](generated/torch.real.html#torch.real
    "torch.real") and its imaginary part equal to [`imag`](generated/torch.imag.html#torch.imag
    "torch.imag"). |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| [`complex`](生成/torch.complex.html#torch.complex "torch.complex") | 构造一个复数张量，其实部等于[`real`](生成/torch.real.html#torch.real
    "torch.real")，虚部等于[`imag`](生成/torch.imag.html#torch.imag "torch.imag")。 |'
- en: '| [`polar`](generated/torch.polar.html#torch.polar "torch.polar") | Constructs
    a complex tensor whose elements are Cartesian coordinates corresponding to the
    polar coordinates with absolute value [`abs`](generated/torch.abs.html#torch.abs
    "torch.abs") and angle [`angle`](generated/torch.angle.html#torch.angle "torch.angle").
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| [`polar`](生成/torch.polar.html#torch.polar "torch.polar") | 构造一个复数张量，其元素是对应于绝对值[`abs`](生成/torch.abs.html#torch.abs
    "torch.abs")和角度[`angle`](生成/torch.angle.html#torch.angle "torch.angle")的极坐标。 |'
- en: '| [`heaviside`](generated/torch.heaviside.html#torch.heaviside "torch.heaviside")
    | Computes the Heaviside step function for each element in `input`. |  ### Indexing,
    Slicing, Joining, Mutating Ops[](#indexing-slicing-joining-mutating-ops "Permalink
    to this heading")'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '| [`heaviside`](生成/torch.heaviside.html#torch.heaviside "torch.heaviside")
    | 计算`input`中每个元素的Heaviside阶跃函数。 |  ### 索引、切片、连接、变异操作[](#indexing-slicing-joining-mutating-ops
    "跳转到此标题的永久链接")'
- en: '| [`adjoint`](generated/torch.adjoint.html#torch.adjoint "torch.adjoint") |
    Returns a view of the tensor conjugated and with the last two dimensions transposed.
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| [`adjoint`](生成/torch.adjoint.html#torch.adjoint "torch.adjoint") | 返回一个共轭并且最后两个维度转置的张量视图。
    |'
- en: '| [`argwhere`](generated/torch.argwhere.html#torch.argwhere "torch.argwhere")
    | Returns a tensor containing the indices of all non-zero elements of `input`.
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| [`argwhere`](生成/torch.argwhere.html#torch.argwhere "torch.argwhere") | 返回一个包含`input`所有非零元素索引的张量。
    |'
- en: '| [`cat`](generated/torch.cat.html#torch.cat "torch.cat") | Concatenates the
    given sequence of `seq` tensors in the given dimension. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| [`cat`](生成/torch.cat.html#torch.cat "torch.cat") | 在给定维度上连接给定序列`seq`的张量。
    |'
- en: '| [`concat`](generated/torch.concat.html#torch.concat "torch.concat") | Alias
    of [`torch.cat()`](generated/torch.cat.html#torch.cat "torch.cat"). |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| [`concat`](生成/torch.concat.html#torch.concat "torch.concat") | [`torch.cat()`](生成/torch.cat.html#torch.cat
    "torch.cat")的别名。 |'
- en: '| [`concatenate`](generated/torch.concatenate.html#torch.concatenate "torch.concatenate")
    | Alias of [`torch.cat()`](generated/torch.cat.html#torch.cat "torch.cat"). |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| [`concatenate`](生成/torch.concatenate.html#torch.concatenate "torch.concatenate")
    | [`torch.cat()`](生成/torch.cat.html#torch.cat "torch.cat")的别名。 |'
- en: '| [`conj`](generated/torch.conj.html#torch.conj "torch.conj") | Returns a view
    of `input` with a flipped conjugate bit. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| [`conj`](生成/torch.conj.html#torch.conj "torch.conj") | 返回一个具有翻转共轭位的`input`视图。
    |'
- en: '| [`chunk`](generated/torch.chunk.html#torch.chunk "torch.chunk") | Attempts
    to split a tensor into the specified number of chunks. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| [`chunk`](generated/torch.chunk.html#torch.chunk "torch.chunk") | 尝试将张量分割成指定数量的块。
    |'
- en: '| [`dsplit`](generated/torch.dsplit.html#torch.dsplit "torch.dsplit") | Splits
    `input`, a tensor with three or more dimensions, into multiple tensors depthwise
    according to `indices_or_sections`. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| [`dsplit`](generated/torch.dsplit.html#torch.dsplit "torch.dsplit") | 根据`indices_or_sections`，将具有三个或更多维度的`input`张量沿深度方向分割成多个张量。
    |'
- en: '| [`column_stack`](generated/torch.column_stack.html#torch.column_stack "torch.column_stack")
    | Creates a new tensor by horizontally stacking the tensors in `tensors`. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| [`column_stack`](generated/torch.column_stack.html#torch.column_stack "torch.column_stack")
    | 通过水平堆叠`tensors`在`tensors`中创建一个新的张量。 |'
- en: '| [`dstack`](generated/torch.dstack.html#torch.dstack "torch.dstack") | Stack
    tensors in sequence depthwise (along third axis). |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| [`dstack`](generated/torch.dstack.html#torch.dstack "torch.dstack") | 深度顺序堆叠张量（沿第三轴）。
    |'
- en: '| [`gather`](generated/torch.gather.html#torch.gather "torch.gather") | Gathers
    values along an axis specified by dim. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| [`gather`](generated/torch.gather.html#torch.gather "torch.gather") | 沿着由dim指定的轴收集值。
    |'
- en: '| [`hsplit`](generated/torch.hsplit.html#torch.hsplit "torch.hsplit") | Splits
    `input`, a tensor with one or more dimensions, into multiple tensors horizontally
    according to `indices_or_sections`. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| [`hsplit`](generated/torch.hsplit.html#torch.hsplit "torch.hsplit") | 根据`indices_or_sections`，将具有一个或多个维度的`input`张量水平分割成多个张量。
    |'
- en: '| [`hstack`](generated/torch.hstack.html#torch.hstack "torch.hstack") | Stack
    tensors in sequence horizontally (column wise). |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| [`hstack`](generated/torch.hstack.html#torch.hstack "torch.hstack") | 水平顺序堆叠张量（按列）。
    |'
- en: '| [`index_add`](generated/torch.index_add.html#torch.index_add "torch.index_add")
    | See [`index_add_()`](generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_
    "torch.Tensor.index_add_") for function description. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| [`index_add`](generated/torch.index_add.html#torch.index_add "torch.index_add")
    | 有关函数描述，请参阅[`index_add_()`](generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_
    "torch.Tensor.index_add_")。 |'
- en: '| [`index_copy`](generated/torch.index_copy.html#torch.index_copy "torch.index_copy")
    | See [`index_add_()`](generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_
    "torch.Tensor.index_add_") for function description. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| [`index_copy`](generated/torch.index_copy.html#torch.index_copy "torch.index_copy")
    | 有关函数描述，请参阅[`index_add_()`](generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_
    "torch.Tensor.index_add_")。 |'
- en: '| [`index_reduce`](generated/torch.index_reduce.html#torch.index_reduce "torch.index_reduce")
    | See [`index_reduce_()`](generated/torch.Tensor.index_reduce_.html#torch.Tensor.index_reduce_
    "torch.Tensor.index_reduce_") for function description. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| [`index_reduce`](generated/torch.index_reduce.html#torch.index_reduce "torch.index_reduce")
    | 有关函数描述，请参阅[`index_reduce_()`](generated/torch.Tensor.index_reduce_.html#torch.Tensor.index_reduce_
    "torch.Tensor.index_reduce_")。 |'
- en: '| [`index_select`](generated/torch.index_select.html#torch.index_select "torch.index_select")
    | Returns a new tensor which indexes the `input` tensor along dimension `dim`
    using the entries in `index` which is a LongTensor. |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| [`index_select`](generated/torch.index_select.html#torch.index_select "torch.index_select")
    | 返回一个新的张量，沿着维度`dim`使用`index`中的条目对`input`张量进行索引，其中`index`是一个LongTensor。 |'
- en: '| [`masked_select`](generated/torch.masked_select.html#torch.masked_select
    "torch.masked_select") | Returns a new 1-D tensor which indexes the `input` tensor
    according to the boolean mask `mask` which is a BoolTensor. |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| [`masked_select`](generated/torch.masked_select.html#torch.masked_select
    "torch.masked_select") | 返回一个新的1-D张量，根据布尔掩码`mask`（BoolTensor）对`input`张量进行索引。 |'
- en: '| [`movedim`](generated/torch.movedim.html#torch.movedim "torch.movedim") |
    Moves the dimension(s) of `input` at the position(s) in `source` to the position(s)
    in `destination`. |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| [`movedim`](generated/torch.movedim.html#torch.movedim "torch.movedim") |
    将`input`张量的维度移动到`source`中的位置到`destination`中的位置。 |'
- en: '| [`moveaxis`](generated/torch.moveaxis.html#torch.moveaxis "torch.moveaxis")
    | Alias for [`torch.movedim()`](generated/torch.movedim.html#torch.movedim "torch.movedim").
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| [`moveaxis`](generated/torch.moveaxis.html#torch.moveaxis "torch.moveaxis")
    | [`torch.movedim()`](generated/torch.movedim.html#torch.movedim "torch.movedim")的别名。
    |'
- en: '| [`narrow`](generated/torch.narrow.html#torch.narrow "torch.narrow") | Returns
    a new tensor that is a narrowed version of `input` tensor. |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| [`narrow`](generated/torch.narrow.html#torch.narrow "torch.narrow") | 返回一个缩小版本的`input`张量的新张量。
    |'
- en: '| [`narrow_copy`](generated/torch.narrow_copy.html#torch.narrow_copy "torch.narrow_copy")
    | Same as [`Tensor.narrow()`](generated/torch.Tensor.narrow.html#torch.Tensor.narrow
    "torch.Tensor.narrow") except this returns a copy rather than shared storage.
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| [`narrow_copy`](generated/torch.narrow_copy.html#torch.narrow_copy "torch.narrow_copy")
    | 与[`Tensor.narrow()`](generated/torch.Tensor.narrow.html#torch.Tensor.narrow
    "torch.Tensor.narrow")相同，除了这里返回的是副本而不是共享存储。 |'
- en: '| [`nonzero`](generated/torch.nonzero.html#torch.nonzero "torch.nonzero") |  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| [`nonzero`](generated/torch.nonzero.html#torch.nonzero "torch.nonzero") |  |'
- en: '| [`permute`](generated/torch.permute.html#torch.permute "torch.permute") |
    Returns a view of the original tensor `input` with its dimensions permuted. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [`permute`](generated/torch.permute.html#torch.permute "torch.permute") |
    返回原始张量`input`的维度重新排列视图。 |'
- en: '| [`reshape`](generated/torch.reshape.html#torch.reshape "torch.reshape") |
    Returns a tensor with the same data and number of elements as `input`, but with
    the specified shape. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [`reshape`](generated/torch.reshape.html#torch.reshape "torch.reshape") |
    返回一个与`input`具有相同数据和元素数量的张量，但具有指定的形状。 |'
- en: '| [`row_stack`](generated/torch.row_stack.html#torch.row_stack "torch.row_stack")
    | Alias of [`torch.vstack()`](generated/torch.vstack.html#torch.vstack "torch.vstack").
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [`row_stack`](generated/torch.row_stack.html#torch.row_stack "torch.row_stack")
    | [`torch.vstack()`](generated/torch.vstack.html#torch.vstack "torch.vstack")的别名。
    |'
- en: '| [`select`](generated/torch.select.html#torch.select "torch.select") | Slices
    the `input` tensor along the selected dimension at the given index. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| [`select`](generated/torch.select.html#torch.select "torch.select") | 在给定索引处沿所选维度切片`input`张量。
    |'
- en: '| [`scatter`](generated/torch.scatter.html#torch.scatter "torch.scatter") |
    Out-of-place version of [`torch.Tensor.scatter_()`](generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_
    "torch.Tensor.scatter_") |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| [`scatter`](generated/torch.scatter.html#torch.scatter "torch.scatter") |
    [`torch.Tensor.scatter_()`](generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_
    "torch.Tensor.scatter_")的就地版本 |'
- en: '| [`diagonal_scatter`](generated/torch.diagonal_scatter.html#torch.diagonal_scatter
    "torch.diagonal_scatter") | Embeds the values of the `src` tensor into `input`
    along the diagonal elements of `input`, with respect to `dim1` and `dim2`. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [`diagonal_scatter`](generated/torch.diagonal_scatter.html#torch.diagonal_scatter
    "torch.diagonal_scatter") | 将`src`张量的值嵌入到`input`的对角线元素中，相对于`dim1`和`dim2`。 |'
- en: '| [`select_scatter`](generated/torch.select_scatter.html#torch.select_scatter
    "torch.select_scatter") | Embeds the values of the `src` tensor into `input` at
    the given index. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [`select_scatter`](generated/torch.select_scatter.html#torch.select_scatter
    "torch.select_scatter") | 将`src`张量的值嵌入到给定索引的`input`中。 |'
- en: '| [`slice_scatter`](generated/torch.slice_scatter.html#torch.slice_scatter
    "torch.slice_scatter") | Embeds the values of the `src` tensor into `input` at
    the given dimension. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| [`slice_scatter`](generated/torch.slice_scatter.html#torch.slice_scatter
    "torch.slice_scatter") | 将`src`张量的值嵌入到给定维度的`input`中。 |'
- en: '| [`scatter_add`](generated/torch.scatter_add.html#torch.scatter_add "torch.scatter_add")
    | Out-of-place version of [`torch.Tensor.scatter_add_()`](generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_
    "torch.Tensor.scatter_add_") |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| [`scatter_add`](generated/torch.scatter_add.html#torch.scatter_add "torch.scatter_add")
    | [`torch.Tensor.scatter_add_()`](generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_
    "torch.Tensor.scatter_add_")的就地版本。 |'
- en: '| [`scatter_reduce`](generated/torch.scatter_reduce.html#torch.scatter_reduce
    "torch.scatter_reduce") | Out-of-place version of [`torch.Tensor.scatter_reduce_()`](generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_
    "torch.Tensor.scatter_reduce_") |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| [`scatter_reduce`](generated/torch.scatter_reduce.html#torch.scatter_reduce
    "torch.scatter_reduce") | [`torch.Tensor.scatter_reduce_()`](generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_
    "torch.Tensor.scatter_reduce_")的就地版本。 |'
- en: '| [`split`](generated/torch.split.html#torch.split "torch.split") | Splits
    the tensor into chunks. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [`split`](generated/torch.split.html#torch.split "torch.split") | 将张量分割成多个块。
    |'
- en: '| [`squeeze`](generated/torch.squeeze.html#torch.squeeze "torch.squeeze") |
    Returns a tensor with all specified dimensions of `input` of size 1 removed. |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| [`squeeze`](generated/torch.squeeze.html#torch.squeeze "torch.squeeze") |
    返回一个去除`input`中所有指定大小为1的维度的张量。 |'
- en: '| [`stack`](generated/torch.stack.html#torch.stack "torch.stack") | Concatenates
    a sequence of tensors along a new dimension. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| [`stack`](generated/torch.stack.html#torch.stack "torch.stack") | 沿着新维度连接一系列张量。
    |'
- en: '| [`swapaxes`](generated/torch.swapaxes.html#torch.swapaxes "torch.swapaxes")
    | Alias for [`torch.transpose()`](generated/torch.transpose.html#torch.transpose
    "torch.transpose"). |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| [`swapaxes`](generated/torch.swapaxes.html#torch.swapaxes "torch.swapaxes")
    | [`torch.transpose()`](generated/torch.transpose.html#torch.transpose "torch.transpose")的别名。
    |'
- en: '| [`swapdims`](generated/torch.swapdims.html#torch.swapdims "torch.swapdims")
    | Alias for [`torch.transpose()`](generated/torch.transpose.html#torch.transpose
    "torch.transpose"). |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| [`swapdims`](generated/torch.swapdims.html#torch.swapdims "torch.swapdims")
    | [`torch.transpose()`](generated/torch.transpose.html#torch.transpose "torch.transpose")的别名。
    |'
- en: '| [`t`](generated/torch.t.html#torch.t "torch.t") | Expects `input` to be <=
    2-D tensor and transposes dimensions 0 and 1. |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| [`t`](generated/torch.t.html#torch.t "torch.t") | 期望`input`是 <= 2-D 张量，并转置维度0和1。
    |'
- en: '| [`take`](generated/torch.take.html#torch.take "torch.take") | Returns a new
    tensor with the elements of `input` at the given indices. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| [`take`](generated/torch.take.html#torch.take "torch.take") | 返回一个包含`input`在给定索引处的元素的新张量。
    |'
- en: '| [`take_along_dim`](generated/torch.take_along_dim.html#torch.take_along_dim
    "torch.take_along_dim") | Selects values from `input` at the 1-dimensional indices
    from `indices` along the given `dim`. |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| [`take_along_dim`](generated/torch.take_along_dim.html#torch.take_along_dim
    "torch.take_along_dim") | 在给定`dim`上沿着`indices`的一维索引从`input`中选择值。 |'
- en: '| [`tensor_split`](generated/torch.tensor_split.html#torch.tensor_split "torch.tensor_split")
    | Splits a tensor into multiple sub-tensors, all of which are views of `input`,
    along dimension `dim` according to the indices or number of sections specified
    by `indices_or_sections`. |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| [`tensor_split`](generated/torch.tensor_split.html#torch.tensor_split "torch.tensor_split")
    | 将张量沿着维度`dim`根据`indices_or_sections`指定的索引或分段数拆分为多个子张量，所有这些子张量都是`input`的视图。 |'
- en: '| [`tile`](generated/torch.tile.html#torch.tile "torch.tile") | Constructs
    a tensor by repeating the elements of `input`. |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| [`tile`](generated/torch.tile.html#torch.tile "torch.tile") | 通过重复`input`的元素构造张量。
    |'
- en: '| [`transpose`](generated/torch.transpose.html#torch.transpose "torch.transpose")
    | Returns a tensor that is a transposed version of `input`. |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| [`transpose`](generated/torch.transpose.html#torch.transpose "torch.transpose")
    | 返回`input`的转置版本的张量。 |'
- en: '| [`unbind`](generated/torch.unbind.html#torch.unbind "torch.unbind") | Removes
    a tensor dimension. |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| [`unbind`](generated/torch.unbind.html#torch.unbind "torch.unbind") | 移除张量的一个维度。
    |'
- en: '| [`unravel_index`](generated/torch.unravel_index.html#torch.unravel_index
    "torch.unravel_index") | Converts a tensor of flat indices into a tuple of coordinate
    tensors that index into an arbitrary tensor of the specified shape. |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| [`unravel_index`](generated/torch.unravel_index.html#torch.unravel_index
    "torch.unravel_index") | 将扁平索引的张量转换为索引到指定形状的任意张量的坐标张量元组。 |'
- en: '| [`unsqueeze`](generated/torch.unsqueeze.html#torch.unsqueeze "torch.unsqueeze")
    | Returns a new tensor with a dimension of size one inserted at the specified
    position. |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| [`unsqueeze`](generated/torch.unsqueeze.html#torch.unsqueeze "torch.unsqueeze")
    | 在指定位置插入一个大小为一的维度，返回一个新的张量。 |'
- en: '| [`vsplit`](generated/torch.vsplit.html#torch.vsplit "torch.vsplit") | Splits
    `input`, a tensor with two or more dimensions, into multiple tensors vertically
    according to `indices_or_sections`. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| [`vsplit`](generated/torch.vsplit.html#torch.vsplit "torch.vsplit") | 根据`indices_or_sections`将具有两个或更多维度的`input`张量垂直拆分为多个张量。
    |'
- en: '| [`vstack`](generated/torch.vstack.html#torch.vstack "torch.vstack") | Stack
    tensors in sequence vertically (row wise). |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| [`vstack`](generated/torch.vstack.html#torch.vstack "torch.vstack") | 按行将张量依次堆叠起来。
    |'
- en: '| [`where`](generated/torch.where.html#torch.where "torch.where") | Return
    a tensor of elements selected from either `input` or `other`, depending on `condition`.
    |  ## Generators'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '| [`where`](generated/torch.where.html#torch.where "torch.where") | 根据`condition`从`input`或`other`中选择元素并返回张量。
    |'
- en: '| [`Generator`](generated/torch.Generator.html#torch.Generator "torch.Generator")
    | Creates and returns a generator object that manages the state of the algorithm
    which produces pseudo random numbers. |  ## Random sampling[](#random-sampling
    "Permalink to this heading")'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '| [`Generator`](generated/torch.Generator.html#torch.Generator "torch.Generator")
    | 创建并返回一个生成器对象，该对象管理产生伪随机数的算法的状态。 |  ## 随机抽样[](#random-sampling "Permalink to
    this heading")'
- en: '| [`seed`](generated/torch.seed.html#torch.seed "torch.seed") | Sets the seed
    for generating random numbers to a non-deterministic random number. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| [`seed`](generated/torch.seed.html#torch.seed "torch.seed") | 将生成随机数的种子设置为非确定性随机数。
    |'
- en: '| [`manual_seed`](generated/torch.manual_seed.html#torch.manual_seed "torch.manual_seed")
    | Sets the seed for generating random numbers. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| [`manual_seed`](generated/torch.manual_seed.html#torch.manual_seed "torch.manual_seed")
    | 设置生成随机数的种子。 |'
- en: '| [`initial_seed`](generated/torch.initial_seed.html#torch.initial_seed "torch.initial_seed")
    | Returns the initial seed for generating random numbers as a Python long. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| [`initial_seed`](generated/torch.initial_seed.html#torch.initial_seed "torch.initial_seed")
    | 将生成随机数的初始种子作为Python长整型返回。 |'
- en: '| [`get_rng_state`](generated/torch.get_rng_state.html#torch.get_rng_state
    "torch.get_rng_state") | Returns the random number generator state as a torch.ByteTensor.
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| [`get_rng_state`](generated/torch.get_rng_state.html#torch.get_rng_state
    "torch.get_rng_state") | 将随机数生成器状态作为torch.ByteTensor返回。 |'
- en: '| [`set_rng_state`](generated/torch.set_rng_state.html#torch.set_rng_state
    "torch.set_rng_state") | Sets the random number generator state. |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| [`set_rng_state`](generated/torch.set_rng_state.html#torch.set_rng_state
    "torch.set_rng_state") | 设置随机数生成器状态。 |'
- en: '[PRE0]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '| [`bernoulli`](generated/torch.bernoulli.html#torch.bernoulli "torch.bernoulli")
    | Draws binary random numbers (0 or 1) from a Bernoulli distribution. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| [`bernoulli`](generated/torch.bernoulli.html#torch.bernoulli "torch.bernoulli")
    | 从伯努利分布中抽取二进制随机数（0或1）。 |'
- en: '| [`multinomial`](generated/torch.multinomial.html#torch.multinomial "torch.multinomial")
    | Returns a tensor where each row contains `num_samples` indices sampled from
    the multinomial (a stricter definition would be multivariate, refer to torch.distributions.multinomial.Multinomial
    for more details) probability distribution located in the corresponding row of
    tensor `input`. |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| [`multinomial`](generated/torch.multinomial.html#torch.multinomial "torch.multinomial")
    | 返回一个张量，其中每行包含从多项式（更严格的定义是多变量，有关更多细节，请参考torch.distributions.multinomial.Multinomial）概率分布中抽样的`num_samples`个索引，这些概率分布位于张量`input`相应行中。
    |'
- en: '| [`normal`](generated/torch.normal.html#torch.normal "torch.normal") | Returns
    a tensor of random numbers drawn from separate normal distributions whose mean
    and standard deviation are given. |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| [`normal`](generated/torch.normal.html#torch.normal "torch.normal") | 返回从具有给定均值和标准差的单独正态分布中抽取的随机数的张量。
    |'
- en: '| [`poisson`](generated/torch.poisson.html#torch.poisson "torch.poisson") |
    Returns a tensor of the same size as `input` with each element sampled from a
    Poisson distribution with rate parameter given by the corresponding element in
    `input` i.e., |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| [`poisson`](generated/torch.poisson.html#torch.poisson "torch.poisson") |
    返回与`input`相同大小的张量，其中每个元素从泊松分布中抽样，速率参数由`input`中相应元素给出。 |'
- en: '| [`rand`](generated/torch.rand.html#torch.rand "torch.rand") | Returns a tensor
    filled with random numbers from a uniform distribution on the interval $[0, 1)$[0,1)
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| [`rand`](generated/torch.rand.html#torch.rand "torch.rand") | 返回一个填充有来自区间$[0,
    1)$的均匀分布的随机数的张量。 |'
- en: '| [`rand_like`](generated/torch.rand_like.html#torch.rand_like "torch.rand_like")
    | Returns a tensor with the same size as `input` that is filled with random numbers
    from a uniform distribution on the interval $[0, 1)$[0,1). |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| [`rand_like`](generated/torch.rand_like.html#torch.rand_like "torch.rand_like")
    | 返回与`input`相同大小的张量，其中填充有来自区间$[0, 1)$的均匀分布的随机数。 |'
- en: '| [`randint`](generated/torch.randint.html#torch.randint "torch.randint") |
    Returns a tensor filled with random integers generated uniformly between `low`
    (inclusive) and `high` (exclusive). |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| [`randint`](generated/torch.randint.html#torch.randint "torch.randint") |
    返回一个填充有在`low`（包含）和`high`（不包含）之间均匀生成的随机整数的张量。 |'
- en: '| [`randint_like`](generated/torch.randint_like.html#torch.randint_like "torch.randint_like")
    | Returns a tensor with the same shape as Tensor `input` filled with random integers
    generated uniformly between `low` (inclusive) and `high` (exclusive). |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| [`randint_like`](generated/torch.randint_like.html#torch.randint_like "torch.randint_like")
    | 返回与张量`input`形状相同的张量，其中填充有在`low`（包含）和`high`（不包含）之间均匀生成的随机整数。 |'
- en: '| [`randn`](generated/torch.randn.html#torch.randn "torch.randn") | Returns
    a tensor filled with random numbers from a normal distribution with mean 0 and
    variance 1 (also called the standard normal distribution). |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| [`randn`](generated/torch.randn.html#torch.randn "torch.randn") | 返回一个填充有来自均值为0，方差为1（也称为标准正态分布）的随机数的张量。
    |'
- en: '| [`randn_like`](generated/torch.randn_like.html#torch.randn_like "torch.randn_like")
    | Returns a tensor with the same size as `input` that is filled with random numbers
    from a normal distribution with mean 0 and variance 1. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| [`randn_like`](generated/torch.randn_like.html#torch.randn_like "torch.randn_like")
    | 返回与`input`相同大小的张量，其中填充有来自均值为0，方差为1的正态分布的随机数。 |'
- en: '| [`randperm`](generated/torch.randperm.html#torch.randperm "torch.randperm")
    | Returns a random permutation of integers from `0` to `n - 1`. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| [`randperm`](generated/torch.randperm.html#torch.randperm "torch.randperm")
    | 返回从`0`到`n - 1`的整数的随机排列。 |'
- en: '### In-place random sampling[](#in-place-random-sampling "Permalink to this
    heading")'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '### 就地随机抽样[](#in-place-random-sampling "Permalink to this heading")'
- en: 'There are a few more in-place random sampling functions defined on Tensors
    as well. Click through to refer to their documentation:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些在张量上定义的就地随机抽样函数。点击查看它们的文档：
- en: '[`torch.Tensor.bernoulli_()`](generated/torch.Tensor.bernoulli_.html#torch.Tensor.bernoulli_
    "torch.Tensor.bernoulli_") - in-place version of [`torch.bernoulli()`](generated/torch.bernoulli.html#torch.bernoulli
    "torch.bernoulli")'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.bernoulli_()`](generated/torch.Tensor.bernoulli_.html#torch.Tensor.bernoulli_
    "torch.Tensor.bernoulli_") - [`torch.bernoulli()`](generated/torch.bernoulli.html#torch.bernoulli
    "torch.bernoulli")的就地版本'
- en: '[`torch.Tensor.cauchy_()`](generated/torch.Tensor.cauchy_.html#torch.Tensor.cauchy_
    "torch.Tensor.cauchy_") - numbers drawn from the Cauchy distribution'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.cauchy_()`](generated/torch.Tensor.cauchy_.html#torch.Tensor.cauchy_
    "torch.Tensor.cauchy_") - 从柯西分布中抽取的数字'
- en: '[`torch.Tensor.exponential_()`](generated/torch.Tensor.exponential_.html#torch.Tensor.exponential_
    "torch.Tensor.exponential_") - numbers drawn from the exponential distribution'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.exponential_()`](generated/torch.Tensor.exponential_.html#torch.Tensor.exponential_
    "torch.Tensor.exponential_") - 从指数分布中抽取的数字'
- en: '[`torch.Tensor.geometric_()`](generated/torch.Tensor.geometric_.html#torch.Tensor.geometric_
    "torch.Tensor.geometric_") - elements drawn from the geometric distribution'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.geometric_()`](generated/torch.Tensor.geometric_.html#torch.Tensor.geometric_
    "torch.Tensor.geometric_") - 从几何分布中抽取的元素'
- en: '[`torch.Tensor.log_normal_()`](generated/torch.Tensor.log_normal_.html#torch.Tensor.log_normal_
    "torch.Tensor.log_normal_") - samples from the log-normal distribution'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.log_normal_()`](generated/torch.Tensor.log_normal_.html#torch.Tensor.log_normal_
    "torch.Tensor.log_normal_") - 从对数正态分布中抽样'
- en: '[`torch.Tensor.normal_()`](generated/torch.Tensor.normal_.html#torch.Tensor.normal_
    "torch.Tensor.normal_") - in-place version of [`torch.normal()`](generated/torch.normal.html#torch.normal
    "torch.normal")'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.normal_()`](generated/torch.Tensor.normal_.html#torch.Tensor.normal_
    "torch.Tensor.normal_") - [`torch.normal()`](generated/torch.normal.html#torch.normal
    "torch.normal") 的原地版本'
- en: '[`torch.Tensor.random_()`](generated/torch.Tensor.random_.html#torch.Tensor.random_
    "torch.Tensor.random_") - numbers sampled from the discrete uniform distribution'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.random_()`](generated/torch.Tensor.random_.html#torch.Tensor.random_
    "torch.Tensor.random_") - 从离散均匀分布中抽取的数字'
- en: '[`torch.Tensor.uniform_()`](generated/torch.Tensor.uniform_.html#torch.Tensor.uniform_
    "torch.Tensor.uniform_") - numbers sampled from the continuous uniform distribution'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`torch.Tensor.uniform_()`](generated/torch.Tensor.uniform_.html#torch.Tensor.uniform_
    "torch.Tensor.uniform_") - 从连续均匀分布中抽取的数字'
- en: Quasi-random sampling
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准随机抽样
- en: '| [`quasirandom.SobolEngine`](generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine
    "torch.quasirandom.SobolEngine") | The [`torch.quasirandom.SobolEngine`](generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine
    "torch.quasirandom.SobolEngine") is an engine for generating (scrambled) Sobol
    sequences. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| [`quasirandom.SobolEngine`](generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine
    "torch.quasirandom.SobolEngine") | [`torch.quasirandom.SobolEngine`](generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine
    "torch.quasirandom.SobolEngine") 是用于生成（混淆）Sobol 序列的引擎。 |'
- en: Serialization
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序列化
- en: '| [`save`](generated/torch.save.html#torch.save "torch.save") | Saves an object
    to a disk file. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| [`save`](generated/torch.save.html#torch.save "torch.save") | 将对象保存到磁盘文件中。
    |'
- en: '| [`load`](generated/torch.load.html#torch.load "torch.load") | Loads an object
    saved with [`torch.save()`](generated/torch.save.html#torch.save "torch.save")
    from a file. |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| [`load`](generated/torch.load.html#torch.load "torch.load") | 从文件中加载使用 [`torch.save()`](generated/torch.save.html#torch.save
    "torch.save") 保存的对象。 |'
- en: Parallelism
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行性
- en: '| [`get_num_threads`](generated/torch.get_num_threads.html#torch.get_num_threads
    "torch.get_num_threads") | Returns the number of threads used for parallelizing
    CPU operations |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| [`get_num_threads`](generated/torch.get_num_threads.html#torch.get_num_threads
    "torch.get_num_threads") | 返回用于并行化 CPU 操作的线程数 |'
- en: '| [`set_num_threads`](generated/torch.set_num_threads.html#torch.set_num_threads
    "torch.set_num_threads") | Sets the number of threads used for intraop parallelism
    on CPU. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| [`set_num_threads`](generated/torch.set_num_threads.html#torch.set_num_threads
    "torch.set_num_threads") | 设置在 CPU 上用于内部并行性的线程数。 |'
- en: '| [`get_num_interop_threads`](generated/torch.get_num_interop_threads.html#torch.get_num_interop_threads
    "torch.get_num_interop_threads") | Returns the number of threads used for inter-op
    parallelism on CPU (e.g. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| [`get_num_interop_threads`](generated/torch.get_num_interop_threads.html#torch.get_num_interop_threads
    "torch.get_num_interop_threads") | 返回在 CPU 上用于互操作并行性的线程数（例如 |'
- en: '| [`set_num_interop_threads`](generated/torch.set_num_interop_threads.html#torch.set_num_interop_threads
    "torch.set_num_interop_threads") | Sets the number of threads used for interop
    parallelism (e.g. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| [`set_num_interop_threads`](generated/torch.set_num_interop_threads.html#torch.set_num_interop_threads
    "torch.set_num_interop_threads") | 设置用于互操作并行性的线程数（例如 |'
- en: '## Locally disabling gradient computation[](#locally-disabling-gradient-computation
    "Permalink to this heading")'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '## 本地禁用梯度计算[](#locally-disabling-gradient-computation "Permalink to this heading")'
- en: The context managers [`torch.no_grad()`](generated/torch.no_grad.html#torch.no_grad
    "torch.no_grad"), [`torch.enable_grad()`](generated/torch.enable_grad.html#torch.enable_grad
    "torch.enable_grad"), and [`torch.set_grad_enabled()`](generated/torch.set_grad_enabled.html#torch.set_grad_enabled
    "torch.set_grad_enabled") are helpful for locally disabling and enabling gradient
    computation. See [Locally disabling gradient computation](autograd.html#locally-disable-grad)
    for more details on their usage. These context managers are thread local, so they
    won’t work if you send work to another thread using the `threading` module, etc.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文管理器 [`torch.no_grad()`](generated/torch.no_grad.html#torch.no_grad "torch.no_grad")、[`torch.enable_grad()`](generated/torch.enable_grad.html#torch.enable_grad
    "torch.enable_grad") 和 [`torch.set_grad_enabled()`](generated/torch.set_grad_enabled.html#torch.set_grad_enabled
    "torch.set_grad_enabled") 对于本地禁用和启用梯度计算非常有用。有关它们的使用详情，请参阅[本地禁用梯度计算](autograd.html#locally-disable-grad)。这些上下文管理器是线程局部的，因此如果使用
    `threading` 模块等将工作发送到另一个线程，则它们将无法工作。
- en: 'Examples:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '| [`no_grad`](generated/torch.no_grad.html#torch.no_grad "torch.no_grad") |
    Context-manager that disables gradient calculation. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| [`no_grad`](generated/torch.no_grad.html#torch.no_grad "torch.no_grad") |
    禁用梯度计算的上下文管理器。 |'
- en: '| [`enable_grad`](generated/torch.enable_grad.html#torch.enable_grad "torch.enable_grad")
    | Context-manager that enables gradient calculation. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| [`enable_grad`](generated/torch.enable_grad.html#torch.enable_grad "torch.enable_grad")
    | 启用梯度计算的上下文管理器。 |'
- en: '| [`set_grad_enabled`](generated/torch.set_grad_enabled.html#torch.set_grad_enabled
    "torch.set_grad_enabled") | Context-manager that sets gradient calculation on
    or off. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| [`set_grad_enabled`](generated/torch.set_grad_enabled.html#torch.set_grad_enabled
    "torch.set_grad_enabled") | 上下文管理器，用于打开或关闭梯度计算。 |'
- en: '| [`is_grad_enabled`](generated/torch.is_grad_enabled.html#torch.is_grad_enabled
    "torch.is_grad_enabled") | Returns True if grad mode is currently enabled. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| [`is_grad_enabled`](generated/torch.is_grad_enabled.html#torch.is_grad_enabled
    "torch.is_grad_enabled") | 如果当前启用梯度模式，则返回True。 |'
- en: '| [`inference_mode`](generated/torch.inference_mode.html#torch.inference_mode
    "torch.inference_mode") | Context-manager that enables or disables inference mode.
    |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| [`inference_mode`](generated/torch.inference_mode.html#torch.inference_mode
    "torch.inference_mode") | 启用或禁用推理模式的上下文管理器。 |'
- en: '| [`is_inference_mode_enabled`](generated/torch.is_inference_mode_enabled.html#torch.is_inference_mode_enabled
    "torch.is_inference_mode_enabled") | Returns True if inference mode is currently
    enabled. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| [`is_inference_mode_enabled`](generated/torch.is_inference_mode_enabled.html#torch.is_inference_mode_enabled
    "torch.is_inference_mode_enabled") | 如果当前启用推理模式，则返回True。 |'
- en: Math operations
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Math operations
- en: Pointwise Ops
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pointwise Ops
- en: '| [`abs`](generated/torch.abs.html#torch.abs "torch.abs") | Computes the absolute
    value of each element in `input`. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| [`abs`](generated/torch.abs.html#torch.abs "torch.abs") | 计算`input`中每个元素的绝对值。
    |'
- en: '| [`absolute`](generated/torch.absolute.html#torch.absolute "torch.absolute")
    | Alias for [`torch.abs()`](generated/torch.abs.html#torch.abs "torch.abs") |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| [`absolute`](generated/torch.absolute.html#torch.absolute "torch.absolute")
    | [`torch.abs()`](generated/torch.abs.html#torch.abs "torch.abs")的别名。 |'
- en: '| [`acos`](generated/torch.acos.html#torch.acos "torch.acos") | Computes the
    inverse cosine of each element in `input`. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| [`acos`](generated/torch.acos.html#torch.acos "torch.acos") | 计算`input`中每个元素的反余弦值。
    |'
- en: '| [`arccos`](generated/torch.arccos.html#torch.arccos "torch.arccos") | Alias
    for [`torch.acos()`](generated/torch.acos.html#torch.acos "torch.acos"). |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| [`arccos`](generated/torch.arccos.html#torch.arccos "torch.arccos") | [`torch.acos()`](generated/torch.acos.html#torch.acos
    "torch.acos")的别名。 |'
- en: '| [`acosh`](generated/torch.acosh.html#torch.acosh "torch.acosh") | Returns
    a new tensor with the inverse hyperbolic cosine of the elements of `input`. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| [`acosh`](generated/torch.acosh.html#torch.acosh "torch.acosh") | 返回一个新的张量，其中包含`input`元素的反双曲余弦值。
    |'
- en: '| [`arccosh`](generated/torch.arccosh.html#torch.arccosh "torch.arccosh") |
    Alias for [`torch.acosh()`](generated/torch.acosh.html#torch.acosh "torch.acosh").
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| [`arccosh`](generated/torch.arccosh.html#torch.arccosh "torch.arccosh") |
    [`torch.acosh()`](generated/torch.acosh.html#torch.acosh "torch.acosh")的别名。 |'
- en: '| [`add`](generated/torch.add.html#torch.add "torch.add") | Adds `other`, scaled
    by `alpha`, to `input`. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| [`add`](generated/torch.add.html#torch.add "torch.add") | 将`other`按`alpha`缩放后加到`input`中。
    |'
- en: '| [`addcdiv`](generated/torch.addcdiv.html#torch.addcdiv "torch.addcdiv") |
    Performs the element-wise division of `tensor1` by `tensor2`, multiplies the result
    by the scalar `value` and adds it to `input`. |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| [`addcdiv`](generated/torch.addcdiv.html#torch.addcdiv "torch.addcdiv") |
    对`tensor1`和`tensor2`进行逐元素除法，将结果乘以标量`value`并加到`input`中。 |'
- en: '| [`addcmul`](generated/torch.addcmul.html#torch.addcmul "torch.addcmul") |
    Performs the element-wise multiplication of `tensor1` by `tensor2`, multiplies
    the result by the scalar `value` and adds it to `input`. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| [`addcmul`](generated/torch.addcmul.html#torch.addcmul "torch.addcmul") |
    对`tensor1`和`tensor2`进行逐元素相乘，将结果乘以标量`value`并加到`input`中。 |'
- en: '| [`angle`](generated/torch.angle.html#torch.angle "torch.angle") | Computes
    the element-wise angle (in radians) of the given `input` tensor. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| [`angle`](generated/torch.angle.html#torch.angle "torch.angle") | 计算给定`input`张量的逐元素角度（弧度）。
    |'
- en: '| [`asin`](generated/torch.asin.html#torch.asin "torch.asin") | Returns a new
    tensor with the arcsine of the elements of `input`. |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| [`asin`](generated/torch.asin.html#torch.asin "torch.asin") | 返回一个新的张量，其中包含`input`元素的反正弦值。
    |'
- en: '| [`arcsin`](generated/torch.arcsin.html#torch.arcsin "torch.arcsin") | Alias
    for [`torch.asin()`](generated/torch.asin.html#torch.asin "torch.asin"). |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| [`arcsin`](generated/torch.arcsin.html#torch.arcsin "torch.arcsin") | [`torch.asin()`](generated/torch.asin.html#torch.asin
    "torch.asin")的别名。 |'
- en: '| [`asinh`](generated/torch.asinh.html#torch.asinh "torch.asinh") | Returns
    a new tensor with the inverse hyperbolic sine of the elements of `input`. |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| [`asinh`](generated/torch.asinh.html#torch.asinh "torch.asinh") | 返回一个新的张量，其中包含`input`元素的反双曲正弦值。
    |'
- en: '| [`arcsinh`](generated/torch.arcsinh.html#torch.arcsinh "torch.arcsinh") |
    Alias for [`torch.asinh()`](generated/torch.asinh.html#torch.asinh "torch.asinh").
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| [`arcsinh`](generated/torch.arcsinh.html#torch.arcsinh "torch.arcsinh") |
    [`torch.asinh()`](generated/torch.asinh.html#torch.asinh "torch.asinh")的别名。 |'
- en: '| [`atan`](generated/torch.atan.html#torch.atan "torch.atan") | Returns a new
    tensor with the arctangent of the elements of `input`. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| [`atan`](generated/torch.atan.html#torch.atan "torch.atan") | 返回一个新的张量，其中包含`input`元素的反正切值。
    |'
- en: '| [`arctan`](generated/torch.arctan.html#torch.arctan "torch.arctan") | Alias
    for [`torch.atan()`](generated/torch.atan.html#torch.atan "torch.atan"). |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| [`arctan`](generated/torch.arctan.html#torch.arctan "torch.arctan") | [`torch.atan()`](generated/torch.atan.html#torch.atan
    "torch.atan")的别名。 |'
- en: '| [`atanh`](generated/torch.atanh.html#torch.atanh "torch.atanh") | Returns
    a new tensor with the inverse hyperbolic tangent of the elements of `input`. |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| [`atanh`](generated/torch.atanh.html#torch.atanh "torch.atanh") | 返回一个新的张量，其中包含`input`元素的反双曲正切值。
    |'
- en: '| [`arctanh`](generated/torch.arctanh.html#torch.arctanh "torch.arctanh") |
    Alias for [`torch.atanh()`](generated/torch.atanh.html#torch.atanh "torch.atanh").
    |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| [`arctanh`](generated/torch.arctanh.html#torch.arctanh "torch.arctanh") |
    [`torch.atanh()`](generated/torch.atanh.html#torch.atanh "torch.atanh")的别名。 |'
- en: '| [`atan2`](generated/torch.atan2.html#torch.atan2 "torch.atan2") | Element-wise
    arctangent of $\text{input}_{i} / \text{other}_{i}$inputi​/otheri​ with consideration
    of the quadrant. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| [`atan2`](generated/torch.atan2.html#torch.atan2 "torch.atan2") | 考虑象限的`inputi​/otheri​`的逐元素反正切。
    |'
- en: '| [`arctan2`](generated/torch.arctan2.html#torch.arctan2 "torch.arctan2") |
    Alias for [`torch.atan2()`](generated/torch.atan2.html#torch.atan2 "torch.atan2").
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| [`arctan2`](generated/torch.arctan2.html#torch.arctan2 "torch.arctan2") |
    [`torch.atan2()`](generated/torch.atan2.html#torch.atan2 "torch.atan2")的别名。 |'
- en: '| [`bitwise_not`](generated/torch.bitwise_not.html#torch.bitwise_not "torch.bitwise_not")
    | Computes the bitwise NOT of the given input tensor. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| [`bitwise_not`](generated/torch.bitwise_not.html#torch.bitwise_not "torch.bitwise_not")
    | 计算给定输入张量的按位非。 |'
- en: '| [`bitwise_and`](generated/torch.bitwise_and.html#torch.bitwise_and "torch.bitwise_and")
    | Computes the bitwise AND of `input` and `other`. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| [`bitwise_and`](generated/torch.bitwise_and.html#torch.bitwise_and "torch.bitwise_and")
    | 计算`input`和`other`的按位与。 |'
- en: '| [`bitwise_or`](generated/torch.bitwise_or.html#torch.bitwise_or "torch.bitwise_or")
    | Computes the bitwise OR of `input` and `other`. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| [`bitwise_or`](generated/torch.bitwise_or.html#torch.bitwise_or "torch.bitwise_or")
    | 计算`input`和`other`的按位或。 |'
- en: '| [`bitwise_xor`](generated/torch.bitwise_xor.html#torch.bitwise_xor "torch.bitwise_xor")
    | Computes the bitwise XOR of `input` and `other`. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| [`bitwise_xor`](generated/torch.bitwise_xor.html#torch.bitwise_xor "torch.bitwise_xor")
    | 计算`input`和`other`的按位异或。 |'
- en: '| [`bitwise_left_shift`](generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift
    "torch.bitwise_left_shift") | Computes the left arithmetic shift of `input` by
    `other` bits. |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| [`bitwise_left_shift`](generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift
    "torch.bitwise_left_shift") | 计算`input`按`other`位的左算术移位。 |'
- en: '| [`bitwise_right_shift`](generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift
    "torch.bitwise_right_shift") | Computes the right arithmetic shift of `input`
    by `other` bits. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| [`bitwise_right_shift`](generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift
    "torch.bitwise_right_shift") | 计算`input`按`other`位的右算术移位。 |'
- en: '| [`ceil`](generated/torch.ceil.html#torch.ceil "torch.ceil") | Returns a new
    tensor with the ceil of the elements of `input`, the smallest integer greater
    than or equal to each element. |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| [`ceil`](generated/torch.ceil.html#torch.ceil "torch.ceil") | 返回一个新的张量，其中包含`input`元素的上限，即大于或等于每个元素的最小整数。
    |'
- en: '| [`clamp`](generated/torch.clamp.html#torch.clamp "torch.clamp") | Clamps
    all elements in `input` into the range [ [`min`](generated/torch.min.html#torch.min
    "torch.min"), [`max`](generated/torch.max.html#torch.max "torch.max") ]. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| [`clamp`](generated/torch.clamp.html#torch.clamp "torch.clamp") | 将`input`中的所有元素夹紧到范围[`min`](generated/torch.min.html#torch.min
    "torch.min"), [`max`](generated/torch.max.html#torch.max "torch.max")内。 |'
- en: '| [`clip`](generated/torch.clip.html#torch.clip "torch.clip") | Alias for [`torch.clamp()`](generated/torch.clamp.html#torch.clamp
    "torch.clamp"). |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| [`clip`](generated/torch.clip.html#torch.clip "torch.clip") | [`torch.clamp()`](generated/torch.clamp.html#torch.clamp
    "torch.clamp")的别名。 |'
- en: '| [`conj_physical`](generated/torch.conj_physical.html#torch.conj_physical
    "torch.conj_physical") | Computes the element-wise conjugate of the given `input`
    tensor. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| [`conj_physical`](generated/torch.conj_physical.html#torch.conj_physical
    "torch.conj_physical") | 计算给定`input`张量的逐元素共轭。 |'
- en: '| [`copysign`](generated/torch.copysign.html#torch.copysign "torch.copysign")
    | Create a new floating-point tensor with the magnitude of `input` and the sign
    of `other`, elementwise. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| [`copysign`](generated/torch.copysign.html#torch.copysign "torch.copysign")
    | 创建一个新的浮点张量，其大小为`input`，符号为`other`，逐元素。 |'
- en: '| [`cos`](generated/torch.cos.html#torch.cos "torch.cos") | Returns a new tensor
    with the cosine of the elements of `input`. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| [`cos`](generated/torch.cos.html#torch.cos "torch.cos") | 返回一个新的张量，其中包含`input`元素的余弦值。
    |'
- en: '| [`cosh`](generated/torch.cosh.html#torch.cosh "torch.cosh") | Returns a new
    tensor with the hyperbolic cosine of the elements of `input`. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| [`cosh`](generated/torch.cosh.html#torch.cosh "torch.cosh") | 返回一个新的张量，其中包含`input`元素的双曲余弦值。
    |'
- en: '| [`deg2rad`](generated/torch.deg2rad.html#torch.deg2rad "torch.deg2rad") |
    Returns a new tensor with each of the elements of `input` converted from angles
    in degrees to radians. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| [`deg2rad`](generated/torch.deg2rad.html#torch.deg2rad "torch.deg2rad") |
    返回一个新的张量，其中包含`input`中每个元素从角度转换为弧度。 |'
- en: '| [`div`](generated/torch.div.html#torch.div "torch.div") | Divides each element
    of the input `input` by the corresponding element of `other`. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| [`div`](generated/torch.div.html#torch.div "torch.div") | 将输入`input`的每个元素除以相应的`other`元素。
    |'
- en: '| [`divide`](generated/torch.divide.html#torch.divide "torch.divide") | Alias
    for [`torch.div()`](generated/torch.div.html#torch.div "torch.div"). |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| [`divide`](generated/torch.divide.html#torch.divide "torch.divide") | [`torch.div()`](generated/torch.div.html#torch.div
    "torch.div")的别名。 |'
- en: '| [`digamma`](generated/torch.digamma.html#torch.digamma "torch.digamma") |
    Alias for [`torch.special.digamma()`](special.html#torch.special.digamma "torch.special.digamma").
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| [`digamma`](generated/torch.digamma.html#torch.digamma "torch.digamma") |
    [`torch.special.digamma()`](special.html#torch.special.digamma "torch.special.digamma")的别名。
    |'
- en: '| [`erf`](generated/torch.erf.html#torch.erf "torch.erf") | Alias for [`torch.special.erf()`](special.html#torch.special.erf
    "torch.special.erf"). |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| [`erf`](generated/torch.erf.html#torch.erf "torch.erf") | [`torch.special.erf()`](special.html#torch.special.erf
    "torch.special.erf")的别名。 |'
- en: '| [`erfc`](generated/torch.erfc.html#torch.erfc "torch.erfc") | Alias for [`torch.special.erfc()`](special.html#torch.special.erfc
    "torch.special.erfc"). |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| [`erfc`](generated/torch.erfc.html#torch.erfc "torch.erfc") | [`torch.special.erfc()`](special.html#torch.special.erfc
    "torch.special.erfc")的别名。 |'
- en: '| [`erfinv`](generated/torch.erfinv.html#torch.erfinv "torch.erfinv") | Alias
    for [`torch.special.erfinv()`](special.html#torch.special.erfinv "torch.special.erfinv").
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| [`erfinv`](generated/torch.erfinv.html#torch.erfinv "torch.erfinv") | [`torch.special.erfinv()`](special.html#torch.special.erfinv
    "torch.special.erfinv")的别名。 |'
- en: '| [`exp`](generated/torch.exp.html#torch.exp "torch.exp") | Returns a new tensor
    with the exponential of the elements of the input tensor `input`. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| [`exp`](generated/torch.exp.html#torch.exp "torch.exp") | 返回一个新的张量，其中包含输入张量`input`元素的指数。
    |'
- en: '| [`exp2`](generated/torch.exp2.html#torch.exp2 "torch.exp2") | Alias for [`torch.special.exp2()`](special.html#torch.special.exp2
    "torch.special.exp2"). |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| [`exp2`](generated/torch.exp2.html#torch.exp2 "torch.exp2") | [`torch.special.exp2()`](special.html#torch.special.exp2
    "torch.special.exp2")的别名。 |'
- en: '| [`expm1`](generated/torch.expm1.html#torch.expm1 "torch.expm1") | Alias for
    [`torch.special.expm1()`](special.html#torch.special.expm1 "torch.special.expm1").
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| [`expm1`](generated/torch.expm1.html#torch.expm1 "torch.expm1") | [`torch.special.expm1()`](special.html#torch.special.expm1
    "torch.special.expm1")的别名。 |'
- en: '| [`fake_quantize_per_channel_affine`](generated/torch.fake_quantize_per_channel_affine.html#torch.fake_quantize_per_channel_affine
    "torch.fake_quantize_per_channel_affine") | Returns a new tensor with the data
    in `input` fake quantized per channel using `scale`, `zero_point`, `quant_min`
    and `quant_max`, across the channel specified by `axis`. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| [`fake_quantize_per_channel_affine`](generated/torch.fake_quantize_per_channel_affine.html#torch.fake_quantize_per_channel_affine
    "torch.fake_quantize_per_channel_affine") | 返回一个新的张量，其中包含使用`scale`、`zero_point`、`quant_min`和`quant_max`对`input`进行每通道伪量化的数据，跨通道由`axis`指定。
    |'
- en: '| [`fake_quantize_per_tensor_affine`](generated/torch.fake_quantize_per_tensor_affine.html#torch.fake_quantize_per_tensor_affine
    "torch.fake_quantize_per_tensor_affine") | Returns a new tensor with the data
    in `input` fake quantized using `scale`, `zero_point`, `quant_min` and `quant_max`.
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| [`fake_quantize_per_tensor_affine`](generated/torch.fake_quantize_per_tensor_affine.html#torch.fake_quantize_per_tensor_affine
    "torch.fake_quantize_per_tensor_affine") | 使用 `scale`、`zero_point`、`quant_min`
    和 `quant_max` 对 `input` 中的数据进行伪量化，并返回一个新的张量。 |'
- en: '| [`fix`](generated/torch.fix.html#torch.fix "torch.fix") | Alias for [`torch.trunc()`](generated/torch.trunc.html#torch.trunc
    "torch.trunc") |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| [`fix`](generated/torch.fix.html#torch.fix "torch.fix") | [`torch.trunc()`](generated/torch.trunc.html#torch.trunc
    "torch.trunc") 的别名 |'
- en: '| [`float_power`](generated/torch.float_power.html#torch.float_power "torch.float_power")
    | Raises `input` to the power of `exponent`, elementwise, in double precision.
    |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| [`float_power`](generated/torch.float_power.html#torch.float_power "torch.float_power")
    | 以双精度计算，对 `input` 的每个元素进行 `exponent` 次幂运算。 |'
- en: '| [`floor`](generated/torch.floor.html#torch.floor "torch.floor") | Returns
    a new tensor with the floor of the elements of `input`, the largest integer less
    than or equal to each element. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| [`floor`](generated/torch.floor.html#torch.floor "torch.floor") | 返回一个新的张量，其元素为
    `input` 的下取整，即小于或等于每个元素的最大整数。 |'
- en: '| [`floor_divide`](generated/torch.floor_divide.html#torch.floor_divide "torch.floor_divide")
    |  |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| [`floor_divide`](generated/torch.floor_divide.html#torch.floor_divide "torch.floor_divide")
    |  |'
- en: '| [`fmod`](generated/torch.fmod.html#torch.fmod "torch.fmod") | Applies C++''s
    [std::fmod](https://en.cppreference.com/w/cpp/numeric/math/fmod) entrywise. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| [`fmod`](generated/torch.fmod.html#torch.fmod "torch.fmod") | 对每个元素应用 C++
    的 [std::fmod](https://en.cppreference.com/w/cpp/numeric/math/fmod)。 |'
- en: '| [`frac`](generated/torch.frac.html#torch.frac "torch.frac") | Computes the
    fractional portion of each element in `input`. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| [`frac`](generated/torch.frac.html#torch.frac "torch.frac") | 计算 `input`
    中每个元素的小数部分。 |'
- en: '| [`frexp`](generated/torch.frexp.html#torch.frexp "torch.frexp") | Decomposes
    `input` into mantissa and exponent tensors such that $\text{input} = \text{mantissa}
    \times 2^{\text{exponent}}$input=mantissa×2exponent. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| [`frexp`](generated/torch.frexp.html#torch.frexp "torch.frexp") | 将 `input`
    分解为尾数和指数张量，使得 $\text{input} = \text{mantissa} \times 2^{\text{exponent}}$。 |'
- en: '| [`gradient`](generated/torch.gradient.html#torch.gradient "torch.gradient")
    | Estimates the gradient of a function $g : \mathbb{R}^n \rightarrow \mathbb{R}$g:Rn→R
    in one or more dimensions using the [second-order accurate central differences
    method](https://www.ams.org/journals/mcom/1988-51-184/S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf)
    and either first or second order estimates at the boundaries. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| [`gradient`](generated/torch.gradient.html#torch.gradient "torch.gradient")
    | 使用 [二阶中心差分方法](https://www.ams.org/journals/mcom/1988-51-184/S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf)
    在一个或多个维度上估计函数 $g : \mathbb{R}^n \rightarrow \mathbb{R}$g:Rn→R 的梯度，并在边界处使用一阶或二阶估计。
    |'
- en: '| [`imag`](generated/torch.imag.html#torch.imag "torch.imag") | Returns a new
    tensor containing imaginary values of the `self` tensor. |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| [`imag`](generated/torch.imag.html#torch.imag "torch.imag") | 返回一个包含 `self`
    张量的虚部的新张量。 |'
- en: '| [`ldexp`](generated/torch.ldexp.html#torch.ldexp "torch.ldexp") | Multiplies
    `input` by 2 ** `other`. |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| [`ldexp`](generated/torch.ldexp.html#torch.ldexp "torch.ldexp") | 将 `input`
    乘以 2 ** `other`。 |'
- en: '| [`lerp`](generated/torch.lerp.html#torch.lerp "torch.lerp") | Does a linear
    interpolation of two tensors `start` (given by `input`) and `end` based on a scalar
    or tensor `weight` and returns the resulting `out` tensor. |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| [`lerp`](generated/torch.lerp.html#torch.lerp "torch.lerp") | 根据标量或张量 `weight`
    对两个张量 `start`（由 `input` 给出）和 `end` 进行线性插值，并返回结果张量 `out`。 |'
- en: '| [`lgamma`](generated/torch.lgamma.html#torch.lgamma "torch.lgamma") | Computes
    the natural logarithm of the absolute value of the gamma function on `input`.
    |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| [`lgamma`](generated/torch.lgamma.html#torch.lgamma "torch.lgamma") | 计算
    `input` 上伽玛函数绝对值的自然对数。 |'
- en: '| [`log`](generated/torch.log.html#torch.log "torch.log") | Returns a new tensor
    with the natural logarithm of the elements of `input`. |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| [`log`](generated/torch.log.html#torch.log "torch.log") | 返回一个新的张量，其元素为 `input`
    的自然对数。 |'
- en: '| [`log10`](generated/torch.log10.html#torch.log10 "torch.log10") | Returns
    a new tensor with the logarithm to the base 10 of the elements of `input`. |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| [`log10`](generated/torch.log10.html#torch.log10 "torch.log10") | 返回一个新的张量，其元素为
    `input` 的以 10 为底的对数。 |'
- en: '| [`log1p`](generated/torch.log1p.html#torch.log1p "torch.log1p") | Returns
    a new tensor with the natural logarithm of (1 + `input`). |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| [`log1p`](generated/torch.log1p.html#torch.log1p "torch.log1p") | 返回一个新的张量，其元素为
    (1 + `input`) 的自然对数。 |'
- en: '| [`log2`](generated/torch.log2.html#torch.log2 "torch.log2") | Returns a new
    tensor with the logarithm to the base 2 of the elements of `input`. |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| [`log2`](generated/torch.log2.html#torch.log2 "torch.log2") | 返回一个新的张量，其元素为
    `input` 的以 2 为底的对数。 |'
- en: '| [`logaddexp`](generated/torch.logaddexp.html#torch.logaddexp "torch.logaddexp")
    | Logarithm of the sum of exponentiations of the inputs. |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| [`logaddexp`](generated/torch.logaddexp.html#torch.logaddexp "torch.logaddexp")
    | 对输入的指数求和的对数。 |'
- en: '| [`logaddexp2`](generated/torch.logaddexp2.html#torch.logaddexp2 "torch.logaddexp2")
    | Logarithm of the sum of exponentiations of the inputs in base-2. |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| [`logaddexp2`](generated/torch.logaddexp2.html#torch.logaddexp2 "torch.logaddexp2")
    | 以 2 为底对输入的指数求和的对数。 |'
- en: '| [`logical_and`](generated/torch.logical_and.html#torch.logical_and "torch.logical_and")
    | Computes the element-wise logical AND of the given input tensors. |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| [`logical_and`](generated/torch.logical_and.html#torch.logical_and "torch.logical_and")
    | 计算给定输入张量的逐元素逻辑与。 |'
- en: '| [`logical_not`](generated/torch.logical_not.html#torch.logical_not "torch.logical_not")
    | Computes the element-wise logical NOT of the given input tensor. |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| [`logical_not`](generated/torch.logical_not.html#torch.logical_not "torch.logical_not")
    | 计算给定输入张量的逐元素逻辑非。 |'
- en: '| [`logical_or`](generated/torch.logical_or.html#torch.logical_or "torch.logical_or")
    | Computes the element-wise logical OR of the given input tensors. |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| [`logical_or`](generated/torch.logical_or.html#torch.logical_or "torch.logical_or")
    | 计算给定输入张量的逐元素逻辑或。 |'
- en: '| [`logical_xor`](generated/torch.logical_xor.html#torch.logical_xor "torch.logical_xor")
    | Computes the element-wise logical XOR of the given input tensors. |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| [`logical_xor`](generated/torch.logical_xor.html#torch.logical_xor "torch.logical_xor")
    | 计算给定输入张量的逐元素逻辑异或。 |'
- en: '| [`logit`](generated/torch.logit.html#torch.logit "torch.logit") | Alias for
    [`torch.special.logit()`](special.html#torch.special.logit "torch.special.logit").
    |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| [`logit`](生成/torch.logit.html#torch.logit "torch.logit") | [`torch.special.logit()`](special.html#torch.special.logit
    "torch.special.logit") 的别名。|'
- en: '| [`hypot`](generated/torch.hypot.html#torch.hypot "torch.hypot") | Given the
    legs of a right triangle, return its hypotenuse. |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| [`hypot`](生成/torch.hypot.html#torch.hypot "torch.hypot") | 给定直角三角形的两条直角边，返回其斜边。|'
- en: '| [`i0`](generated/torch.i0.html#torch.i0 "torch.i0") | Alias for [`torch.special.i0()`](special.html#torch.special.i0
    "torch.special.i0"). |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| [`i0`](生成/torch.i0.html#torch.i0 "torch.i0") | [`torch.special.i0()`](special.html#torch.special.i0
    "torch.special.i0") 的别名。|'
- en: '| [`igamma`](generated/torch.igamma.html#torch.igamma "torch.igamma") | Alias
    for [`torch.special.gammainc()`](special.html#torch.special.gammainc "torch.special.gammainc").
    |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| [`igamma`](生成/torch.igamma.html#torch.igamma "torch.igamma") | [`torch.special.gammainc()`](special.html#torch.special.gammainc
    "torch.special.gammainc") 的别名。|'
- en: '| [`igammac`](generated/torch.igammac.html#torch.igammac "torch.igammac") |
    Alias for [`torch.special.gammaincc()`](special.html#torch.special.gammaincc "torch.special.gammaincc").
    |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| [`igammac`](生成/torch.igammac.html#torch.igammac "torch.igammac") | [`torch.special.gammaincc()`](special.html#torch.special.gammaincc
    "torch.special.gammaincc") 的别名。|'
- en: '| [`mul`](generated/torch.mul.html#torch.mul "torch.mul") | Multiplies `input`
    by `other`. |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| [`mul`](生成/torch.mul.html#torch.mul "torch.mul") | 将 `input` 乘以 `other`。|'
- en: '| [`multiply`](generated/torch.multiply.html#torch.multiply "torch.multiply")
    | Alias for [`torch.mul()`](generated/torch.mul.html#torch.mul "torch.mul"). |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| [`multiply`](生成/torch.multiply.html#torch.multiply "torch.multiply") | [`torch.mul()`](生成/torch.mul.html#torch.mul
    "torch.mul") 的别名。|'
- en: '| [`mvlgamma`](generated/torch.mvlgamma.html#torch.mvlgamma "torch.mvlgamma")
    | Alias for [`torch.special.multigammaln()`](special.html#torch.special.multigammaln
    "torch.special.multigammaln"). |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| [`mvlgamma`](生成/torch.mvlgamma.html#torch.mvlgamma "torch.mvlgamma") | [`torch.special.multigammaln()`](special.html#torch.special.multigammaln
    "torch.special.multigammaln") 的别名。|'
- en: '| [`nan_to_num`](generated/torch.nan_to_num.html#torch.nan_to_num "torch.nan_to_num")
    | Replaces `NaN`, positive infinity, and negative infinity values in `input` with
    the values specified by `nan`, `posinf`, and `neginf`, respectively. |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| [`nan_to_num`](生成/torch.nan_to_num.html#torch.nan_to_num "torch.nan_to_num")
    | 用 `nan`、`posinf` 和 `neginf` 指定的值替换 `input` 中的 `NaN`、正无穷大和负无穷大值。|'
- en: '| [`neg`](generated/torch.neg.html#torch.neg "torch.neg") | Returns a new tensor
    with the negative of the elements of `input`. |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| [`neg`](生成/torch.neg.html#torch.neg "torch.neg") | 返回一个新的张量，其元素为 `input`
    的负数。|'
- en: '| [`negative`](generated/torch.negative.html#torch.negative "torch.negative")
    | Alias for [`torch.neg()`](generated/torch.neg.html#torch.neg "torch.neg") |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| [`negative`](生成/torch.negative.html#torch.negative "torch.negative") | [`torch.neg()`](生成/torch.neg.html#torch.neg
    "torch.neg") 的别名。|'
- en: '| [`nextafter`](generated/torch.nextafter.html#torch.nextafter "torch.nextafter")
    | Return the next floating-point value after `input` towards `other`, elementwise.
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| [`nextafter`](生成/torch.nextafter.html#torch.nextafter "torch.nextafter")
    | 返回 `input` 向 `other` 方向的下一个浮点值，逐元素进行。|'
- en: '| [`polygamma`](generated/torch.polygamma.html#torch.polygamma "torch.polygamma")
    | Alias for [`torch.special.polygamma()`](special.html#torch.special.polygamma
    "torch.special.polygamma"). |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| [`polygamma`](生成/torch.polygamma.html#torch.polygamma "torch.polygamma")
    | [`torch.special.polygamma()`](special.html#torch.special.polygamma "torch.special.polygamma")
    的别名。|'
- en: '| [`positive`](generated/torch.positive.html#torch.positive "torch.positive")
    | Returns `input`. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| [`positive`](生成/torch.positive.html#torch.positive "torch.positive") | 返回
    `input`。|'
- en: '| [`pow`](generated/torch.pow.html#torch.pow "torch.pow") | Takes the power
    of each element in `input` with `exponent` and returns a tensor with the result.
    |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| [`pow`](生成/torch.pow.html#torch.pow "torch.pow") | 对 `input` 中的每个元素进行 `exponent`
    次幂运算，并返回结果张量。|'
- en: '| [`quantized_batch_norm`](generated/torch.quantized_batch_norm.html#torch.quantized_batch_norm
    "torch.quantized_batch_norm") | Applies batch normalization on a 4D (NCHW) quantized
    tensor. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| [`quantized_batch_norm`](生成/torch.quantized_batch_norm.html#torch.quantized_batch_norm
    "torch.quantized_batch_norm") | 对4D（NCHW）量化张量应用批量归一化。|'
- en: '| [`quantized_max_pool1d`](generated/torch.quantized_max_pool1d.html#torch.quantized_max_pool1d
    "torch.quantized_max_pool1d") | Applies a 1D max pooling over an input quantized
    tensor composed of several input planes. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| [`quantized_max_pool1d`](生成/torch.quantized_max_pool1d.html#torch.quantized_max_pool1d
    "torch.quantized_max_pool1d") | 对由多个输入平面组成的输入量化张量应用1D最大池化。|'
- en: '| [`quantized_max_pool2d`](generated/torch.quantized_max_pool2d.html#torch.quantized_max_pool2d
    "torch.quantized_max_pool2d") | Applies a 2D max pooling over an input quantized
    tensor composed of several input planes. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| [`quantized_max_pool2d`](生成/torch.quantized_max_pool2d.html#torch.quantized_max_pool2d
    "torch.quantized_max_pool2d") | 对由多个输入平面组成的输入量化张量应用2D最大池化。|'
- en: '| [`rad2deg`](generated/torch.rad2deg.html#torch.rad2deg "torch.rad2deg") |
    Returns a new tensor with each of the elements of `input` converted from angles
    in radians to degrees. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| [`rad2deg`](生成/torch.rad2deg.html#torch.rad2deg "torch.rad2deg") | 返回一个新的张量，其中
    `input` 的每个元素从弧度转换为度。|'
- en: '| [`real`](generated/torch.real.html#torch.real "torch.real") | Returns a new
    tensor containing real values of the `self` tensor. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| [`real`](生成/torch.real.html#torch.real "torch.real") | 返回一个包含 `self` 张量的实数值的新张量。|'
- en: '| [`reciprocal`](generated/torch.reciprocal.html#torch.reciprocal "torch.reciprocal")
    | Returns a new tensor with the reciprocal of the elements of `input` |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| [`reciprocal`](生成/torch.reciprocal.html#torch.reciprocal "torch.reciprocal")
    | 返回一个新的张量，其元素为 `input` 的倒数。|'
- en: '| [`remainder`](generated/torch.remainder.html#torch.remainder "torch.remainder")
    | Computes [Python''s modulus operation](https://docs.python.org/3/reference/expressions.html#binary-arithmetic-operations)
    entrywise. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| [`remainder`](生成/torch.remainder.html#torch.remainder "torch.remainder")
    | 计算逐元素的[Python取模运算](https://docs.python.org/3/reference/expressions.html#binary-arithmetic-operations)。|'
- en: '| [`round`](generated/torch.round.html#torch.round "torch.round") | Rounds
    elements of `input` to the nearest integer. |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| [`round`](生成/torch.round.html#torch.round "torch.round") | 将 `input` 的元素四舍五入到最接近的整数。|'
- en: '| [`rsqrt`](generated/torch.rsqrt.html#torch.rsqrt "torch.rsqrt") | Returns
    a new tensor with the reciprocal of the square-root of each of the elements of
    `input`. |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| [`rsqrt`](生成/torch.rsqrt.html#torch.rsqrt "torch.rsqrt") | 返回一个新的张量，其元素为
    `input` 的平方根的倒数。|'
- en: '| [`sigmoid`](generated/torch.sigmoid.html#torch.sigmoid "torch.sigmoid") |
    Alias for [`torch.special.expit()`](special.html#torch.special.expit "torch.special.expit").
    |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| [`sigmoid`](generated/torch.sigmoid.html#torch.sigmoid "torch.sigmoid") |
    [`torch.special.expit()`](special.html#torch.special.expit "torch.special.expit")的别名。
    |'
- en: '| [`sign`](generated/torch.sign.html#torch.sign "torch.sign") | Returns a new
    tensor with the signs of the elements of `input`. |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| [`sign`](generated/torch.sign.html#torch.sign "torch.sign") | 返回具有`input`元素的符号的新张量。
    |'
- en: '| [`sgn`](generated/torch.sgn.html#torch.sgn "torch.sgn") | This function is
    an extension of torch.sign() to complex tensors. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| [`sgn`](generated/torch.sgn.html#torch.sgn "torch.sgn") | 这个函数是对复数张量的torch.sign()的扩展。
    |'
- en: '| [`signbit`](generated/torch.signbit.html#torch.signbit "torch.signbit") |
    Tests if each element of `input` has its sign bit set or not. |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| [`signbit`](generated/torch.signbit.html#torch.signbit "torch.signbit") |
    检查`input`的每个元素是否设置了符号位。 |'
- en: '| [`sin`](generated/torch.sin.html#torch.sin "torch.sin") | Returns a new tensor
    with the sine of the elements of `input`. |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| [`sin`](generated/torch.sin.html#torch.sin "torch.sin") | 返回具有`input`元素的正弦的新张量。
    |'
- en: '| [`sinc`](generated/torch.sinc.html#torch.sinc "torch.sinc") | Alias for [`torch.special.sinc()`](special.html#torch.special.sinc
    "torch.special.sinc"). |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| [`sinc`](generated/torch.sinc.html#torch.sinc "torch.sinc") | [`torch.special.sinc()`](special.html#torch.special.sinc
    "torch.special.sinc")的别名。 |'
- en: '| [`sinh`](generated/torch.sinh.html#torch.sinh "torch.sinh") | Returns a new
    tensor with the hyperbolic sine of the elements of `input`. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| [`sinh`](generated/torch.sinh.html#torch.sinh "torch.sinh") | 返回具有`input`元素的双曲正弦的新张量。
    |'
- en: '| [`softmax`](generated/torch.softmax.html#torch.softmax "torch.softmax") |
    Alias for [`torch.nn.functional.softmax()`](generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax
    "torch.nn.functional.softmax"). |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| [`softmax`](generated/torch.softmax.html#torch.softmax "torch.softmax") |
    [`torch.nn.functional.softmax()`](generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax
    "torch.nn.functional.softmax")的别名。 |'
- en: '| [`sqrt`](generated/torch.sqrt.html#torch.sqrt "torch.sqrt") | Returns a new
    tensor with the square-root of the elements of `input`. |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| [`sqrt`](generated/torch.sqrt.html#torch.sqrt "torch.sqrt") | 返回具有`input`元素的平方根的新张量。
    |'
- en: '| [`square`](generated/torch.square.html#torch.square "torch.square") | Returns
    a new tensor with the square of the elements of `input`. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| [`square`](generated/torch.square.html#torch.square "torch.square") | 返回具有`input`元素的平方的新张量。
    |'
- en: '| [`sub`](generated/torch.sub.html#torch.sub "torch.sub") | Subtracts `other`,
    scaled by `alpha`, from `input`. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| [`sub`](generated/torch.sub.html#torch.sub "torch.sub") | 从`input`中减去经过`alpha`缩放的`other`。
    |'
- en: '| [`subtract`](generated/torch.subtract.html#torch.subtract "torch.subtract")
    | Alias for [`torch.sub()`](generated/torch.sub.html#torch.sub "torch.sub"). |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| [`subtract`](generated/torch.subtract.html#torch.subtract "torch.subtract")
    | [`torch.sub()`](generated/torch.sub.html#torch.sub "torch.sub")的别名。 |'
- en: '| [`tan`](generated/torch.tan.html#torch.tan "torch.tan") | Returns a new tensor
    with the tangent of the elements of `input`. |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| [`tan`](generated/torch.tan.html#torch.tan "torch.tan") | 返回具有`input`元素的正切的新张量。
    |'
- en: '| [`tanh`](generated/torch.tanh.html#torch.tanh "torch.tanh") | Returns a new
    tensor with the hyperbolic tangent of the elements of `input`. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| [`tanh`](generated/torch.tanh.html#torch.tanh "torch.tanh") | 返回具有`input`元素的双曲正切的新张量。
    |'
- en: '| [`true_divide`](generated/torch.true_divide.html#torch.true_divide "torch.true_divide")
    | Alias for [`torch.div()`](generated/torch.div.html#torch.div "torch.div") with
    `rounding_mode=None`. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| [`true_divide`](generated/torch.true_divide.html#torch.true_divide "torch.true_divide")
    | 使用`rounding_mode=None`的[`torch.div()`](generated/torch.div.html#torch.div "torch.div")的别名。
    |'
- en: '| [`trunc`](generated/torch.trunc.html#torch.trunc "torch.trunc") | Returns
    a new tensor with the truncated integer values of the elements of `input`. |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| [`trunc`](generated/torch.trunc.html#torch.trunc "torch.trunc") | 返回具有`input`元素的截断整数值的新张量。
    |'
- en: '| [`xlogy`](generated/torch.xlogy.html#torch.xlogy "torch.xlogy") | Alias for
    [`torch.special.xlogy()`](special.html#torch.special.xlogy "torch.special.xlogy").
    |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| [`xlogy`](generated/torch.xlogy.html#torch.xlogy "torch.xlogy") | [`torch.special.xlogy()`](special.html#torch.special.xlogy
    "torch.special.xlogy")的别名。 |'
- en: Reduction Ops
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Reduction Ops
- en: '| [`argmax`](generated/torch.argmax.html#torch.argmax "torch.argmax") | Returns
    the indices of the maximum value of all elements in the `input` tensor. |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| [`argmax`](generated/torch.argmax.html#torch.argmax "torch.argmax") | 返回`input`张量中所有元素的最大值的索引。
    |'
- en: '| [`argmin`](generated/torch.argmin.html#torch.argmin "torch.argmin") | Returns
    the indices of the minimum value(s) of the flattened tensor or along a dimension
    |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| [`argmin`](generated/torch.argmin.html#torch.argmin "torch.argmin") | 返回扁平张量或沿着维度的最小值的索引。
    |'
- en: '| [`amax`](generated/torch.amax.html#torch.amax "torch.amax") | Returns the
    maximum value of each slice of the `input` tensor in the given dimension(s) `dim`.
    |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| [`amax`](generated/torch.amax.html#torch.amax "torch.amax") | 返回给定维度`dim`中`input`张量每个切片的最大值。
    |'
- en: '| [`amin`](generated/torch.amin.html#torch.amin "torch.amin") | Returns the
    minimum value of each slice of the `input` tensor in the given dimension(s) `dim`.
    |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| [`amin`](generated/torch.amin.html#torch.amin "torch.amin") | 返回给定维度`dim`中`input`张量每个切片的最小值。
    |'
- en: '| [`aminmax`](generated/torch.aminmax.html#torch.aminmax "torch.aminmax") |
    Computes the minimum and maximum values of the `input` tensor. |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| [`aminmax`](generated/torch.aminmax.html#torch.aminmax "torch.aminmax") |
    计算`input`张量的最小值和最大值。 |'
- en: '| [`all`](generated/torch.all.html#torch.all "torch.all") | Tests if all elements
    in `input` evaluate to True. |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| [`all`](generated/torch.all.html#torch.all "torch.all") | 检查`input`中是否所有元素评估为True。
    |'
- en: '| [`any`](generated/torch.any.html#torch.any "torch.any") | Tests if any element
    in `input` evaluates to True. |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| [`any`](generated/torch.any.html#torch.any "torch.any") | 检查`input`中是否有任何元素评估为True。
    |'
- en: '| [`max`](generated/torch.max.html#torch.max "torch.max") | Returns the maximum
    value of all elements in the `input` tensor. |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| [`max`](generated/torch.max.html#torch.max "torch.max") | 返回`input`张量中所有元素的最大值。
    |'
- en: '| [`min`](generated/torch.min.html#torch.min "torch.min") | Returns the minimum
    value of all elements in the `input` tensor. |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| [`min`](generated/torch.min.html#torch.min "torch.min") | 返回`input`张量中所有元素的最小值。
    |'
- en: '| [`dist`](generated/torch.dist.html#torch.dist "torch.dist") | Returns the
    p-norm of (`input` - `other`) |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| [`dist`](generated/torch.dist.html#torch.dist "torch.dist") | 返回(`input`
    - `other`)的p-范数 |'
- en: '| [`logsumexp`](generated/torch.logsumexp.html#torch.logsumexp "torch.logsumexp")
    | Returns the log of summed exponentials of each row of the `input` tensor in
    the given dimension `dim`. |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| [`logsumexp`](生成/torch.logsumexp.html#torch.logsumexp "torch.logsumexp")
    | 返回`input`张量每行在给定维度`dim`上的对数求和指数。 |'
- en: '| [`mean`](generated/torch.mean.html#torch.mean "torch.mean") | Returns the
    mean value of all elements in the `input` tensor. |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| [`mean`](生成/torch.mean.html#torch.mean "torch.mean") | 返回`input`张量中所有元素的均值。
    |'
- en: '| [`nanmean`](generated/torch.nanmean.html#torch.nanmean "torch.nanmean") |
    Computes the mean of all non-NaN elements along the specified dimensions. |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| [`nanmean`](生成/torch.nanmean.html#torch.nanmean "torch.nanmean") | 计算指定维度上所有非NaN元素的均值。
    |'
- en: '| [`median`](generated/torch.median.html#torch.median "torch.median") | Returns
    the median of the values in `input`. |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| [`median`](生成/torch.median.html#torch.median "torch.median") | 返回`input`中值的中位数。
    |'
- en: '| [`nanmedian`](generated/torch.nanmedian.html#torch.nanmedian "torch.nanmedian")
    | Returns the median of the values in `input`, ignoring `NaN` values. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| [`nanmedian`](生成/torch.nanmedian.html#torch.nanmedian "torch.nanmedian")
    | 返回`input`中值的中位数，忽略`NaN`值。 |'
- en: '| [`mode`](generated/torch.mode.html#torch.mode "torch.mode") | Returns a namedtuple
    `(values, indices)` where `values` is the mode value of each row of the `input`
    tensor in the given dimension `dim`, i.e. a value which appears most often in
    that row, and `indices` is the index location of each mode value found. |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| [`mode`](生成/torch.mode.html#torch.mode "torch.mode") | 返回一个命名元组`(values,
    indices)`，其中`values`是`input`张量每行在给定维度`dim`上的众数值，即在该行中出现最频繁的值，`indices`是找到的每个众数值的索引位置。
    |'
- en: '| [`norm`](generated/torch.norm.html#torch.norm "torch.norm") | Returns the
    matrix norm or vector norm of a given tensor. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| [`norm`](生成/torch.norm.html#torch.norm "torch.norm") | 返回给定张量的矩阵范数或向量范数。
    |'
- en: '| [`nansum`](generated/torch.nansum.html#torch.nansum "torch.nansum") | Returns
    the sum of all elements, treating Not a Numbers (NaNs) as zero. |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| [`nansum`](生成/torch.nansum.html#torch.nansum "torch.nansum") | 返回所有元素的和，将非数值（NaN）视为零。
    |'
- en: '| [`prod`](generated/torch.prod.html#torch.prod "torch.prod") | Returns the
    product of all elements in the `input` tensor. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| [`prod`](生成/torch.prod.html#torch.prod "torch.prod") | 返回`input`张量中所有元素的乘积。
    |'
- en: '| [`quantile`](generated/torch.quantile.html#torch.quantile "torch.quantile")
    | Computes the q-th quantiles of each row of the `input` tensor along the dimension
    `dim`. |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| [`quantile`](生成/torch.quantile.html#torch.quantile "torch.quantile") | 计算`input`张量每行沿维度`dim`的q分位数。
    |'
- en: '| [`nanquantile`](generated/torch.nanquantile.html#torch.nanquantile "torch.nanquantile")
    | This is a variant of [`torch.quantile()`](generated/torch.quantile.html#torch.quantile
    "torch.quantile") that "ignores" `NaN` values, computing the quantiles `q` as
    if `NaN` values in `input` did not exist. |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| [`nanquantile`](生成/torch.nanquantile.html#torch.nanquantile "torch.nanquantile")
    | 这是[`torch.quantile()`](生成/torch.quantile.html#torch.quantile "torch.quantile")的一个变体，"忽略"
    `NaN` 值，计算`input`中的分位数`q`，就好像`input`中不存在`NaN`值一样。 |'
- en: '| [`std`](generated/torch.std.html#torch.std "torch.std") | Calculates the
    standard deviation over the dimensions specified by `dim`. |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| [`std`](生成/torch.std.html#torch.std "torch.std") | 计算由`dim`指定的维度上的标准差。 |'
- en: '| [`std_mean`](generated/torch.std_mean.html#torch.std_mean "torch.std_mean")
    | Calculates the standard deviation and mean over the dimensions specified by
    `dim`. |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| [`std_mean`](生成/torch.std_mean.html#torch.std_mean "torch.std_mean") | 计算由`dim`指定的维度上的标准差和均值。
    |'
- en: '| [`sum`](generated/torch.sum.html#torch.sum "torch.sum") | Returns the sum
    of all elements in the `input` tensor. |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| [`sum`](生成/torch.sum.html#torch.sum "torch.sum") | 返回`input`张量中所有元素的和。 |'
- en: '| [`unique`](generated/torch.unique.html#torch.unique "torch.unique") | Returns
    the unique elements of the input tensor. |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| [`unique`](生成/torch.unique.html#torch.unique "torch.unique") | 返回输入张量的唯一元素。
    |'
- en: '| [`unique_consecutive`](generated/torch.unique_consecutive.html#torch.unique_consecutive
    "torch.unique_consecutive") | Eliminates all but the first element from every
    consecutive group of equivalent elements. |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| [`unique_consecutive`](生成/torch.unique_consecutive.html#torch.unique_consecutive
    "torch.unique_consecutive") | 消除每个连续等价元素组中除第一个元素之外的所有元素。 |'
- en: '| [`var`](generated/torch.var.html#torch.var "torch.var") | Calculates the
    variance over the dimensions specified by `dim`. |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| [`var`](生成/torch.var.html#torch.var "torch.var") | 计算由`dim`指定的维度上的方差。 |'
- en: '| [`var_mean`](generated/torch.var_mean.html#torch.var_mean "torch.var_mean")
    | Calculates the variance and mean over the dimensions specified by `dim`. |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| [`var_mean`](生成/torch.var_mean.html#torch.var_mean "torch.var_mean") | 计算由`dim`指定的维度上的方差和均值。
    |'
- en: '| [`count_nonzero`](generated/torch.count_nonzero.html#torch.count_nonzero
    "torch.count_nonzero") | Counts the number of non-zero values in the tensor `input`
    along the given `dim`. |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| [`count_nonzero`](生成/torch.count_nonzero.html#torch.count_nonzero "torch.count_nonzero")
    | 计算张量`input`沿给定`dim`中的非零值的数量。 |'
- en: Comparison Ops
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Comparison Ops
- en: '| [`allclose`](generated/torch.allclose.html#torch.allclose "torch.allclose")
    | This function checks if `input` and `other` satisfy the condition: |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| [`allclose`](生成/torch.allclose.html#torch.allclose "torch.allclose") | 此函数检查`input`和`other`是否满足条件：
    |'
- en: '| [`argsort`](generated/torch.argsort.html#torch.argsort "torch.argsort") |
    Returns the indices that sort a tensor along a given dimension in ascending order
    by value. |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| [`argsort`](生成/torch.argsort.html#torch.argsort "torch.argsort") | 返回按值升序沿给定维度对张量进行排序的索引。
    |'
- en: '| [`eq`](generated/torch.eq.html#torch.eq "torch.eq") | Computes element-wise
    equality |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| [`eq`](生成/torch.eq.html#torch.eq "torch.eq") | 计算逐元素相等 |'
- en: '| [`equal`](generated/torch.equal.html#torch.equal "torch.equal") | `True`
    if two tensors have the same size and elements, `False` otherwise. |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| [`equal`](生成/torch.equal.html#torch.equal "torch.equal") | 如果两个张量具有相同的大小和元素，则为`True`，否则为`False`。
    |'
- en: '| [`ge`](generated/torch.ge.html#torch.ge "torch.ge") | Computes $\text{input}
    \geq \text{other}$input≥other element-wise. |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| [`ge`](生成/torch.ge.html#torch.ge "torch.ge") | 计算$\text{input} \geq \text{other}$逐元素。
    |'
- en: '| [`greater_equal`](generated/torch.greater_equal.html#torch.greater_equal
    "torch.greater_equal") | Alias for [`torch.ge()`](generated/torch.ge.html#torch.ge
    "torch.ge"). |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| [`greater_equal`](generated/torch.greater_equal.html#torch.greater_equal
    "torch.greater_equal") | [`torch.ge()`](generated/torch.ge.html#torch.ge "torch.ge")
    的别名。 |'
- en: '| [`gt`](generated/torch.gt.html#torch.gt "torch.gt") | Computes $\text{input}
    > \text{other}$input>other element-wise. |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| [`gt`](generated/torch.gt.html#torch.gt "torch.gt") | 计算 $\text{input} >
    \text{other}$input>other 逐元素。 |'
- en: '| [`greater`](generated/torch.greater.html#torch.greater "torch.greater") |
    Alias for [`torch.gt()`](generated/torch.gt.html#torch.gt "torch.gt"). |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| [`greater`](generated/torch.greater.html#torch.greater "torch.greater") |
    [`torch.gt()`](generated/torch.gt.html#torch.gt "torch.gt") 的别名。 |'
- en: '| [`isclose`](generated/torch.isclose.html#torch.isclose "torch.isclose") |
    Returns a new tensor with boolean elements representing if each element of `input`
    is "close" to the corresponding element of `other`. |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| [`isclose`](generated/torch.isclose.html#torch.isclose "torch.isclose") |
    返回一个新张量，其中的布尔元素表示 `input` 的每个元素是否与 `other` 的对应元素“接近”。 |'
- en: '| [`isfinite`](generated/torch.isfinite.html#torch.isfinite "torch.isfinite")
    | Returns a new tensor with boolean elements representing if each element is finite
    or not. |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| [`isfinite`](generated/torch.isfinite.html#torch.isfinite "torch.isfinite")
    | 返回一个新张量，其中的布尔元素表示每个元素是否为有限数。 |'
- en: '| [`isin`](generated/torch.isin.html#torch.isin "torch.isin") | Tests if each
    element of `elements` is in `test_elements`. |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| [`isin`](generated/torch.isin.html#torch.isin "torch.isin") | 检查 `elements`
    的每个元素是否在 `test_elements` 中。 |'
- en: '| [`isinf`](generated/torch.isinf.html#torch.isinf "torch.isinf") | Tests if
    each element of `input` is infinite (positive or negative infinity) or not. |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| [`isinf`](generated/torch.isinf.html#torch.isinf "torch.isinf") | 检查 `input`
    的每个元素是否为无穷大（正无穷大或负无穷大）。 |'
- en: '| [`isposinf`](generated/torch.isposinf.html#torch.isposinf "torch.isposinf")
    | Tests if each element of `input` is positive infinity or not. |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| [`isposinf`](generated/torch.isposinf.html#torch.isposinf "torch.isposinf")
    | 检查 `input` 的每个元素是否为正无穷大。 |'
- en: '| [`isneginf`](generated/torch.isneginf.html#torch.isneginf "torch.isneginf")
    | Tests if each element of `input` is negative infinity or not. |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| [`isneginf`](generated/torch.isneginf.html#torch.isneginf "torch.isneginf")
    | 检查 `input` 的每个元素是否为负无穷大。 |'
- en: '| [`isnan`](generated/torch.isnan.html#torch.isnan "torch.isnan") | Returns
    a new tensor with boolean elements representing if each element of `input` is
    NaN or not. |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| [`isnan`](generated/torch.isnan.html#torch.isnan "torch.isnan") | 返回一个新张量，其中的布尔元素表示
    `input` 的每个元素是否为 NaN。 |'
- en: '| [`isreal`](generated/torch.isreal.html#torch.isreal "torch.isreal") | Returns
    a new tensor with boolean elements representing if each element of `input` is
    real-valued or not. |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| [`isreal`](generated/torch.isreal.html#torch.isreal "torch.isreal") | 返回一个新张量，其中的布尔元素表示
    `input` 的每个元素是否为实数或非实数。 |'
- en: '| [`kthvalue`](generated/torch.kthvalue.html#torch.kthvalue "torch.kthvalue")
    | Returns a namedtuple `(values, indices)` where `values` is the `k` th smallest
    element of each row of the `input` tensor in the given dimension `dim`. |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| [`kthvalue`](generated/torch.kthvalue.html#torch.kthvalue "torch.kthvalue")
    | 返回一个命名元组 `(values, indices)`，其中 `values` 是 `input` 张量在给定维度 `dim` 中每行的第 `k` 小元素。
    |'
- en: '| [`le`](generated/torch.le.html#torch.le "torch.le") | Computes $\text{input}
    \leq \text{other}$input≤other element-wise. |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| [`le`](generated/torch.le.html#torch.le "torch.le") | 计算 $\text{input} \leq
    \text{other}$input≤other 逐元素。 |'
- en: '| [`less_equal`](generated/torch.less_equal.html#torch.less_equal "torch.less_equal")
    | Alias for [`torch.le()`](generated/torch.le.html#torch.le "torch.le"). |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| [`less_equal`](generated/torch.less_equal.html#torch.less_equal "torch.less_equal")
    | [`torch.le()`](generated/torch.le.html#torch.le "torch.le") 的别名。 |'
- en: '| [`lt`](generated/torch.lt.html#torch.lt "torch.lt") | Computes $\text{input}
    < \text{other}$input<other element-wise. |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| [`lt`](generated/torch.lt.html#torch.lt "torch.lt") | 计算 $\text{input} <
    \text{other}$input<other 逐元素。 |'
- en: '| [`less`](generated/torch.less.html#torch.less "torch.less") | Alias for [`torch.lt()`](generated/torch.lt.html#torch.lt
    "torch.lt"). |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| [`less`](generated/torch.less.html#torch.less "torch.less") | [`torch.lt()`](generated/torch.lt.html#torch.lt
    "torch.lt") 的别名。 |'
- en: '| [`maximum`](generated/torch.maximum.html#torch.maximum "torch.maximum") |
    Computes the element-wise maximum of `input` and `other`. |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| [`maximum`](generated/torch.maximum.html#torch.maximum "torch.maximum") |
    计算 `input` 和 `other` 的逐元素最大值。 |'
- en: '| [`minimum`](generated/torch.minimum.html#torch.minimum "torch.minimum") |
    Computes the element-wise minimum of `input` and `other`. |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| [`minimum`](generated/torch.minimum.html#torch.minimum "torch.minimum") |
    计算 `input` 和 `other` 的逐元素最小值。 |'
- en: '| [`fmax`](generated/torch.fmax.html#torch.fmax "torch.fmax") | Computes the
    element-wise maximum of `input` and `other`. |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| [`fmax`](generated/torch.fmax.html#torch.fmax "torch.fmax") | 计算 `input`
    和 `other` 的逐元素最大值。 |'
- en: '| [`fmin`](generated/torch.fmin.html#torch.fmin "torch.fmin") | Computes the
    element-wise minimum of `input` and `other`. |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| [`fmin`](generated/torch.fmin.html#torch.fmin "torch.fmin") | 计算 `input`
    和 `other` 的逐元素最小值。 |'
- en: '| [`ne`](generated/torch.ne.html#torch.ne "torch.ne") | Computes $\text{input}
    \neq \text{other}$input=other element-wise. |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| [`ne`](generated/torch.ne.html#torch.ne "torch.ne") | 计算 $\text{input} \neq
    \text{other}$input=other 逐元素。 |'
- en: '| [`not_equal`](generated/torch.not_equal.html#torch.not_equal "torch.not_equal")
    | Alias for [`torch.ne()`](generated/torch.ne.html#torch.ne "torch.ne"). |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| [`not_equal`](generated/torch.not_equal.html#torch.not_equal "torch.not_equal")
    | [`torch.ne()`](generated/torch.ne.html#torch.ne "torch.ne") 的别名。 |'
- en: '| [`sort`](generated/torch.sort.html#torch.sort "torch.sort") | Sorts the elements
    of the `input` tensor along a given dimension in ascending order by value. |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| [`sort`](generated/torch.sort.html#torch.sort "torch.sort") | 按值升序对 `input`
    张量沿指定维度排序。 |'
- en: '| [`topk`](generated/torch.topk.html#torch.topk "torch.topk") | Returns the
    `k` largest elements of the given `input` tensor along a given dimension. |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| [`topk`](generated/torch.topk.html#torch.topk "torch.topk") | 返回给定 `input`
    张量沿指定维度的前 `k` 个最大元素。 |'
- en: '| [`msort`](generated/torch.msort.html#torch.msort "torch.msort") | Sorts the
    elements of the `input` tensor along its first dimension in ascending order by
    value. |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| [`msort`](generated/torch.msort.html#torch.msort "torch.msort") | 按值升序对 `input`
    张量沿其第一维排序。 |'
- en: Spectral Ops
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spectral Ops
- en: '| [`stft`](generated/torch.stft.html#torch.stft "torch.stft") | Short-time
    Fourier transform (STFT). |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| [`stft`](generated/torch.stft.html#torch.stft "torch.stft") | 短时傅里叶变换（STFT）。
    |'
- en: '| [`istft`](generated/torch.istft.html#torch.istft "torch.istft") | Inverse
    short time Fourier Transform. |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| [`istft`](generated/torch.istft.html#torch.istft "torch.istft") | 短时傅里叶逆变换。
    |'
- en: '| [`bartlett_window`](generated/torch.bartlett_window.html#torch.bartlett_window
    "torch.bartlett_window") | Bartlett window function. |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| [`bartlett_window`](generated/torch.bartlett_window.html#torch.bartlett_window
    "torch.bartlett_window") | Bartlett窗口函数。 |'
- en: '| [`blackman_window`](generated/torch.blackman_window.html#torch.blackman_window
    "torch.blackman_window") | Blackman window function. |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| [`blackman_window`](generated/torch.blackman_window.html#torch.blackman_window
    "torch.blackman_window") | Blackman窗口函数。 |'
- en: '| [`hamming_window`](generated/torch.hamming_window.html#torch.hamming_window
    "torch.hamming_window") | Hamming window function. |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| [`hamming_window`](generated/torch.hamming_window.html#torch.hamming_window
    "torch.hamming_window") | Hamming窗口函数。 |'
- en: '| [`hann_window`](generated/torch.hann_window.html#torch.hann_window "torch.hann_window")
    | Hann window function. |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| [`hann_window`](generated/torch.hann_window.html#torch.hann_window "torch.hann_window")
    | Hann窗口函数。 |'
- en: '| [`kaiser_window`](generated/torch.kaiser_window.html#torch.kaiser_window
    "torch.kaiser_window") | Computes the Kaiser window with window length `window_length`
    and shape parameter `beta`. |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| [`kaiser_window`](generated/torch.kaiser_window.html#torch.kaiser_window
    "torch.kaiser_window") | 计算具有窗口长度`window_length`和形状参数`beta`的Kaiser窗口。 |'
- en: Other Operations
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他操作
- en: '| [`atleast_1d`](generated/torch.atleast_1d.html#torch.atleast_1d "torch.atleast_1d")
    | Returns a 1-dimensional view of each input tensor with zero dimensions. |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| [`atleast_1d`](generated/torch.atleast_1d.html#torch.atleast_1d "torch.atleast_1d")
    | 返回每个输入张量的零维视图的一维视图。 |'
- en: '| [`atleast_2d`](generated/torch.atleast_2d.html#torch.atleast_2d "torch.atleast_2d")
    | Returns a 2-dimensional view of each input tensor with zero dimensions. |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| [`atleast_2d`](generated/torch.atleast_2d.html#torch.atleast_2d "torch.atleast_2d")
    | 返回每个输入张量的零维视图的二维视图。 |'
- en: '| [`atleast_3d`](generated/torch.atleast_3d.html#torch.atleast_3d "torch.atleast_3d")
    | Returns a 3-dimensional view of each input tensor with zero dimensions. |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| [`atleast_3d`](generated/torch.atleast_3d.html#torch.atleast_3d "torch.atleast_3d")
    | 返回每个输入张量的零维视图的三维视图。 |'
- en: '| [`bincount`](generated/torch.bincount.html#torch.bincount "torch.bincount")
    | Count the frequency of each value in an array of non-negative ints. |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| [`bincount`](generated/torch.bincount.html#torch.bincount "torch.bincount")
    | 计算非负整数数组中每个值的频率。 |'
- en: '| [`block_diag`](generated/torch.block_diag.html#torch.block_diag "torch.block_diag")
    | Create a block diagonal matrix from provided tensors. |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| [`block_diag`](generated/torch.block_diag.html#torch.block_diag "torch.block_diag")
    | 从提供的张量创建一个分块对角矩阵。 |'
- en: '| [`broadcast_tensors`](generated/torch.broadcast_tensors.html#torch.broadcast_tensors
    "torch.broadcast_tensors") | Broadcasts the given tensors according to [Broadcasting
    semantics](notes/broadcasting.html#broadcasting-semantics). |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| [`broadcast_tensors`](generated/torch.broadcast_tensors.html#torch.broadcast_tensors
    "torch.broadcast_tensors") | 根据[广播语义](notes/broadcasting.html#broadcasting-semantics)广播给定的张量。
    |'
- en: '| [`broadcast_to`](generated/torch.broadcast_to.html#torch.broadcast_to "torch.broadcast_to")
    | Broadcasts `input` to the shape `shape`. |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| [`broadcast_to`](generated/torch.broadcast_to.html#torch.broadcast_to "torch.broadcast_to")
    | 将`input`广播到形状`shape`。 |'
- en: '| [`broadcast_shapes`](generated/torch.broadcast_shapes.html#torch.broadcast_shapes
    "torch.broadcast_shapes") | Similar to [`broadcast_tensors()`](generated/torch.broadcast_tensors.html#torch.broadcast_tensors
    "torch.broadcast_tensors") but for shapes. |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| [`broadcast_shapes`](generated/torch.broadcast_shapes.html#torch.broadcast_shapes
    "torch.broadcast_shapes") | 类似于[`broadcast_tensors()`](generated/torch.broadcast_tensors.html#torch.broadcast_tensors
    "torch.broadcast_tensors")，但用于形状。 |'
- en: '| [`bucketize`](generated/torch.bucketize.html#torch.bucketize "torch.bucketize")
    | Returns the indices of the buckets to which each value in the `input` belongs,
    where the boundaries of the buckets are set by `boundaries`. |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| [`bucketize`](generated/torch.bucketize.html#torch.bucketize "torch.bucketize")
    | 返回`input`中每个值所属的桶的索引，其中桶的边界由`boundaries`设置。 |'
- en: '| [`cartesian_prod`](generated/torch.cartesian_prod.html#torch.cartesian_prod
    "torch.cartesian_prod") | Do cartesian product of the given sequence of tensors.
    |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| [`cartesian_prod`](generated/torch.cartesian_prod.html#torch.cartesian_prod
    "torch.cartesian_prod") | 对给定的张量序列进行笛卡尔积。 |'
- en: '| [`cdist`](generated/torch.cdist.html#torch.cdist "torch.cdist") | Computes
    batched the p-norm distance between each pair of the two collections of row vectors.
    |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| [`cdist`](generated/torch.cdist.html#torch.cdist "torch.cdist") | 计算两个行向量集合中每对之间的批次p-范数距离。
    |'
- en: '| [`clone`](generated/torch.clone.html#torch.clone "torch.clone") | Returns
    a copy of `input`. |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| [`clone`](generated/torch.clone.html#torch.clone "torch.clone") | 返回`input`的副本。
    |'
- en: '| [`combinations`](generated/torch.combinations.html#torch.combinations "torch.combinations")
    | Compute combinations of length $r$r of the given tensor. |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| [`combinations`](generated/torch.combinations.html#torch.combinations "torch.combinations")
    | 计算给定张量的长度为$r$的组合。 |'
- en: '| [`corrcoef`](generated/torch.corrcoef.html#torch.corrcoef "torch.corrcoef")
    | Estimates the Pearson product-moment correlation coefficient matrix of the variables
    given by the `input` matrix, where rows are the variables and columns are the
    observations. |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| [`corrcoef`](generated/torch.corrcoef.html#torch.corrcoef "torch.corrcoef")
    | 估计由`input`矩阵给出的变量的Pearson积矩相关系数矩阵，其中行是变量，列是观测。 |'
- en: '| [`cov`](generated/torch.cov.html#torch.cov "torch.cov") | Estimates the covariance
    matrix of the variables given by the `input` matrix, where rows are the variables
    and columns are the observations. |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| [`cov`](generated/torch.cov.html#torch.cov "torch.cov") | 估计由`input`矩阵给出的变量的协方差矩阵，其中行是变量，列是观测。
    |'
- en: '| [`cross`](generated/torch.cross.html#torch.cross "torch.cross") | Returns
    the cross product of vectors in dimension `dim` of `input` and `other`. |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| [`cross`](generated/torch.cross.html#torch.cross "torch.cross") | 返回`input`和`other`在维度`dim`中向量的叉积。
    |'
- en: '| [`cummax`](generated/torch.cummax.html#torch.cummax "torch.cummax") | Returns
    a namedtuple `(values, indices)` where `values` is the cumulative maximum of elements
    of `input` in the dimension `dim`. |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| [`cummax`](generated/torch.cummax.html#torch.cummax "torch.cummax") | 返回一个命名元组`(values,
    indices)`，其中`values`是维度`dim`中`input`元素的累积最大值。 |'
- en: '| [`cummin`](generated/torch.cummin.html#torch.cummin "torch.cummin") | Returns
    a namedtuple `(values, indices)` where `values` is the cumulative minimum of elements
    of `input` in the dimension `dim`. |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| [`cummin`](generated/torch.cummin.html#torch.cummin "torch.cummin") | 返回一个命名元组
    `(values, indices)`，其中 `values` 是 `input` 在维度 `dim` 中元素的累积最小值。 |'
- en: '| [`cumprod`](generated/torch.cumprod.html#torch.cumprod "torch.cumprod") |
    Returns the cumulative product of elements of `input` in the dimension `dim`.
    |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| [`cumprod`](generated/torch.cumprod.html#torch.cumprod "torch.cumprod") |
    返回 `input` 在维度 `dim` 中元素的累积积。 |'
- en: '| [`cumsum`](generated/torch.cumsum.html#torch.cumsum "torch.cumsum") | Returns
    the cumulative sum of elements of `input` in the dimension `dim`. |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| [`cumsum`](generated/torch.cumsum.html#torch.cumsum "torch.cumsum") | 返回
    `input` 在维度 `dim` 中元素的累积和。 |'
- en: '| [`diag`](generated/torch.diag.html#torch.diag "torch.diag") |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| [`diag`](generated/torch.diag.html#torch.diag "torch.diag") |'
- en: If `input` is a vector (1-D tensor), then returns a 2-D square tensor
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`input`是一个向量（1-D张量），则返回一个2-D方形张量
- en: '|'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [`diag_embed`](generated/torch.diag_embed.html#torch.diag_embed "torch.diag_embed")
    | Creates a tensor whose diagonals of certain 2D planes (specified by `dim1` and
    `dim2`) are filled by `input`. |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| [`diag_embed`](generated/torch.diag_embed.html#torch.diag_embed "torch.diag_embed")
    | 创建一个张量，其中某些二维平面（由 `dim1` 和 `dim2` 指定）的对角线由 `input` 填充。 |'
- en: '| [`diagflat`](generated/torch.diagflat.html#torch.diagflat "torch.diagflat")
    |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| [`diagflat`](generated/torch.diagflat.html#torch.diagflat "torch.diagflat")
    |'
- en: If `input` is a vector (1-D tensor), then returns a 2-D square tensor
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`input`是一个向量（1-D张量），则返回一个2-D方形张量
- en: '|'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [`diagonal`](generated/torch.diagonal.html#torch.diagonal "torch.diagonal")
    | Returns a partial view of `input` with the its diagonal elements with respect
    to `dim1` and `dim2` appended as a dimension at the end of the shape. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| [`diagonal`](generated/torch.diagonal.html#torch.diagonal "torch.diagonal")
    | 返回 `input` 的部分视图，其对角线元素相对于 `dim1` 和 `dim2` 附加为形状末尾的维度。 |'
- en: '| [`diff`](generated/torch.diff.html#torch.diff "torch.diff") | Computes the
    n-th forward difference along the given dimension. |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| [`diff`](generated/torch.diff.html#torch.diff "torch.diff") | 计算沿给定维度的第n个前向差分。
    |'
- en: '| [`einsum`](generated/torch.einsum.html#torch.einsum "torch.einsum") | Sums
    the product of the elements of the input `operands` along dimensions specified
    using a notation based on the Einstein summation convention. |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| [`einsum`](generated/torch.einsum.html#torch.einsum "torch.einsum") | 按照基于Einstein求和约定的符号，沿着指定维度对输入`operands`的元素的乘积求和。
    |'
- en: '| [`flatten`](generated/torch.flatten.html#torch.flatten "torch.flatten") |
    Flattens `input` by reshaping it into a one-dimensional tensor. |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| [`flatten`](generated/torch.flatten.html#torch.flatten "torch.flatten") |
    通过将其重新形状为一维张量来展平 `input`。 |'
- en: '| [`flip`](generated/torch.flip.html#torch.flip "torch.flip") | Reverse the
    order of an n-D tensor along given axis in dims. |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| [`flip`](generated/torch.flip.html#torch.flip "torch.flip") | 沿着给定轴在dims中反转n-D张量的顺序。
    |'
- en: '| [`fliplr`](generated/torch.fliplr.html#torch.fliplr "torch.fliplr") | Flip
    tensor in the left/right direction, returning a new tensor. |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| [`fliplr`](generated/torch.fliplr.html#torch.fliplr "torch.fliplr") | 在左/右方向上翻转张量，返回一个新的张量。
    |'
- en: '| [`flipud`](generated/torch.flipud.html#torch.flipud "torch.flipud") | Flip
    tensor in the up/down direction, returning a new tensor. |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| [`flipud`](generated/torch.flipud.html#torch.flipud "torch.flipud") | 在上/下方向上翻转张量，返回一个新的张量。
    |'
- en: '| [`kron`](generated/torch.kron.html#torch.kron "torch.kron") | Computes the
    Kronecker product, denoted by $\otimes$⊗, of `input` and `other`. |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| [`kron`](generated/torch.kron.html#torch.kron "torch.kron") | 计算 `input`
    和 `other` 的Kronecker积，表示为 $\otimes$⊗。 |'
- en: '| [`rot90`](generated/torch.rot90.html#torch.rot90 "torch.rot90") | Rotate
    an n-D tensor by 90 degrees in the plane specified by dims axis. |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| [`rot90`](generated/torch.rot90.html#torch.rot90 "torch.rot90") | 将n-D张量按dims轴指定的平面旋转90度。
    |'
- en: '| [`gcd`](generated/torch.gcd.html#torch.gcd "torch.gcd") | Computes the element-wise
    greatest common divisor (GCD) of `input` and `other`. |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| [`gcd`](generated/torch.gcd.html#torch.gcd "torch.gcd") | 计算 `input` 和 `other`
    的逐元素最大公约数（GCD）。 |'
- en: '| [`histc`](generated/torch.histc.html#torch.histc "torch.histc") | Computes
    the histogram of a tensor. |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| [`histc`](generated/torch.histc.html#torch.histc "torch.histc") | 计算张量的直方图。
    |'
- en: '| [`histogram`](generated/torch.histogram.html#torch.histogram "torch.histogram")
    | Computes a histogram of the values in a tensor. |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| [`histogram`](generated/torch.histogram.html#torch.histogram "torch.histogram")
    | 计算张量中值的直方图。 |'
- en: '| [`histogramdd`](generated/torch.histogramdd.html#torch.histogramdd "torch.histogramdd")
    | Computes a multi-dimensional histogram of the values in a tensor. |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| [`histogramdd`](generated/torch.histogramdd.html#torch.histogramdd "torch.histogramdd")
    | 计算张量中值的多维直方图。 |'
- en: '| [`meshgrid`](generated/torch.meshgrid.html#torch.meshgrid "torch.meshgrid")
    | Creates grids of coordinates specified by the 1D inputs in attr:tensors. |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| [`meshgrid`](generated/torch.meshgrid.html#torch.meshgrid "torch.meshgrid")
    | 创建由属性`tensors`中的1D输入指定的坐标网格。 |'
- en: '| [`lcm`](generated/torch.lcm.html#torch.lcm "torch.lcm") | Computes the element-wise
    least common multiple (LCM) of `input` and `other`. |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| [`lcm`](generated/torch.lcm.html#torch.lcm "torch.lcm") | 计算 `input` 和 `other`
    的逐元素最小公倍数（LCM）。 |'
- en: '| [`logcumsumexp`](generated/torch.logcumsumexp.html#torch.logcumsumexp "torch.logcumsumexp")
    | Returns the logarithm of the cumulative summation of the exponentiation of elements
    of `input` in the dimension `dim`. |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| [`logcumsumexp`](generated/torch.logcumsumexp.html#torch.logcumsumexp "torch.logcumsumexp")
    | 返回 `input` 元素的指数的累积求和的对数，维度为 `dim`。 |'
- en: '| [`ravel`](generated/torch.ravel.html#torch.ravel "torch.ravel") | Return
    a contiguous flattened tensor. |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| [`ravel`](generated/torch.ravel.html#torch.ravel "torch.ravel") | 返回一个连续的展平张量。
    |'
- en: '| [`renorm`](generated/torch.renorm.html#torch.renorm "torch.renorm") | Returns
    a tensor where each sub-tensor of `input` along dimension `dim` is normalized
    such that the p-norm of the sub-tensor is lower than the value `maxnorm` |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| [`renorm`](generated/torch.renorm.html#torch.renorm "torch.renorm") | 返回一个张量，其中沿着维度`dim`的每个子张量被归一化，使得子张量的p-范数低于值`maxnorm`
    |'
- en: '| [`repeat_interleave`](generated/torch.repeat_interleave.html#torch.repeat_interleave
    "torch.repeat_interleave") | Repeat elements of a tensor. |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| [`repeat_interleave`](generated/torch.repeat_interleave.html#torch.repeat_interleave
    "torch.repeat_interleave") | 重复张量的元素。 |'
- en: '| [`roll`](generated/torch.roll.html#torch.roll "torch.roll") | Roll the tensor
    `input` along the given dimension(s). |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| [`roll`](generated/torch.roll.html#torch.roll "torch.roll") | 沿给定维度滚动张量`input`。
    |'
- en: '| [`searchsorted`](generated/torch.searchsorted.html#torch.searchsorted "torch.searchsorted")
    | Find the indices from the *innermost* dimension of `sorted_sequence` such that,
    if the corresponding values in `values` were inserted before the indices, when
    sorted, the order of the corresponding *innermost* dimension within `sorted_sequence`
    would be preserved. |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| [`searchsorted`](generated/torch.searchsorted.html#torch.searchsorted "torch.searchsorted")
    | 找到`sorted_sequence`的*最内层*维度中的索引，使得如果将`values`中的相应值插入到这些索引之前，排序后，`sorted_sequence`中的*最内层*维度的顺序将被保留。
    |'
- en: '| [`tensordot`](generated/torch.tensordot.html#torch.tensordot "torch.tensordot")
    | Returns a contraction of a and b over multiple dimensions. |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| [`tensordot`](generated/torch.tensordot.html#torch.tensordot "torch.tensordot")
    | 在多个维度上返回a和b的收缩。 |'
- en: '| [`trace`](generated/torch.trace.html#torch.trace "torch.trace") | Returns
    the sum of the elements of the diagonal of the input 2-D matrix. |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| [`trace`](generated/torch.trace.html#torch.trace "torch.trace") | 返回输入2-D矩阵对角线元素的和。
    |'
- en: '| [`tril`](generated/torch.tril.html#torch.tril "torch.tril") | Returns the
    lower triangular part of the matrix (2-D tensor) or batch of matrices `input`,
    the other elements of the result tensor `out` are set to 0. |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| [`tril`](generated/torch.tril.html#torch.tril "torch.tril") | 返回矩阵（2-D张量）或批量矩阵`input`的下三角部分，结果张量`out`的其他元素设置为0。
    |'
- en: '| [`tril_indices`](generated/torch.tril_indices.html#torch.tril_indices "torch.tril_indices")
    | Returns the indices of the lower triangular part of a `row`-by- `col` matrix
    in a 2-by-N Tensor, where the first row contains row coordinates of all indices
    and the second row contains column coordinates. |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| [`tril_indices`](generated/torch.tril_indices.html#torch.tril_indices "torch.tril_indices")
    | 返回`row`-by-`col`矩阵的下三角部分的索引，以2xN张量的形式返回，其中第一行包含所有索引的行坐标，第二行包含列坐标。 |'
- en: '| [`triu`](generated/torch.triu.html#torch.triu "torch.triu") | Returns the
    upper triangular part of a matrix (2-D tensor) or batch of matrices `input`, the
    other elements of the result tensor `out` are set to 0. |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| [`triu`](generated/torch.triu.html#torch.triu "torch.triu") | 返回矩阵（2-D张量）或批量矩阵`input`的上三角部分，结果张量`out`的其他元素设置为0。
    |'
- en: '| [`triu_indices`](generated/torch.triu_indices.html#torch.triu_indices "torch.triu_indices")
    | Returns the indices of the upper triangular part of a `row` by `col` matrix
    in a 2-by-N Tensor, where the first row contains row coordinates of all indices
    and the second row contains column coordinates. |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| [`triu_indices`](generated/torch.triu_indices.html#torch.triu_indices "torch.triu_indices")
    | 返回`row`乘以`col`矩阵的上三角部分的索引，以2xN张量的形式返回，其中第一行包含所有索引的行坐标，第二行包含列坐标。 |'
- en: '| [`unflatten`](generated/torch.unflatten.html#torch.unflatten "torch.unflatten")
    | Expands a dimension of the input tensor over multiple dimensions. |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| [`unflatten`](generated/torch.unflatten.html#torch.unflatten "torch.unflatten")
    | 将输入张量的一个维度扩展到多个维度。 |'
- en: '| [`vander`](generated/torch.vander.html#torch.vander "torch.vander") | Generates
    a Vandermonde matrix. |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| [`vander`](generated/torch.vander.html#torch.vander "torch.vander") | 生成Vandermonde矩阵。
    |'
- en: '| [`view_as_real`](generated/torch.view_as_real.html#torch.view_as_real "torch.view_as_real")
    | Returns a view of `input` as a real tensor. |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| [`view_as_real`](generated/torch.view_as_real.html#torch.view_as_real "torch.view_as_real")
    | 将`input`作为实数张量返回视图。 |'
- en: '| [`view_as_complex`](generated/torch.view_as_complex.html#torch.view_as_complex
    "torch.view_as_complex") | Returns a view of `input` as a complex tensor. |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| [`view_as_complex`](generated/torch.view_as_complex.html#torch.view_as_complex
    "torch.view_as_complex") | 将`input`作为复数张量返回视图。 |'
- en: '| [`resolve_conj`](generated/torch.resolve_conj.html#torch.resolve_conj "torch.resolve_conj")
    | Returns a new tensor with materialized conjugation if `input`''s conjugate bit
    is set to True, else returns `input`. |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| [`resolve_conj`](generated/torch.resolve_conj.html#torch.resolve_conj "torch.resolve_conj")
    | 如果`input`的共轭位设置为True，则返回具有实现共轭的新张量，否则返回`input`。 |'
- en: '| [`resolve_neg`](generated/torch.resolve_neg.html#torch.resolve_neg "torch.resolve_neg")
    | Returns a new tensor with materialized negation if `input`''s negative bit is
    set to True, else returns `input`. |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| [`resolve_neg`](generated/torch.resolve_neg.html#torch.resolve_neg "torch.resolve_neg")
    | 如果`input`的负位设置为True，则返回具有实现否定的新张量，否则返回`input`。 |'
- en: BLAS and LAPACK Operations[](#blas-and-lapack-operations "Permalink to this
    heading")
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BLAS和LAPACK操作
- en: '| [`addbmm`](generated/torch.addbmm.html#torch.addbmm "torch.addbmm") | Performs
    a batch matrix-matrix product of matrices stored in `batch1` and `batch2`, with
    a reduced add step (all matrix multiplications get accumulated along the first
    dimension). |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| [`addbmm`](generated/torch.addbmm.html#torch.addbmm "torch.addbmm") | 对存储在`batch1`和`batch2`中的矩阵执行批量矩阵乘法，具有减少的加法步骤（所有矩阵乘法沿第一维度累积）。
    |'
- en: '| [`addmm`](generated/torch.addmm.html#torch.addmm "torch.addmm") | Performs
    a matrix multiplication of the matrices `mat1` and `mat2`. |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| [`addmm`](generated/torch.addmm.html#torch.addmm "torch.addmm") | 执行矩阵`mat1`和`mat2`的矩阵乘法。
    |'
- en: '| [`addmv`](generated/torch.addmv.html#torch.addmv "torch.addmv") | Performs
    a matrix-vector product of the matrix `mat` and the vector `vec`. |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| [`addmv`](generated/torch.addmv.html#torch.addmv "torch.addmv") | 执行矩阵`mat`和向量`vec`的矩阵-向量乘积。
    |'
- en: '| [`addr`](generated/torch.addr.html#torch.addr "torch.addr") | Performs the
    outer-product of vectors `vec1` and `vec2` and adds it to the matrix `input`.
    |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| [`addr`](generated/torch.addr.html#torch.addr "torch.addr") | 执行向量`vec1`和`vec2`的外积，并将其添加到矩阵`input`中。
    |'
- en: '| [`baddbmm`](generated/torch.baddbmm.html#torch.baddbmm "torch.baddbmm") |
    Performs a batch matrix-matrix product of matrices in `batch1` and `batch2`. |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| [`baddbmm`](generated/torch.baddbmm.html#torch.baddbmm "torch.baddbmm") |
    对`batch1`和`batch2`中的矩阵执行批量矩阵乘法。 |'
- en: '| [`bmm`](generated/torch.bmm.html#torch.bmm "torch.bmm") | Performs a batch
    matrix-matrix product of matrices stored in `input` and `mat2`. |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| [`bmm`](generated/torch.bmm.html#torch.bmm "torch.bmm") | 对存储在`input`和`mat2`中的矩阵执行批量矩阵乘法。
    |'
- en: '| [`chain_matmul`](generated/torch.chain_matmul.html#torch.chain_matmul "torch.chain_matmul")
    | Returns the matrix product of the $N$N 2-D tensors. |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| [`chain_matmul`](generated/torch.chain_matmul.html#torch.chain_matmul "torch.chain_matmul")
    | 返回$N$个2-D张量的矩阵乘积。 |'
- en: '| [`cholesky`](generated/torch.cholesky.html#torch.cholesky "torch.cholesky")
    | Computes the Cholesky decomposition of a symmetric positive-definite matrix
    $A$A or for batches of symmetric positive-definite matrices. |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| [`cholesky`](generated/torch.cholesky.html#torch.cholesky "torch.cholesky")
    | 计算对称正定矩阵$A$A或对称正定矩阵批次的Cholesky分解。 |'
- en: '| [`cholesky_inverse`](generated/torch.cholesky_inverse.html#torch.cholesky_inverse
    "torch.cholesky_inverse") | Computes the inverse of a complex Hermitian or real
    symmetric positive-definite matrix given its Cholesky decomposition. |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| [`cholesky_inverse`](generated/torch.cholesky_inverse.html#torch.cholesky_inverse
    "torch.cholesky_inverse") | 计算具有Cholesky分解的复Hermite或实对称正定矩阵的逆矩阵。 |'
- en: '| [`cholesky_solve`](generated/torch.cholesky_solve.html#torch.cholesky_solve
    "torch.cholesky_solve") | Computes the solution of a system of linear equations
    with complex Hermitian or real symmetric positive-definite lhs given its Cholesky
    decomposition. |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| [`cholesky_solve`](generated/torch.cholesky_solve.html#torch.cholesky_solve
    "torch.cholesky_solve") | 计算具有Cholesky分解的复Hermite或实对称正定lhs的线性方程组的解。 |'
- en: '| [`dot`](generated/torch.dot.html#torch.dot "torch.dot") | Computes the dot
    product of two 1D tensors. |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| [`dot`](generated/torch.dot.html#torch.dot "torch.dot") | 计算两个1D张量的点积。 |'
- en: '| [`geqrf`](generated/torch.geqrf.html#torch.geqrf "torch.geqrf") | This is
    a low-level function for calling LAPACK''s geqrf directly. |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| [`geqrf`](generated/torch.geqrf.html#torch.geqrf "torch.geqrf") | 这是一个直接调用LAPACK的geqrf的低级函数。
    |'
- en: '| [`ger`](generated/torch.ger.html#torch.ger "torch.ger") | Alias of [`torch.outer()`](generated/torch.outer.html#torch.outer
    "torch.outer"). |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| [`ger`](generated/torch.ger.html#torch.ger "torch.ger") | [`torch.outer()`](generated/torch.outer.html#torch.outer
    "torch.outer")的别名。 |'
- en: '| [`inner`](generated/torch.inner.html#torch.inner "torch.inner") | Computes
    the dot product for 1D tensors. |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| [`inner`](generated/torch.inner.html#torch.inner "torch.inner") | 计算1D张量的点积。
    |'
- en: '| [`inverse`](generated/torch.inverse.html#torch.inverse "torch.inverse") |
    Alias for [`torch.linalg.inv()`](generated/torch.linalg.inv.html#torch.linalg.inv
    "torch.linalg.inv") |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| [`inverse`](generated/torch.inverse.html#torch.inverse "torch.inverse") |
    [`torch.linalg.inv()`](generated/torch.linalg.inv.html#torch.linalg.inv "torch.linalg.inv")的别名
    |'
- en: '| [`det`](generated/torch.det.html#torch.det "torch.det") | Alias for [`torch.linalg.det()`](generated/torch.linalg.det.html#torch.linalg.det
    "torch.linalg.det") |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| [`det`](generated/torch.det.html#torch.det "torch.det") | [`torch.linalg.det()`](generated/torch.linalg.det.html#torch.linalg.det
    "torch.linalg.det")的别名 |'
- en: '| [`logdet`](generated/torch.logdet.html#torch.logdet "torch.logdet") | Calculates
    log determinant of a square matrix or batches of square matrices. |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| [`logdet`](generated/torch.logdet.html#torch.logdet "torch.logdet") | 计算方阵或方阵批次的对数行列式。
    |'
- en: '| [`slogdet`](generated/torch.slogdet.html#torch.slogdet "torch.slogdet") |
    Alias for [`torch.linalg.slogdet()`](generated/torch.linalg.slogdet.html#torch.linalg.slogdet
    "torch.linalg.slogdet") |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| [`slogdet`](generated/torch.slogdet.html#torch.slogdet "torch.slogdet") |
    [`torch.linalg.slogdet()`](generated/torch.linalg.slogdet.html#torch.linalg.slogdet
    "torch.linalg.slogdet")的别名 |'
- en: '| [`lu`](generated/torch.lu.html#torch.lu "torch.lu") | Computes the LU factorization
    of a matrix or batches of matrices `A`. |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| [`lu`](generated/torch.lu.html#torch.lu "torch.lu") | 计算矩阵或矩阵批次`A`的LU分解。
    |'
- en: '| [`lu_solve`](generated/torch.lu_solve.html#torch.lu_solve "torch.lu_solve")
    | Returns the LU solve of the linear system $Ax = b$Ax=b using the partially pivoted
    LU factorization of A from [`lu_factor()`](generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor
    "torch.linalg.lu_factor"). |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| [`lu_solve`](generated/torch.lu_solve.html#torch.lu_solve "torch.lu_solve")
    | 使用从[`lu_factor()`](generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor
    "torch.linalg.lu_factor")得到的A的部分主元LU分解返回线性系统$Ax = b$Ax=b的LU解。 |'
- en: '| [`lu_unpack`](generated/torch.lu_unpack.html#torch.lu_unpack "torch.lu_unpack")
    | Unpacks the LU decomposition returned by [`lu_factor()`](generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor
    "torch.linalg.lu_factor") into the P, L, U matrices. |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| [`lu_unpack`](generated/torch.lu_unpack.html#torch.lu_unpack "torch.lu_unpack")
    | 将[`lu_factor()`](generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor
    "torch.linalg.lu_factor")返回的LU分解解包成P、L、U矩阵。 |'
- en: '| [`matmul`](generated/torch.matmul.html#torch.matmul "torch.matmul") | Matrix
    product of two tensors. |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| [`matmul`](generated/torch.matmul.html#torch.matmul "torch.matmul") | 两个张量的矩阵乘积。
    |'
- en: '| [`matrix_power`](generated/torch.matrix_power.html#torch.matrix_power "torch.matrix_power")
    | Alias for [`torch.linalg.matrix_power()`](generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power
    "torch.linalg.matrix_power") |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| [`matrix_power`](generated/torch.matrix_power.html#torch.matrix_power "torch.matrix_power")
    | [`torch.linalg.matrix_power()`](generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power
    "torch.linalg.matrix_power")的别名 |'
- en: '| [`matrix_exp`](generated/torch.matrix_exp.html#torch.matrix_exp "torch.matrix_exp")
    | Alias for [`torch.linalg.matrix_exp()`](generated/torch.linalg.matrix_exp.html#torch.linalg.matrix_exp
    "torch.linalg.matrix_exp"). |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| [`matrix_exp`](generated/torch.matrix_exp.html#torch.matrix_exp "torch.matrix_exp")
    | [`torch.linalg.matrix_exp()`](generated/torch.linalg.matrix_exp.html#torch.linalg.matrix_exp
    "torch.linalg.matrix_exp")的别名。 |'
- en: '| [`mm`](generated/torch.mm.html#torch.mm "torch.mm") | Performs a matrix multiplication
    of the matrices `input` and `mat2`. |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| [`mm`](generated/torch.mm.html#torch.mm "torch.mm") | 计算矩阵`input`和`mat2`的矩阵乘法。
    |'
- en: '| [`mv`](generated/torch.mv.html#torch.mv "torch.mv") | Performs a matrix-vector
    product of the matrix `input` and the vector `vec`. |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| [`mv`](generated/torch.mv.html#torch.mv "torch.mv") | 计算矩阵`input`和向量`vec`的矩阵-向量乘积。
    |'
- en: '| [`orgqr`](generated/torch.orgqr.html#torch.orgqr "torch.orgqr") | Alias for
    [`torch.linalg.householder_product()`](generated/torch.linalg.householder_product.html#torch.linalg.householder_product
    "torch.linalg.householder_product"). |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| [`orgqr`](generated/torch.orgqr.html#torch.orgqr "torch.orgqr") | [`torch.linalg.householder_product()`](generated/torch.linalg.householder_product.html#torch.linalg.householder_product
    "torch.linalg.householder_product")的别名。 |'
- en: '| [`ormqr`](generated/torch.ormqr.html#torch.ormqr "torch.ormqr") | Computes
    the matrix-matrix multiplication of a product of Householder matrices with a general
    matrix. |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| [`ormqr`](generated/torch.ormqr.html#torch.ormqr "torch.ormqr") | 计算Householder矩阵乘积与一般矩阵的矩阵-矩阵乘积。
    |'
- en: '| [`outer`](generated/torch.outer.html#torch.outer "torch.outer") | Outer product
    of `input` and `vec2`. |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| [`outer`](generated/torch.outer.html#torch.outer "torch.outer") | `input`
    和 `vec2` 的外积。 |'
- en: '| [`pinverse`](generated/torch.pinverse.html#torch.pinverse "torch.pinverse")
    | Alias for [`torch.linalg.pinv()`](generated/torch.linalg.pinv.html#torch.linalg.pinv
    "torch.linalg.pinv") |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| [`pinverse`](generated/torch.pinverse.html#torch.pinverse "torch.pinverse")
    | [`torch.linalg.pinv()`](generated/torch.linalg.pinv.html#torch.linalg.pinv "torch.linalg.pinv")
    的别名 |'
- en: '| [`qr`](generated/torch.qr.html#torch.qr "torch.qr") | Computes the QR decomposition
    of a matrix or a batch of matrices `input`, and returns a namedtuple (Q, R) of
    tensors such that $\text{input} = Q R$input=QR with $Q$Q being an orthogonal matrix
    or batch of orthogonal matrices and $R$R being an upper triangular matrix or batch
    of upper triangular matrices. |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| [`qr`](generated/torch.qr.html#torch.qr "torch.qr") | 计算矩阵或批量矩阵 `input` 的
    QR 分解，并返回一个命名元组 (Q, R)，使得 $\text{input} = Q R$input=QR，其中 $Q$Q 是正交矩阵或批量正交矩阵，$R$R
    是上三角矩阵或批量上三角矩阵。 |'
- en: '| [`svd`](generated/torch.svd.html#torch.svd "torch.svd") | Computes the singular
    value decomposition of either a matrix or batch of matrices `input`. |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| [`svd`](generated/torch.svd.html#torch.svd "torch.svd") | 计算矩阵或矩阵批次 `input`
    的奇异值分解。 |'
- en: '| [`svd_lowrank`](generated/torch.svd_lowrank.html#torch.svd_lowrank "torch.svd_lowrank")
    | Return the singular value decomposition `(U, S, V)` of a matrix, batches of
    matrices, or a sparse matrix $A$A such that $A \approx U diag(S) V^T$A≈Udiag(S)VT.
    |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| [`svd_lowrank`](generated/torch.svd_lowrank.html#torch.svd_lowrank "torch.svd_lowrank")
    | 返回矩阵、矩阵批次或稀疏矩阵 $A$A 的奇异值分解 `(U, S, V)`，使得 $A \approx U diag(S) V^T$A≈Udiag(S)VT。
    |'
- en: '| [`pca_lowrank`](generated/torch.pca_lowrank.html#torch.pca_lowrank "torch.pca_lowrank")
    | Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches
    of such matrices, or sparse matrix. |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| [`pca_lowrank`](generated/torch.pca_lowrank.html#torch.pca_lowrank "torch.pca_lowrank")
    | 对低秩矩阵、这类矩阵批次或稀疏矩阵执行线性主成分分析（PCA）。 |'
- en: '| [`lobpcg`](generated/torch.lobpcg.html#torch.lobpcg "torch.lobpcg") | Find
    the k largest (or smallest) eigenvalues and the corresponding eigenvectors of
    a symmetric positive definite generalized eigenvalue problem using matrix-free
    LOBPCG methods. |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| [`lobpcg`](generated/torch.lobpcg.html#torch.lobpcg "torch.lobpcg") | 使用无矩阵
    LOBPCG 方法找到对称正定广义特征值问题的 k 个最大（或最小）特征值及其对应的特征向量。 |'
- en: '| [`trapz`](generated/torch.trapz.html#torch.trapz "torch.trapz") | Alias for
    [`torch.trapezoid()`](generated/torch.trapezoid.html#torch.trapezoid "torch.trapezoid").
    |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| [`trapz`](generated/torch.trapz.html#torch.trapz "torch.trapz") | [`torch.trapezoid()`](generated/torch.trapezoid.html#torch.trapezoid
    "torch.trapezoid") 的别名。 |'
- en: '| [`trapezoid`](generated/torch.trapezoid.html#torch.trapezoid "torch.trapezoid")
    | Computes the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)
    along `dim`. |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| [`trapezoid`](generated/torch.trapezoid.html#torch.trapezoid "torch.trapezoid")
    | 计算沿着 `dim` 的 [梯形法则](https://en.wikipedia.org/wiki/Trapezoidal_rule)。 |'
- en: '| [`cumulative_trapezoid`](generated/torch.cumulative_trapezoid.html#torch.cumulative_trapezoid
    "torch.cumulative_trapezoid") | Cumulatively computes the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)
    along `dim`. |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| [`cumulative_trapezoid`](generated/torch.cumulative_trapezoid.html#torch.cumulative_trapezoid
    "torch.cumulative_trapezoid") | 累积计算沿着 `dim` 的 [梯形法则](https://en.wikipedia.org/wiki/Trapezoidal_rule)。
    |'
- en: '| [`triangular_solve`](generated/torch.triangular_solve.html#torch.triangular_solve
    "torch.triangular_solve") | Solves a system of equations with a square upper or
    lower triangular invertible matrix $A$A and multiple right-hand sides $b$b. |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| [`triangular_solve`](generated/torch.triangular_solve.html#torch.triangular_solve
    "torch.triangular_solve") | 解一个具有方形上三角或下三角可逆矩阵 $A$A 和多个右侧的方程组 $b$b。 |'
- en: '| [`vdot`](generated/torch.vdot.html#torch.vdot "torch.vdot") | Computes the
    dot product of two 1D vectors along a dimension. |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| [`vdot`](generated/torch.vdot.html#torch.vdot "torch.vdot") | 计算沿着一个维度的两个
    1D 向量的点积。 |'
- en: Foreach Operations
  id: totrans-433
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Foreach 操作
- en: Warning
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: This API is in beta and subject to future changes. Forward-mode AD is not supported.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 此 API 处于 beta 阶段，可能会有未来更改。不支持正向模式自动微分。
- en: '| [`_foreach_abs`](generated/torch._foreach_abs.html#torch._foreach_abs "torch._foreach_abs")
    | Apply [`torch.abs()`](generated/torch.abs.html#torch.abs "torch.abs") to each
    Tensor of the input list. |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_abs`](generated/torch._foreach_abs.html#torch._foreach_abs "torch._foreach_abs")
    | 对输入列表中的每个张量应用 [`torch.abs()`](generated/torch.abs.html#torch.abs "torch.abs")。
    |'
- en: '| [`_foreach_abs_`](generated/torch._foreach_abs_.html#torch._foreach_abs_
    "torch._foreach_abs_") | Apply [`torch.abs()`](generated/torch.abs.html#torch.abs
    "torch.abs") to each Tensor of the input list. |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_abs_`](generated/torch._foreach_abs_.html#torch._foreach_abs_
    "torch._foreach_abs_") | 对输入列表中的每个张量应用 [`torch.abs()`](generated/torch.abs.html#torch.abs
    "torch.abs")。 |'
- en: '| [`_foreach_acos`](generated/torch._foreach_acos.html#torch._foreach_acos
    "torch._foreach_acos") | Apply [`torch.acos()`](generated/torch.acos.html#torch.acos
    "torch.acos") to each Tensor of the input list. |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_acos`](generated/torch._foreach_acos.html#torch._foreach_acos
    "torch._foreach_acos") | 对输入列表中的每个张量应用 [`torch.acos()`](generated/torch.acos.html#torch.acos
    "torch.acos")。 |'
- en: '| [`_foreach_acos_`](generated/torch._foreach_acos_.html#torch._foreach_acos_
    "torch._foreach_acos_") | Apply [`torch.acos()`](generated/torch.acos.html#torch.acos
    "torch.acos") to each Tensor of the input list. |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_acos_`](generated/torch._foreach_acos_.html#torch._foreach_acos_
    "torch._foreach_acos_") | 对输入列表中的每个张量应用 [`torch.acos()`](generated/torch.acos.html#torch.acos
    "torch.acos")。 |'
- en: '| [`_foreach_asin`](generated/torch._foreach_asin.html#torch._foreach_asin
    "torch._foreach_asin") | Apply [`torch.asin()`](generated/torch.asin.html#torch.asin
    "torch.asin") to each Tensor of the input list. |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_asin`](generated/torch._foreach_asin.html#torch._foreach_asin
    "torch._foreach_asin") | 对输入列表中的每个张量应用 [`torch.asin()`](generated/torch.asin.html#torch.asin
    "torch.asin")。 |'
- en: '| [`_foreach_asin_`](generated/torch._foreach_asin_.html#torch._foreach_asin_
    "torch._foreach_asin_") | Apply [`torch.asin()`](generated/torch.asin.html#torch.asin
    "torch.asin") to each Tensor of the input list. |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_asin_`](generated/torch._foreach_asin_.html#torch._foreach_asin_
    "torch._foreach_asin_") | 对输入列表中的每个张量应用 [`torch.asin()`](generated/torch.asin.html#torch.asin
    "torch.asin")。 |'
- en: '| [`_foreach_atan`](generated/torch._foreach_atan.html#torch._foreach_atan
    "torch._foreach_atan") | Apply [`torch.atan()`](generated/torch.atan.html#torch.atan
    "torch.atan") to each Tensor of the input list. |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_atan`](generated/torch._foreach_atan.html#torch._foreach_atan
    "torch._foreach_atan") | 对输入列表中的每个张量应用 [`torch.atan()`](generated/torch.atan.html#torch.atan
    "torch.atan")。 |'
- en: '| [`_foreach_atan_`](generated/torch._foreach_atan_.html#torch._foreach_atan_
    "torch._foreach_atan_") | Apply [`torch.atan()`](generated/torch.atan.html#torch.atan
    "torch.atan") to each Tensor of the input list. |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_atan_`](generated/torch._foreach_atan_.html#torch._foreach_atan_
    "torch._foreach_atan_") | 对输入列表中的每个张量应用 [`torch.atan()`](generated/torch.atan.html#torch.atan
    "torch.atan")。 |'
- en: '| [`_foreach_ceil`](generated/torch._foreach_ceil.html#torch._foreach_ceil
    "torch._foreach_ceil") | Apply [`torch.ceil()`](generated/torch.ceil.html#torch.ceil
    "torch.ceil") to each Tensor of the input list. |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_ceil`](generated/torch._foreach_ceil.html#torch._foreach_ceil
    "torch._foreach_ceil") | 对输入列表中的每个张量应用 [`torch.ceil()`](generated/torch.ceil.html#torch.ceil
    "torch.ceil")。 |'
- en: '| [`_foreach_ceil_`](generated/torch._foreach_ceil_.html#torch._foreach_ceil_
    "torch._foreach_ceil_") | Apply [`torch.ceil()`](generated/torch.ceil.html#torch.ceil
    "torch.ceil") to each Tensor of the input list. |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_ceil_`](generated/torch._foreach_ceil_.html#torch._foreach_ceil_
    "torch._foreach_ceil_") | 对输入列表中的每个张量应用 [`torch.ceil()`](generated/torch.ceil.html#torch.ceil
    "torch.ceil")。 |'
- en: '| [`_foreach_cos`](generated/torch._foreach_cos.html#torch._foreach_cos "torch._foreach_cos")
    | Apply [`torch.cos()`](generated/torch.cos.html#torch.cos "torch.cos") to each
    Tensor of the input list. |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_cos`](generated/torch._foreach_cos.html#torch._foreach_cos "torch._foreach_cos")
    | 对输入列表中的每个张量应用 [`torch.cos()`](generated/torch.cos.html#torch.cos "torch.cos")。
    |'
- en: '| [`_foreach_cos_`](generated/torch._foreach_cos_.html#torch._foreach_cos_
    "torch._foreach_cos_") | Apply [`torch.cos()`](generated/torch.cos.html#torch.cos
    "torch.cos") to each Tensor of the input list. |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_cos_`](generated/torch._foreach_cos_.html#torch._foreach_cos_
    "torch._foreach_cos_") | 对输入列表中的每个张量应用 [`torch.cos()`](generated/torch.cos.html#torch.cos
    "torch.cos")。 |'
- en: '| [`_foreach_cosh`](generated/torch._foreach_cosh.html#torch._foreach_cosh
    "torch._foreach_cosh") | Apply [`torch.cosh()`](generated/torch.cosh.html#torch.cosh
    "torch.cosh") to each Tensor of the input list. |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_cosh`](generated/torch._foreach_cosh.html#torch._foreach_cosh
    "torch._foreach_cosh") | 对输入列表中的每个张量应用 [`torch.cosh()`](generated/torch.cosh.html#torch.cosh
    "torch.cosh")。 |'
- en: '| [`_foreach_cosh_`](generated/torch._foreach_cosh_.html#torch._foreach_cosh_
    "torch._foreach_cosh_") | Apply [`torch.cosh()`](generated/torch.cosh.html#torch.cosh
    "torch.cosh") to each Tensor of the input list. |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_cosh_`](generated/torch._foreach_cosh_.html#torch._foreach_cosh_
    "torch._foreach_cosh_") | 对输入列表中的每个张量应用 [`torch.cosh()`](generated/torch.cosh.html#torch.cosh
    "torch.cosh")。 |'
- en: '| [`_foreach_erf`](generated/torch._foreach_erf.html#torch._foreach_erf "torch._foreach_erf")
    | Apply [`torch.erf()`](generated/torch.erf.html#torch.erf "torch.erf") to each
    Tensor of the input list. |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_erf`](generated/torch._foreach_erf.html#torch._foreach_erf "torch._foreach_erf")
    | 对输入列表中的每个张量应用 [`torch.erf()`](generated/torch.erf.html#torch.erf "torch.erf")。
    |'
- en: '| [`_foreach_erf_`](generated/torch._foreach_erf_.html#torch._foreach_erf_
    "torch._foreach_erf_") | Apply [`torch.erf()`](generated/torch.erf.html#torch.erf
    "torch.erf") to each Tensor of the input list. |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_erf_`](generated/torch._foreach_erf_.html#torch._foreach_erf_
    "torch._foreach_erf_") | 对输入列表中的每个张量应用 [`torch.erf()`](generated/torch.erf.html#torch.erf
    "torch.erf")。 |'
- en: '| [`_foreach_erfc`](generated/torch._foreach_erfc.html#torch._foreach_erfc
    "torch._foreach_erfc") | Apply [`torch.erfc()`](generated/torch.erfc.html#torch.erfc
    "torch.erfc") to each Tensor of the input list. |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_erfc`](generated/torch._foreach_erfc.html#torch._foreach_erfc
    "torch._foreach_erfc") | 对输入列表中的每个张量应用 [`torch.erfc()`](generated/torch.erfc.html#torch.erfc
    "torch.erfc")。 |'
- en: '| [`_foreach_erfc_`](generated/torch._foreach_erfc_.html#torch._foreach_erfc_
    "torch._foreach_erfc_") | Apply [`torch.erfc()`](generated/torch.erfc.html#torch.erfc
    "torch.erfc") to each Tensor of the input list. |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_erfc_`](generated/torch._foreach_erfc_.html#torch._foreach_erfc_
    "torch._foreach_erfc_") | 对输入列表中的每个张量应用 [`torch.erfc()`](generated/torch.erfc.html#torch.erfc
    "torch.erfc")。 |'
- en: '| [`_foreach_exp`](generated/torch._foreach_exp.html#torch._foreach_exp "torch._foreach_exp")
    | Apply [`torch.exp()`](generated/torch.exp.html#torch.exp "torch.exp") to each
    Tensor of the input list. |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_exp`](generated/torch._foreach_exp.html#torch._foreach_exp "torch._foreach_exp")
    | 对输入列表中的每个张量应用 [`torch.exp()`](generated/torch.exp.html#torch.exp "torch.exp")。
    |'
- en: '| [`_foreach_exp_`](generated/torch._foreach_exp_.html#torch._foreach_exp_
    "torch._foreach_exp_") | Apply [`torch.exp()`](generated/torch.exp.html#torch.exp
    "torch.exp") to each Tensor of the input list. |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_exp_`](generated/torch._foreach_exp_.html#torch._foreach_exp_
    "torch._foreach_exp_") | 对输入列表中的每个张量应用 [`torch.exp()`](generated/torch.exp.html#torch.exp
    "torch.exp")。 |'
- en: '| [`_foreach_expm1`](generated/torch._foreach_expm1.html#torch._foreach_expm1
    "torch._foreach_expm1") | Apply [`torch.expm1()`](generated/torch.expm1.html#torch.expm1
    "torch.expm1") to each Tensor of the input list. |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_expm1`](generated/torch._foreach_expm1.html#torch._foreach_expm1
    "torch._foreach_expm1") | 对输入列表中的每个张量应用 [`torch.expm1()`](generated/torch.expm1.html#torch.expm1
    "torch.expm1")。 |'
- en: '| [`_foreach_expm1_`](generated/torch._foreach_expm1_.html#torch._foreach_expm1_
    "torch._foreach_expm1_") | Apply [`torch.expm1()`](generated/torch.expm1.html#torch.expm1
    "torch.expm1") to each Tensor of the input list. |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_expm1_`](generated/torch._foreach_expm1_.html#torch._foreach_expm1_
    "torch._foreach_expm1_") | 对输入列表中的每个张量应用 [`torch.expm1()`](generated/torch.expm1.html#torch.expm1
    "torch.expm1")。 |'
- en: '| [`_foreach_floor`](generated/torch._foreach_floor.html#torch._foreach_floor
    "torch._foreach_floor") | Apply [`torch.floor()`](generated/torch.floor.html#torch.floor
    "torch.floor") to each Tensor of the input list. |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_floor`](generated/torch._foreach_floor.html#torch._foreach_floor
    "torch._foreach_floor") | 对输入列表中的每个张量应用 [`torch.floor()`](generated/torch.floor.html#torch.floor
    "torch.floor")。 |'
- en: '| [`_foreach_floor_`](generated/torch._foreach_floor_.html#torch._foreach_floor_
    "torch._foreach_floor_") | Apply [`torch.floor()`](generated/torch.floor.html#torch.floor
    "torch.floor") to each Tensor of the input list. |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_floor_`](generated/torch._foreach_floor_.html#torch._foreach_floor_
    "torch._foreach_floor_") | 对输入列表中的每个张量应用 [`torch.floor()`](generated/torch.floor.html#torch.floor
    "torch.floor")。 |'
- en: '| [`_foreach_log`](generated/torch._foreach_log.html#torch._foreach_log "torch._foreach_log")
    | Apply [`torch.log()`](generated/torch.log.html#torch.log "torch.log") to each
    Tensor of the input list. |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log`](generated/torch._foreach_log.html#torch._foreach_log "torch._foreach_log")
    | 对输入列表中的每个张量应用 [`torch.log()`](generated/torch.log.html#torch.log "torch.log")。
    |'
- en: '| [`_foreach_log_`](generated/torch._foreach_log_.html#torch._foreach_log_
    "torch._foreach_log_") | Apply [`torch.log()`](generated/torch.log.html#torch.log
    "torch.log") to each Tensor of the input list. |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log_`](generated/torch._foreach_log_.html#torch._foreach_log_
    "torch._foreach_log_") | 对输入列表中的每个张量应用 [`torch.log()`](generated/torch.log.html#torch.log
    "torch.log")。 |'
- en: '| [`_foreach_log10`](generated/torch._foreach_log10.html#torch._foreach_log10
    "torch._foreach_log10") | Apply [`torch.log10()`](generated/torch.log10.html#torch.log10
    "torch.log10") to each Tensor of the input list. |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log10`](generated/torch._foreach_log10.html#torch._foreach_log10
    "torch._foreach_log10") | 对输入列表中的每个张量应用 [`torch.log10()`](generated/torch.log10.html#torch.log10
    "torch.log10")。 |'
- en: '| [`_foreach_log10_`](generated/torch._foreach_log10_.html#torch._foreach_log10_
    "torch._foreach_log10_") | Apply [`torch.log10()`](generated/torch.log10.html#torch.log10
    "torch.log10") to each Tensor of the input list. |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log10_`](generated/torch._foreach_log10_.html#torch._foreach_log10_
    "torch._foreach_log10_") | 对输入列表中的每个张量应用 [`torch.log10()`](generated/torch.log10.html#torch.log10
    "torch.log10")。 |'
- en: '| [`_foreach_log1p`](generated/torch._foreach_log1p.html#torch._foreach_log1p
    "torch._foreach_log1p") | Apply [`torch.log1p()`](generated/torch.log1p.html#torch.log1p
    "torch.log1p") to each Tensor of the input list. |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log1p`](generated/torch._foreach_log1p.html#torch._foreach_log1p
    "torch._foreach_log1p") | 对输入列表中的每个张量应用 [`torch.log1p()`](generated/torch.log1p.html#torch.log1p
    "torch.log1p")。 |'
- en: '| [`_foreach_log1p_`](generated/torch._foreach_log1p_.html#torch._foreach_log1p_
    "torch._foreach_log1p_") | Apply [`torch.log1p()`](generated/torch.log1p.html#torch.log1p
    "torch.log1p") to each Tensor of the input list. |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log1p_`](generated/torch._foreach_log1p_.html#torch._foreach_log1p_
    "torch._foreach_log1p_") | 对输入列表中的每个张量应用 [`torch.log1p()`](generated/torch.log1p.html#torch.log1p
    "torch.log1p")。 |'
- en: '| [`_foreach_log2`](generated/torch._foreach_log2.html#torch._foreach_log2
    "torch._foreach_log2") | Apply [`torch.log2()`](generated/torch.log2.html#torch.log2
    "torch.log2") to each Tensor of the input list. |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log2`](generated/torch._foreach_log2.html#torch._foreach_log2
    "torch._foreach_log2") | 对输入列表中的每个张量应用 [`torch.log2()`](generated/torch.log2.html#torch.log2
    "torch.log2")。 |'
- en: '| [`_foreach_log2_`](generated/torch._foreach_log2_.html#torch._foreach_log2_
    "torch._foreach_log2_") | Apply [`torch.log2()`](generated/torch.log2.html#torch.log2
    "torch.log2") to each Tensor of the input list. |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_log2_`](generated/torch._foreach_log2_.html#torch._foreach_log2_
    "torch._foreach_log2_") | 对输入列表中的每个张量应用 [`torch.log2()`](generated/torch.log2.html#torch.log2
    "torch.log2")。 |'
- en: '| [`_foreach_neg`](generated/torch._foreach_neg.html#torch._foreach_neg "torch._foreach_neg")
    | Apply [`torch.neg()`](generated/torch.neg.html#torch.neg "torch.neg") to each
    Tensor of the input list. |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_neg`](generated/torch._foreach_neg.html#torch._foreach_neg "torch._foreach_neg")
    | 对输入列表中的每个张量应用 [`torch.neg()`](generated/torch.neg.html#torch.neg "torch.neg")。
    |'
- en: '| [`_foreach_neg_`](generated/torch._foreach_neg_.html#torch._foreach_neg_
    "torch._foreach_neg_") | Apply [`torch.neg()`](generated/torch.neg.html#torch.neg
    "torch.neg") to each Tensor of the input list. |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_neg_`](generated/torch._foreach_neg_.html#torch._foreach_neg_
    "torch._foreach_neg_") | 对输入列表中的每个张量应用 [`torch.neg()`](generated/torch.neg.html#torch.neg
    "torch.neg")。 |'
- en: '| [`_foreach_tan`](generated/torch._foreach_tan.html#torch._foreach_tan "torch._foreach_tan")
    | Apply [`torch.tan()`](generated/torch.tan.html#torch.tan "torch.tan") to each
    Tensor of the input list. |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_tan`](generated/torch._foreach_tan.html#torch._foreach_tan "torch._foreach_tan")
    | 对输入列表中的每个张量应用 [`torch.tan()`](generated/torch.tan.html#torch.tan "torch.tan")。
    |'
- en: '| [`_foreach_tan_`](generated/torch._foreach_tan_.html#torch._foreach_tan_
    "torch._foreach_tan_") | Apply [`torch.tan()`](generated/torch.tan.html#torch.tan
    "torch.tan") to each Tensor of the input list. |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_tan_`](generated/torch._foreach_tan_.html#torch._foreach_tan_
    "torch._foreach_tan_") | 对输入列表中的每个张量应用 [`torch.tan()`](generated/torch.tan.html#torch.tan
    "torch.tan")。 |'
- en: '| [`_foreach_sin`](generated/torch._foreach_sin.html#torch._foreach_sin "torch._foreach_sin")
    | Apply [`torch.sin()`](generated/torch.sin.html#torch.sin "torch.sin") to each
    Tensor of the input list. |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sin`](generated/torch._foreach_sin.html#torch._foreach_sin "torch._foreach_sin")
    | 对输入列表中的每个张量应用 [`torch.sin()`](generated/torch.sin.html#torch.sin "torch.sin")。
    |'
- en: '| [`_foreach_sin_`](generated/torch._foreach_sin_.html#torch._foreach_sin_
    "torch._foreach_sin_") | Apply [`torch.sin()`](generated/torch.sin.html#torch.sin
    "torch.sin") to each Tensor of the input list. |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sin_`](generated/torch._foreach_sin_.html#torch._foreach_sin_
    "torch._foreach_sin_") | 对输入列表中的每个张量应用 [`torch.sin()`](generated/torch.sin.html#torch.sin
    "torch.sin")。 |'
- en: '| [`_foreach_sinh`](generated/torch._foreach_sinh.html#torch._foreach_sinh
    "torch._foreach_sinh") | Apply [`torch.sinh()`](generated/torch.sinh.html#torch.sinh
    "torch.sinh") to each Tensor of the input list. |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sinh`](generated/torch._foreach_sinh.html#torch._foreach_sinh
    "torch._foreach_sinh") | 对输入列表中的每个张量应用 [`torch.sinh()`](generated/torch.sinh.html#torch.sinh
    "torch.sinh")。 |'
- en: '| [`_foreach_sinh_`](generated/torch._foreach_sinh_.html#torch._foreach_sinh_
    "torch._foreach_sinh_") | Apply [`torch.sinh()`](generated/torch.sinh.html#torch.sinh
    "torch.sinh") to each Tensor of the input list. |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sinh_`](generated/torch._foreach_sinh_.html#torch._foreach_sinh_
    "torch._foreach_sinh_") | 对输入列表中的每个张量应用 [`torch.sinh()`](generated/torch.sinh.html#torch.sinh
    "torch.sinh")。 |'
- en: '| [`_foreach_round`](generated/torch._foreach_round.html#torch._foreach_round
    "torch._foreach_round") | Apply [`torch.round()`](generated/torch.round.html#torch.round
    "torch.round") to each Tensor of the input list. |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_round`](generated/torch._foreach_round.html#torch._foreach_round
    "torch._foreach_round") | 对输入列表中的每个张量应用 [`torch.round()`](generated/torch.round.html#torch.round
    "torch.round")。 |'
- en: '| [`_foreach_round_`](generated/torch._foreach_round_.html#torch._foreach_round_
    "torch._foreach_round_") | Apply [`torch.round()`](generated/torch.round.html#torch.round
    "torch.round") to each Tensor of the input list. |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_round_`](generated/torch._foreach_round_.html#torch._foreach_round_
    "torch._foreach_round_") | 对输入列表中的每个张量应用 [`torch.round()`](generated/torch.round.html#torch.round
    "torch.round")。 |'
- en: '| [`_foreach_sqrt`](generated/torch._foreach_sqrt.html#torch._foreach_sqrt
    "torch._foreach_sqrt") | Apply [`torch.sqrt()`](generated/torch.sqrt.html#torch.sqrt
    "torch.sqrt") to each Tensor of the input list. |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sqrt`](generated/torch._foreach_sqrt.html#torch._foreach_sqrt
    "torch._foreach_sqrt") | 对输入列表中的每个张量应用 [`torch.sqrt()`](generated/torch.sqrt.html#torch.sqrt
    "torch.sqrt")。 |'
- en: '| [`_foreach_sqrt_`](generated/torch._foreach_sqrt_.html#torch._foreach_sqrt_
    "torch._foreach_sqrt_") | Apply [`torch.sqrt()`](generated/torch.sqrt.html#torch.sqrt
    "torch.sqrt") to each Tensor of the input list. |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sqrt_`](generated/torch._foreach_sqrt_.html#torch._foreach_sqrt_
    "torch._foreach_sqrt_") | 对输入列表中的每个张量应用 [`torch.sqrt()`](generated/torch.sqrt.html#torch.sqrt
    "torch.sqrt")。 |'
- en: '| [`_foreach_lgamma`](generated/torch._foreach_lgamma.html#torch._foreach_lgamma
    "torch._foreach_lgamma") | Apply [`torch.lgamma()`](generated/torch.lgamma.html#torch.lgamma
    "torch.lgamma") to each Tensor of the input list. |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_lgamma`](generated/torch._foreach_lgamma.html#torch._foreach_lgamma
    "torch._foreach_lgamma") | 对输入列表中的每个张量应用 [`torch.lgamma()`](generated/torch.lgamma.html#torch.lgamma
    "torch.lgamma")。 |'
- en: '| [`_foreach_lgamma_`](generated/torch._foreach_lgamma_.html#torch._foreach_lgamma_
    "torch._foreach_lgamma_") | Apply [`torch.lgamma()`](generated/torch.lgamma.html#torch.lgamma
    "torch.lgamma") to each Tensor of the input list. |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_lgamma_`](generated/torch._foreach_lgamma_.html#torch._foreach_lgamma_
    "torch._foreach_lgamma_") | 对输入列表中的每个张量应用 [`torch.lgamma()`](generated/torch.lgamma.html#torch.lgamma
    "torch.lgamma")。 |'
- en: '| [`_foreach_frac`](generated/torch._foreach_frac.html#torch._foreach_frac
    "torch._foreach_frac") | Apply [`torch.frac()`](generated/torch.frac.html#torch.frac
    "torch.frac") to each Tensor of the input list. |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_frac`](generated/torch._foreach_frac.html#torch._foreach_frac
    "torch._foreach_frac") | 对输入列表中的每个张量应用 [`torch.frac()`](generated/torch.frac.html#torch.frac
    "torch.frac")。 |'
- en: '| [`_foreach_frac_`](generated/torch._foreach_frac_.html#torch._foreach_frac_
    "torch._foreach_frac_") | Apply [`torch.frac()`](generated/torch.frac.html#torch.frac
    "torch.frac") to each Tensor of the input list. |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_frac_`](generated/torch._foreach_frac_.html#torch._foreach_frac_
    "torch._foreach_frac_") | 对输入列表中的每个张量应用 [`torch.frac()`](generated/torch.frac.html#torch.frac
    "torch.frac")。 |'
- en: '| [`_foreach_reciprocal`](generated/torch._foreach_reciprocal.html#torch._foreach_reciprocal
    "torch._foreach_reciprocal") | Apply [`torch.reciprocal()`](generated/torch.reciprocal.html#torch.reciprocal
    "torch.reciprocal") to each Tensor of the input list. |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_reciprocal`](generated/torch._foreach_reciprocal.html#torch._foreach_reciprocal
    "torch._foreach_reciprocal") | 对输入列表中的每个张量应用 [`torch.reciprocal()`](generated/torch.reciprocal.html#torch.reciprocal
    "torch.reciprocal")。 |'
- en: '| [`_foreach_reciprocal_`](generated/torch._foreach_reciprocal_.html#torch._foreach_reciprocal_
    "torch._foreach_reciprocal_") | Apply [`torch.reciprocal()`](generated/torch.reciprocal.html#torch.reciprocal
    "torch.reciprocal") to each Tensor of the input list. |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_reciprocal_`](generated/torch._foreach_reciprocal_.html#torch._foreach_reciprocal_
    "torch._foreach_reciprocal_") | 对输入列表中的每个张量应用 [`torch.reciprocal()`](generated/torch.reciprocal.html#torch.reciprocal
    "torch.reciprocal")。 |'
- en: '| [`_foreach_sigmoid`](generated/torch._foreach_sigmoid.html#torch._foreach_sigmoid
    "torch._foreach_sigmoid") | Apply [`torch.sigmoid()`](generated/torch.sigmoid.html#torch.sigmoid
    "torch.sigmoid") to each Tensor of the input list. |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sigmoid`](generated/torch._foreach_sigmoid.html#torch._foreach_sigmoid
    "torch._foreach_sigmoid") | 对输入列表中的每个张量应用 [`torch.sigmoid()`](generated/torch.sigmoid.html#torch.sigmoid
    "torch.sigmoid")。 |'
- en: '| [`_foreach_sigmoid_`](generated/torch._foreach_sigmoid_.html#torch._foreach_sigmoid_
    "torch._foreach_sigmoid_") | Apply [`torch.sigmoid()`](generated/torch.sigmoid.html#torch.sigmoid
    "torch.sigmoid") to each Tensor of the input list. |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_sigmoid_`](generated/torch._foreach_sigmoid_.html#torch._foreach_sigmoid_
    "torch._foreach_sigmoid_") | 对输入列表中的每个张量应用 [`torch.sigmoid()`](generated/torch.sigmoid.html#torch.sigmoid
    "torch.sigmoid")。 |'
- en: '| [`_foreach_trunc`](generated/torch._foreach_trunc.html#torch._foreach_trunc
    "torch._foreach_trunc") | Apply [`torch.trunc()`](generated/torch.trunc.html#torch.trunc
    "torch.trunc") to each Tensor of the input list. |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_trunc`](generated/torch._foreach_trunc.html#torch._foreach_trunc
    "torch._foreach_trunc") | 对输入列表中的每个张量应用 [`torch.trunc()`](generated/torch.trunc.html#torch.trunc
    "torch.trunc")。 |'
- en: '| [`_foreach_trunc_`](generated/torch._foreach_trunc_.html#torch._foreach_trunc_
    "torch._foreach_trunc_") | Apply [`torch.trunc()`](generated/torch.trunc.html#torch.trunc
    "torch.trunc") to each Tensor of the input list. |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_trunc_`](generated/torch._foreach_trunc_.html#torch._foreach_trunc_
    "torch._foreach_trunc_") | 对输入列表中的每个张量应用 [`torch.trunc()`](generated/torch.trunc.html#torch.trunc
    "torch.trunc")。 |'
- en: '| [`_foreach_zero_`](generated/torch._foreach_zero_.html#torch._foreach_zero_
    "torch._foreach_zero_") | Apply `torch.zero()` to each Tensor of the input list.
    |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| [`_foreach_zero_`](generated/torch._foreach_zero_.html#torch._foreach_zero_
    "torch._foreach_zero_") | 对输入列表中的每个张量应用 `torch.zero()`。 |'
- en: Utilities
  id: totrans-491
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Utilities
- en: '| [`compiled_with_cxx11_abi`](generated/torch.compiled_with_cxx11_abi.html#torch.compiled_with_cxx11_abi
    "torch.compiled_with_cxx11_abi") | Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1
    |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| [`compiled_with_cxx11_abi`](generated/torch.compiled_with_cxx11_abi.html#torch.compiled_with_cxx11_abi
    "torch.compiled_with_cxx11_abi") | 返回 PyTorch 是否使用 _GLIBCXX_USE_CXX11_ABI=1 构建。
    |'
- en: '| [`result_type`](generated/torch.result_type.html#torch.result_type "torch.result_type")
    | Returns the [`torch.dtype`](tensor_attributes.html#torch.dtype "torch.dtype")
    that would result from performing an arithmetic operation on the provided input
    tensors. |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| [`result_type`](generated/torch.result_type.html#torch.result_type "torch.result_type")
    | 返回在提供的输入张量上执行算术运算后将产生的 [`torch.dtype`](tensor_attributes.html#torch.dtype "torch.dtype")。
    |'
- en: '| [`can_cast`](generated/torch.can_cast.html#torch.can_cast "torch.can_cast")
    | Determines if a type conversion is allowed under PyTorch casting rules described
    in the type promotion [documentation](tensor_attributes.html#type-promotion-doc).
    |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| [`can_cast`](generated/torch.can_cast.html#torch.can_cast "torch.can_cast")
    | 确定在 PyTorch 类型转换规则下是否允许类型转换，规则描述在类型提升 [文档](tensor_attributes.html#type-promotion-doc)中。
    |'
- en: '| [`promote_types`](generated/torch.promote_types.html#torch.promote_types
    "torch.promote_types") | Returns the [`torch.dtype`](tensor_attributes.html#torch.dtype
    "torch.dtype") with the smallest size and scalar kind that is not smaller nor
    of lower kind than either type1 or type2. |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '| [`promote_types`](generated/torch.promote_types.html#torch.promote_types
    "torch.promote_types") | 返回具有不小于 type1 或 type2 的大小和标量类型的 [`torch.dtype`](tensor_attributes.html#torch.dtype
    "torch.dtype")。 |'
- en: '| [`use_deterministic_algorithms`](generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms
    "torch.use_deterministic_algorithms") | Sets whether PyTorch operations must use
    "deterministic" algorithms. |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| [`use_deterministic_algorithms`](generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms
    "torch.use_deterministic_algorithms") | 设置 PyTorch 操作是否必须使用“确定性”算法。 |'
- en: '| [`are_deterministic_algorithms_enabled`](generated/torch.are_deterministic_algorithms_enabled.html#torch.are_deterministic_algorithms_enabled
    "torch.are_deterministic_algorithms_enabled") | Returns True if the global deterministic
    flag is turned on. |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| [`are_deterministic_algorithms_enabled`](generated/torch.are_deterministic_algorithms_enabled.html#torch.are_deterministic_algorithms_enabled
    "torch.are_deterministic_algorithms_enabled") | 如果全局确定性标志打开，则返回True。 |'
- en: '| [`is_deterministic_algorithms_warn_only_enabled`](generated/torch.is_deterministic_algorithms_warn_only_enabled.html#torch.is_deterministic_algorithms_warn_only_enabled
    "torch.is_deterministic_algorithms_warn_only_enabled") | Returns True if the global
    deterministic flag is set to warn only. |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| [`is_deterministic_algorithms_warn_only_enabled`](generated/torch.is_deterministic_algorithms_warn_only_enabled.html#torch.is_deterministic_algorithms_warn_only_enabled
    "torch.is_deterministic_algorithms_warn_only_enabled") | 如果全局确定性标志设置为仅警告，则返回True。
    |'
- en: '| [`set_deterministic_debug_mode`](generated/torch.set_deterministic_debug_mode.html#torch.set_deterministic_debug_mode
    "torch.set_deterministic_debug_mode") | Sets the debug mode for deterministic
    operations. |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| [`set_deterministic_debug_mode`](generated/torch.set_deterministic_debug_mode.html#torch.set_deterministic_debug_mode
    "torch.set_deterministic_debug_mode") | 设置确定性操作的调试模式。 |'
- en: '| [`get_deterministic_debug_mode`](generated/torch.get_deterministic_debug_mode.html#torch.get_deterministic_debug_mode
    "torch.get_deterministic_debug_mode") | Returns the current value of the debug
    mode for deterministic operations. |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| [`get_deterministic_debug_mode`](generated/torch.get_deterministic_debug_mode.html#torch.get_deterministic_debug_mode
    "torch.get_deterministic_debug_mode") | 返回确定性操作的调试模式的当前值。 |'
- en: '| [`set_float32_matmul_precision`](generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
    "torch.set_float32_matmul_precision") | Sets the internal precision of float32
    matrix multiplications. |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| [`set_float32_matmul_precision`](generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
    "torch.set_float32_matmul_precision") | 设置float32矩阵乘法的内部精度。 |'
- en: '| [`get_float32_matmul_precision`](generated/torch.get_float32_matmul_precision.html#torch.get_float32_matmul_precision
    "torch.get_float32_matmul_precision") | Returns the current value of float32 matrix
    multiplication precision. |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| [`get_float32_matmul_precision`](generated/torch.get_float32_matmul_precision.html#torch.get_float32_matmul_precision
    "torch.get_float32_matmul_precision") | 返回float32矩阵乘法精度的当前值。 |'
- en: '| [`set_warn_always`](generated/torch.set_warn_always.html#torch.set_warn_always
    "torch.set_warn_always") | When this flag is False (default) then some PyTorch
    warnings may only appear once per process. |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| [`set_warn_always`](generated/torch.set_warn_always.html#torch.set_warn_always
    "torch.set_warn_always") | 当此标志为False（默认）时，一些PyTorch警告可能只会在进程中出现一次。 |'
- en: '| [`is_warn_always_enabled`](generated/torch.is_warn_always_enabled.html#torch.is_warn_always_enabled
    "torch.is_warn_always_enabled") | Returns True if the global warn_always flag
    is turned on. |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '| [`is_warn_always_enabled`](generated/torch.is_warn_always_enabled.html#torch.is_warn_always_enabled
    "torch.is_warn_always_enabled") | 如果全局的warn_always标志打开，则返回True。 |'
- en: '| [`vmap`](generated/torch.vmap.html#torch.vmap "torch.vmap") | vmap is the
    vectorizing map; `vmap(func)` returns a new function that maps `func` over some
    dimension of the inputs. |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| [`vmap`](generated/torch.vmap.html#torch.vmap "torch.vmap") | vmap是矢量化映射；`vmap(func)`返回一个新函数，该函数将`func`映射到输入的某个维度上。
    |'
- en: '| [`_assert`](generated/torch._assert.html#torch._assert "torch._assert") |
    A wrapper around Python''s assert which is symbolically traceable. |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| [`_assert`](generated/torch._assert.html#torch._assert "torch._assert") |
    Python的assert的包装器，可进行符号跟踪。 |'
- en: Symbolic Numbers
  id: totrans-507
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号数字
- en: '[PRE2]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Like an int (including magic methods), but redirects all operations on the wrapped
    node. This is used in particular to symbolically record operations in the symbolic
    shape workflow.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 像一个整数（包括魔术方法），但重定向包装节点上的所有操作。这特别用于在符号形状工作流程中符号记录操作。
- en: '[PRE3]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Like an float (including magic methods), but redirects all operations on the
    wrapped node. This is used in particular to symbolically record operations in
    the symbolic shape workflow.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 像一个浮点数（包括魔术方法），但重定向包装节点上的所有操作。这特别用于在符号形状工作流程中符号记录操作。
- en: '[PRE4]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Like an bool (including magic methods), but redirects all operations on the
    wrapped node. This is used in particular to symbolically record operations in
    the symbolic shape workflow.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 像一个布尔值（包括魔术方法），但重定向包装节点上的所有操作。这特别用于在符号形状工作流程中符号记录操作。
- en: Unlike regular bools, regular boolean operators will force extra guards instead
    of symbolically evaluate. Use the bitwise operators instead to handle this.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 与常规布尔值不同，常规布尔运算符会强制额外的保护而不是符号化评估。请改用位运算符来处理这个问题。
- en: '| [`sym_float`](generated/torch.sym_float.html#torch.sym_float "torch.sym_float")
    | SymInt-aware utility for float casting. |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| [`sym_float`](generated/torch.sym_float.html#torch.sym_float "torch.sym_float")
    | 用于浮点数转换的SymInt感知实用程序。 |'
- en: '| [`sym_int`](generated/torch.sym_int.html#torch.sym_int "torch.sym_int") |
    SymInt-aware utility for int casting. |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| [`sym_int`](generated/torch.sym_int.html#torch.sym_int "torch.sym_int") |
    用于整数转换的SymInt感知实用程序。 |'
- en: '| [`sym_max`](generated/torch.sym_max.html#torch.sym_max "torch.sym_max") |
    SymInt-aware utility for max(). |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| [`sym_max`](generated/torch.sym_max.html#torch.sym_max "torch.sym_max") |
    用于max()的SymInt感知实用程序。 |'
- en: '| [`sym_min`](generated/torch.sym_min.html#torch.sym_min "torch.sym_min") |
    SymInt-aware utility for max(). |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| [`sym_min`](generated/torch.sym_min.html#torch.sym_min "torch.sym_min") |
    用于max()的SymInt感知实用程序。 |'
- en: '| [`sym_not`](generated/torch.sym_not.html#torch.sym_not "torch.sym_not") |
    SymInt-aware utility for logical negation. |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| [`sym_not`](generated/torch.sym_not.html#torch.sym_not "torch.sym_not") |
    用于逻辑否定的SymInt感知实用程序。 |'
- en: '| [`sym_ite`](generated/torch.sym_ite.html#torch.sym_ite "torch.sym_ite") |  |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| [`sym_ite`](generated/torch.sym_ite.html#torch.sym_ite "torch.sym_ite") |  |'
- en: Export Path
  id: totrans-521
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出路径
- en: Warning
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: This feature is a prototype and may have compatibility breaking changes in the
    future.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能是一个原型，未来可能会有兼容性破坏性的更改。
- en: export generated/exportdb/index
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 导出生成的/exportdb/index
- en: Control Flow
  id: totrans-525
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制流
- en: Warning
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: This feature is a prototype and may have compatibility breaking changes in the
    future.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能是一个原型，未来可能会有兼容性破坏性的更改。
- en: '| [`cond`](generated/torch.cond.html#torch.cond "torch.cond") | Conditionally
    applies true_fn or false_fn. |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| [`cond`](generated/torch.cond.html#torch.cond "torch.cond") | 有条件地应用true_fn或false_fn。
    |'
- en: Optimizations
  id: totrans-529
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化
- en: '| [`compile`](generated/torch.compile.html#torch.compile "torch.compile") |
    Optimizes given model/function using TorchDynamo and specified backend. |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| [`compile`](generated/torch.compile.html#torch.compile "torch.compile") |
    使用TorchDynamo和指定的后端优化给定的模型/函数。|'
- en: '[torch.compile documentation](https://pytorch.org/docs/main/compile/index.html)'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '[torch.compile文档](https://pytorch.org/docs/main/compile/index.html)'
- en: Operator Tags
  id: totrans-532
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作符标签
- en: '[PRE5]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Members:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 成员：
- en: core
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 核心
- en: data_dependent_output
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 数据相关输出
- en: dynamic_output_shape
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 动态输出形状
- en: generated
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的
- en: inplace_view
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 原地视图
- en: nondeterministic_bitwise
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 非确定性位运算
- en: nondeterministic_seeded
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 非确定性种子
- en: pointwise
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 逐点
- en: pt2_compliant_tag
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: pt2兼容标签
- en: view_copy
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 视图复制
- en: '[PRE6]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
