# torch.compiler

> 原文：[https://pytorch.org/docs/stable/torch.compiler.html](https://pytorch.org/docs/stable/torch.compiler.html)

`torch.compiler` 是一个命名空间，通过该命名空间，一些内部编译器方法被公开供用户使用。该命名空间中的主要函数和特性是 `torch.compile`。

`torch.compile` 是 PyTorch 2.x 中引入的一个函数，旨在解决 PyTorch 中准确捕获图形的问题，最终使软件工程师能够更快地运行他们的 PyTorch 程序。`torch.compile` 是用 Python 编写的，标志着 PyTorch 从 C++ 转向 Python。

`torch.compile` 利用以下基础技术：

+   **TorchDynamo (torch._dynamo)** 是一个内部 API，使用了一个名为 Frame Evaluation API 的 CPython 特性，安全地捕获 PyTorch 图。对于 PyTorch 用户可用的方法通过 `torch.compiler` 命名空间公开。

+   **TorchInductor** 是默认的 `torch.compile` 深度学习编译器，可以为多个加速器和后端生成快速代码。您需要使用后端编译器才能通过 `torch.compile` 实现加速。对于 NVIDIA 和 AMD GPU，它利用 OpenAI Triton 作为关键构建模块。

+   **AOT Autograd** 不仅捕获用户级代码，还包括反向传播，这导致提前捕获反向传播。这使得使用 TorchInductor 加速前向和反向传播成为可能。

注意

在某些情况下，本文档中可能会互换使用术语 `torch.compile`、TorchDynamo、`torch.compiler`。

如上所述，为了更快地运行您的工作流程，通过 TorchDynamo 的 `torch.compile` 需要一个将捕获的图转换为快速机器代码的后端。不同的后端可能会导致不同的优化收益。默认后端称为 TorchInductor，也称为 *inductor*，TorchDynamo 有一个由我们的合作伙伴开发的支持后端列表，可以通过运行 `torch.compiler.list_backends()` 查看，每个后端都有其可选依赖项。

一些最常用的后端包括：

**训练和推理后端**

| 后端 | 描述 |
| --- | --- |
| `torch.compile(m, backend="inductor")` | 使用 TorchInductor 后端。[阅读更多](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747) |
| `torch.compile(m, backend="cudagraphs")` | 使用 CUDA 图形与 AOT Autograd。[阅读更多](https://github.com/pytorch/torchdynamo/pull/757) |
| `torch.compile(m, backend="ipex")` | 在 CPU 上使用 IPEX。[阅读更多](https://github.com/intel/intel-extension-for-pytorch) |
| `torch.compile(m, backend="onnxrt")` | 使用 ONNX Runtime 在 CPU/GPU 上进行训练。[阅读更多](onnx_dynamo_onnxruntime_backend.html) |

**仅推理后端**

| 后端 | 描述 |
| --- | --- |
| `torch.compile(m, backend="tensorrt")` | 使用 Torch-TensorRT 进行推理优化。需要在调用脚本中导入 `torch_tensorrt` 来注册后端。[阅读更多](https://github.com/pytorch/TensorRT) |
| `torch.compile(m, backend="ipex")` | 在 CPU 上使用 IPEX 进行推理。[阅读更多](https://github.com/intel/intel-extension-for-pytorch) |
| `torch.compile(m, backend="tvm")` | 使用 Apache TVM 进行推理优化。[阅读更多](https://tvm.apache.org/) |
| `torch.compile(m, backend="openvino")` | 使用 OpenVINO 进行推理优化。[阅读更多](https://docs.openvino.ai/2023.1/pytorch_2_0_torch_compile.html) |

## 阅读更多

PyTorch 用户入门

+   [入门指南](torch.compiler_get_started.html)

+   [torch.compiler API 参考](torch.compiler_api.html)

+   [TorchDynamo 用于细粒度跟踪的 API](torch.compiler_fine_grain_apis.html)

+   [AOTInductor：Torch.Export-ed 模型的预编译](torch.compiler_aot_inductor.html)

+   [TorchInductor GPU Profiling](torch.compiler_inductor_profiling.html)

+   [分析以了解 torch.compile 性能](torch.compiler_profiling_torch_compile.html)

+   [常见问题解答](torch.compiler_faq.html)

+   [PyTorch 2.0 故障排除](torch.compiler_troubleshooting.html)

+   [PyTorch 2.0 性能仪表板](torch.compiler_performance_dashboard.html)

PyTorch 开发者深入研究

+   [TorchDynamo 深入研究](torch.compiler_deepdive.html)

+   [守卫概述](torch.compiler_guards_overview.html)

+   [动态形状](torch.compiler_dynamic_shapes.html)

+   [PyTorch 2.0 NNModule 支持](torch.compiler_nn_module.html)

+   [后端最佳实践](torch.compiler_best_practices_for_backends.html)

+   [CUDAGraph 树](torch.compiler_cudagraph_trees.html)

+   [伪张量](torch.compiler_fake_tensor.html)

PyTorch 后端供应商操作指南

+   [自定义后端](torch.compiler_custom_backends.html)

+   [在 ATen IR 上编写图转换](torch.compiler_transformations.html)

+   [IRs](torch.compiler_ir.html)
