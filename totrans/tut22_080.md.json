["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n[torch.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed \"torch.manual_seed\")(0)\n\n# Here's a simple CNN and loss function:\n\nclass SimpleCNN([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self):\n        super([SimpleCNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(1, 32, 3, 1)\n        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(32, 64, 3, 1)\n        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(9216, 128)\n        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = self.conv2(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = [F.max_pool2d](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d \"torch.nn.functional.max_pool2d\")(x, 2)\n        x = [torch.flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten \"torch.flatten\")(x, 1)\n        x = self.fc1(x)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(x)\n        x = self.fc2(x)\n        output = [F.log_softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax \"torch.nn.functional.log_softmax\")(x, dim=1)\n        output = x\n        return output\n\ndef loss_fn([predictions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")):\n    return [F.nll_loss](https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss \"torch.nn.functional.nll_loss\")([predictions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\ndevice = 'cuda'\n\nnum_models = 10\nbatch_size = 64\n[data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.randn](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn \"torch.randn\")(batch_size, 1, 28, 28, device=device)\n\n[targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.randint](https://pytorch.org/docs/stable/generated/torch.randint.html#torch.randint \"torch.randint\")(10, (64,), device=device) \n```", "```py\nmodel = [SimpleCNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")().to(device=device)\n[predictions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = model([data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))  # move the entire mini-batch through the model\n\n[loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = loss_fn([predictions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[loss.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward \"torch.Tensor.backward\")()  # back propagate the 'average' gradient of this mini-batch \n```", "```py\ndef compute_grad(sample, target):\n    sample = sample.unsqueeze(0)  # prepend batch dimension for processing\n    target = target.unsqueeze(0)\n\n    prediction = model(sample)\n    [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = loss_fn(prediction, target)\n\n    return [torch.autograd.grad](https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad \"torch.autograd.grad\")([loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), list([model.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")()))\n\ndef compute_sample_grads([data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")):\n  \"\"\" manually process each sample with per sample gradient \"\"\"\n    sample_grads = [compute_grad([data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[i], [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[i]) for i in range(batch_size)]\n    sample_grads = zip(*sample_grads)\n    sample_grads = [[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack \"torch.stack\")(shards) for shards in sample_grads]\n    return sample_grads\n\nper_sample_grads = compute_sample_grads([data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nprint(per_sample_grads[0].shape) \n```", "```py\ntorch.Size([64, 32, 1, 3, 3]) \n```", "```py\nfrom torch.func import [functional_call](https://pytorch.org/docs/stable/generated/torch.func.functional_call.html#torch.func.functional_call \"torch.func.functional_call\"), [vmap](https://pytorch.org/docs/stable/generated/torch.vmap.html#torch.vmap \"torch.vmap\"), [grad](https://pytorch.org/docs/stable/generated/torch.func.grad.html#torch.func.grad \"torch.func.grad\")\n\nparams = {k: v.detach() for k, v in [model.named_parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters \"torch.nn.Module.named_parameters\")()}\nbuffers = {k: v.detach() for k, v in [model.named_buffers](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_buffers \"torch.nn.Module.named_buffers\")()} \n```", "```py\ndef compute_loss(params, buffers, sample, target):\n    batch = sample.unsqueeze(0)\n    [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = target.unsqueeze(0)\n\n    [predictions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [functional_call](https://pytorch.org/docs/stable/generated/torch.func.functional_call.html#torch.func.functional_call \"torch.func.functional_call\")(model, (params, buffers), (batch,))\n    [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = loss_fn([predictions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n    return [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") \n```", "```py\nft_compute_grad = [grad](https://pytorch.org/docs/stable/generated/torch.func.grad.html#torch.func.grad \"torch.func.grad\")(compute_loss) \n```", "```py\nft_compute_sample_grad = [vmap](https://pytorch.org/docs/stable/generated/torch.vmap.html#torch.vmap \"torch.vmap\")(ft_compute_grad, in_dims=(None, None, 0, 0)) \n```", "```py\nft_per_sample_grads = ft_compute_sample_grad(params, buffers, [data](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [targets](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nfor [per_sample_grad](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [ft_per_sample_grad](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") in zip(per_sample_grads, ft_per_sample_grads.values()):\n    assert [torch.allclose](https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose \"torch.allclose\")([per_sample_grad](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [ft_per_sample_grad](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), atol=3e-3, rtol=1e-5) \n```", "```py\ndef get_perf(first, first_descriptor, second, second_descriptor):\n  \"\"\"takes torch.benchmark objects and compares delta of second vs first.\"\"\"\n    second_res = second.times[0]\n    first_res = first.times[0]\n\n    gain = (first_res-second_res)/first_res\n    if gain < 0: gain *=-1\n    final_gain = gain*100\n\n    print(f\"Performance delta: {final_gain:.4f} percent improvement with {first_descriptor} \")\n\nfrom torch.utils.benchmark import [Timer](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\")\n\n[without_vmap](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\") = [Timer](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\")(stmt=\"compute_sample_grads(data, targets)\", globals=globals())\n[with_vmap](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\") = [Timer](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer \"torch.utils.benchmark.utils.timer.Timer\")(stmt=\"ft_compute_sample_grad(params, buffers, data, targets)\",globals=globals())\n[no_vmap_timing](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement \"torch.utils.benchmark.utils.common.Measurement\") = [without_vmap.timeit](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer.timeit \"torch.utils.benchmark.Timer.timeit\")(100)\n[with_vmap_timing](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement \"torch.utils.benchmark.utils.common.Measurement\") = [with_vmap.timeit](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer.timeit \"torch.utils.benchmark.Timer.timeit\")(100)\n\nprint(f'Per-sample-grads without vmap {[no_vmap_timing](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement \"torch.utils.benchmark.utils.common.Measurement\")}')\nprint(f'Per-sample-grads with vmap {[with_vmap_timing](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement \"torch.utils.benchmark.utils.common.Measurement\")}')\n\nget_perf([with_vmap_timing](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement \"torch.utils.benchmark.utils.common.Measurement\"), \"vmap\", [no_vmap_timing](https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement \"torch.utils.benchmark.utils.common.Measurement\"), \"no vmap\") \n```", "```py\nPer-sample-grads without vmap <torch.utils.benchmark.utils.common.Measurement object at 0x7f883d01eaa0>\ncompute_sample_grads(data, targets)\n  92.24 ms\n  1 measurement, 100 runs , 1 thread\nPer-sample-grads with vmap <torch.utils.benchmark.utils.common.Measurement object at 0x7f883cf3bf40>\nft_compute_sample_grad(params, buffers, data, targets)\n  8.65 ms\n  1 measurement, 100 runs , 1 thread\nPerformance delta: 966.7210 percent improvement with vmap \n```"]