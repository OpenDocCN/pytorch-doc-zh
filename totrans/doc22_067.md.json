["```py\nclass torch.profiler._KinetoProfile(*, activities=None, record_shapes=False, profile_memory=False, with_stack=False, with_flops=False, with_modules=False, experimental_config=None)\u00b6\n```", "```py\nadd_metadata(key, value)\u00b6\n```", "```py\nadd_metadata_json(key, value)\u00b6\n```", "```py\nevents()\u00b6\n```", "```py\nexport_chrome_trace(path)\u00b6\n```", "```py\nexport_memory_timeline(path, device=None)\u00b6\n```", "```py\nexport_stacks(path, metric='self_cpu_time_total')\u00b6\n```", "```py\nkey_averages(group_by_input_shape=False, group_by_stack_n=0)\u00b6\n```", "```py\nclass torch.profiler.profile(*, activities=None, schedule=None, on_trace_ready=None, record_shapes=False, profile_memory=False, with_stack=False, with_flops=False, with_modules=False, experimental_config=None, use_cuda=None)\u00b6\n```", "```py\nwith torch.profiler.profile(\n    activities=[\n        torch.profiler.ProfilerActivity.CPU,\n        torch.profiler.ProfilerActivity.CUDA,\n    ]\n) as p:\n    code_to_profile()\nprint(p.key_averages().table(\n    sort_by=\"self_cuda_time_total\", row_limit=-1)) \n```", "```py\n# Non-default profiler schedule allows user to turn profiler on and off\n# on different iterations of the training loop;\n# trace_handler is called every time a new trace becomes available\ndef trace_handler(prof):\n    print(prof.key_averages().table(\n        sort_by=\"self_cuda_time_total\", row_limit=-1))\n    # prof.export_chrome_trace(\"/tmp/test_trace_\" + str(prof.step_num) + \".json\")\n\nwith torch.profiler.profile(\n    activities=[\n        torch.profiler.ProfilerActivity.CPU,\n        torch.profiler.ProfilerActivity.CUDA,\n    ],\n\n    # In this example with wait=1, warmup=1, active=2, repeat=1,\n    # profiler will skip the first step/iteration,\n    # start warming up on the second, record\n    # the third and the forth iterations,\n    # after which the trace will become available\n    # and on_trace_ready (when set) is called;\n    # the cycle repeats starting with the next step\n\n    schedule=torch.profiler.schedule(\n        wait=1,\n        warmup=1,\n        active=2,\n        repeat=1),\n    on_trace_ready=trace_handler\n    # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n    # used when outputting for tensorboard\n    ) as p:\n        for iter in range(N):\n            code_iteration_to_profile(iter)\n            # send a signal to the profiler that the next iteration has started\n            p.step() \n```", "```py\nstep()\u00b6\n```", "```py\nclass torch.profiler.ProfilerAction(value)\u00b6\n```", "```py\nclass torch.profiler.ProfilerActivity\u00b6\n```", "```py\nproperty name\u00b6\n```", "```py\ntorch.profiler.schedule(*, wait, warmup, active, repeat=0, skip_first=0)\u00b6\n```", "```py\ntorch.profiler.tensorboard_trace_handler(dir_name, worker_name=None, use_gzip=False)\u00b6\n```", "```py\ntorch.profiler.itt.is_available()\u00b6\n```", "```py\ntorch.profiler.itt.mark(msg)\u00b6\n```", "```py\ntorch.profiler.itt.range_push(msg)\u00b6\n```", "```py\ntorch.profiler.itt.range_pop()\u00b6\n```"]