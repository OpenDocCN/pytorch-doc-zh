["```py\nauto  x  =  torch::ones({2,  2},  torch::requires_grad());\nstd::cout  <<  x  <<  std::endl; \n```", "```py\n1  1\n1  1\n[  CPUFloatType{2,2}  ] \n```", "```py\nauto  y  =  x  +  2;\nstd::cout  <<  y  <<  std::endl; \n```", "```py\n 3  3\n  3  3\n[  CPUFloatType{2,2}  ] \n```", "```py\nstd::cout  <<  y.grad_fn()->name()  <<  std::endl; \n```", "```py\nAddBackward1 \n```", "```py\nauto  z  =  y  *  y  *  3;\nauto  out  =  z.mean();\n\nstd::cout  <<  z  <<  std::endl;\nstd::cout  <<  z.grad_fn()->name()  <<  std::endl;\nstd::cout  <<  out  <<  std::endl;\nstd::cout  <<  out.grad_fn()->name()  <<  std::endl; \n```", "```py\n 27  27\n  27  27\n[  CPUFloatType{2,2}  ]\nMulBackward1\n27\n[  CPUFloatType{}  ]\nMeanBackward0 \n```", "```py\nauto  a  =  torch::randn({2,  2});\na  =  ((a  *  3)  /  (a  -  1));\nstd::cout  <<  a.requires_grad()  <<  std::endl;\n\na.requires_grad_(true);\nstd::cout  <<  a.requires_grad()  <<  std::endl;\n\nauto  b  =  (a  *  a).sum();\nstd::cout  <<  b.grad_fn()->name()  <<  std::endl; \n```", "```py\nfalse\ntrue\nSumBackward0 \n```", "```py\nout.backward(); \n```", "```py\nstd::cout  <<  x.grad()  <<  std::endl; \n```", "```py\n 4.5000  4.5000\n  4.5000  4.5000\n[  CPUFloatType{2,2}  ] \n```", "```py\nx  =  torch::randn(3,  torch::requires_grad());\n\ny  =  x  *  2;\nwhile  (y.norm().item<double>()  <  1000)  {\n  y  =  y  *  2;\n}\n\nstd::cout  <<  y  <<  std::endl;\nstd::cout  <<  y.grad_fn()->name()  <<  std::endl; \n```", "```py\n-1021.4020\n  314.6695\n  -613.4944\n[  CPUFloatType{3}  ]\nMulBackward1 \n```", "```py\nauto  v  =  torch::tensor({0.1,  1.0,  0.0001},  torch::kFloat);\ny.backward(v);\n\nstd::cout  <<  x.grad()  <<  std::endl; \n```", "```py\n 102.4000\n  1024.0000\n  0.1024\n[  CPUFloatType{3}  ] \n```", "```py\nstd::cout  <<  x.requires_grad()  <<  std::endl;\nstd::cout  <<  x.pow(2).requires_grad()  <<  std::endl;\n\n{\n  torch::NoGradGuard  no_grad;\n  std::cout  <<  x.pow(2).requires_grad()  <<  std::endl;\n} \n```", "```py\ntrue\ntrue\nfalse \n```", "```py\nstd::cout  <<  x.requires_grad()  <<  std::endl;\ny  =  x.detach();\nstd::cout  <<  y.requires_grad()  <<  std::endl;\nstd::cout  <<  x.eq(y).all().item<bool>()  <<  std::endl; \n```", "```py\ntrue\nfalse\ntrue \n```", "```py\n#include  <torch/torch.h>\n\nauto  model  =  torch::nn::Linear(4,  3);\n\nauto  input  =  torch::randn({3,  4}).requires_grad_(true);\nauto  output  =  model(input);\n\n// Calculate loss\nauto  target  =  torch::randn({3,  3});\nauto  loss  =  torch::nn::MSELoss()(output,  target);\n\n// Use norm of gradients as penalty\nauto  grad_output  =  torch::ones_like(output);\nauto  gradient  =  torch::autograd::grad({output},  {input},  /*grad_outputs=*/{grad_output},  /*create_graph=*/true)[0];\nauto  gradient_penalty  =  torch::pow((gradient.norm(2,  /*dim=*/1)  -  1),  2).mean();\n\n// Add gradient penalty to loss\nauto  combined_loss  =  loss  +  gradient_penalty;\ncombined_loss.backward();\n\nstd::cout  <<  input.grad()  <<  std::endl; \n```", "```py\n-0.1042  -0.0638  0.0103  0.0723\n-0.2543  -0.1222  0.0071  0.0814\n-0.1683  -0.1052  0.0355  0.1024\n[  CPUFloatType{3,4}  ] \n```", "```py\n#include  <torch/torch.h>\n\nusing  namespace  torch::autograd;\n\n// Inherit from Function\nclass  LinearFunction  :  public  Function<LinearFunction>  {\n  public:\n  // Note that both forward and backward are static functions\n\n  // bias is an optional argument\n  static  torch::Tensor  forward(\n  AutogradContext  *ctx,  torch::Tensor  input,  torch::Tensor  weight,  torch::Tensor  bias  =  torch::Tensor())  {\n  ctx->save_for_backward({input,  weight,  bias});\n  auto  output  =  input.mm(weight.t());\n  if  (bias.defined())  {\n  output  +=  bias.unsqueeze(0).expand_as(output);\n  }\n  return  output;\n  }\n\n  static  tensor_list  backward(AutogradContext  *ctx,  tensor_list  grad_outputs)  {\n  auto  saved  =  ctx->get_saved_variables();\n  auto  input  =  saved[0];\n  auto  weight  =  saved[1];\n  auto  bias  =  saved[2];\n\n  auto  grad_output  =  grad_outputs[0];\n  auto  grad_input  =  grad_output.mm(weight);\n  auto  grad_weight  =  grad_output.t().mm(input);\n  auto  grad_bias  =  torch::Tensor();\n  if  (bias.defined())  {\n  grad_bias  =  grad_output.sum(0);\n  }\n\n  return  {grad_input,  grad_weight,  grad_bias};\n  }\n}; \n```", "```py\nauto  x  =  torch::randn({2,  3}).requires_grad_();\nauto  weight  =  torch::randn({4,  3}).requires_grad_();\nauto  y  =  LinearFunction::apply(x,  weight);\ny.sum().backward();\n\nstd::cout  <<  x.grad()  <<  std::endl;\nstd::cout  <<  weight.grad()  <<  std::endl; \n```", "```py\n 0.5314  1.2807  1.4864\n  0.5314  1.2807  1.4864\n[  CPUFloatType{2,3}  ]\n  3.7608  0.9101  0.0073\n  3.7608  0.9101  0.0073\n  3.7608  0.9101  0.0073\n  3.7608  0.9101  0.0073\n[  CPUFloatType{4,3}  ] \n```", "```py\n#include  <torch/torch.h>\n\nusing  namespace  torch::autograd;\n\nclass  MulConstant  :  public  Function<MulConstant>  {\n  public:\n  static  torch::Tensor  forward(AutogradContext  *ctx,  torch::Tensor  tensor,  double  constant)  {\n  // ctx is a context object that can be used to stash information\n  // for backward computation\n  ctx->saved_data[\"constant\"]  =  constant;\n  return  tensor  *  constant;\n  }\n\n  static  tensor_list  backward(AutogradContext  *ctx,  tensor_list  grad_outputs)  {\n  // We return as many input gradients as there were arguments.\n  // Gradients of non-tensor arguments to forward must be `torch::Tensor()`.\n  return  {grad_outputs[0]  *  ctx->saved_data[\"constant\"].toDouble(),  torch::Tensor()};\n  }\n}; \n```", "```py\nauto  x  =  torch::randn({2}).requires_grad_();\nauto  y  =  MulConstant::apply(x,  5.5);\ny.sum().backward();\n\nstd::cout  <<  x.grad()  <<  std::endl; \n```", "```py\n 5.5000\n  5.5000\n[  CPUFloatType{2}  ] \n```"]