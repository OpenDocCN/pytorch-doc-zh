- en: Introduction to Holistic Trace Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/tutorials/beginner/hta_intro_tutorial.html](https://pytorch.org/tutorials/beginner/hta_intro_tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Author:** [Anupam Bhatnagar](https://github.com/anupambhatnagar)'
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we demonstrate how to use Holistic Trace Analysis (HTA) to
    analyze traces from a distributed training job. To get started follow the steps
    below.
  prefs: []
  type: TYPE_NORMAL
- en: Installing HTA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We recommend using a Conda environment to install HTA. To install Anaconda,
    see [the official Anaconda documentation](https://docs.anaconda.com/anaconda/install/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Install HTA using pip:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '(Optional and recommended) Set up a Conda environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Getting Started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Launch a Jupyter notebook and set the `trace_dir` variable to the location of
    the traces.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Temporal Breakdown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To effectively utilize the GPUs, it is crucial to understand how they are spending
    time for a specific job. Are they primarily engaged in computation, communication,
    memory events, or are they idle? The temporal breakdown feature provides a detailed
    analysis of the time spent in these three categories.
  prefs: []
  type: TYPE_NORMAL
- en: Idle time - GPU is idle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute time - GPU is being used for matrix multiplications or vector operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-compute time - GPU is being used for communication or memory events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To achieve high training efficiency, the code should maximize compute time and
    minimize idle time and non-compute time. The following function generates a dataframe
    that provides a detailed breakdown of the temporal usage for each rank.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/temporal_breakdown_df.png](../Images/60b7f8f0a40cb20a24581889399ab070.png)'
  prefs: []
  type: TYPE_IMG
- en: When the `visualize` argument is set to `True` in the [get_temporal_breakdown](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_temporal_breakdown)
    function it also generates a bar graph representing the breakdown by rank.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/temporal_breakdown_plot.png](../Images/3d68f72d6d1ff2ec6be135764006f250.png)'
  prefs: []
  type: TYPE_IMG
- en: Idle Time Breakdown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Gaining insight into the amount of time the GPU spends idle and the reasons
    behind it can help guide optimization strategies. A GPU is considered idle when
    no kernel is running on it. We have developed an algorithm to categorize the Idle
    time into three distinct categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Host wait:** refers to the idle time on the GPU that is caused by the CPU
    not enqueuing kernels quickly enough to keep the GPU fully utilized. These types
    of inefficiencies can be addressed by examining the CPU operators that are contributing
    to the slowdown, increasing the batch size and applying operator fusion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kernel wait:** This refers to brief overhead associated with launching consecutive
    kernels on the GPU. The idle time attributed to this category can be minimized
    by using CUDA Graph optimizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Other wait:** This category includes idle time that cannot currently be attributed
    due to insufficient information. The likely causes include synchronization among
    CUDA streams using CUDA events and delays in launching kernels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The host wait time can be interpreted as the time when the GPU is stalling
    due to the CPU. To attribute the idle time as kernel wait we use the following
    heuristic:'
  prefs: []
  type: TYPE_NORMAL
- en: '**gap between consecutive kernels < threshold**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The default threshold value is 30 nanoseconds and can be configured using the
    `consecutive_kernel_delay` argument. By default, the idle time breakdown is computed
    for rank 0 only. In order to calculate the breakdown for other ranks, use the
    `ranks` argument in the [get_idle_time_breakdown](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_idle_time_breakdown)
    function. The idle time breakdown can be generated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/idle_time_breakdown_percentage.png](../Images/e42cbade7eb10063307e87d32466961d.png)'
  prefs: []
  type: TYPE_IMG
- en: The function returns a tuple of dataframes. The first dataframe contains the
    idle time by category on each stream for each rank.
  prefs: []
  type: TYPE_NORMAL
- en: '[![../_images/idle_time.png](../Images/804d1bbaf4c125dff21648945b3082ff.png)](../_images/idle_time.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The second dataframe is generated when `show_idle_interval_stats` is set to
    `True`. It contains the summary statistics of the idle time for each stream on
    each rank.
  prefs: []
  type: TYPE_NORMAL
- en: '[![../_images/idle_time_summary.png](../Images/0d0f42e11aa0c33b2fe4b1b2dcdc3d20.png)](../_images/idle_time_summary.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: By default, the idle time breakdown presents the percentage of each of the idle
    time categories. Setting the `visualize_pctg` argument to `False`, the function
    renders with absolute time on the y-axis.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Breakdown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The kernel breakdown feature breaks down the time spent for each kernel type,
    such as communication (COMM), computation (COMP), and memory (MEM), across all
    ranks and presents the proportion of time spent in each category. Here is the
    percentage of time spent in each category as a pie chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/kernel_type_breakdown.png](../Images/2045c580266388911dcf15707d71beb1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The kernel breakdown can be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first dataframe returned by the function contains the raw values used to
    generate the pie chart.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Duration Distribution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The second dataframe returned by [get_gpu_kernel_breakdown](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_gpu_kernel_breakdown)
    contains duration summary statistics for each kernel. In particular, this includes
    the count, min, max, average, standard deviation, sum, and kernel type for each
    kernel on each rank.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/kernel_metrics_df.png](../Images/f3d40422223cdceb830e8200c2cacacc.png)'
  prefs: []
  type: TYPE_IMG
- en: Using this data HTA creates many visualizations to identify performance bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Pie charts of the top kernels for each kernel type for each rank.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bar graphs of the average duration across all ranks for each of the top kernels
    and for each kernel type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![../_images/pie_charts.png](../Images/9e31307e5d6ad0ae17c6a2b7b27a6c9a.png)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: All images are generated using plotly. Hovering on the graph shows the mode
    bar on the top right which allows the user to zoom, pan, select, and download
    the graph.
  prefs: []
  type: TYPE_NORMAL
- en: The pie charts above show the top 5 computation, communication, and memory kernels.
    Similar pie charts are generated for each rank. The pie charts can be configured
    to show the top k kernels using the `num_kernels` argument passed to the get_gpu_kernel_breakdown
    function. Additionally, the `duration_ratio` argument can be used to tune the
    percentage of time that needs to be analyzed. If both `num_kernels` and `duration_ratio`
    are specified, then `num_kernels` takes precedence.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/comm_across_ranks.png](../Images/86d7071d6a176ea6b007dd4c911e8cf0.png)'
  prefs: []
  type: TYPE_IMG
- en: The bar graph above shows the average duration of the NCCL AllReduce kernel
    across all the ranks. The black lines indicate the minimum and maximum time taken
    on each rank.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: When using jupyter-lab set the “image_renderer” argument value to “jupyterlab”
    otherwise the graphs will not render in the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: For a detailed walkthrough of this feature see the [gpu_kernel_breakdown notebook](https://github.com/facebookresearch/HolisticTraceAnalysis/blob/main/examples/kernel_breakdown_demo.ipynb)
    in the examples folder of the repo.
  prefs: []
  type: TYPE_NORMAL
- en: Communication Computation Overlap
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In distributed training, a significant amount of time is spent in communication
    and synchronization events between GPUs. To achieve high GPU efficiency (such
    as TFLOPS/GPU), it is crucial to keep the GPU oversubscribed with computation
    kernels. In other words, the GPU should not be blocked due to unresolved data
    dependencies. One way to measure the extent to which computation is blocked by
    data dependencies is to calculate the communication computation overlap. Higher
    GPU efficiency is observed if communication events overlap computation events.
    Lack of communication and computation overlap will lead to the GPU being idle,
    resulting in low efficiency. To sum up, a higher communication computation overlap
    is desirable. To calculate the overlap percentage for each rank, we measure the
    following ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '**(time spent in computation while communicating) / (time spent in communication)**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The communication computation overlap can be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The function returns a dataframe containing the overlap percentage for each
    rank.
  prefs: []
  type: TYPE_NORMAL
- en: '[![../_images/overlap_df.png](../Images/22a0d906eede5591c1d5935dba1324f4.png)](../_images/overlap_df.png)'
  prefs: []
  type: TYPE_NORMAL
- en: When the `visualize` argument is set to True, the [get_comm_comp_overlap](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_comm_comp_overlap)
    function also generates a bar graph representing the overlap by rank.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/overlap_plot.png](../Images/3a88d4853f57cfa224a569edfee9e5d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Augmented Counters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Memory Bandwidth & Queue Length Counters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Memory bandwidth counters measure the memory copy bandwidth used while copying
    the data from H2D, D2H and D2D by memory copy (memcpy) and memory set (memset)
    events. HTA also computes the number of outstanding operations on each CUDA stream.
    We refer to this as **queue length**. When the queue length on a stream is 1024
    or larger new events cannot be scheduled on that stream and the CPU will stall
    until the events on the GPU stream have processed.
  prefs: []
  type: TYPE_NORMAL
- en: The [generate_trace_with_counters](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.generate_trace_with_counters)
    API outputs a new trace file with the memory bandwidth and queue length counters.
    The new trace file contains tracks which indicate the memory bandwidth used by
    memcpy/memset operations and tracks for the queue length on each stream. By default,
    these counters are generated using the rank 0 trace file, and the new file contains
    the suffix `_with_counters` in its name. Users have the option to generate the
    counters for multiple ranks by using the `ranks` argument in the `generate_trace_with_counters`
    API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: A screenshot of the generated trace file with augmented counters.
  prefs: []
  type: TYPE_NORMAL
- en: '[![../_images/mem_bandwidth_queue_length.png](../Images/7b09c2f07fe7daff2c296c3c17fec795.png)](../_images/mem_bandwidth_queue_length.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'HTA also provides a summary of the memory copy bandwidth and queue length counters
    as well as the time series of the counters for the profiled portion of the code
    using the following API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[get_memory_bw_summary](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_memory_bw_summary)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[get_queue_length_summary](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_queue_length_summary)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[get_memory_bw_time_series](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_memory_bw_time_series)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[get_queue_length_time_series](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_queue_length_time_series)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To view the summary and time series, use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The summary contains the count, min, max, mean, standard deviation, 25th, 50th,
    and 75th percentile.
  prefs: []
  type: TYPE_NORMAL
- en: '[![../_images/queue_length_summary.png](../Images/c176e0b671c636afdb57c7dcde4ec7b2.png)](../_images/queue_length_summary.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The time series only contains the points when a value changes. Once a value
    is observed the time series stays constant until the next update. The memory bandwidth
    and queue length time series functions return a dictionary whose key is the rank
    and the value is the time series for that rank. By default, the time series is
    computed for rank 0 only.
  prefs: []
  type: TYPE_NORMAL
- en: CUDA Kernel Launch Statistics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![../_images/cuda_kernel_launch.png](../Images/c27ff818f9cd6a18831ba7ce5bed959e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For each event launched on the GPU, there is a corresponding scheduling event
    on the CPU, such as `CudaLaunchKernel`, `CudaMemcpyAsync`, `CudaMemsetAsync`.
    These events are linked by a common correlation ID in the trace - see the figure
    above. This feature computes the duration of the CPU runtime event, its corresponding
    GPU kernel and the launch delay, for example, the difference between GPU kernel
    starting and CPU operator ending. The kernel launch info can be generated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: A screenshot of the generated dataframe is given below.
  prefs: []
  type: TYPE_NORMAL
- en: '[![../_images/cuda_kernel_launch_stats.png](../Images/f08d3cd24db3c350255e51c1217848bf.png)](../_images/cuda_kernel_launch_stats.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The duration of the CPU op, GPU kernel, and the launch delay allow us to find
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Short GPU kernels** - GPU kernels with duration less than the corresponding
    CPU runtime event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Runtime event outliers** - CPU runtime events with excessive duration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Launch delay outliers** - GPU kernels which take too long to be scheduled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTA generates distribution plots for each of the aforementioned three categories.
  prefs: []
  type: TYPE_NORMAL
- en: '**Short GPU kernels**'
  prefs: []
  type: TYPE_NORMAL
- en: Typically, the launch time on the CPU side ranges from 5-20 microseconds. In
    some cases, the GPU execution time is lower than the launch time itself. The graph
    below helps us to find how frequently such instances occur in the code.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/short_gpu_kernels.png](../Images/5659a2d4c00bf8426b78c0ae3665a617.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Runtime event outliers**'
  prefs: []
  type: TYPE_NORMAL
- en: The runtime outliers depend on the cutoff used to classify the outliers, hence
    the [get_cuda_kernel_launch_stats](https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_cuda_kernel_launch_stats)
    API provides the `runtime_cutoff` argument to configure the value.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/runtime_outliers.png](../Images/bdc1a7dd3417b484ec5a627c589915df.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Launch delay outliers**'
  prefs: []
  type: TYPE_NORMAL
- en: The launch delay outliers depend on the cutoff used to classify the outliers,
    hence the get_cuda_kernel_launch_stats API provides the `launch_delay_cutoff`
    argument to configure the value.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/launch_delay_outliers.png](../Images/048059c775c69a3b4b7b7e03ec1bd8fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this tutorial, you have learned how to install and use HTA, a performance
    tool that enables you analyze bottlenecks in your distributed training workflows.
    To learn how you can use the HTA tool to perform trace diff analysis, see [Trace
    Diff using Holistic Trace Analysis](https://pytorch.org/tutorials/beginner/hta_trace_diff_tutorial.html).
  prefs: []
  type: TYPE_NORMAL
