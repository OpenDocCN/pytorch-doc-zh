["```py\ntorch.utils.cpp_extension.CppExtension(name, sources, *args, **kwargs)\u00b6\n```", "```py\n>>> from setuptools import setup\n>>> from torch.utils.cpp_extension import BuildExtension, CppExtension\n>>> setup(\n...     name='extension',\n...     ext_modules=[\n...         CppExtension(\n...             name='extension',\n...             sources=['extension.cpp'],\n...             extra_compile_args=['-g']),\n...     ],\n...     cmdclass={\n...         'build_ext': BuildExtension\n...     }) \n```", "```py\ntorch.utils.cpp_extension.CUDAExtension(name, sources, *args, **kwargs)\u00b6\n```", "```py\n>>> from setuptools import setup\n>>> from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n>>> setup(\n...     name='cuda_extension',\n...     ext_modules=[\n...         CUDAExtension(\n...                 name='cuda_extension',\n...                 sources=['extension.cpp', 'extension_kernel.cu'],\n...                 extra_compile_args={'cxx': ['-g'],\n...                                     'nvcc': ['-O2']})\n...     ],\n...     cmdclass={\n...         'build_ext': BuildExtension\n...     }) \n```", "```py\n>>> CUDAExtension(\n...        name='cuda_extension',\n...        sources=['extension.cpp', 'extension_kernel.cu'],\n...        dlink=True,\n...        dlink_libraries=[\"dlink_lib\"],\n...        extra_compile_args={'cxx': ['-g'],\n...                            'nvcc': ['-O2', '-rdc=true']}) \n```", "```py\ntorch.utils.cpp_extension.BuildExtension(*args, **kwargs)\u00b6\n```", "```py\ntorch.utils.cpp_extension.load(name, sources, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True, is_standalone=False, keep_intermediates=True)\u00b6\n```", "```py\n>>> from torch.utils.cpp_extension import load\n>>> module = load(\n...     name='extension',\n...     sources=['extension.cpp', 'extension_kernel.cu'],\n...     extra_cflags=['-O2'],\n...     verbose=True) \n```", "```py\ntorch.utils.cpp_extension.load_inline(name, cpp_sources, cuda_sources=None, functions=None, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True, with_pytorch_error_handling=True, keep_intermediates=True, use_pch=False)\u00b6\n```", "```py\n>>> from torch.utils.cpp_extension import load_inline\n>>> source = \"\"\"\nat::Tensor sin_add(at::Tensor x, at::Tensor y) {\n return x.sin() + y.sin();\n}\n\"\"\"\n>>> module = load_inline(name='inline_extension',\n...                      cpp_sources=[source],\n...                      functions=['sin_add']) \n```", "```py\ntorch.utils.cpp_extension.include_paths(cuda=False)\u00b6\n```", "```py\ntorch.utils.cpp_extension.get_compiler_abi_compatibility_and_version(compiler)\u00b6\n```", "```py\ntorch.utils.cpp_extension.verify_ninja_availability()\u00b6\n```", "```py\ntorch.utils.cpp_extension.is_ninja_available()\u00b6\n```"]