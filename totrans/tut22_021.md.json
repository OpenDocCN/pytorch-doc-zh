["```py\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# PyTorch TensorBoard support\nfrom torch.utils.tensorboard import [SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\")\nfrom datetime import datetime\n\n[transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\") = [transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")(\n    [[transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")(),\n    [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")((0.5,), (0.5,))])\n\n# Create datasets for training & validation, download if necessary\n[training_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\") = [torchvision.datasets.FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\")('./data', train=True, [transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")=[transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\"), download=True)\n[validation_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\") = [torchvision.datasets.FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\")('./data', train=False, [transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")=[transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\"), download=True)\n\n# Create data loaders for our datasets; shuffle for training, not for validation\n[training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")([training_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\"), batch_size=4, shuffle=True)\n[validation_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")([validation_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\"), batch_size=4, shuffle=False)\n\n# Class labels\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# Report split sizes\nprint('Training set has {} instances'.format(len([training_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\"))))\nprint('Validation set has {} instances'.format(len([validation_set](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST \"torchvision.datasets.FashionMNIST\")))) \n```", "```py\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n\n  0%|          | 0/26421880 [00:00<?, ?it/s]\n  0%|          | 65536/26421880 [00:00<01:12, 364219.97it/s]\n  1%|          | 229376/26421880 [00:00<00:38, 686138.70it/s]\n  4%|3         | 950272/26421880 [00:00<00:11, 2201377.51it/s]\n 14%|#4        | 3801088/26421880 [00:00<00:02, 7581352.34it/s]\n 37%|###7      | 9797632/26421880 [00:00<00:00, 16849344.06it/s]\n 59%|#####9    | 15663104/26421880 [00:01<00:00, 26145189.61it/s]\n 71%|#######1  | 18776064/26421880 [00:01<00:00, 23360633.32it/s]\n 93%|#########2| 24543232/26421880 [00:01<00:00, 26387177.79it/s]\n100%|##########| 26421880/26421880 [00:01<00:00, 19446710.50it/s]\nExtracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n\n  0%|          | 0/29515 [00:00<?, ?it/s]\n100%|##########| 29515/29515 [00:00<00:00, 326274.86it/s]\nExtracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n\n  0%|          | 0/4422102 [00:00<?, ?it/s]\n  1%|1         | 65536/4422102 [00:00<00:11, 364622.91it/s]\n  5%|5         | 229376/4422102 [00:00<00:06, 684813.81it/s]\n 21%|##1       | 950272/4422102 [00:00<00:01, 2200476.22it/s]\n 85%|########5 | 3768320/4422102 [00:00<00:00, 7506714.24it/s]\n100%|##########| 4422102/4422102 [00:00<00:00, 6115026.62it/s]\nExtracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n\n  0%|          | 0/5148 [00:00<?, ?it/s]\n100%|##########| 5148/5148 [00:00<00:00, 35867569.75it/s]\nExtracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n\nTraining set has 60000 instances\nValidation set has 10000 instances \n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Helper function for inline image display\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\ndataiter = iter([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"))\n[images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = next(dataiter)\n\n# Create a grid from the images and show them\n[img_grid](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torchvision.utils.make_grid](https://pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid \"torchvision.utils.make_grid\")([images](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nmatplotlib_imshow([img_grid](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), one_channel=True)\nprint('  '.join(classes[[labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[j]] for j in range(4))) \n```", "```py\nSandal  Sneaker  Coat  Sneaker \n```", "```py\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# PyTorch models inherit from torch.nn.Module\nclass GarmentClassifier([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self):\n        super([GarmentClassifier](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(1, 6, 5)\n        self.pool = [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d \"torch.nn.MaxPool2d\")(2, 2)\n        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(6, 16, 5)\n        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(16 * 4 * 4, 120)\n        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(120, 84)\n        self.fc3 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(84, 10)\n\n    def forward(self, x):\n        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.conv1(x)))\n        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.fc1(x))\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nmodel = [GarmentClassifier](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")() \n```", "```py\n[loss_fn](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\") = [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")()\n\n# NB: Loss functions expect data in batches, so we're creating batches of 4\n# Represents the model's confidence in each of the 10 classes for a given input\n[dummy_outputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(4, 10)\n# Represents the correct class among the 10 being tested\n[dummy_labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor \"torch.tensor\")([1, 5, 3, 7])\n\nprint([dummy_outputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint([dummy_labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\n[loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [loss_fn](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")([dummy_outputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [dummy_labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint('Total loss for this batch: {}'.format([loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").item())) \n```", "```py\ntensor([[0.7026, 0.1489, 0.0065, 0.6841, 0.4166, 0.3980, 0.9849, 0.6701, 0.4601,\n         0.8599],\n        [0.7461, 0.3920, 0.9978, 0.0354, 0.9843, 0.0312, 0.5989, 0.2888, 0.8170,\n         0.4150],\n        [0.8408, 0.5368, 0.0059, 0.8931, 0.3942, 0.7349, 0.5500, 0.0074, 0.0554,\n         0.1537],\n        [0.7282, 0.8755, 0.3649, 0.4566, 0.8796, 0.2390, 0.9865, 0.7549, 0.9105,\n         0.5427]])\ntensor([1, 5, 3, 7])\nTotal loss for this batch: 2.428950071334839 \n```", "```py\n# Optimizers specified in the torch.optim package\n[optimizer](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\") = [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\")([model.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")(), lr=0.001, momentum=0.9) \n```", "```py\ndef train_one_epoch(epoch_index, tb_writer):\n    running_loss = 0.\n    last_loss = 0.\n\n    # Here, we use enumerate(training_loader) instead of\n    # iter(training_loader) so that we can track the batch\n    # index and do some intra-epoch reporting\n    for i, data in enumerate([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")):\n        # Every data instance is an input + label pair\n        inputs, [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = data\n\n        # Zero your gradients for every batch!\n        [optimizer.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.zero_grad \"torch.optim.SGD.zero_grad\")()\n\n        # Make predictions for this batch\n        outputs = model(inputs)\n\n        # Compute the loss and its gradients\n        [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [loss_fn](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")(outputs, [labels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        [loss.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward \"torch.Tensor.backward\")()\n\n        # Adjust learning weights\n        [optimizer.step](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.step \"torch.optim.SGD.step\")()\n\n        # Gather data and report\n        running_loss += [loss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").item()\n        if i % 1000 == 999:\n            last_loss = running_loss / 1000 # loss per batch\n            print('  batch {} loss: {}'.format(i + 1, last_loss))\n            tb_x = epoch_index * len([training_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")) + i + 1\n            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n            running_loss = 0.\n\n    return last_loss \n```", "```py\n# Initializing in a separate cell so we can easily add more epochs to the same run\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n[writer](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\") = [SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\")('runs/fashion_trainer_{}'.format(timestamp))\nepoch_number = 0\n\nEPOCHS = 5\n\n[best_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = 1_000_000.\n\nfor epoch in range(EPOCHS):\n    print('EPOCH {}:'.format(epoch_number + 1))\n\n    # Make sure gradient tracking is on, and do a pass over the data\n    [model.train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train \"torch.nn.Module.train\")(True)\n    avg_loss = train_one_epoch(epoch_number, [writer](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter \"torch.utils.tensorboard.writer.SummaryWriter\"))\n\n    [running_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = 0.0\n    # Set the model to evaluation mode, disabling dropout and using population\n    # statistics for batch normalization.\n    [model.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval \"torch.nn.Module.eval\")()\n\n    # Disable gradient computation and reduce memory consumption.\n    with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n        for i, vdata in enumerate([validation_loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")):\n            [vinputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [vlabels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = vdata\n            [voutputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = model([vinputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n            [vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [loss_fn](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")([voutputs](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [vlabels](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n            [running_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") += [vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n\n    [avg_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [running_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") / (i + 1)\n    print('LOSS train {} valid {}'.format(avg_loss, [avg_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n\n    # Log the running loss averaged per batch\n    # for both training and validation\n    [writer.add_scalars](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars \"torch.utils.tensorboard.writer.SummaryWriter.add_scalars\")('Training vs. Validation Loss',\n                    { 'Training' : avg_loss, 'Validation' : [avg_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") },\n                    epoch_number + 1)\n    [writer.flush](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush \"torch.utils.tensorboard.writer.SummaryWriter.flush\")()\n\n    # Track best performance, and save the model's state\n    if [avg_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") < [best_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"):\n        [best_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [avg_vloss](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n        [torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save \"torch.save\")([model.state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict \"torch.nn.Module.state_dict\")(), model_path)\n\n    epoch_number += 1 \n```", "```py\nEPOCH 1:\n  batch 1000 loss: 1.6334228584356607\n  batch 2000 loss: 0.8325267538074403\n  batch 3000 loss: 0.7359380583595484\n  batch 4000 loss: 0.6198329215242994\n  batch 5000 loss: 0.6000315657821484\n  batch 6000 loss: 0.555109024874866\n  batch 7000 loss: 0.5260250487388112\n  batch 8000 loss: 0.4973462742221891\n  batch 9000 loss: 0.4781935699362075\n  batch 10000 loss: 0.47880298678041433\n  batch 11000 loss: 0.45598648857555235\n  batch 12000 loss: 0.4327470133750467\n  batch 13000 loss: 0.41800182418141046\n  batch 14000 loss: 0.4115047634313814\n  batch 15000 loss: 0.4211296908891527\nLOSS train 0.4211296908891527 valid 0.414460688829422\nEPOCH 2:\n  batch 1000 loss: 0.3879808729066281\n  batch 2000 loss: 0.35912817339546743\n  batch 3000 loss: 0.38074520684120944\n  batch 4000 loss: 0.3614532373107213\n  batch 5000 loss: 0.36850082185724753\n  batch 6000 loss: 0.3703581801643886\n  batch 7000 loss: 0.38547042514081115\n  batch 8000 loss: 0.37846584360170527\n  batch 9000 loss: 0.3341486988377292\n  batch 10000 loss: 0.3433013284947956\n  batch 11000 loss: 0.35607743899174965\n  batch 12000 loss: 0.3499939931873523\n  batch 13000 loss: 0.33874178926000603\n  batch 14000 loss: 0.35130289171106416\n  batch 15000 loss: 0.3394507191307202\nLOSS train 0.3394507191307202 valid 0.3581162691116333\nEPOCH 3:\n  batch 1000 loss: 0.3319729989422485\n  batch 2000 loss: 0.29558994361863006\n  batch 3000 loss: 0.3107374766407593\n  batch 4000 loss: 0.3298987646112146\n  batch 5000 loss: 0.30858693152241906\n  batch 6000 loss: 0.33916381367447684\n  batch 7000 loss: 0.3105102765217889\n  batch 8000 loss: 0.3011080777524912\n  batch 9000 loss: 0.3142058177240979\n  batch 10000 loss: 0.31458891937109\n  batch 11000 loss: 0.31527258940579483\n  batch 12000 loss: 0.31501667268342864\n  batch 13000 loss: 0.3011875962628328\n  batch 14000 loss: 0.30012811454350596\n  batch 15000 loss: 0.31833117976446373\nLOSS train 0.31833117976446373 valid 0.3307691514492035\nEPOCH 4:\n  batch 1000 loss: 0.2786161053752294\n  batch 2000 loss: 0.27965198021690596\n  batch 3000 loss: 0.28595415444140965\n  batch 4000 loss: 0.292985666413857\n  batch 5000 loss: 0.3069892351147719\n  batch 6000 loss: 0.29902250939945224\n  batch 7000 loss: 0.2863366014406201\n  batch 8000 loss: 0.2655441066541243\n  batch 9000 loss: 0.3045048695363293\n  batch 10000 loss: 0.27626545656517554\n  batch 11000 loss: 0.2808379335970967\n  batch 12000 loss: 0.29241049340573955\n  batch 13000 loss: 0.28030834131941446\n  batch 14000 loss: 0.2983542350126445\n  batch 15000 loss: 0.3009556676162611\nLOSS train 0.3009556676162611 valid 0.41686952114105225\nEPOCH 5:\n  batch 1000 loss: 0.2614263167564495\n  batch 2000 loss: 0.2587047562422049\n  batch 3000 loss: 0.2642477260621345\n  batch 4000 loss: 0.2825975873669813\n  batch 5000 loss: 0.26987933717705165\n  batch 6000 loss: 0.2759250026817317\n  batch 7000 loss: 0.26055969463163275\n  batch 8000 loss: 0.29164007206353565\n  batch 9000 loss: 0.2893096504513578\n  batch 10000 loss: 0.2486029507305684\n  batch 11000 loss: 0.2732803234480907\n  batch 12000 loss: 0.27927226484491985\n  batch 13000 loss: 0.2686819267635074\n  batch 14000 loss: 0.24746483912148323\n  batch 15000 loss: 0.27903492261294194\nLOSS train 0.27903492261294194 valid 0.31206756830215454 \n```", "```py\nsaved_model = [GarmentClassifier](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")()\nsaved_model.load_state_dict(torch.load(PATH)) \n```"]