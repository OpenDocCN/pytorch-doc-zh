["```py\nclass torch.distributed.GradBucket\u00b6\n```", "```py\ntorch.distributed.GradBucket.index(self: torch._C._distributed_c10d.GradBucket) \u2192 int\u00b6\n```", "```py\ntorch.distributed.GradBucket.buffer(self: torch._C._distributed_c10d.GradBucket) \u2192 torch.Tensor\u00b6\n```", "```py\ntorch.distributed.GradBucket.gradients(self: torch._C._distributed_c10d.GradBucket) \u2192 List[torch.Tensor]\u00b6\n```", "```py\ntorch.distributed.GradBucket.is_last(self: torch._C._distributed_c10d.GradBucket) \u2192 bool\u00b6\n```", "```py\ntorch.distributed.GradBucket.set_buffer(self: torch._C._distributed_c10d.GradBucket, buffer: torch.Tensor) \u2192 None\u00b6\n```", "```py\ntorch.distributed.GradBucket.parameters(self: torch._C._distributed_c10d.GradBucket) \u2192 List[torch.Tensor]\u00b6\n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.default_hooks.allreduce_hook(process_group, bucket)\u00b6\n```", "```py\n>>> ddp_model.register_comm_hook(process_group, allreduce_hook) \n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_hook(process_group, bucket)\u00b6\n```", "```py\n>>> ddp_model.register_comm_hook(process_group, fp16_compress_hook) \n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_hook(process_group, bucket)\u00b6\n```", "```py\n>>> ddp_model.register_comm_hook(process_group, bf16_compress_hook) \n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_wrapper(hook)\u00b6\n```", "```py\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1, start_powerSGD_iter=10)\n>>> ddp_model.register_comm_hook(state, fp16_compress_wrapper(powerSGD_hook)) \n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_wrapper(hook)\u00b6\n```", "```py\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1, start_powerSGD_iter=10)\n>>> ddp_model.register_comm_hook(state, bf16_compress_wrapper(powerSGD_hook)) \n```", "```py\nclass torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState(process_group, matrix_approximation_rank=1, start_powerSGD_iter=1000, min_compression_rate=2, use_error_feedback=True, warm_start=True, orthogonalization_epsilon=0, random_seed=0, compression_stats_logging_frequency=10000, batch_tensors_with_same_shape=False)\u00b6\n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.powerSGD_hook(state, bucket)\u00b6\n```", "```py\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1,\n start_powerSGD_iter=10, min_compression_rate=0.5)\n>>> ddp_model.register_comm_hook(state, powerSGD_hook) \n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.batched_powerSGD_hook(state, bucket)\u00b6\n```", "```py\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1)\n>>> ddp_model.register_comm_hook(state, batched_powerSGD_hook) \n```", "```py\ntorch.distributed.algorithms.ddp_comm_hooks.debugging_hooks.noop_hook(_, bucket)\u00b6\n```", "```py\n>>> ddp_model.register_comm_hook(None, noop_hook) \n```", "```py\nclass torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState\n```", "```py\n__getstate__()\u00b6\n```", "```py\n__setstate__(state)\u00b6\n```", "```py\nimport os\nimport sys\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel\nfrom torch.distributed.algorithms.ddp_comm_hooks import powerSGD_hook as powerSGD\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(24,24)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(24,12)\n\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n\n    # initialize the process group\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef run_demo(demo_fn, world_size):\n    mp.spawn(\n        demo_fn,\n        args=(world_size,),\n        nprocs=world_size,\n        join=True)\n\ndef demo_serialization(rank, world_size):\n    setup(rank, world_size)\n\n    CHECKPOINT = tempfile.gettempdir() + \"/checkpoint.pt\"\n\n    model = SimpleModel().to(rank)\n    ddp_model = DistributedDataParallel(model, device_ids=[rank])\n\n    powersgd_hook = powerSGD.powerSGD_hook\n    powersgd_state = powerSGD.PowerSGDState(process_group=None)\n\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n    ddp_model.register_comm_hook(powersgd_state, powersgd_hook)\n\n    state = {\n        'state_dict': ddp_model.state_dict(),\n        'comm_hook': powersgd_hook,\n        'comm_hook_state': powersgd_state}\n\n    if rank == 0:\n        torch.save(state, CHECKPOINT)\n\n    dist.barrier()\n    map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n    checkpoint = torch.load(CHECKPOINT, map_location=map_location)\n\n    new_ddp_model = DistributedDataParallel(SimpleModel().to(rank), device_ids=[rank])\n    new_ddp_model.load_state_dict(checkpoint['state_dict'])\n    powersgd_hook = checkpoint['comm_hook']\n    powersgd_state = checkpoint['comm_hook_state']\n\n    new_ddp_model.register_comm_hook(powersgd_state, powersgd_hook)\n\n    if rank == 0:\n        os.remove(CHECKPOINT)\n\n    cleanup()\n\nif __name__ == \"__main__\":\n    n_gpus = torch.cuda.device_count()\n    assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n    world_size = n_gpus\n    run_demo(demo_serialization, world_size) \n```"]