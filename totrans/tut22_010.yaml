- en: Build the Neural Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建神经网络
- en: 原文：[https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)
- en: Note
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Click [here](#sphx-glr-download-beginner-basics-buildmodel-tutorial-py) to download
    the full example code
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[这里](#sphx-glr-download-beginner-basics-buildmodel-tutorial-py)下载完整示例代码
- en: '[Learn the Basics](intro.html) || [Quickstart](quickstart_tutorial.html) ||
    [Tensors](tensorqs_tutorial.html) || [Datasets & DataLoaders](data_tutorial.html)
    || [Transforms](transforms_tutorial.html) || **Build Model** || [Autograd](autogradqs_tutorial.html)
    || [Optimization](optimization_tutorial.html) || [Save & Load Model](saveloadrun_tutorial.html)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[学习基础知识](intro.html) || [快速入门](quickstart_tutorial.html) || [张量](tensorqs_tutorial.html)
    || [数据集和数据加载器](data_tutorial.html) || [变换](transforms_tutorial.html) || **构建模型**
    || [自动求导](autogradqs_tutorial.html) || [优化](optimization_tutorial.html) || [保存和加载模型](saveloadrun_tutorial.html)'
- en: Neural networks comprise of layers/modules that perform operations on data.
    The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace provides all
    the building blocks you need to build your own neural network. Every module in
    PyTorch subclasses the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).
    A neural network is a module itself that consists of other modules (layers). This
    nested structure allows for building and managing complex architectures easily.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络由在数据上执行操作的层/模块组成。[torch.nn](https://pytorch.org/docs/stable/nn.html) 命名空间提供了构建自己的神经网络所需的所有构建模块。PyTorch
    中的每个模块都是 [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)
    的子类。神经网络本身是一个模块，包含其他模块（层）。这种嵌套结构使得轻松构建和管理复杂的架构成为可能。
- en: In the following sections, we’ll build a neural network to classify images in
    the FashionMNIST dataset.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将构建一个神经网络来对 FashionMNIST 数据集中的图像进行分类。
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Get Device for Training
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取训练设备
- en: We want to be able to train our model on a hardware accelerator like the GPU
    or MPS, if available. Let’s check to see if [torch.cuda](https://pytorch.org/docs/stable/notes/cuda.html)
    or [torch.backends.mps](https://pytorch.org/docs/stable/notes/mps.html) are available,
    otherwise we use the CPU.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有可能，我们希望能够在 GPU 或 MPS 等硬件加速器上训练模型。让我们检查一下是否有 [torch.cuda](https://pytorch.org/docs/stable/notes/cuda.html)
    或 [torch.backends.mps](https://pytorch.org/docs/stable/notes/mps.html)，否则我们使用
    CPU。
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Define the Class
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义类别
- en: We define our neural network by subclassing `nn.Module`, and initialize the
    neural network layers in `__init__`. Every `nn.Module` subclass implements the
    operations on input data in the `forward` method.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过子类化 `nn.Module` 来定义我们的神经网络，并在 `__init__` 中初始化神经网络层。每个 `nn.Module` 子类在 `forward`
    方法中实现对输入数据的操作。
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We create an instance of `NeuralNetwork`, and move it to the `device`, and print
    its structure.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个 `NeuralNetwork` 实例，并将其移动到 `device`，然后打印其结构。
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: To use the model, we pass it the input data. This executes the model’s `forward`,
    along with some [background operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).
    Do not call `model.forward()` directly!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用模型，我们将输入数据传递给它。这会执行模型的 `forward`，以及一些[后台操作](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866)。不要直接调用
    `model.forward()`！
- en: Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding
    to each output of 10 raw predicted values for each class, and dim=1 corresponding
    to the individual values of each output. We get the prediction probabilities by
    passing it through an instance of the `nn.Softmax` module.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对输入调用模型会返回一个二维张量，dim=0 对应每个类别的 10 个原始预测值，dim=1 对应每个输出的单个值。通过将其传递给 `nn.Softmax`
    模块，我们可以得到预测概率。
- en: '[PRE6]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '* * *'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Model Layers
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型层
- en: Let’s break down the layers in the FashionMNIST model. To illustrate it, we
    will take a sample minibatch of 3 images of size 28x28 and see what happens to
    it as we pass it through the network.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解 FashionMNIST 模型中的层。为了说明，我们将取一个大小为 28x28 的 3 张图像的示例小批量，并看看当我们将其通过网络时会发生什么。
- en: '[PRE8]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: nn.Flatten
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: nn.Flatten
- en: We initialize the [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)
    layer to convert each 2D 28x28 image into a contiguous array of 784 pixel values
    ( the minibatch dimension (at dim=0) is maintained).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化 [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)
    层，将每个 2D 的 28x28 图像转换为一个连续的包含 784 个像素值的数组（保持 minibatch 维度（在 dim=0））。
- en: '[PRE10]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: nn.Linear
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: nn.Linear
- en: The [linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)
    is a module that applies a linear transformation on the input using its stored
    weights and biases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[线性层](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) 是一个模块，使用其存储的权重和偏置对输入进行线性变换。'
- en: '[PRE12]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: nn.ReLU
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: nn.ReLU
- en: Non-linear activations are what create the complex mappings between the model’s
    inputs and outputs. They are applied after linear transformations to introduce
    *nonlinearity*, helping neural networks learn a wide variety of phenomena.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性激活是创建模型输入和输出之间复杂映射的关键。它们在线性变换之后应用，引入 *非线性*，帮助神经网络学习各种现象。
- en: In this model, we use [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)
    between our linear layers, but there’s other activations to introduce non-linearity
    in your model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，我们在线性层之间使用 [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)，但还有其他激活函数可以引入模型的非线性。
- en: '[PRE14]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: nn.Sequential
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: nn.Sequential
- en: '[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)
    is an ordered container of modules. The data is passed through all the modules
    in the same order as defined. You can use sequential containers to put together
    a quick network like `seq_modules`.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)
    是一个有序的模块容器。数据按照定义的顺序通过所有模块。您可以使用序列容器来组合一个快速网络，比如 `seq_modules`。'
- en: '[PRE16]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: nn.Softmax
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: nn.Softmax
- en: The last linear layer of the neural network returns logits - raw values in [-infty,
    infty] - which are passed to the [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)
    module. The logits are scaled to values [0, 1] representing the model’s predicted
    probabilities for each class. `dim` parameter indicates the dimension along which
    the values must sum to 1.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的最后一个线性层返回logits - 在[-infty, infty]范围内的原始值 - 这些值传递给[nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)模块。logits被缩放到表示模型对每个类别的预测概率的值[0,
    1]。`dim`参数指示值必须在其上求和为1的维度。
- en: '[PRE17]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Model Parameters
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型参数
- en: Many layers inside a neural network are *parameterized*, i.e. have associated
    weights and biases that are optimized during training. Subclassing `nn.Module`
    automatically tracks all fields defined inside your model object, and makes all
    parameters accessible using your model’s `parameters()` or `named_parameters()`
    methods.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络内部的许多层都是*参数化*的，即具有在训练期间优化的相关权重和偏差。通过对`nn.Module`进行子类化，自动跟踪模型对象内定义的所有字段，并使用模型的`parameters()`或`named_parameters()`方法使所有参数可访问。
- en: In this example, we iterate over each parameter, and print its size and a preview
    of its values.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们遍历每个参数，并打印其大小和值的预览。
- en: '[PRE18]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '* * *'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Further Reading
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[torch.nn API](https://pytorch.org/docs/stable/nn.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[torch.nn API](https://pytorch.org/docs/stable/nn.html)'
- en: '**Total running time of the script:** ( 0 minutes 2.486 seconds)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚本的总运行时间：**（0分钟2.486秒）'
- en: '[`Download Python source code: buildmodel_tutorial.py`](../../_downloads/ac800c8c4c9c372154788058b1e89246/buildmodel_tutorial.py)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Python源代码：buildmodel_tutorial.py`](../../_downloads/ac800c8c4c9c372154788058b1e89246/buildmodel_tutorial.py)'
- en: '[`Download Jupyter notebook: buildmodel_tutorial.ipynb`](../../_downloads/76d764ad694d0795e494a1edbfb068a6/buildmodel_tutorial.ipynb)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Jupyter笔记本：buildmodel_tutorial.ipynb`](../../_downloads/76d764ad694d0795e494a1edbfb068a6/buildmodel_tutorial.ipynb)'
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sphinx-Gallery生成的图库](https://sphinx-gallery.github.io)'
