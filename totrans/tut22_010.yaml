- en: Build the Neural Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Click [here](#sphx-glr-download-beginner-basics-buildmodel-tutorial-py) to download
    the full example code
  prefs: []
  type: TYPE_NORMAL
- en: '[Learn the Basics](intro.html) || [Quickstart](quickstart_tutorial.html) ||
    [Tensors](tensorqs_tutorial.html) || [Datasets & DataLoaders](data_tutorial.html)
    || [Transforms](transforms_tutorial.html) || **Build Model** || [Autograd](autogradqs_tutorial.html)
    || [Optimization](optimization_tutorial.html) || [Save & Load Model](saveloadrun_tutorial.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks comprise of layers/modules that perform operations on data.
    The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace provides all
    the building blocks you need to build your own neural network. Every module in
    PyTorch subclasses the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).
    A neural network is a module itself that consists of other modules (layers). This
    nested structure allows for building and managing complex architectures easily.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we’ll build a neural network to classify images in
    the FashionMNIST dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Get Device for Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We want to be able to train our model on a hardware accelerator like the GPU
    or MPS, if available. Let’s check to see if [torch.cuda](https://pytorch.org/docs/stable/notes/cuda.html)
    or [torch.backends.mps](https://pytorch.org/docs/stable/notes/mps.html) are available,
    otherwise we use the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Define the Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We define our neural network by subclassing `nn.Module`, and initialize the
    neural network layers in `__init__`. Every `nn.Module` subclass implements the
    operations on input data in the `forward` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We create an instance of `NeuralNetwork`, and move it to the `device`, and print
    its structure.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To use the model, we pass it the input data. This executes the model’s `forward`,
    along with some [background operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).
    Do not call `model.forward()` directly!
  prefs: []
  type: TYPE_NORMAL
- en: Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding
    to each output of 10 raw predicted values for each class, and dim=1 corresponding
    to the individual values of each output. We get the prediction probabilities by
    passing it through an instance of the `nn.Softmax` module.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Model Layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s break down the layers in the FashionMNIST model. To illustrate it, we
    will take a sample minibatch of 3 images of size 28x28 and see what happens to
    it as we pass it through the network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: nn.Flatten
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We initialize the [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)
    layer to convert each 2D 28x28 image into a contiguous array of 784 pixel values
    ( the minibatch dimension (at dim=0) is maintained).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: nn.Linear
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)
    is a module that applies a linear transformation on the input using its stored
    weights and biases.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: nn.ReLU
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Non-linear activations are what create the complex mappings between the model’s
    inputs and outputs. They are applied after linear transformations to introduce
    *nonlinearity*, helping neural networks learn a wide variety of phenomena.
  prefs: []
  type: TYPE_NORMAL
- en: In this model, we use [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)
    between our linear layers, but there’s other activations to introduce non-linearity
    in your model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: nn.Sequential
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)
    is an ordered container of modules. The data is passed through all the modules
    in the same order as defined. You can use sequential containers to put together
    a quick network like `seq_modules`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: nn.Softmax
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last linear layer of the neural network returns logits - raw values in [-infty,
    infty] - which are passed to the [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)
    module. The logits are scaled to values [0, 1] representing the model’s predicted
    probabilities for each class. `dim` parameter indicates the dimension along which
    the values must sum to 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Model Parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many layers inside a neural network are *parameterized*, i.e. have associated
    weights and biases that are optimized during training. Subclassing `nn.Module`
    automatically tracks all fields defined inside your model object, and makes all
    parameters accessible using your model’s `parameters()` or `named_parameters()`
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we iterate over each parameter, and print its size and a preview
    of its values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[torch.nn API](https://pytorch.org/docs/stable/nn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total running time of the script:** ( 0 minutes 2.486 seconds)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Python source code: buildmodel_tutorial.py`](../../_downloads/ac800c8c4c9c372154788058b1e89246/buildmodel_tutorial.py)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Jupyter notebook: buildmodel_tutorial.ipynb`](../../_downloads/76d764ad694d0795e494a1edbfb068a6/buildmodel_tutorial.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  prefs: []
  type: TYPE_NORMAL
