["```py\nclass torch.dtype\u00b6\n```", "```py\n>>> float_tensor = torch.ones(1, dtype=torch.float)\n>>> double_tensor = torch.ones(1, dtype=torch.double)\n>>> complex_float_tensor = torch.ones(1, dtype=torch.complex64)\n>>> complex_double_tensor = torch.ones(1, dtype=torch.complex128)\n>>> int_tensor = torch.ones(1, dtype=torch.int)\n>>> long_tensor = torch.ones(1, dtype=torch.long)\n>>> uint_tensor = torch.ones(1, dtype=torch.uint8)\n>>> double_tensor = torch.ones(1, dtype=torch.double)\n>>> bool_tensor = torch.ones(1, dtype=torch.bool)\n# zero-dim tensors\n>>> long_zerodim = torch.tensor(1, dtype=torch.long)\n>>> int_zerodim = torch.tensor(1, dtype=torch.int)\n\n>>> torch.add(5, 5).dtype\ntorch.int64\n# 5 is an int64, but does not have higher category than int_tensor so is not considered.\n>>> (int_tensor + 5).dtype\ntorch.int32\n>>> (int_tensor + long_zerodim).dtype\ntorch.int32\n>>> (long_tensor + int_tensor).dtype\ntorch.int64\n>>> (bool_tensor + long_tensor).dtype\ntorch.int64\n>>> (bool_tensor + uint_tensor).dtype\ntorch.uint8\n>>> (float_tensor + double_tensor).dtype\ntorch.float64\n>>> (complex_float_tensor + complex_double_tensor).dtype\ntorch.complex128\n>>> (bool_tensor + int_tensor).dtype\ntorch.int32\n# Since long is a different kind than float, result dtype only needs to be large enough\n# to hold the float.\n>>> torch.add(long_tensor, float_tensor).dtype\ntorch.float32 \n```", "```py\n# allowed:\n>>> float_tensor *= float_tensor\n>>> float_tensor *= int_tensor\n>>> float_tensor *= uint_tensor\n>>> float_tensor *= bool_tensor\n>>> float_tensor *= double_tensor\n>>> int_tensor *= long_tensor\n>>> int_tensor *= uint_tensor\n>>> uint_tensor *= int_tensor\n\n# disallowed (RuntimeError: result type can't be cast to the desired output type):\n>>> int_tensor *= float_tensor\n>>> bool_tensor *= int_tensor\n>>> bool_tensor *= uint_tensor\n>>> float_tensor *= complex_float_tensor \n```", "```py\nclass torch.device\u00b6\n```", "```py\n>>> torch.device('cuda:0')\ndevice(type='cuda', index=0)\n\n>>> torch.device('cpu')\ndevice(type='cpu')\n\n>>> torch.device('mps')\ndevice(type='mps')\n\n>>> torch.device('cuda')  # current cuda device\ndevice(type='cuda') \n```", "```py\n>>> torch.device('cuda', 0)\ndevice(type='cuda', index=0)\n\n>>> torch.device('mps', 0)\ndevice(type='mps', index=0)\n\n>>> torch.device('cpu', 0)\ndevice(type='cpu', index=0) \n```", "```py\n>>> with torch.device('cuda:1'):\n...     r = torch.randn(2, 3)\n>>> r.device\ndevice(type='cuda', index=1) \n```", "```py\n>>> # Example of a function that takes in a torch.device\n>>> cuda1 = torch.device('cuda:1')\n>>> torch.randn((2,3), device=cuda1) \n```", "```py\n>>> # You can substitute the torch.device with a string\n>>> torch.randn((2,3), device='cuda:1') \n```", "```py\n>>> torch.device(1)\ndevice(type='cuda', index=1) \n```", "```py\n>>> torch.randn((2,3), device=torch.device('cuda:1'))\n>>> torch.randn((2,3), device='cuda:1')\n>>> torch.randn((2,3), device=1)  # legacy \n```", "```py\nclass torch.layout\u00b6\n```", "```py\n>>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n>>> x.stride()\n(5, 1)\n\n>>> x.t().stride()\n(1, 5) \n```", "```py\nclass torch.memory_format\u00b6\n```"]