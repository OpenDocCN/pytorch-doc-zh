["```py\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms \n```", "```py\ndevice = (\n    \"cuda\"\n    if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")()\n    else \"mps\"\n    if [torch.backends.mps.is_available](https://pytorch.org/docs/stable/backends.html#torch.backends.mps.is_available \"torch.backends.mps.is_available\")()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\") \n```", "```py\nUsing cuda device \n```", "```py\nclass NeuralNetwork([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self):\n        super().__init__()\n        self.[flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\") = [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\")()\n        self.linear_relu_stack = [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential \"torch.nn.Sequential\")(\n            [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(28*28, 512),\n            [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \"torch.nn.ReLU\")(),\n            [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(512, 512),\n            [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \"torch.nn.ReLU\")(),\n            [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.[flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\")(x)\n        [logits](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = self.linear_relu_stack(x)\n        return [logits](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") \n```", "```py\nmodel = [NeuralNetwork](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")().to(device)\nprint(model) \n```", "```py\nNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n) \n```", "```py\n[X](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(1, 28, 28, device=device)\n[logits](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = model([X](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[pred_probab](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax \"torch.nn.Softmax\")(dim=1)([logits](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[y_pred](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [pred_probab](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").argmax(1)\nprint(f\"Predicted class: {[y_pred](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")}\") \n```", "```py\nPredicted class: tensor([7], device='cuda:0') \n```", "```py\n[input_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(3,28,28)\nprint([input_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size()) \n```", "```py\ntorch.Size([3, 28, 28]) \n```", "```py\n[flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\") = [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\")()\n[flat_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\")([input_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint([flat_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size()) \n```", "```py\ntorch.Size([3, 784]) \n```", "```py\n[layer1](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\") = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(in_features=28*28, out_features=20)\n[hidden1](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [layer1](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")([flat_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint([hidden1](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size()) \n```", "```py\ntorch.Size([3, 20]) \n```", "```py\nprint(f\"Before ReLU: {[hidden1](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")}\\n\\n\")\n[hidden1](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \"torch.nn.ReLU\")()([hidden1](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint(f\"After ReLU: {[hidden1](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")}\") \n```", "```py\nBefore ReLU: tensor([[ 0.4158, -0.0130, -0.1144,  0.3960,  0.1476, -0.0690, -0.0269,  0.2690,\n          0.1353,  0.1975,  0.4484,  0.0753,  0.4455,  0.5321, -0.1692,  0.4504,\n          0.2476, -0.1787, -0.2754,  0.2462],\n        [ 0.2326,  0.0623, -0.2984,  0.2878,  0.2767, -0.5434, -0.5051,  0.4339,\n          0.0302,  0.1634,  0.5649, -0.0055,  0.2025,  0.4473, -0.2333,  0.6611,\n          0.1883, -0.1250,  0.0820,  0.2778],\n        [ 0.3325,  0.2654,  0.1091,  0.0651,  0.3425, -0.3880, -0.0152,  0.2298,\n          0.3872,  0.0342,  0.8503,  0.0937,  0.1796,  0.5007, -0.1897,  0.4030,\n          0.1189, -0.3237,  0.2048,  0.4343]], grad_fn=<AddmmBackward0>)\n\nAfter ReLU: tensor([[0.4158, 0.0000, 0.0000, 0.3960, 0.1476, 0.0000, 0.0000, 0.2690, 0.1353,\n         0.1975, 0.4484, 0.0753, 0.4455, 0.5321, 0.0000, 0.4504, 0.2476, 0.0000,\n         0.0000, 0.2462],\n        [0.2326, 0.0623, 0.0000, 0.2878, 0.2767, 0.0000, 0.0000, 0.4339, 0.0302,\n         0.1634, 0.5649, 0.0000, 0.2025, 0.4473, 0.0000, 0.6611, 0.1883, 0.0000,\n         0.0820, 0.2778],\n        [0.3325, 0.2654, 0.1091, 0.0651, 0.3425, 0.0000, 0.0000, 0.2298, 0.3872,\n         0.0342, 0.8503, 0.0937, 0.1796, 0.5007, 0.0000, 0.4030, 0.1189, 0.0000,\n         0.2048, 0.4343]], grad_fn=<ReluBackward0>) \n```", "```py\n[seq_modules](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential \"torch.nn.Sequential\") = [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential \"torch.nn.Sequential\")(\n    [flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten \"torch.nn.Flatten\"),\n    [layer1](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\"),\n    [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \"torch.nn.ReLU\")(),\n    [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(20, 10)\n)\n[input_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(3,28,28)\n[logits](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [seq_modules](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential \"torch.nn.Sequential\")([input_image](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\n[softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax \"torch.nn.Softmax\") = [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax \"torch.nn.Softmax\")(dim=1)\n[pred_probab](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax \"torch.nn.Softmax\")([logits](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nprint(f\"Model structure: {model}\\n\\n\")\n\nfor name, [param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\") in [model.named_parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters \"torch.nn.Module.named_parameters\")():\n    print(f\"Layer: {name} | Size: {[param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\").size()} | Values : {[param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\")[:2]}  \\n\") \n```", "```py\nModel structure: NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\nLayer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115]],\n       device='cuda:0', grad_fn=<SliceBackward0>)\n\nLayer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0155, -0.0327], device='cuda:0', grad_fn=<SliceBackward0>)\n\nLayer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0116,  0.0293, -0.0280,  ...,  0.0334, -0.0078,  0.0298],\n        [ 0.0095,  0.0038,  0.0009,  ..., -0.0365, -0.0011, -0.0221]],\n       device='cuda:0', grad_fn=<SliceBackward0>)\n\nLayer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0148, -0.0256], device='cuda:0', grad_fn=<SliceBackward0>)\n\nLayer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0147, -0.0229,  0.0180,  ..., -0.0013,  0.0177,  0.0070],\n        [-0.0202, -0.0417, -0.0279,  ..., -0.0441,  0.0185, -0.0268]],\n       device='cuda:0', grad_fn=<SliceBackward0>)\n\nLayer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0070, -0.0411], device='cuda:0', grad_fn=<SliceBackward0>) \n```"]