- en: Spatial Transformer Networks Tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html](https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Click [here](#sphx-glr-download-intermediate-spatial-transformer-tutorial-py)
    to download the full example code
  prefs: []
  type: TYPE_NORMAL
- en: '**Author**: [Ghassen HAMROUNI](https://github.com/GHamrouni)'
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/FSeq.png](../Images/877d6867c0446fc513ee14aeb45673fb.png)'
  prefs: []
  type: TYPE_IMG
- en: In this tutorial, you will learn how to augment your network using a visual
    attention mechanism called spatial transformer networks. You can read more about
    the spatial transformer networks in the [DeepMind paper](https://arxiv.org/abs/1506.02025)
  prefs: []
  type: TYPE_NORMAL
- en: Spatial transformer networks are a generalization of differentiable attention
    to any spatial transformation. Spatial transformer networks (STN for short) allow
    a neural network to learn how to perform spatial transformations on the input
    image in order to enhance the geometric invariance of the model. For example,
    it can crop a region of interest, scale and correct the orientation of an image.
    It can be a useful mechanism because CNNs are not invariant to rotation and scale
    and more general affine transformations.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best things about STN is the ability to simply plug it into any existing
    CNN with very little modification.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Loading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this post we experiment with the classic MNIST dataset. Using a standard
    convolutional network augmented with a spatial transformer network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Depicting spatial transformer networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Spatial transformer networks boils down to three main components :'
  prefs: []
  type: TYPE_NORMAL
- en: The localization network is a regular CNN which regresses the transformation
    parameters. The transformation is never learned explicitly from this dataset,
    instead the network learns automatically the spatial transformations that enhances
    the global accuracy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The grid generator generates a grid of coordinates in the input image corresponding
    to each pixel from the output image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sampler uses the parameters of the transformation and applies it to the
    input image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../_images/stn-arch.png](../Images/0f822bf7763e04e2824dcc9c9dd89eea.png)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We need the latest version of PyTorch that contains affine_grid and grid_sample
    modules.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s use the SGD algorithm to train the model. The network is learning
    the classification task in a supervised way. In the same time the model is learning
    STN automatically in an end-to-end fashion.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Visualizing the STN results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will inspect the results of our learned visual attention mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: We define a small helper function in order to visualize the transformations
    while training.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![Dataset Images, Transformed Images](../Images/a77d97dad93b9a6680a39672f8bf21ff.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Total running time of the script:** ( 3 minutes 30.487 seconds)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Python source code: spatial_transformer_tutorial.py`](../_downloads/a4f07fecba75b5e84fe9e56cac0c7b71/spatial_transformer_tutorial.py)'
  prefs: []
  type: TYPE_NORMAL
- en: '[`Download Jupyter notebook: spatial_transformer_tutorial.ipynb`](../_downloads/a5513958454950ed22df8da4c47f6429/spatial_transformer_tutorial.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  prefs: []
  type: TYPE_NORMAL
