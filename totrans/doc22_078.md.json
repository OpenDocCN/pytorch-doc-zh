["```py\n>>> a, b = torch.arange(3), torch.arange(5) + 3\n>>> a\ntensor([0, 1, 2])\n>>> b\ntensor([3, 4, 5, 6, 7])\n>>> nt = torch.nested.nested_tensor([a, b])\n>>> nt\nnested_tensor([\n tensor([0, 1, 2]),\n tensor([3, 4, 5, 6, 7])\n ]) \n```", "```py\n>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32, device=\"cuda\", requires_grad=True)\n>>> nt\nnested_tensor([\n tensor([0., 1., 2.], device='cuda:0', requires_grad=True),\n tensor([3., 4., 5., 6., 7.], device='cuda:0', requires_grad=True)\n], device='cuda:0', requires_grad=True) \n```", "```py\n>>> a = torch.randn(3, 50, 70) # image 1\n>>> b = torch.randn(3, 128, 64) # image 2\n>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)\n>>> nt.dim()\n4 \n```", "```py\n>>> a = torch.randn(50, 128) # text 1\n>>> b = torch.randn(3, 128, 64) # image 2\n>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nRuntimeError: All Tensors given to nested_tensor must have the same dimension. Found dimension 3 for Tensor at index 1 and dimension 2 for Tensor at index 0. \n```", "```py\n>>> a = torch.randn(50, 128) # text 1\n>>> b = torch.randn(32, 128) # text 2\n>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)\n>>> nt.size(0)\n2\n>>> nt.size(1)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nRuntimeError: Given dimension 1 is irregular and does not have a size.\n>>> nt.size(2)\n128 \n```", "```py\n>>> a = torch.randn(20, 128) # text 1\n>>> nt = torch.nested.nested_tensor([a, a], dtype=torch.float32)\n>>> nt.size(0)\n2\n>>> nt.size(1)\n20\n>>> nt.size(2)\n128\n>>> torch.stack(nt.unbind()).size()\ntorch.Size([2, 20, 128])\n>>> torch.stack([a, a]).size()\ntorch.Size([2, 20, 128])\n>>> torch.equal(torch.stack(nt.unbind()), torch.stack([a, a]))\nTrue \n```", "```py\n>>> import torch\n>>> a = torch.randn(2, 3)\n>>> b = torch.randn(3, 4)\n>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)\n>>> nt\nnested_tensor([\n tensor([[ 1.2286, -1.2343, -1.4842],\n [-0.7827,  0.6745,  0.0658]]),\n tensor([[-1.1247, -0.4078, -1.0633,  0.8083],\n [-0.2871, -0.2980,  0.5559,  1.9885],\n [ 0.4074,  2.4855,  0.0733,  0.8285]])\n])\n>>> nt.unbind()\n(tensor([[ 1.2286, -1.2343, -1.4842],\n [-0.7827,  0.6745,  0.0658]]), tensor([[-1.1247, -0.4078, -1.0633,  0.8083],\n [-0.2871, -0.2980,  0.5559,  1.9885],\n [ 0.4074,  2.4855,  0.0733,  0.8285]]))\n>>> nt.unbind()[0] is not a\nTrue\n>>> nt.unbind()[0].mul_(3)\ntensor([[ 3.6858, -3.7030, -4.4525],\n [-2.3481,  2.0236,  0.1975]])\n>>> nt\nnested_tensor([\n tensor([[ 3.6858, -3.7030, -4.4525],\n [-2.3481,  2.0236,  0.1975]]),\n tensor([[-1.1247, -0.4078, -1.0633,  0.8083],\n [-0.2871, -0.2980,  0.5559,  1.9885],\n [ 0.4074,  2.4855,  0.0733,  0.8285]])\n]) \n```", "```py\ntorch.nested.nested_tensor(tensor_list, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False)\u00b6\n```", "```py\n>>> a = torch.arange(3, dtype=torch.float, requires_grad=True)\n>>> b = torch.arange(5, dtype=torch.float, requires_grad=True)\n>>> nt = torch.nested.nested_tensor([a, b], requires_grad=True)\n>>> nt.is_leaf\nTrue \n```", "```py\ntorch.nested.as_nested_tensor(tensor_list, dtype=None, device=None, layout=None)\u00b6\n```", "```py\n>>> a = torch.arange(3, dtype=torch.float, requires_grad=True)\n>>> b = torch.arange(5, dtype=torch.float, requires_grad=True)\n>>> nt = torch.nested.as_nested_tensor([a, b])\n>>> nt.is_leaf\nFalse\n>>> fake_grad = torch.nested.nested_tensor([torch.ones_like(a), torch.zeros_like(b)])\n>>> nt.backward(fake_grad)\n>>> a.grad\ntensor([1., 1., 1.])\n>>> b.grad\ntensor([0., 0., 0., 0., 0.]) \n```", "```py\ntorch.nested.to_padded_tensor(input, padding, output_size=None, out=None) \u2192 Tensor\u00b6\n```", "```py\n>>> nt = torch.nested.nested_tensor([torch.randn((2, 5)), torch.randn((3, 4))])\nnested_tensor([\n tensor([[ 1.6862, -1.1282,  1.1031,  0.0464, -1.3276],\n [-1.9967, -1.0054,  1.8972,  0.9174, -1.4995]]),\n tensor([[-1.8546, -0.7194, -0.2918, -0.1846],\n [ 0.2773,  0.8793, -0.5183, -0.6447],\n [ 1.8009,  1.8468, -0.9832, -1.5272]])\n])\n>>> pt_infer = torch.nested.to_padded_tensor(nt, 0.0)\ntensor([[[ 1.6862, -1.1282,  1.1031,  0.0464, -1.3276],\n [-1.9967, -1.0054,  1.8972,  0.9174, -1.4995],\n [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n [[-1.8546, -0.7194, -0.2918, -0.1846,  0.0000],\n [ 0.2773,  0.8793, -0.5183, -0.6447,  0.0000],\n [ 1.8009,  1.8468, -0.9832, -1.5272,  0.0000]]])\n>>> pt_large = torch.nested.to_padded_tensor(nt, 1.0, (2, 4, 6))\ntensor([[[ 1.6862, -1.1282,  1.1031,  0.0464, -1.3276,  1.0000],\n [-1.9967, -1.0054,  1.8972,  0.9174, -1.4995,  1.0000],\n [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000]],\n [[-1.8546, -0.7194, -0.2918, -0.1846,  1.0000,  1.0000],\n [ 0.2773,  0.8793, -0.5183, -0.6447,  1.0000,  1.0000],\n [ 1.8009,  1.8468, -0.9832, -1.5272,  1.0000,  1.0000],\n [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000]]])\n>>> pt_small = torch.nested.to_padded_tensor(nt, 2.0, (2, 2, 2))\nRuntimeError: Value in output_size is less than NestedTensor padded size. Truncation is not supported. \n```"]