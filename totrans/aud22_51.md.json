["```py\n# Define custom feature extraction pipeline.\n#\n# 1\\. Resample audio\n# 2\\. Convert to power spectrogram\n# 3\\. Apply augmentations\n# 4\\. Convert to mel-scale\n#\nclass MyPipeline(torch.nn.Module):\n    def __init__(\n        self,\n        input_freq=16000,\n        resample_freq=8000,\n        n_fft=1024,\n        n_mel=256,\n        stretch_factor=0.8,\n    ):\n        super().__init__()\n        self.resample = Resample(orig_freq=input_freq, new_freq=resample_freq)\n\n        self.spec = Spectrogram(n_fft=n_fft, power=2)\n\n        self.spec_aug = torch.nn.Sequential(\n            TimeStretch(stretch_factor, fixed_rate=True),\n            FrequencyMasking(freq_mask_param=80),\n            TimeMasking(time_mask_param=80),\n        )\n\n        self.mel_scale = MelScale(\n            n_mels=n_mel, sample_rate=resample_freq, n_stft=n_fft // 2 + 1)\n\n    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n        # Resample the input\n        resampled = self.resample(waveform)\n\n        # Convert to power spectrogram\n        spec = self.spec(resampled)\n\n        # Apply SpecAugment\n        spec = self.spec_aug(spec)\n\n        # Convert to mel-scale\n        mel = self.mel_scale(spec)\n\n        return mel \n```", "```py\n# Instantiate a pipeline\npipeline = MyPipeline()\n\n# Move the computation graph to CUDA\npipeline.to(device=torch.device(\"cuda\"), dtype=torch.float32)\n\n# Perform the transform\nfeatures = pipeline(waveform) \n```"]