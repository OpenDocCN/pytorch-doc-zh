["```py\nfrom functools import partial\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split \"torch.utils.data.random_split\")\nimport torchvision\nimport torchvision.transforms as transforms\nfrom ray import tune\nfrom ray.air import Checkpoint, session\nfrom ray.tune.schedulers import ASHAScheduler \n```", "```py\ndef load_data(data_dir=\"./data\"):\n    transform = [transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose \"torchvision.transforms.Compose\")(\n        [[transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")(), [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize \"torchvision.transforms.Normalize\")((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n    )\n\n    trainset = [torchvision.datasets.CIFAR10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10 \"torchvision.datasets.CIFAR10\")(\n        root=data_dir, train=True, download=True, transform=transform\n    )\n\n    testset = [torchvision.datasets.CIFAR10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10 \"torchvision.datasets.CIFAR10\")(\n        root=data_dir, train=False, download=True, transform=transform\n    )\n\n    return trainset, testset \n```", "```py\nclass Net([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, l1=120, l2=84):\n        super([Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(3, 6, 5)\n        self.pool = [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d \"torch.nn.MaxPool2d\")(2, 2)\n        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(6, 16, 5)\n        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(16 * 5 * 5, l1)\n        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(l1, l2)\n        self.fc3 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(l2, 10)\n\n    def forward(self, x):\n        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.conv1(x)))\n        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.conv2(x)))\n        x = [torch.flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten \"torch.flatten\")(x, 1)  # flatten all dimensions except batch\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.fc1(x))\n        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(self.fc2(x))\n        x = self.fc3(x)\n        return x \n```", "```py\nnet = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(config[\"l1\"], config[\"l2\"])\n\ncheckpoint = session.get_checkpoint()\n\nif checkpoint:\n    checkpoint_state = checkpoint.to_dict()\n    start_epoch = checkpoint_state[\"epoch\"]\n    net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n    optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\nelse:\n    start_epoch = 0 \n```", "```py\noptimizer = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\")(net.parameters(), lr=config[\"lr\"], momentum=0.9) \n```", "```py\ndevice = \"cpu\"\nif [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")():\n    device = \"cuda:0\"\n    if [torch.cuda.device_count](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count \"torch.cuda.device_count\")() > 1:\n        net = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel \"torch.nn.DataParallel\")(net)\nnet.to(device) \n```", "```py\nfor i, data in enumerate(trainloader, 0):\n    inputs, labels = data\n    inputs, labels = inputs.to(device), labels.to(device) \n```", "```py\ncheckpoint_data = {\n    \"epoch\": epoch,\n    \"net_state_dict\": net.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict(),\n}\ncheckpoint = Checkpoint.from_dict(checkpoint_data)\n\nsession.report(\n    {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n    checkpoint=checkpoint,\n) \n```", "```py\ndef train_cifar(config, data_dir=None):\n    net = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(config[\"l1\"], config[\"l2\"])\n\n    device = \"cpu\"\n    if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")():\n        device = \"cuda:0\"\n        if [torch.cuda.device_count](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count \"torch.cuda.device_count\")() > 1:\n            net = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel \"torch.nn.DataParallel\")(net)\n    net.to(device)\n\n    criterion = [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss \"torch.nn.CrossEntropyLoss\")()\n    optimizer = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD \"torch.optim.SGD\")(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n    checkpoint = session.get_checkpoint()\n\n    if checkpoint:\n        checkpoint_state = checkpoint.to_dict()\n        start_epoch = checkpoint_state[\"epoch\"]\n        net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n    else:\n        start_epoch = 0\n\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split \"torch.utils.data.random_split\")(\n        trainset, [test_abs, len(trainset) - test_abs]\n    )\n\n    trainloader = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")(\n        train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8\n    )\n    valloader = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")(\n        val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8\n    )\n\n    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\n                    \"[%d, %5d] loss: %.3f\"\n                    % (epoch + 1, i + 1, running_loss / epoch_steps)\n                )\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max \"torch.max\")(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        checkpoint_data = {\n            \"epoch\": epoch,\n            \"net_state_dict\": net.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n        }\n        checkpoint = Checkpoint.from_dict(checkpoint_data)\n\n        session.report(\n            {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n            checkpoint=checkpoint,\n        )\n    print(\"Finished Training\") \n```", "```py\ndef test_accuracy(net, device=\"cpu\"):\n    trainset, testset = load_data()\n\n    testloader = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")(\n        testset, batch_size=4, shuffle=False, num_workers=2\n    )\n\n    correct = 0\n    total = 0\n    with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max \"torch.max\")(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total \n```", "```py\nconfig = {\n    \"l1\": tune.choice([2 ** i for i in range(9)]),\n    \"l2\": tune.choice([2 ** i for i in range(9)]),\n    \"lr\": tune.loguniform(1e-4, 1e-1),\n    \"batch_size\": tune.choice([2, 4, 8, 16])\n} \n```", "```py\ngpus_per_trial = 2\n# ...\nresult = tune.run(\n    partial(train_cifar, data_dir=data_dir),\n    resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n    config=config,\n    num_samples=num_samples,\n    scheduler=scheduler,\n    checkpoint_at_end=True) \n```", "```py\ndef main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n    data_dir = os.path.abspath(\"./data\")\n    load_data(data_dir)\n    config = {\n        \"l1\": tune.choice([2**i for i in range(9)]),\n        \"l2\": tune.choice([2**i for i in range(9)]),\n        \"lr\": tune.loguniform(1e-4, 1e-1),\n        \"batch_size\": tune.choice([2, 4, 8, 16]),\n    }\n    scheduler = ASHAScheduler(\n        metric=\"loss\",\n        mode=\"min\",\n        max_t=max_num_epochs,\n        grace_period=1,\n        reduction_factor=2,\n    )\n    result = tune.run(\n        partial(train_cifar, data_dir=data_dir),\n        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n        config=config,\n        num_samples=num_samples,\n        scheduler=scheduler,\n    )\n\n    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n    print(f\"Best trial config: {best_trial.config}\")\n    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n    print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n\n    best_trained_model = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n    device = \"cpu\"\n    if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")():\n        device = \"cuda:0\"\n        if gpus_per_trial > 1:\n            best_trained_model = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel \"torch.nn.DataParallel\")(best_trained_model)\n    best_trained_model.to(device)\n\n    best_checkpoint = best_trial.checkpoint.to_air_checkpoint()\n    best_checkpoint_data = best_checkpoint.to_dict()\n\n    best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n\n    test_acc = test_accuracy(best_trained_model, device)\n    print(\"Best trial test set accuracy: {}\".format(test_acc))\n\nif __name__ == \"__main__\":\n    # You can change the number of GPUs per trial here:\n    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0) \n```", "```py\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz\n\n  0% 0/170498071 [00:00<?, ?it/s]\n  0% 491520/170498071 [00:00<00:34, 4901426.98it/s]\n  4% 7307264/170498071 [00:00<00:03, 42047898.29it/s]\n 10% 17629184/170498071 [00:00<00:02, 69798204.67it/s]\n 16% 27820032/170498071 [00:00<00:01, 82407622.17it/s]\n 22% 38338560/170498071 [00:00<00:01, 90604441.34it/s]\n 29% 48726016/170498071 [00:00<00:01, 95049915.99it/s]\n 35% 59342848/170498071 [00:00<00:01, 98624828.60it/s]\n 41% 69828608/170498071 [00:00<00:01, 100103452.88it/s]\n 47% 80707584/170498071 [00:00<00:00, 102701251.79it/s]\n 54% 91226112/170498071 [00:01<00:00, 103410219.64it/s]\n 60% 101842944/170498071 [00:01<00:00, 104217418.28it/s]\n 66% 112394240/170498071 [00:01<00:00, 104577303.94it/s]\n 72% 122912768/170498071 [00:01<00:00, 104690232.44it/s]\n 78% 133464064/170498071 [00:01<00:00, 104835011.32it/s]\n 84% 144015360/170498071 [00:01<00:00, 104975230.73it/s]\n 91% 154566656/170498071 [00:01<00:00, 105068640.23it/s]\n 97% 165085184/170498071 [00:01<00:00, 104644047.95it/s]\n100% 170498071/170498071 [00:01<00:00, 96529746.41it/s]\nExtracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data\nFiles already downloaded and verified\n2024-02-03 05:16:34,052 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n2024-02-03 05:16:34,193 INFO worker.py:1625 -- Started a local Ray instance.\n2024-02-03 05:16:35,349 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n(pid=2669) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n(pid=2669)   _torch_pytree._register_pytree_node(\n== Status ==\nCurrent time: 2024-02-03 05:16:40 (running for 00:00:05.27)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (9 PENDING, 1 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n(func pid=2669) Files already downloaded and verified\n(func pid=2669) Files already downloaded and verified\n(pid=2758)   _torch_pytree._register_pytree_node(\n(pid=2758)   _torch_pytree._register_pytree_node(\n(pid=2765) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n(pid=2765)   _torch_pytree._register_pytree_node(\n== Status ==\nCurrent time: 2024-02-03 05:16:46 (running for 00:00:11.10)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 PENDING, 7 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n(func pid=2756) Files already downloaded and verified\n(func pid=2765) Files already downloaded and verified\n(pid=3549) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead. [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\n(pid=3549)   _torch_pytree._register_pytree_node( [repeated 5x across cluster]\n(func pid=2669) [1,  2000] loss: 2.332\n(func pid=2758) Files already downloaded and verified [repeated 10x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:16:53 (running for 00:00:18.39)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:16:58 (running for 00:00:23.40)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n(func pid=2756) [1,  2000] loss: 2.311\n(func pid=3549) Files already downloaded and verified [repeated 2x across cluster]\n(func pid=2764) [1,  2000] loss: 2.303\n== Status ==\nCurrent time: 2024-02-03 05:17:03 (running for 00:00:28.41)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:17:08 (running for 00:00:33.42)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n(func pid=3549) [1,  2000] loss: 1.855 [repeated 6x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:17:13 (running for 00:00:38.43)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n(func pid=2760) [1,  4000] loss: 1.031 [repeated 7x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:17:18 (running for 00:00:43.44)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:17:23 (running for 00:00:48.45)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\n(func pid=2756) [1,  6000] loss: 0.770\n(func pid=2764) [1,  6000] loss: 0.681\n== Status ==\nCurrent time: 2024-02-03 05:17:28 (running for 00:00:53.46)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n|-------------------------+----------+-----------------+--------------+------+------+-------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+\n\nResult for train_cifar_668d1_00006:\n  accuracy: 0.1208\n  date: 2024-02-03_05-17-29\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.293956341743469\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 43.53398323059082\n  time_this_iter_s: 43.53398323059082\n  time_total_s: 43.53398323059082\n  timestamp: 1706937449\n  training_iteration: 1\n  trial_id: 668d1_00006\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2079\n  date: 2024-02-03_05-17-31\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.028138545417786\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 45.46037745475769\n  time_this_iter_s: 45.46037745475769\n  time_total_s: 45.46037745475769\n  timestamp: 1706937451\n  training_iteration: 1\n  trial_id: 668d1_00003\n\n(func pid=2669) [1, 10000] loss: 0.461 [repeated 5x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:17:37 (running for 00:01:01.57)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00007:\n  accuracy: 0.4793\n  date: 2024-02-03_05-17-40\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 1.4310961763858796\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 46.97845983505249\n  time_this_iter_s: 46.97845983505249\n  time_total_s: 46.97845983505249\n  timestamp: 1706937460\n  training_iteration: 1\n  trial_id: 668d1_00007\n\n(func pid=2758) [1,  8000] loss: 0.575 [repeated 4x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:17:45 (running for 00:01:10.40)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.028138545417786\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2762) [1, 10000] loss: 0.468 [repeated 6x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:17:50 (running for 00:01:15.41)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.028138545417786\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:17:55 (running for 00:01:20.42)\nUsing AsyncHyperBand: num_stopped=0\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.028138545417786\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 PENDING, 8 RUNNING)\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |\n| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |\n| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |\n| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [2,  2000] loss: 1.406\n(func pid=2669) [1, 14000] loss: 0.329\nResult for train_cifar_668d1_00001:\n  accuracy: 0.1009\n  date: 2024-02-03_05-17-58\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.3118444224357604\n  node_ip: 172.17.0.2\n  pid: 2756\n  should_checkpoint: true\n  time_since_restore: 72.15020895004272\n  time_this_iter_s: 72.15020895004272\n  time_total_s: 72.15020895004272\n  timestamp: 1706937478\n  training_iteration: 1\n  trial_id: 668d1_00001\n\nTrial train_cifar_668d1_00001 completed.\nResult for train_cifar_668d1_00005:\n  accuracy: 0.3539\n  date: 2024-02-03_05-17-58\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 1.7180780637741089\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 72.5149827003479\n  time_this_iter_s: 72.5149827003479\n  time_total_s: 72.5149827003479\n  timestamp: 1706937478\n  training_iteration: 1\n  trial_id: 668d1_00005\n\n(func pid=2756) Files already downloaded and verified\nResult for train_cifar_668d1_00004:\n  accuracy: 0.1042\n  date: 2024-02-03_05-17-59\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.317199463367462\n  node_ip: 172.17.0.2\n  pid: 2762\n  should_checkpoint: true\n  time_since_restore: 73.49483036994934\n  time_this_iter_s: 73.49483036994934\n  time_total_s: 73.49483036994934\n  timestamp: 1706937479\n  training_iteration: 1\n  trial_id: 668d1_00004\n\nTrial train_cifar_668d1_00004 completed.\n(func pid=2756) Files already downloaded and verified\n== Status ==\nCurrent time: 2024-02-03 05:18:04 (running for 00:01:29.51)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2669) [1, 16000] loss: 0.288 [repeated 4x across cluster]\n(func pid=2762) Files already downloaded and verified [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:18:09 (running for 00:01:34.53)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00006:\n  accuracy: 0.1824\n  date: 2024-02-03_05-18-11\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 2\n  loss: 2.1994362588882446\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 84.67864155769348\n  time_this_iter_s: 41.14465832710266\n  time_total_s: 84.67864155769348\n  timestamp: 1706937491\n  training_iteration: 2\n  trial_id: 668d1_00006\n\n(func pid=2756) [1,  2000] loss: 2.138 [repeated 5x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:18:16 (running for 00:01:40.64)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1994362588882446 | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2459\n  date: 2024-02-03_05-18-16\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 2\n  loss: 1.9869435796737671\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 90.14830899238586\n  time_this_iter_s: 44.687931537628174\n  time_total_s: 90.14830899238586\n  timestamp: 1706937496\n  training_iteration: 2\n  trial_id: 668d1_00003\n\n== Status ==\nCurrent time: 2024-02-03 05:18:21 (running for 00:01:46.25)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0931899192810057 | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [2,  4000] loss: 0.814 [repeated 2x across cluster]\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5056\n  date: 2024-02-03_05-18-25\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 2\n  loss: 1.4163358207702637\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 91.53078818321228\n  time_this_iter_s: 44.55232834815979\n  time_total_s: 91.53078818321228\n  timestamp: 1706937505\n  training_iteration: 2\n  trial_id: 668d1_00007\n\n(func pid=2758) [1, 14000] loss: 0.310 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:18:30 (running for 00:01:54.95)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:18:35 (running for 00:01:59.96)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2762) [1,  6000] loss: 0.779 [repeated 4x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:18:40 (running for 00:02:04.97)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [3,  2000] loss: 1.268 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:18:45 (running for 00:02:09.98)\nUsing AsyncHyperBand: num_stopped=2\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273\nLogical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (8 RUNNING, 2 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00008:\n  accuracy: 0.2278\n  date: 2024-02-03_05-18-45\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.150844239425659\n  node_ip: 172.17.0.2\n  pid: 2756\n  should_checkpoint: true\n  time_since_restore: 47.30649995803833\n  time_this_iter_s: 47.30649995803833\n  time_total_s: 47.30649995803833\n  timestamp: 1706937525\n  training_iteration: 1\n  trial_id: 668d1_00008\n\n(func pid=2762) [1,  8000] loss: 0.585 [repeated 2x across cluster]\nResult for train_cifar_668d1_00000:\n  accuracy: 0.0961\n  date: 2024-02-03_05-18-48\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.3129488151073456\n  node_ip: 172.17.0.2\n  pid: 2669\n  should_checkpoint: true\n  time_since_restore: 127.89715909957886\n  time_this_iter_s: 127.89715909957886\n  time_total_s: 127.89715909957886\n  timestamp: 1706937528\n  training_iteration: 1\n  trial_id: 668d1_00000\n\nTrial train_cifar_668d1_00000 completed.\nResult for train_cifar_668d1_00006:\n  accuracy: 0.2072\n  date: 2024-02-03_05-18-51\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 3\n  loss: 2.098891372299194\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 125.34813141822815\n  time_this_iter_s: 40.66948986053467\n  time_total_s: 125.34813141822815\n  timestamp: 1706937531\n  training_iteration: 3\n  trial_id: 668d1_00006\n\n== Status ==\nCurrent time: 2024-02-03 05:18:51 (running for 00:02:16.30)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [3,  4000] loss: 0.627 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:18:56 (running for 00:02:21.31)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2298\n  date: 2024-02-03_05-19-00\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 3\n  loss: 2.000217504119873\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 133.78930187225342\n  time_this_iter_s: 43.640992879867554\n  time_total_s: 133.78930187225342\n  timestamp: 1706937540\n  training_iteration: 3\n  trial_id: 668d1_00003\n\n(func pid=2756) [2,  2000] loss: 2.167 [repeated 4x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:19:05 (running for 00:02:29.90)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2762) [1, 12000] loss: 0.389 [repeated 2x across cluster]\nResult for train_cifar_668d1_00005:\n  accuracy: 0.4677\n  date: 2024-02-03_05-19-08\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 2\n  loss: 1.4615094123959542\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 141.90429210662842\n  time_this_iter_s: 69.38930940628052\n  time_total_s: 141.90429210662842\n  timestamp: 1706937548\n  training_iteration: 2\n  trial_id: 668d1_00005\n\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5436\n  date: 2024-02-03_05-19-08\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 3\n  loss: 1.3132171389341354\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 134.65492868423462\n  time_this_iter_s: 43.12414050102234\n  time_total_s: 134.65492868423462\n  timestamp: 1706937548\n  training_iteration: 3\n  trial_id: 668d1_00007\n\n== Status ==\nCurrent time: 2024-02-03 05:19:13 (running for 00:02:38.06)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2758) [1, 20000] loss: 0.213\n(func pid=2760) [4,  2000] loss: 2.060\n== Status ==\nCurrent time: 2024-02-03 05:19:18 (running for 00:02:43.08)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [4,  2000] loss: 1.165 [repeated 5x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:19:23 (running for 00:02:48.09)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:19:28 (running for 00:02:53.10)\nUsing AsyncHyperBand: num_stopped=3\nBracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564\nLogical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (7 RUNNING, 3 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |\n| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2762) [1, 16000] loss: 0.292\n(func pid=2760) [4,  4000] loss: 1.015\nResult for train_cifar_668d1_00006:\n  accuracy: 0.2527\n  date: 2024-02-03_05-19-30\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 4\n  loss: 1.9832857732772826\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 164.49138188362122\n  time_this_iter_s: 39.143250465393066\n  time_total_s: 164.49138188362122\n  timestamp: 1706937570\n  training_iteration: 4\n  trial_id: 668d1_00006\n\nResult for train_cifar_668d1_00002:\n  accuracy: 0.2024\n  date: 2024-02-03_05-19-31\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.10914013671875\n  node_ip: 172.17.0.2\n  pid: 2758\n  should_checkpoint: true\n  time_since_restore: 164.5055296421051\n  time_this_iter_s: 164.5055296421051\n  time_total_s: 164.5055296421051\n  timestamp: 1706937571\n  training_iteration: 1\n  trial_id: 668d1_00002\n\nResult for train_cifar_668d1_00008:\n  accuracy: 0.1979\n  date: 2024-02-03_05-19-32\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 2\n  loss: 2.0927836849212644\n  node_ip: 172.17.0.2\n  pid: 2756\n  should_checkpoint: true\n  time_since_restore: 93.59351873397827\n  time_this_iter_s: 46.28701877593994\n  time_total_s: 93.59351873397827\n  timestamp: 1706937572\n  training_iteration: 2\n  trial_id: 668d1_00008\n\nTrial train_cifar_668d1_00008 completed.\n== Status ==\nCurrent time: 2024-02-03 05:19:37 (running for 00:03:01.79)\nUsing AsyncHyperBand: num_stopped=4\nBracket: Iter 8.000: None | Iter 4.000: -1.9832857732772826 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659\nLogical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [4,  4000] loss: 0.594 [repeated 2x across cluster]\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2432\n  date: 2024-02-03_05-19-42\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 4\n  loss: 1.9813426310539246\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 175.52458882331848\n  time_this_iter_s: 41.73528695106506\n  time_total_s: 175.52458882331848\n  timestamp: 1706937582\n  training_iteration: 4\n  trial_id: 668d1_00003\n\n(func pid=2764) [3,  6000] loss: 0.479 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:19:47 (running for 00:03:11.64)\nUsing AsyncHyperBand: num_stopped=4\nBracket: Iter 8.000: None | Iter 4.000: -1.9823142021656035 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659\nLogical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2762) [1, 20000] loss: 0.234 [repeated 3x across cluster]\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5489\n  date: 2024-02-03_05-19-49\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 4\n  loss: 1.3539480135917663\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 175.67858505249023\n  time_this_iter_s: 41.023656368255615\n  time_total_s: 175.67858505249023\n  timestamp: 1706937589\n  training_iteration: 4\n  trial_id: 668d1_00007\n\n== Status ==\nCurrent time: 2024-02-03 05:19:54 (running for 00:03:19.09)\nUsing AsyncHyperBand: num_stopped=4\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659\nLogical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2760) [5,  2000] loss: 2.053 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:19:59 (running for 00:03:24.10)\nUsing AsyncHyperBand: num_stopped=4\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659\nLogical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [5,  2000] loss: 1.101 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:20:04 (running for 00:03:29.11)\nUsing AsyncHyperBand: num_stopped=4\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659\nLogical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |\n| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00009:\n  accuracy: 0.1016\n  date: 2024-02-03_05-20-04\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 1\n  loss: 2.3339982474803924\n  node_ip: 172.17.0.2\n  pid: 2762\n  should_checkpoint: true\n  time_since_restore: 124.63368916511536\n  time_this_iter_s: 124.63368916511536\n  time_total_s: 124.63368916511536\n  timestamp: 1706937604\n  training_iteration: 1\n  trial_id: 668d1_00009\n\nTrial train_cifar_668d1_00009 completed.\nResult for train_cifar_668d1_00006:\n  accuracy: 0.2585\n  date: 2024-02-03_05-20-07\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 5\n  loss: 1.8845026599884034\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 200.95251536369324\n  time_this_iter_s: 36.46113348007202\n  time_total_s: 200.95251536369324\n  timestamp: 1706937607\n  training_iteration: 5\n  trial_id: 668d1_00006\n\n(func pid=2760) [5,  4000] loss: 1.015 [repeated 2x across cluster]\nResult for train_cifar_668d1_00005:\n  accuracy: 0.494\n  date: 2024-02-03_05-20-12\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 3\n  loss: 1.3753272988915444\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 205.61224055290222\n  time_this_iter_s: 63.707948446273804\n  time_total_s: 205.61224055290222\n  timestamp: 1706937612\n  training_iteration: 3\n  trial_id: 668d1_00005\n\n== Status ==\nCurrent time: 2024-02-03 05:20:12 (running for 00:03:36.62)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [5,  4000] loss: 0.562 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:20:17 (running for 00:03:41.64)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2346\n  date: 2024-02-03_05-20-21\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 5\n  loss: 2.0240508323669433\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 214.7431402206421\n  time_this_iter_s: 39.21855139732361\n  time_total_s: 214.7431402206421\n  timestamp: 1706937621\n  training_iteration: 5\n  trial_id: 668d1_00003\n\n(func pid=2764) [4,  2000] loss: 1.377 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:20:26 (running for 00:03:50.84)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5797\n  date: 2024-02-03_05-20-27\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 5\n  loss: 1.2155838934659957\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 213.9574224948883\n  time_this_iter_s: 38.27883744239807\n  time_total_s: 213.9574224948883\n  timestamp: 1706937627\n  training_iteration: 5\n  trial_id: 668d1_00007\n\n(func pid=2765) [6,  4000] loss: 0.918 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:20:32 (running for 00:03:57.37)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:20:37 (running for 00:04:02.38)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2758) [2, 10000] loss: 0.464 [repeated 3x across cluster]\nResult for train_cifar_668d1_00006:\n  accuracy: 0.2804\n  date: 2024-02-03_05-20-42\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 6\n  loss: 1.8407883693695068\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 235.6918430328369\n  time_this_iter_s: 34.73932766914368\n  time_total_s: 235.6918430328369\n  timestamp: 1706937642\n  training_iteration: 6\n  trial_id: 668d1_00006\n\n== Status ==\nCurrent time: 2024-02-03 05:20:47 (running for 00:04:11.64)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2760) [6,  4000] loss: 1.016 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:20:52 (running for 00:04:16.65)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [4,  8000] loss: 0.331\n(func pid=2765) [7,  2000] loss: 1.810\n== Status ==\nCurrent time: 2024-02-03 05:20:57 (running for 00:04:21.66)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2534\n  date: 2024-02-03_05-20-59\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 6\n  loss: 1.9832046443939209\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 252.8883557319641\n  time_this_iter_s: 38.14521551132202\n  time_total_s: 252.8883557319641\n  timestamp: 1706937659\n  training_iteration: 6\n  trial_id: 668d1_00003\n\n(func pid=2764) [4, 10000] loss: 0.264 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:21:04 (running for 00:04:29.00)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5712\n  date: 2024-02-03_05-21-05\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 6\n  loss: 1.256609897506237\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 251.51965427398682\n  time_this_iter_s: 37.56223177909851\n  time_total_s: 251.51965427398682\n  timestamp: 1706937665\n  training_iteration: 6\n  trial_id: 668d1_00007\n\n== Status ==\nCurrent time: 2024-02-03 05:21:10 (running for 00:04:34.92)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00005:\n  accuracy: 0.5231\n  date: 2024-02-03_05-21-11\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 4\n  loss: 1.296015057128668\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 264.93886256217957\n  time_this_iter_s: 59.326622009277344\n  time_total_s: 264.93886256217957\n  timestamp: 1706937671\n  training_iteration: 4\n  trial_id: 668d1_00005\n\n(func pid=2760) [7,  2000] loss: 2.025 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:21:16 (running for 00:04:40.96)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00006:\n  accuracy: 0.2967\n  date: 2024-02-03_05-21-16\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 7\n  loss: 1.792528931903839\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 270.1484785079956\n  time_this_iter_s: 34.45663547515869\n  time_total_s: 270.1484785079956\n  timestamp: 1706937676\n  training_iteration: 7\n  trial_id: 668d1_00006\n\n(func pid=3549) [7,  2000] loss: 0.982\n== Status ==\nCurrent time: 2024-02-03 05:21:21 (running for 00:04:46.10)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2758) [2, 16000] loss: 0.265\n== Status ==\nCurrent time: 2024-02-03 05:21:26 (running for 00:04:51.11)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2765) [8,  2000] loss: 1.780 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:21:31 (running for 00:04:56.12)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2758) [2, 18000] loss: 0.242 [repeated 3x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:21:36 (running for 00:05:01.13)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2295\n  date: 2024-02-03_05-21-37\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 7\n  loss: 2.0266551568984985\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 291.2936282157898\n  time_this_iter_s: 38.405272483825684\n  time_total_s: 291.2936282157898\n  timestamp: 1706937697\n  training_iteration: 7\n  trial_id: 668d1_00003\n\n(func pid=2765) [8,  4000] loss: 0.883\n(func pid=2764) [5,  6000] loss: 0.421\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5504\n  date: 2024-02-03_05-21-42\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 7\n  loss: 1.3819816076278686\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 288.94591212272644\n  time_this_iter_s: 37.426257848739624\n  time_total_s: 288.94591212272644\n  timestamp: 1706937702\n  training_iteration: 7\n  trial_id: 668d1_00007\n\n== Status ==\nCurrent time: 2024-02-03 05:21:42 (running for 00:05:07.34)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:21:47 (running for 00:05:12.36)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2758) [2, 20000] loss: 0.216\nResult for train_cifar_668d1_00006:\n  accuracy: 0.2982\n  date: 2024-02-03_05-21-51\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 8\n  loss: 1.7897322436332703\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 304.81253695487976\n  time_this_iter_s: 34.664058446884155\n  time_total_s: 304.81253695487976\n  timestamp: 1706937711\n  training_iteration: 8\n  trial_id: 668d1_00006\n\n(func pid=2760) [8,  2000] loss: 2.023\n== Status ==\nCurrent time: 2024-02-03 05:21:56 (running for 00:05:20.76)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:22:01 (running for 00:05:25.77)\nUsing AsyncHyperBand: num_stopped=5\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564\nLogical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [5, 10000] loss: 0.254 [repeated 3x across cluster]\nResult for train_cifar_668d1_00002:\n  accuracy: 0.1941\n  date: 2024-02-03_05-22-03\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 2\n  loss: 2.08221128718853\n  node_ip: 172.17.0.2\n  pid: 2758\n  should_checkpoint: true\n  time_since_restore: 317.1054368019104\n  time_this_iter_s: 152.5999071598053\n  time_total_s: 317.1054368019104\n  timestamp: 1706937723\n  training_iteration: 2\n  trial_id: 668d1_00002\n\nTrial train_cifar_668d1_00002 completed.\n== Status ==\nCurrent time: 2024-02-03 05:22:08 (running for 00:05:33.23)\nUsing AsyncHyperBand: num_stopped=6\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [8,  4000] loss: 0.510 [repeated 3x across cluster]\nResult for train_cifar_668d1_00005:\n  accuracy: 0.529\n  date: 2024-02-03_05-22-10\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 5\n  loss: 1.2870607646644114\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 324.0226089954376\n  time_this_iter_s: 59.08374643325806\n  time_total_s: 324.0226089954376\n  timestamp: 1706937730\n  training_iteration: 5\n  trial_id: 668d1_00005\n\n(func pid=2765) [9,  4000] loss: 0.870\n== Status ==\nCurrent time: 2024-02-03 05:22:15 (running for 00:05:40.04)\nUsing AsyncHyperBand: num_stopped=6\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00003:\n  accuracy: 0.2151\n  date: 2024-02-03_05-22-16\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 8\n  loss: 2.0069383046150207\n  node_ip: 172.17.0.2\n  pid: 2760\n  should_checkpoint: true\n  time_since_restore: 329.57353925704956\n  time_this_iter_s: 38.279911041259766\n  time_total_s: 329.57353925704956\n  timestamp: 1706937736\n  training_iteration: 8\n  trial_id: 668d1_00003\n\nTrial train_cifar_668d1_00003 completed.\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5562\n  date: 2024-02-03_05-22-19\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 8\n  loss: 1.386238949227333\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 325.1725585460663\n  time_this_iter_s: 36.226646423339844\n  time_total_s: 325.1725585460663\n  timestamp: 1706937739\n  training_iteration: 8\n  trial_id: 668d1_00007\n\n(func pid=2764) [6,  2000] loss: 1.247\n== Status ==\nCurrent time: 2024-02-03 05:22:24 (running for 00:05:48.58)\nUsing AsyncHyperBand: num_stopped=7\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00006:\n  accuracy: 0.318\n  date: 2024-02-03_05-22-24\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 9\n  loss: 1.740590954399109\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 338.0199918746948\n  time_this_iter_s: 33.20745491981506\n  time_total_s: 338.0199918746948\n  timestamp: 1706937744\n  training_iteration: 9\n  trial_id: 668d1_00006\n\n(func pid=2764) [6,  4000] loss: 0.620\n== Status ==\nCurrent time: 2024-02-03 05:22:29 (running for 00:05:53.97)\nUsing AsyncHyperBand: num_stopped=7\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=3549) [9,  2000] loss: 0.930\n== Status ==\nCurrent time: 2024-02-03 05:22:34 (running for 00:05:58.98)\nUsing AsyncHyperBand: num_stopped=7\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [6,  6000] loss: 0.416 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:22:39 (running for 00:06:03.99)\nUsing AsyncHyperBand: num_stopped=7\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:22:44 (running for 00:06:09.00)\nUsing AsyncHyperBand: num_stopped=7\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2765) [10,  4000] loss: 0.860 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:22:49 (running for 00:06:14.01)\nUsing AsyncHyperBand: num_stopped=7\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5697\n  date: 2024-02-03_05-22-50\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 9\n  loss: 1.3044582264721394\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 356.96855640411377\n  time_this_iter_s: 31.795997858047485\n  time_total_s: 356.96855640411377\n  timestamp: 1706937770\n  training_iteration: 9\n  trial_id: 668d1_00007\n\nResult for train_cifar_668d1_00006:\n  accuracy: 0.3233\n  date: 2024-02-03_05-22-54\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 10\n  loss: 1.7479507164001464\n  node_ip: 172.17.0.2\n  pid: 2765\n  should_checkpoint: true\n  time_since_restore: 367.6761510372162\n  time_this_iter_s: 29.656159162521362\n  time_total_s: 367.6761510372162\n  timestamp: 1706937774\n  training_iteration: 10\n  trial_id: 668d1_00006\n\nTrial train_cifar_668d1_00006 completed.\n(func pid=2764) [6, 10000] loss: 0.244 [repeated 2x across cluster]\n== Status ==\nCurrent time: 2024-02-03 05:22:59 (running for 00:06:23.63)\nUsing AsyncHyperBand: num_stopped=8\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00005:\n  accuracy: 0.5427\n  date: 2024-02-03_05-23-01\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 6\n  loss: 1.2477094298124314\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 375.21164202690125\n  time_this_iter_s: 51.18903303146362\n  time_total_s: 375.21164202690125\n  timestamp: 1706937781\n  training_iteration: 6\n  trial_id: 668d1_00005\n\n(func pid=3549) [10,  2000] loss: 0.915\n== Status ==\nCurrent time: 2024-02-03 05:23:06 (running for 00:06:31.24)\nUsing AsyncHyperBand: num_stopped=8\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [7,  2000] loss: 1.214\n== Status ==\nCurrent time: 2024-02-03 05:23:11 (running for 00:06:36.25)\nUsing AsyncHyperBand: num_stopped=8\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:23:16 (running for 00:06:41.26)\nUsing AsyncHyperBand: num_stopped=8\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [7,  4000] loss: 0.603 [repeated 2x across cluster]\nResult for train_cifar_668d1_00007:\n  accuracy: 0.5706\n  date: 2024-02-03_05-23-21\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 10\n  loss: 1.4145498059391974\n  node_ip: 172.17.0.2\n  pid: 3549\n  should_checkpoint: true\n  time_since_restore: 387.638968706131\n  time_this_iter_s: 30.670412302017212\n  time_total_s: 387.638968706131\n  timestamp: 1706937801\n  training_iteration: 10\n  trial_id: 668d1_00007\n\nTrial train_cifar_668d1_00007 completed.\n(func pid=2764) [7,  6000] loss: 0.396\n== Status ==\nCurrent time: 2024-02-03 05:23:26 (running for 00:06:51.05)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:23:31 (running for 00:06:56.05)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [7,  8000] loss: 0.300\n== Status ==\nCurrent time: 2024-02-03 05:23:36 (running for 00:07:01.06)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:23:41 (running for 00:07:06.07)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [7, 10000] loss: 0.236\n== Status ==\nCurrent time: 2024-02-03 05:23:46 (running for 00:07:11.08)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00005:\n  accuracy: 0.5725\n  date: 2024-02-03_05-23-48\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 7\n  loss: 1.2115788961529732\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 421.9987733364105\n  time_this_iter_s: 46.78713130950928\n  time_total_s: 421.9987733364105\n  timestamp: 1706937828\n  training_iteration: 7\n  trial_id: 668d1_00005\n\n== Status ==\nCurrent time: 2024-02-03 05:23:53 (running for 00:07:18.01)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [8,  2000] loss: 1.179\n== Status ==\nCurrent time: 2024-02-03 05:23:58 (running for 00:07:23.02)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:24:03 (running for 00:07:28.02)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [8,  4000] loss: 0.583\n== Status ==\nCurrent time: 2024-02-03 05:24:08 (running for 00:07:33.03)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [8,  6000] loss: 0.386\n== Status ==\nCurrent time: 2024-02-03 05:24:13 (running for 00:07:38.04)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:24:18 (running for 00:07:43.05)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [8,  8000] loss: 0.293\n== Status ==\nCurrent time: 2024-02-03 05:24:23 (running for 00:07:48.06)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:24:28 (running for 00:07:53.07)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [8, 10000] loss: 0.232\n== Status ==\nCurrent time: 2024-02-03 05:24:33 (running for 00:07:58.08)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00005:\n  accuracy: 0.5445\n  date: 2024-02-03_05-24-34\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 8\n  loss: 1.2921000151872635\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 468.24409079551697\n  time_this_iter_s: 46.245317459106445\n  time_total_s: 468.24409079551697\n  timestamp: 1706937874\n  training_iteration: 8\n  trial_id: 668d1_00005\n\n== Status ==\nCurrent time: 2024-02-03 05:24:39 (running for 00:08:04.26)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [9,  2000] loss: 1.129\n== Status ==\nCurrent time: 2024-02-03 05:24:44 (running for 00:08:09.26)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:24:49 (running for 00:08:14.27)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [9,  4000] loss: 0.575\n== Status ==\nCurrent time: 2024-02-03 05:24:54 (running for 00:08:19.28)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [9,  6000] loss: 0.383\n== Status ==\nCurrent time: 2024-02-03 05:24:59 (running for 00:08:24.29)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:25:04 (running for 00:08:29.30)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [9,  8000] loss: 0.287\n== Status ==\nCurrent time: 2024-02-03 05:25:09 (running for 00:08:34.31)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [9, 10000] loss: 0.231\n== Status ==\nCurrent time: 2024-02-03 05:25:14 (running for 00:08:39.32)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:25:19 (running for 00:08:44.33)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00005:\n  accuracy: 0.5753\n  date: 2024-02-03_05-25-20\n  done: false\n  hostname: 8642c088913e\n  iterations_since_restore: 9\n  loss: 1.1927328542232514\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 514.1986174583435\n  time_this_iter_s: 45.95452666282654\n  time_total_s: 514.1986174583435\n  timestamp: 1706937920\n  training_iteration: 9\n  trial_id: 668d1_00005\n\n== Status ==\nCurrent time: 2024-02-03 05:25:25 (running for 00:08:50.21)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [10,  2000] loss: 1.124\n== Status ==\nCurrent time: 2024-02-03 05:25:30 (running for 00:08:55.22)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:25:35 (running for 00:09:00.22)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [10,  4000] loss: 0.564\n== Status ==\nCurrent time: 2024-02-03 05:25:40 (running for 00:09:05.23)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [10,  6000] loss: 0.382\n== Status ==\nCurrent time: 2024-02-03 05:25:45 (running for 00:09:10.24)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:25:50 (running for 00:09:15.25)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [10,  8000] loss: 0.278\n== Status ==\nCurrent time: 2024-02-03 05:25:55 (running for 00:09:20.26)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n(func pid=2764) [10, 10000] loss: 0.223\n== Status ==\nCurrent time: 2024-02-03 05:26:00 (running for 00:09:25.27)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n== Status ==\nCurrent time: 2024-02-03 05:26:05 (running for 00:09:30.28)\nUsing AsyncHyperBand: num_stopped=9\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\nResult for train_cifar_668d1_00005:\n  accuracy: 0.5878\n  date: 2024-02-03_05-26-06\n  done: true\n  hostname: 8642c088913e\n  iterations_since_restore: 10\n  loss: 1.1539024412691594\n  node_ip: 172.17.0.2\n  pid: 2764\n  should_checkpoint: true\n  time_since_restore: 560.4044351577759\n  time_this_iter_s: 46.20581769943237\n  time_total_s: 560.4044351577759\n  timestamp: 1706937966\n  training_iteration: 10\n  trial_id: 668d1_00005\n\nTrial train_cifar_668d1_00005 completed.\n== Status ==\nCurrent time: 2024-02-03 05:26:06 (running for 00:09:31.42)\nUsing AsyncHyperBand: num_stopped=10\nBracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564\nLogical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)\nResult logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35\nNumber of trials: 10/10 (10 TERMINATED)\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |\n|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|\n| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |\n| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |\n| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |\n| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |\n| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |\n| train_cifar_668d1_00005 | TERMINATED | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |     10 |         560.404  | 1.1539  |     0.5878 |\n| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |\n| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |\n| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |\n| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |\n+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+\n\n2024-02-03 05:26:06,866 INFO tune.py:945 -- Total run time: 571.52 seconds (571.41 seconds for the tuning loop).\nBest trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}\nBest trial final validation loss: 1.1539024412691594\nBest trial final validation accuracy: 0.5878\nFiles already downloaded and verified\nFiles already downloaded and verified\nBest trial test set accuracy: 0.5864 \n```", "```py\nNumber  of  trials:  10/10  (10  TERMINATED)\n+-----+--------------+------+------+-------------+--------+---------+------------+\n|  ...  |  batch_size  |  l1  |  l2  |  lr  |  iter  |  loss  |  accuracy  |\n|-----+--------------+------+------+-------------+--------+---------+------------|\n|  ...  |  2  |  1  |  256  |  0.000668163  |  1  |  2.31479  |  0.0977  |\n|  ...  |  4  |  64  |  8  |  0.0331514  |  1  |  2.31605  |  0.0983  |\n|  ...  |  4  |  2  |  1  |  0.000150295  |  1  |  2.30755  |  0.1023  |\n|  ...  |  16  |  32  |  32  |  0.0128248  |  10  |  1.66912  |  0.4391  |\n|  ...  |  4  |  8  |  128  |  0.00464561  |  2  |  1.7316  |  0.3463  |\n|  ...  |  8  |  256  |  8  |  0.00031556  |  1  |  2.19409  |  0.1736  |\n|  ...  |  4  |  16  |  256  |  0.00574329  |  2  |  1.85679  |  0.3368  |\n|  ...  |  8  |  2  |  2  |  0.00325652  |  1  |  2.30272  |  0.0984  |\n|  ...  |  2  |  2  |  2  |  0.000342987  |  2  |  1.76044  |  0.292  |\n|  ...  |  4  |  64  |  32  |  0.003734  |  8  |  1.53101  |  0.4761  |\n+-----+--------------+------+------+-------------+--------+---------+------------+\n\nBest  trial  config:  {'l1':  64,  'l2':  32,  'lr':  0.0037339984519545164,  'batch_size':  4}\nBest  trial  final  validation  loss:  1.5310075663924216\nBest  trial  final  validation  accuracy:  0.4761\nBest  trial  test  set  accuracy:  0.4737 \n```"]