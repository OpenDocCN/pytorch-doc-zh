# 使用Wav2Vec2进行强制对齐

> 原文：[https://pytorch.org/audio/stable/tutorials/forced_alignment_tutorial.html](https://pytorch.org/audio/stable/tutorials/forced_alignment_tutorial.html)

注意

点击[这里](#sphx-glr-download-tutorials-forced-alignment-tutorial-py)下载完整示例代码

**作者**：[Moto Hira](mailto:moto%40meta.com)

本教程展示了如何使用`torchaudio`将转录对齐到语音，使用[CTC-Segmentation of Large Corpora for German End-to-end Speech Recognition](https://arxiv.org/abs/2007.09127)中描述的CTC分割算法。

注意

本教程最初是为了说明Wav2Vec2预训练模型的用例而编写的。

TorchAudio现在有一组专为强制对齐设计的API。[CTC强制对齐API教程](./ctc_forced_alignment_api_tutorial.html)说明了[`torchaudio.functional.forced_align()`](../generated/torchaudio.functional.forced_align.html#torchaudio.functional.forced_align "torchaudio.functional.forced_align")的用法，这是核心API。

如果您想要对齐您的语料库，我们建议使用[`torchaudio.pipelines.Wav2Vec2FABundle`](../generated/torchaudio.pipelines.Wav2Vec2FABundle.html#torchaudio.pipelines.Wav2Vec2FABundle "torchaudio.pipelines.Wav2Vec2FABundle")，它结合了[`forced_align()`](../generated/torchaudio.functional.forced_align.html#torchaudio.functional.forced_align "torchaudio.functional.forced_align")和其他支持函数，专门针对强制对齐进行了训练的预训练模型。请参考[多语言数据的强制对齐](forced_alignment_for_multilingual_data_tutorial.html)以了解其用法。

```py
import torch
import torchaudio

print(torch.__version__)
print([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))

[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")("cuda" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available")() else "cpu")
print([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")) 
```

```py
2.2.0
2.2.0
cuda 
```

## 概述[](#overview "跳转到此标题的永久链接")

对齐过程如下所示。

1.  从音频波形中估计逐帧标签概率

1.  生成表示时间步对齐标签概率的状态图矩阵。

1.  从状态图中找到最可能的路径。

在本示例中，我们使用`torchaudio`的`Wav2Vec2`模型进行声学特征提取。

## 准备工作[](#preparation "跳转到此标题的永久链接")

首先导入必要的包，并获取我们要处理的数据。

```py
from dataclasses import [dataclass](https://docs.python.org/3/library/dataclasses.html#dataclasses.dataclass "dataclasses.dataclass")

import IPython
import matplotlib.pyplot as plt

[torch.random.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed "torch.manual_seed")(0)

[SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = torchaudio.utils.download_asset("tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav") 
```

## 生成逐帧标签概率[](#generate-frame-wise-label-probability "跳转到此标题的永久链接")

第一步是生成每个音频帧的标签类概率。我们可以使用为ASR训练的Wav2Vec2模型。这里我们使用[`torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H()`](../generated/torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H.html#torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H "torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H")。

`torchaudio`提供了易于访问的预训练模型和相关标签。

注意

在接下来的部分中，我们将在对数域中计算概率，以避免数值不稳定性。为此，我们使用`torch.log_softmax()`对`emission`进行归一化。

```py
bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H
model = bundle.get_model().to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))
[labels](https://docs.python.org/3/library/stdtypes.html#tuple "builtins.tuple") = bundle.get_labels()
with [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode "torch.inference_mode")():
    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), _ = torchaudio.load([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
    [emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), _ = model([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")))
    [emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = torch.log_softmax([emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), dim=-1)

[emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [emissions](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[0].cpu().detach()

print([labels](https://docs.python.org/3/library/stdtypes.html#tuple "builtins.tuple")) 
```

```py
('-', '|', 'E', 'T', 'A', 'O', 'N', 'I', 'H', 'S', 'R', 'D', 'L', 'U', 'M', 'W', 'C', 'F', 'G', 'Y', 'P', 'B', 'V', 'K', "'", 'X', 'J', 'Q', 'Z') 
```

### 可视化[](#visualization "跳转到此标题的永久链接")

```py
def plot():
    fig, ax = plt.subplots()
    img = ax.imshow([emission.T](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
    ax.set_title("Frame-wise class probability")
    ax.set_xlabel("Time")
    ax.set_ylabel("Labels")
    fig.colorbar(img, ax=ax, shrink=0.6, location="bottom")
    fig.tight_layout()

plot() 
```

![逐帧类概率](../Images/efb61f2d411fc5066755dd6b78a9a867.png)

## 生成对齐概率（状态图）[](#generate-alignment-probability-trellis "跳转到此标题的永久链接")

从发射矩阵中，接下来我们生成表示每个时间帧发生转录标签概率的状态图。

状态图是一个二维矩阵，具有时间轴和标签轴。标签轴表示我们正在对齐的转录。在下文中，我们使用\(t\)表示时间轴中的索引，使用\(j\)表示标签轴中的索引。\(c_j\)表示标签索引\(j\)处的标签。

为了生成时间步长\(t+1\)的概率，我们查看从时间步长\(t\)到时间步长\(t+1\)的格子和发射。有两种路径可以到达时间步长\(t+1\)，标签为\(c_{j+1}\)。第一种情况是标签在\(t\)时为\(c_{j+1}\)，从\(t\)到\(t+1\)没有标签变化。另一种情况是标签在\(t\)时为\(c_j\)，在\(t+1\)转换为下一个标签\(c_{j+1}\)。

以下图表说明了这种转变。

！[https://download.pytorch.org/torchaudio/tutorial-assets/ctc-forward.png](../Images/cb0c89f6f8c29828d4d4d04ded7193b6.png)

由于我们正在寻找最可能的转换，因此我们为\(k_{(t+1, j+1)}\)的更可能路径取更可能的路径，即

\(k_{(t+1, j+1)} = max( k_{(t, j)} p(t+1, c_{j+1}), k_{(t, j+1)} p(t+1, repeat) )\)

其中\(k\)代表格子矩阵，\(p(t, c_j)\)代表时间步长\(t\)处标签\(c_j\)的概率。\(repeat\)代表CTC公式中的空白标记。（有关CTC算法的详细信息，请参阅*使用CTC进行序列建模*[[distill.pub](https://distill.pub/2017/ctc/)）

```py
# We enclose the transcript with space tokens, which represent SOS and EOS.
[transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = "|I|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT|"
[dictionary](https://docs.python.org/3/library/stdtypes.html#dict "builtins.dict") = {c: i for i, c in enumerate([labels](https://docs.python.org/3/library/stdtypes.html#tuple "builtins.tuple"))}

[tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [[dictionary](https://docs.python.org/3/library/stdtypes.html#dict "builtins.dict")[c] for c in [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")]
print(list(zip([transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"))))

def get_trellis([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), blank_id=0):
    num_frame = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0)
    num_tokens = len([tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"))

    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [torch.zeros](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros "torch.zeros")((num_frame, num_tokens))
    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[1:, 0] = [torch.cumsum](https://pytorch.org/docs/stable/generated/torch.cumsum.html#torch.cumsum "torch.cumsum")([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[1:, blank_id], 0)
    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[0, 1:] = -float("inf")
    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[-num_tokens + 1 :, 0] = float("inf")

    for t in range(num_frame - 1):
        [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t + 1, 1:] = [torch.maximum](https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum "torch.maximum")(
            # Score for staying at the same token
            [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t, 1:] + [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t, blank_id],
            # Score for changing to the next token
            [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t, :-1] + [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t, [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[1:]],
        )
    return [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")

[trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = get_trellis([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")) 
```

```py
[('|', 1), ('I', 7), ('|', 1), ('H', 8), ('A', 4), ('D', 11), ('|', 1), ('T', 3), ('H', 8), ('A', 4), ('T', 3), ('|', 1), ('C', 16), ('U', 13), ('R', 10), ('I', 7), ('O', 5), ('S', 9), ('I', 7), ('T', 3), ('Y', 19), ('|', 1), ('B', 21), ('E', 2), ('S', 9), ('I', 7), ('D', 11), ('E', 2), ('|', 1), ('M', 14), ('E', 2), ('|', 1), ('A', 4), ('T', 3), ('|', 1), ('T', 3), ('H', 8), ('I', 7), ('S', 9), ('|', 1), ('M', 14), ('O', 5), ('M', 14), ('E', 2), ('N', 6), ('T', 3), ('|', 1)] 
```

### 可视化[]（＃id1“此标题的永久链接”）

```py
def plot():
    fig, ax = plt.subplots()
    img = ax.imshow([trellis.T](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), origin="lower")
    ax.annotate("- Inf", ([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1) / 5, [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1) / 1.5))
    ax.annotate("+ Inf", ([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0) - [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1) / 5, [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1) / 3))
    fig.colorbar(img, ax=ax, shrink=0.6, location="bottom")
    fig.tight_layout()

plot() 
```

！[强制对齐教程](../Images/9cba4b626edb17a6e4b5838fd55a4e90.png)

在上面的可视化中，我们可以看到有一个高概率的痕迹对角穿过矩阵。

## 找到最可能的路径（回溯）[]（＃find-the-most-likely-path-backtracking“此标题的永久链接”）

生成了格子后，我们将沿着具有高概率元素的路径遍历它。

我们将从具有最高概率时间步长的最后标签索引开始，然后，我们向后遍历时间，根据过渡后概率\(k_{t, j} p(t+1, c_{j+1})\)或\(k_{t, j+1} p(t+1, repeat)\)选择停留（\(c_j \rightarrow c_j\)）或过渡（\(c_j \rightarrow c_{j+1}\)）。

一旦标签到达开头，转换就完成了。

格子矩阵用于寻找路径，但对于每个段的最终概率，我们从发射矩阵中获取逐帧概率。

```py
@dataclass
class Point:
    token_index: int
    time_index: int
    score: float

def backtrack([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), blank_id=0):
    t, j = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0) - 1, [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1) - 1

    [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [Point(j, t, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t, blank_id].exp().item())]
    while j > 0:
        # Should not happen but just in case
        assert t > 0

        # 1\. Figure out if the current position was stay or change
        # Frame-wise score of stay vs change
        p_stay = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t - 1, blank_id]
        p_change = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t - 1, [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[j]]

        # Context-aware score for stay vs change
        stayed = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t - 1, j] + p_stay
        changed = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t - 1, j - 1] + p_change

        # Update position
        t -= 1
        if changed > stayed:
            j -= 1

        # Store the path with frame-wise probability.
        prob = (p_change if changed > stayed else p_stay).exp().item()
        [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list").append(Point(j, t, prob))

    # Now j == 0, which means, it reached the SoS.
    # Fill up the rest for the sake of visualization
    while t > 0:
        prob = [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[t - 1, blank_id].exp().item()
        [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list").append(Point(j, t - 1, prob))
        t -= 1

    return [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[::-1]

[path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = backtrack([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [tokens](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"))
for p in [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    print(p) 
```

```py
Point(token_index=0, time_index=0, score=0.9999996423721313)
Point(token_index=0, time_index=1, score=0.9999996423721313)
Point(token_index=0, time_index=2, score=0.9999996423721313)
Point(token_index=0, time_index=3, score=0.9999996423721313)
Point(token_index=0, time_index=4, score=0.9999996423721313)
Point(token_index=0, time_index=5, score=0.9999996423721313)
Point(token_index=0, time_index=6, score=0.9999996423721313)
Point(token_index=0, time_index=7, score=0.9999996423721313)
Point(token_index=0, time_index=8, score=0.9999998807907104)
Point(token_index=0, time_index=9, score=0.9999996423721313)
Point(token_index=0, time_index=10, score=0.9999996423721313)
Point(token_index=0, time_index=11, score=0.9999998807907104)
Point(token_index=0, time_index=12, score=0.9999996423721313)
Point(token_index=0, time_index=13, score=0.9999996423721313)
Point(token_index=0, time_index=14, score=0.9999996423721313)
Point(token_index=0, time_index=15, score=0.9999996423721313)
Point(token_index=0, time_index=16, score=0.9999996423721313)
Point(token_index=0, time_index=17, score=0.9999996423721313)
Point(token_index=0, time_index=18, score=0.9999998807907104)
Point(token_index=0, time_index=19, score=0.9999996423721313)
Point(token_index=0, time_index=20, score=0.9999996423721313)
Point(token_index=0, time_index=21, score=0.9999996423721313)
Point(token_index=0, time_index=22, score=0.9999996423721313)
Point(token_index=0, time_index=23, score=0.9999997615814209)
Point(token_index=0, time_index=24, score=0.9999998807907104)
Point(token_index=0, time_index=25, score=0.9999998807907104)
Point(token_index=0, time_index=26, score=0.9999998807907104)
Point(token_index=0, time_index=27, score=0.9999998807907104)
Point(token_index=0, time_index=28, score=0.9999985694885254)
Point(token_index=0, time_index=29, score=0.9999943971633911)
Point(token_index=0, time_index=30, score=0.9999842643737793)
Point(token_index=1, time_index=31, score=0.9846165180206299)
Point(token_index=1, time_index=32, score=0.9999706745147705)
Point(token_index=1, time_index=33, score=0.15376661717891693)
Point(token_index=1, time_index=34, score=0.9999172687530518)
Point(token_index=2, time_index=35, score=0.6086705327033997)
Point(token_index=2, time_index=36, score=0.9997723698616028)
Point(token_index=3, time_index=37, score=0.9997134804725647)
Point(token_index=3, time_index=38, score=0.9999358654022217)
Point(token_index=4, time_index=39, score=0.9861685633659363)
Point(token_index=4, time_index=40, score=0.9242331385612488)
Point(token_index=5, time_index=41, score=0.926007866859436)
Point(token_index=5, time_index=42, score=0.01556419488042593)
Point(token_index=5, time_index=43, score=0.9998375177383423)
Point(token_index=6, time_index=44, score=0.9988489151000977)
Point(token_index=7, time_index=45, score=0.1021796241402626)
Point(token_index=7, time_index=46, score=0.9999427795410156)
Point(token_index=8, time_index=47, score=0.9999943971633911)
Point(token_index=8, time_index=48, score=0.9979604482650757)
Point(token_index=9, time_index=49, score=0.0360121876001358)
Point(token_index=9, time_index=50, score=0.06167365238070488)
Point(token_index=9, time_index=51, score=4.336783240432851e-05)
Point(token_index=10, time_index=52, score=0.9999799728393555)
Point(token_index=11, time_index=53, score=0.9967040419578552)
Point(token_index=11, time_index=54, score=0.9999257326126099)
Point(token_index=11, time_index=55, score=0.9999982118606567)
Point(token_index=12, time_index=56, score=0.9990678429603577)
Point(token_index=12, time_index=57, score=0.9999996423721313)
Point(token_index=12, time_index=58, score=0.9999996423721313)
Point(token_index=12, time_index=59, score=0.8453492522239685)
Point(token_index=12, time_index=60, score=0.9999996423721313)
Point(token_index=13, time_index=61, score=0.9996009469032288)
Point(token_index=13, time_index=62, score=0.999998927116394)
Point(token_index=14, time_index=63, score=0.00353023293428123)
Point(token_index=14, time_index=64, score=1.0)
Point(token_index=14, time_index=65, score=1.0)
Point(token_index=14, time_index=66, score=0.9999915361404419)
Point(token_index=15, time_index=67, score=0.9971516132354736)
Point(token_index=15, time_index=68, score=0.9999990463256836)
Point(token_index=15, time_index=69, score=0.9999992847442627)
Point(token_index=15, time_index=70, score=0.9999997615814209)
Point(token_index=15, time_index=71, score=0.9999998807907104)
Point(token_index=15, time_index=72, score=0.9999880790710449)
Point(token_index=15, time_index=73, score=0.011415631510317326)
Point(token_index=15, time_index=74, score=0.9999977350234985)
Point(token_index=16, time_index=75, score=0.9996123909950256)
Point(token_index=16, time_index=76, score=0.999998927116394)
Point(token_index=16, time_index=77, score=0.9729099869728088)
Point(token_index=16, time_index=78, score=0.999998927116394)
Point(token_index=17, time_index=79, score=0.9949352145195007)
Point(token_index=17, time_index=80, score=0.999998927116394)
Point(token_index=17, time_index=81, score=0.9999123811721802)
Point(token_index=17, time_index=82, score=0.9999774694442749)
Point(token_index=18, time_index=83, score=0.6568986177444458)
Point(token_index=18, time_index=84, score=0.9984309077262878)
Point(token_index=18, time_index=85, score=0.9999876022338867)
Point(token_index=19, time_index=86, score=0.9993754029273987)
Point(token_index=19, time_index=87, score=0.9999988079071045)
Point(token_index=19, time_index=88, score=0.10457336902618408)
Point(token_index=19, time_index=89, score=0.9999969005584717)
Point(token_index=20, time_index=90, score=0.39713507890701294)
Point(token_index=20, time_index=91, score=0.9999932050704956)
Point(token_index=21, time_index=92, score=1.69728946275427e-06)
Point(token_index=21, time_index=93, score=0.9861241579055786)
Point(token_index=21, time_index=94, score=0.9999960660934448)
Point(token_index=22, time_index=95, score=0.9992733597755432)
Point(token_index=22, time_index=96, score=0.9993415474891663)
Point(token_index=22, time_index=97, score=0.9999983310699463)
Point(token_index=23, time_index=98, score=0.9999971389770508)
Point(token_index=23, time_index=99, score=0.9999998807907104)
Point(token_index=23, time_index=100, score=0.9999995231628418)
Point(token_index=23, time_index=101, score=0.9999732971191406)
Point(token_index=24, time_index=102, score=0.9983206391334534)
Point(token_index=24, time_index=103, score=0.9999991655349731)
Point(token_index=24, time_index=104, score=0.9999996423721313)
Point(token_index=24, time_index=105, score=0.9999998807907104)
Point(token_index=24, time_index=106, score=1.0)
Point(token_index=24, time_index=107, score=0.9998623132705688)
Point(token_index=24, time_index=108, score=0.9999980926513672)
Point(token_index=25, time_index=109, score=0.9988552331924438)
Point(token_index=25, time_index=110, score=0.9999798536300659)
Point(token_index=26, time_index=111, score=0.8575102090835571)
Point(token_index=26, time_index=112, score=0.9999847412109375)
Point(token_index=27, time_index=113, score=0.9870213866233826)
Point(token_index=27, time_index=114, score=1.8971080862684175e-05)
Point(token_index=27, time_index=115, score=0.9999794960021973)
Point(token_index=28, time_index=116, score=0.9998254179954529)
Point(token_index=28, time_index=117, score=0.9999990463256836)
Point(token_index=29, time_index=118, score=0.9999732971191406)
Point(token_index=29, time_index=119, score=0.0009179709595628083)
Point(token_index=29, time_index=120, score=0.9993636012077332)
Point(token_index=30, time_index=121, score=0.9975398778915405)
Point(token_index=30, time_index=122, score=0.0003043622418772429)
Point(token_index=30, time_index=123, score=0.9999344348907471)
Point(token_index=31, time_index=124, score=6.090586339269066e-06)
Point(token_index=31, time_index=125, score=0.9833256006240845)
Point(token_index=32, time_index=126, score=0.9974588751792908)
Point(token_index=33, time_index=127, score=0.0008251128601841629)
Point(token_index=33, time_index=128, score=0.9965149164199829)
Point(token_index=34, time_index=129, score=0.017433946952223778)
Point(token_index=34, time_index=130, score=0.9989169836044312)
Point(token_index=35, time_index=131, score=0.9999697208404541)
Point(token_index=36, time_index=132, score=0.9999842643737793)
Point(token_index=36, time_index=133, score=0.9997639060020447)
Point(token_index=37, time_index=134, score=0.5118544101715088)
Point(token_index=37, time_index=135, score=0.9998302459716797)
Point(token_index=38, time_index=136, score=0.0852130874991417)
Point(token_index=38, time_index=137, score=0.004070050548762083)
Point(token_index=38, time_index=138, score=0.9999815225601196)
Point(token_index=39, time_index=139, score=0.012034581042826176)
Point(token_index=39, time_index=140, score=0.9999980926513672)
Point(token_index=39, time_index=141, score=0.0005822110688313842)
Point(token_index=39, time_index=142, score=0.9999072551727295)
Point(token_index=40, time_index=143, score=0.9999960660934448)
Point(token_index=40, time_index=144, score=0.9999980926513672)
Point(token_index=40, time_index=145, score=0.9999916553497314)
Point(token_index=41, time_index=146, score=0.9971168041229248)
Point(token_index=41, time_index=147, score=0.9981781244277954)
Point(token_index=41, time_index=148, score=0.9999310970306396)
Point(token_index=42, time_index=149, score=0.9879370331764221)
Point(token_index=42, time_index=150, score=0.9997633099555969)
Point(token_index=42, time_index=151, score=0.9999535083770752)
Point(token_index=43, time_index=152, score=0.9999715089797974)
Point(token_index=44, time_index=153, score=0.31822556257247925)
Point(token_index=44, time_index=154, score=0.999782145023346)
Point(token_index=45, time_index=155, score=0.01603216677904129)
Point(token_index=45, time_index=156, score=0.999901294708252)
Point(token_index=46, time_index=157, score=0.46628203988075256)
Point(token_index=46, time_index=158, score=0.9999994039535522)
Point(token_index=46, time_index=159, score=0.9999996423721313)
Point(token_index=46, time_index=160, score=0.9999995231628418)
Point(token_index=46, time_index=161, score=0.9999996423721313)
Point(token_index=46, time_index=162, score=0.9999996423721313)
Point(token_index=46, time_index=163, score=0.9999996423721313)
Point(token_index=46, time_index=164, score=0.9999995231628418)
Point(token_index=46, time_index=165, score=0.9999995231628418)
Point(token_index=46, time_index=166, score=0.9999996423721313)
Point(token_index=46, time_index=167, score=0.9999996423721313)
Point(token_index=46, time_index=168, score=0.9999995231628418) 
```

### 可视化[]（＃id2“此标题的永久链接”）

```py
def plot_trellis_with_path([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
    # To plot trellis with path, we take advantage of 'nan' value
    trellis_with_path = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").clone()
    for _, p in enumerate([path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        trellis_with_path[[p.time_index](https://docs.python.org/3/library/functions.html#int "builtins.int"), [p.token_index](https://docs.python.org/3/library/functions.html#int "builtins.int")] = float("nan")
    plt.imshow(trellis_with_path.T, origin="lower")
    plt.title("The path found by backtracking")
    plt.tight_layout()

plot_trellis_with_path([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")) 
```

！[通过回溯找到的路径](../Images/bfe239f26439c642dad7b47fc213e358.png)

看起来不错。

## 分割路径[]（＃segment-the-path“此标题的永久链接”）

现在这条路径包含相同标签的重复，所以让我们合并它们使其接近原始文本。

在合并多个路径点时，我们简单地取合并段的平均概率。

```py
# Merge the labels
@dataclass
class Segment:
    label: str
    start: int
    end: int
    score: float

    def __repr__(self):
        return f"{self.label}\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})"

    @property
    def length(self):
        return self.end - self.start

def merge_repeats([path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
    i1, i2 = 0, 0
    [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = []
    while i1 < len([path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        while i2 < len([path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")) and [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i1].token_index == [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i2].token_index:
            i2 += 1
        score = sum([path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[k].score for k in range(i1, i2)) / (i2 - i1)
        [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list").append(
            Segment(
                [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")[[path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i1].token_index],
                [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i1].time_index,
                [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i2 - 1].time_index + 1,
                score,
            )
        )
        i1 = i2
    return [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")

[segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = merge_repeats([path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"))
for seg in [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    print(seg) 
```

```py
|       (1.00): [    0,    31)
I       (0.78): [   31,    35)
|       (0.80): [   35,    37)
H       (1.00): [   37,    39)
A       (0.96): [   39,    41)
D       (0.65): [   41,    44)
|       (1.00): [   44,    45)
T       (0.55): [   45,    47)
H       (1.00): [   47,    49)
A       (0.03): [   49,    52)
T       (1.00): [   52,    53)
|       (1.00): [   53,    56)
C       (0.97): [   56,    61)
U       (1.00): [   61,    63)
R       (0.75): [   63,    67)
I       (0.88): [   67,    75)
O       (0.99): [   75,    79)
S       (1.00): [   79,    83)
I       (0.89): [   83,    86)
T       (0.78): [   86,    90)
Y       (0.70): [   90,    92)
|       (0.66): [   92,    95)
B       (1.00): [   95,    98)
E       (1.00): [   98,   102)
S       (1.00): [  102,   109)
I       (1.00): [  109,   111)
D       (0.93): [  111,   113)
E       (0.66): [  113,   116)
|       (1.00): [  116,   118)
M       (0.67): [  118,   121)
E       (0.67): [  121,   124)
|       (0.49): [  124,   126)
A       (1.00): [  126,   127)
T       (0.50): [  127,   129)
|       (0.51): [  129,   131)
T       (1.00): [  131,   132)
H       (1.00): [  132,   134)
I       (0.76): [  134,   136)
S       (0.36): [  136,   139)
|       (0.50): [  139,   143)
M       (1.00): [  143,   146)
O       (1.00): [  146,   149)
M       (1.00): [  149,   152)
E       (1.00): [  152,   153)
N       (0.66): [  153,   155)
T       (0.51): [  155,   157)
|       (0.96): [  157,   169) 
```

### 可视化[]（＃id3“此标题的永久链接”）

```py
def plot_trellis_with_segments([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")):
    # To plot trellis with path, we take advantage of 'nan' value
    trellis_with_path = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").clone()
    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") != "|":
            trellis_with_path[[seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int") : [seg.end](https://docs.python.org/3/library/functions.html#int "builtins.int"), i] = float("nan")

    fig, [ax1, ax2] = plt.subplots(2, 1, sharex=True)
    ax1.set_title("Path, label and probability for each label")
    ax1.imshow(trellis_with_path.T, origin="lower", aspect="auto")

    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") != "|":
            ax1.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), ([seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int"), i - 0.7), size="small")
            ax1.annotate(f"{[seg.score](https://docs.python.org/3/library/functions.html#float "builtins.float"):.2f}", ([seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int"), i + 3), size="small")

    ax2.set_title("Label probability with and without repetation")
    xs, hs, ws = [], [], []
    for seg in [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") != "|":
            xs.append(([seg.end](https://docs.python.org/3/library/functions.html#int "builtins.int") + [seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int")) / 2 + 0.4)
            hs.append([seg.score](https://docs.python.org/3/library/functions.html#float "builtins.float"))
            ws.append([seg.end](https://docs.python.org/3/library/functions.html#int "builtins.int") - [seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int"))
            ax2.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), ([seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int") + 0.8, -0.07))
    ax2.bar(xs, hs, width=ws, color="gray", alpha=0.5, edgecolor="black")

    xs, hs = [], []
    for p in [path](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
        label = [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")[[p.token_index](https://docs.python.org/3/library/functions.html#int "builtins.int")]
        if label != "|":
            xs.append([p.time_index](https://docs.python.org/3/library/functions.html#int "builtins.int") + 1)
            hs.append([p.score](https://docs.python.org/3/library/functions.html#float "builtins.float"))

    ax2.bar(xs, hs, width=0.5, alpha=0.5)
    ax2.axhline(0, color="black")
    ax2.grid(True, axis="y")
    ax2.set_ylim(-0.1, 1.1)
    fig.tight_layout()

plot_trellis_with_segments([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), [transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")) 
```

！[路径，标签和每个标签的概率，带和不带重复的标签概率](../Images/f07166f8b26588977594bdaa39644315.png)

看起来不错。

## 将段合并成单词[]（＃merge-the-segments-into-words“此标题的永久链接”）

现在让我们合并这些单词。Wav2Vec2模型使用`'|'`作为单词边界，因此我们在每次出现`'|'`之前合并段。

最后，我们将原始音频分割成分段音频，并听取它们以查看分割是否正确。

```py
# Merge words
def merge_words([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), separator="|"):
    words = []
    i1, i2 = 0, 0
    while i1 < len([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        if i2 >= len([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")) or [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i2].label == separator:
            if i1 != i2:
                segs = [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i1:i2]
                word = "".join([[seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") for seg in segs])
                score = sum([seg.score](https://docs.python.org/3/library/functions.html#float "builtins.float") * seg.length for seg in segs) / sum(seg.length for seg in segs)
                words.append(Segment(word, [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i1].start, [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i2 - 1].end, score))
            i1 = i2 + 1
            i2 = i1
        else:
            i2 += 1
    return words

[word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = merge_words([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"))
for word in [word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    print(word) 
```

```py
I       (0.78): [   31,    35)
HAD     (0.84): [   37,    44)
THAT    (0.52): [   45,    53)
CURIOSITY       (0.89): [   56,    92)
BESIDE  (0.94): [   95,   116)
ME      (0.67): [  118,   124)
AT      (0.66): [  126,   129)
THIS    (0.70): [  131,   139)
MOMENT  (0.88): [  143,   157) 
```

### 可视化[]（＃id4“此标题的永久链接”）

```py
def plot_alignments([trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), [word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"), [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), sample_rate=bundle.sample_rate):
    trellis_with_path = [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").clone()
    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") != "|":
            trellis_with_path[[seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int") : [seg.end](https://docs.python.org/3/library/functions.html#int "builtins.int"), i] = float("nan")

    fig, [ax1, ax2] = plt.subplots(2, 1)

    ax1.imshow(trellis_with_path.T, origin="lower", aspect="auto")
    ax1.set_facecolor("lightgray")
    ax1.set_xticks([])
    ax1.set_yticks([])

    for word in [word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
        ax1.axvspan([word.start](https://docs.python.org/3/library/functions.html#int "builtins.int") - 0.5, [word.end](https://docs.python.org/3/library/functions.html#int "builtins.int") - 0.5, edgecolor="white", facecolor="none")

    for i, seg in enumerate([segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")):
        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") != "|":
            ax1.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), ([seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int"), i - 0.7), size="small")
            ax1.annotate(f"{[seg.score](https://docs.python.org/3/library/functions.html#float "builtins.float"):.2f}", ([seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int"), i + 3), size="small")

    # The original waveform
    ratio = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0) / sample_rate / [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0)
    ax2.specgram([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), Fs=sample_rate)
    for word in [word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
        x0 = ratio * [word.start](https://docs.python.org/3/library/functions.html#int "builtins.int")
        x1 = ratio * [word.end](https://docs.python.org/3/library/functions.html#int "builtins.int")
        ax2.axvspan(x0, x1, facecolor="none", edgecolor="white", hatch="/")
        ax2.annotate(f"{[word.score](https://docs.python.org/3/library/functions.html#float "builtins.float"):.2f}", (x0, sample_rate * 0.51), annotation_clip=False)

    for seg in [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
        if [seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") != "|":
            ax2.annotate([seg.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"), ([seg.start](https://docs.python.org/3/library/functions.html#int "builtins.int") * ratio, sample_rate * 0.55), annotation_clip=False)
    ax2.set_xlabel("time [second]")
    ax2.set_yticks([])
    fig.tight_layout()

plot_alignments(
    [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"),
    [segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"),
    [word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"),
    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[0],
) 
```

！[强制对齐教程](../Images/5f304131dabeba702068f67a1e4db351.png)

## 音频样本[]（＃audio-samples“此标题的永久链接”）

```py
def display_segment(i):
    ratio = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(1) / [trellis](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0)
    word = [word_segments](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i]
    x0 = int(ratio * [word.start](https://docs.python.org/3/library/functions.html#int "builtins.int"))
    x1 = int(ratio * [word.end](https://docs.python.org/3/library/functions.html#int "builtins.int"))
    print(f"{[word.label](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")} ({[word.score](https://docs.python.org/3/library/functions.html#float "builtins.float"):.2f}): {x0  /  bundle.sample_rate:.3f} - {x1  /  bundle.sample_rate:.3f} sec")
    segment = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")[:, x0:x1]
    return IPython.display.Audio(segment.numpy(), rate=bundle.sample_rate) 
```

```py
# Generate the audio for each segment
print([transcript](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
IPython.display.Audio([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")) 
```

```py
|I|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT| 
```

您的浏览器不支持音频元素。

```py
display_segment(0) 
```

```py
I (0.78): 0.624 - 0.704 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(1) 
```

```py
HAD (0.84): 0.744 - 0.885 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(2) 
```

```py
THAT (0.52): 0.905 - 1.066 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(3) 
```

```py
CURIOSITY (0.89): 1.127 - 1.851 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(4) 
```

```py
BESIDE (0.94): 1.911 - 2.334 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(5) 
```

```py
ME (0.67): 2.374 - 2.495 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(6) 
```

```py
AT (0.66): 2.535 - 2.595 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(7) 
```

```py
THIS (0.70): 2.635 - 2.796 sec 
```

您的浏览器不支持音频元素。

```py
display_segment(8) 
```

```py
MOMENT (0.88): 2.877 - 3.159 sec 
```

您的浏览器不支持音频元素。

## 结论[]（＃conclusion“此标题的永久链接”）

在本教程中，我们看了如何使用torchaudio的Wav2Vec2模型执行强制对齐的CTC分割。

脚本的总运行时间：（0分钟1.734秒）

[`下载Python源代码：forced_alignment_tutorial.py`](../_downloads/fa57890a830bd47c0baa254781b3a8e1/forced_alignment_tutorial.py)

[`下载Jupyter笔记本：forced_alignment_tutorial.ipynb`](../_downloads/160356f33d521341c47ec6b1406a3c2e/forced_alignment_tutorial.ipynb)

[Sphinx-Gallery生成的图库](https://sphinx-gallery.github.io)
