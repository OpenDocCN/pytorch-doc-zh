["```py\nclass torchrec.models.deepfm.DenseArch(in_features: int, hidden_layer_size: int, embedding_dim: int)\u00b6\n```", "```py\nB = 20\nD = 3\nin_features = 10\ndense_arch = DenseArch(\n    in_features=in_features, hidden_layer_size=10, embedding_dim=D\n)\n\ndense_arch_input = torch.rand((B, in_features))\ndense_embedded = dense_arch(dense_arch_input) \n```", "```py\nforward(features: Tensor) \u2192 Tensor\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.models.deepfm.FMInteractionArch(fm_in_features: int, sparse_feature_names: List[str], deep_fm_dimension: int)\u00b6\n```", "```py\nD = 3\nB = 10\nkeys = [\"f1\", \"f2\"]\nF = len(keys)\nfm_inter_arch = FMInteractionArch(sparse_feature_names=keys)\ndense_features = torch.rand((B, D))\nsparse_features = KeyedTensor(\n    keys=keys,\n    length_per_key=[D, D],\n    values=torch.rand((B, D * F)),\n)\ncat_fm_output = fm_inter_arch(dense_features, sparse_features) \n```", "```py\nforward(dense_features: Tensor, sparse_features: KeyedTensor) \u2192 Tensor\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.models.deepfm.OverArch(in_features: int)\u00b6\n```", "```py\nB = 20\nover_arch = OverArch()\nlogits = over_arch(torch.rand((B, 10))) \n```", "```py\nforward(features: Tensor) \u2192 Tensor\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.models.deepfm.SimpleDeepFMNN(num_dense_features: int, embedding_bag_collection: EmbeddingBagCollection, hidden_layer_size: int, deep_fm_dimension: int)\u00b6\n```", "```py\nB = 2\nD = 8\n\neb1_config = EmbeddingBagConfig(\n    name=\"t1\", embedding_dim=D, num_embeddings=100, feature_names=[\"f1\", \"f3\"]\n)\neb2_config = EmbeddingBagConfig(\n    name=\"t2\",\n    embedding_dim=D,\n    num_embeddings=100,\n    feature_names=[\"f2\"],\n)\n\nebc = EmbeddingBagCollection(tables=[eb1_config, eb2_config])\nsparse_nn = SimpleDeepFMNN(\n    embedding_bag_collection=ebc, hidden_layer_size=20, over_embedding_dim=5\n)\n\nfeatures = torch.rand((B, 100))\n\n#     0       1\n# 0   [1,2] [4,5]\n# 1   [4,3] [2,9]\n# ^\n# feature\nsparse_features = KeyedJaggedTensor.from_offsets_sync(\n    keys=[\"f1\", \"f3\"],\n    values=torch.tensor([1, 2, 4, 5, 4, 3, 2, 9]),\n    offsets=torch.tensor([0, 2, 4, 6, 8]),\n)\n\nlogits = sparse_nn(\n    dense_features=features,\n    sparse_features=sparse_features,\n) \n```", "```py\nforward(dense_features: Tensor, sparse_features: KeyedJaggedTensor) \u2192 Tensor\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.models.deepfm.SparseArch(embedding_bag_collection: EmbeddingBagCollection)\u00b6\n```", "```py\neb1_config = EmbeddingBagConfig(\n    name=\"t1\", embedding_dim=3, num_embeddings=10, feature_names=[\"f1\"]\n)\neb2_config = EmbeddingBagConfig(\n    name=\"t2\", embedding_dim=4, num_embeddings=10, feature_names=[\"f2\"]\n)\n\nebc = EmbeddingBagCollection(tables=[eb1_config, eb2_config])\n\n#     0       1        2  <-- batch\n# 0   [0,1] None    [2]\n# 1   [3]    [4]    [5,6,7]\n# ^\n# feature\nfeatures = KeyedJaggedTensor.from_offsets_sync(\n    keys=[\"f1\", \"f2\"],\n    values=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7]),\n    offsets=torch.tensor([0, 2, 2, 3, 4, 5, 8]),\n)\n\nsparse_arch(features) \n```", "```py\nforward(features: KeyedJaggedTensor) \u2192 KeyedTensor\u00b6\n```", "```py\ntraining: bool\u00b6\n```"]