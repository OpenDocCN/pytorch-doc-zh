["```py\n%%bash\npip3  install  deep_phonemizer \n```", "```py\nimport torch\nimport torchaudio\n\n[torch.random.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed \"torch.manual_seed\")(0)\n[device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"cuda\" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\"\n\nprint(torch.__version__)\nprint([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\nprint([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n2.2.0\n2.2.0\ncuda \n```", "```py\nimport IPython\nimport matplotlib.pyplot as plt \n```", "```py\n[symbols](https://docs.python.org/3/library/stdtypes.html#set \"builtins.set\") = \"_-!'(),.:;? abcdefghijklmnopqrstuvwxyz\"\n[look_up](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\") = {s: i for i, s in enumerate([symbols](https://docs.python.org/3/library/stdtypes.html#set \"builtins.set\"))}\n[symbols](https://docs.python.org/3/library/stdtypes.html#set \"builtins.set\") = set([symbols](https://docs.python.org/3/library/stdtypes.html#set \"builtins.set\"))\n\ndef text_to_sequence([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")):\n    [text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = [text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\").lower()\n    return [[look_up](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[s] for s in [text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") if s in [symbols](https://docs.python.org/3/library/stdtypes.html#set \"builtins.set\")]\n\n[text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"Hello world! Text to speech!\"\nprint(text_to_sequence([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))) \n```", "```py\n[19, 16, 23, 23, 26, 11, 34, 26, 29, 23, 15, 2, 11, 31, 16, 35, 31, 11, 31, 26, 11, 30, 27, 16, 16, 14, 19, 2] \n```", "```py\nprocessor = torchaudio.pipelines.TACOTRON2_WAVERNN_CHAR_LJSPEECH.get_text_processor()\n\n[text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"Hello world! Text to speech!\"\n[processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = processor([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\nprint([processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint([lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\ntensor([[19, 16, 23, 23, 26, 11, 34, 26, 29, 23, 15,  2, 11, 31, 16, 35, 31, 11,\n         31, 26, 11, 30, 27, 16, 16, 14, 19,  2]])\ntensor([28], dtype=torch.int32) \n```", "```py\nprint([processor.tokens[i] for i in [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0, : [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0]]]) \n```", "```py\n['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd', '!', ' ', 't', 'e', 'x', 't', ' ', 't', 'o', ' ', 's', 'p', 'e', 'e', 'c', 'h', '!'] \n```", "```py\nbundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n\nprocessor = bundle.get_text_processor()\n\n[text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"Hello world! Text to speech!\"\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = processor([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\nprint([processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint([lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\n 0%|          | 0.00/63.6M [00:00<?, ?B/s]\n  0%|          | 56.0k/63.6M [00:00<03:29, 319kB/s]\n  0%|          | 272k/63.6M [00:00<01:05, 1.01MB/s]\n  1%|          | 592k/63.6M [00:00<00:41, 1.60MB/s]\n  3%|3         | 2.23M/63.6M [00:00<00:10, 5.87MB/s]\n  8%|7         | 4.85M/63.6M [00:00<00:05, 10.9MB/s]\n 16%|#5        | 10.2M/63.6M [00:00<00:02, 21.1MB/s]\n 21%|##1       | 13.6M/63.6M [00:00<00:02, 22.8MB/s]\n 30%|##9       | 18.9M/63.6M [00:01<00:01, 28.5MB/s]\n 35%|###5      | 22.4M/63.6M [00:01<00:01, 27.9MB/s]\n 43%|####3     | 27.5M/63.6M [00:01<00:01, 31.8MB/s]\n 49%|####8     | 31.1M/63.6M [00:01<00:01, 30.6MB/s]\n 55%|#####4    | 35.0M/63.6M [00:01<00:00, 32.9MB/s]\n 61%|######    | 38.6M/63.6M [00:01<00:00, 32.1MB/s]\n 67%|######7   | 42.8M/63.6M [00:01<00:00, 31.8MB/s]\n 74%|#######4  | 47.2M/63.6M [00:02<00:00, 33.1MB/s]\n 80%|########  | 51.1M/63.6M [00:02<00:00, 35.1MB/s]\n 86%|########5 | 54.5M/63.6M [00:02<00:00, 32.3MB/s]\n 92%|#########2| 58.6M/63.6M [00:02<00:00, 32.8MB/s]\n 98%|#########8| 62.5M/63.6M [00:02<00:00, 34.6MB/s]\n100%|##########| 63.6M/63.6M [00:02<00:00, 26.3MB/s]\n/pytorch/audio/ci_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\ntensor([[54, 20, 65, 69, 11, 92, 44, 65, 38,  2, 11, 81, 40, 64, 79, 81, 11, 81,\n         20, 11, 79, 77, 59, 37,  2]])\ntensor([25], dtype=torch.int32) \n```", "```py\nprint([processor.tokens[i] for i in [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0, : [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0]]]) \n```", "```py\n['HH', 'AH', 'L', 'OW', ' ', 'W', 'ER', 'L', 'D', '!', ' ', 'T', 'EH', 'K', 'S', 'T', ' ', 'T', 'AH', ' ', 'S', 'P', 'IY', 'CH', '!'] \n```", "```py\nbundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\nprocessor = bundle.get_text_processor()\ntacotron2 = bundle.get_tacotron2().to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"Hello world! Text to speech!\"\n\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = processor([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = tacotron2.infer([processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\n[_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = plt.imshow([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].cpu().detach(), origin=\"lower\", aspect=\"auto\") \n```", "```py\n/pytorch/audio/ci_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\nDownloading: \"https://download.pytorch.org/torchaudio/models/tacotron2_english_phonemes_1500_epochs_wavernn_ljspeech.pth\" to /root/.cache/torch/hub/checkpoints/tacotron2_english_phonemes_1500_epochs_wavernn_ljspeech.pth\n\n  0%|          | 0.00/107M [00:00<?, ?B/s]\n 14%|#3        | 14.8M/107M [00:00<00:01, 65.2MB/s]\n 20%|#9        | 21.0M/107M [00:00<00:01, 55.6MB/s]\n 30%|##9       | 32.0M/107M [00:00<00:01, 58.4MB/s]\n 45%|####4     | 48.0M/107M [00:00<00:00, 74.5MB/s]\n 59%|#####9    | 63.7M/107M [00:00<00:00, 80.3MB/s]\n 66%|######6   | 71.4M/107M [00:01<00:00, 73.7MB/s]\n 74%|#######4  | 80.0M/107M [00:01<00:00, 62.5MB/s]\n 89%|########9 | 95.7M/107M [00:01<00:00, 75.5MB/s]\n 96%|#########5| 103M/107M [00:01<00:00, 61.0MB/s]\n100%|##########| 107M/107M [00:01<00:00, 64.2MB/s] \n```", "```py\ndef plot():\n    fig, ax = plt.subplots(3, 1)\n    for i in range(3):\n        with [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n            [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec_lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = tacotron2.infer([processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        print([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].shape)\n        ax[i].imshow([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].cpu().detach(), origin=\"lower\", aspect=\"auto\")\n\nplot() \n```", "```py\ntorch.Size([80, 190])\ntorch.Size([80, 184])\ntorch.Size([80, 185]) \n```", "```py\nbundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n\nprocessor = bundle.get_text_processor()\ntacotron2 = bundle.get_tacotron2().to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\nvocoder = bundle.get_vocoder().to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = \"Hello world! Text to speech!\"\n\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = processor([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec_lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = tacotron2.infer([processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n    [waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = vocoder([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec_lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\n/pytorch/audio/ci_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\nDownloading: \"https://download.pytorch.org/torchaudio/models/wavernn_10k_epochs_8bits_ljspeech.pth\" to /root/.cache/torch/hub/checkpoints/wavernn_10k_epochs_8bits_ljspeech.pth\n\n  0%|          | 0.00/16.7M [00:00<?, ?B/s]\n100%|##########| 16.7M/16.7M [00:00<00:00, 394MB/s] \n```", "```py\ndef plot([waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), sample_rate):\n    [waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").cpu().detach()\n\n    fig, [ax1, ax2] = plt.subplots(2, 1)\n    ax1.plot([waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0])\n    ax1.set_xlim(0, [waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size(-1))\n    ax1.grid(True)\n    ax2.imshow([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].cpu().detach(), origin=\"lower\", aspect=\"auto\")\n    return IPython.display.Audio([waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0:1], rate=sample_rate)\n\nplot([waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), vocoder.sample_rate) \n```", "```py\nbundle = torchaudio.pipelines.TACOTRON2_GRIFFINLIM_PHONE_LJSPEECH\n\nprocessor = bundle.get_text_processor()\ntacotron2 = bundle.get_tacotron2().to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\nvocoder = bundle.get_vocoder().to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = processor([text](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n    [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec_lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = tacotron2.infer([processed](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n[waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = vocoder([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec_lengths](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\n/pytorch/audio/ci_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\nDownloading: \"https://download.pytorch.org/torchaudio/models/tacotron2_english_phonemes_1500_epochs_ljspeech.pth\" to /root/.cache/torch/hub/checkpoints/tacotron2_english_phonemes_1500_epochs_ljspeech.pth\n\n  0%|          | 0.00/107M [00:00<?, ?B/s]\n 39%|###8      | 41.7M/107M [00:00<00:00, 437MB/s]\n 78%|#######7  | 83.4M/107M [00:00<00:00, 420MB/s]\n100%|##########| 107M/107M [00:00<00:00, 438MB/s] \n```", "```py\nplot([waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), vocoder.sample_rate) \n```", "```py\n# Workaround to load model mapped on GPU\n# https://stackoverflow.com/a/61840832\nwaveglow = [torch.hub.load](https://pytorch.org/docs/stable/hub.html#torch.hub.load \"torch.hub.load\")(\n    \"NVIDIA/DeepLearningExamples:torchhub\",\n    \"nvidia_waveglow\",\n    model_math=\"fp32\",\n    pretrained=False,\n)\n[checkpoint](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\") = [torch.hub.load_state_dict_from_url](https://pytorch.org/docs/stable/hub.html#torch.hub.load_state_dict_from_url \"torch.hub.load_state_dict_from_url\")(\n    \"https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth\",  # noqa: E501\n    progress=False,\n    map_location=[device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"),\n)\n[state_dict](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\") = {key.replace(\"module.\", \"\"): value for key, value in [checkpoint](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[\"state_dict\"].items()}\n\n[waveglow.load_state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict \"torch.nn.Module.load_state_dict\")([state_dict](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\"))\nwaveglow = waveglow.remove_weightnorm(waveglow)\nwaveglow = [waveglow.to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to \"torch.nn.Module.to\")([device](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n[waveglow.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval \"torch.nn.Module.eval\")()\n\nwith [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n    [waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = waveglow.infer([spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\n/pytorch/audio/ci_env/lib/python3.10/site-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n  warnings.warn(\n/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n  warnings.warn(\n/pytorch/audio/ci_env/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\nDownloading: \"https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth\" to /root/.cache/torch/hub/checkpoints/nvidia_waveglowpyt_fp32_20190306.pth \n```", "```py\nplot([waveforms](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), 22050) \n```"]