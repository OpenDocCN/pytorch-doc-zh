- en: Introduction to TorchScript
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TorchScript介绍
- en: 原文：[https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 访问原文：[https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)
- en: Note
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Click [here](#sphx-glr-download-beginner-intro-to-torchscript-tutorial-py) to
    download the full example code
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[这里](#sphx-glr-download-beginner-intro-to-torchscript-tutorial-py)下载完整的示例代码
- en: '**Authors:** James Reed ([jamesreed@fb.com](mailto:jamesreed%40fb.com)), Michael
    Suo ([suo@fb.com](mailto:suo%40fb.com)), rev2'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：** James Reed ([jamesreed@fb.com](mailto:jamesreed%40fb.com)), Michael
    Suo ([suo@fb.com](mailto:suo%40fb.com)), rev2'
- en: This tutorial is an introduction to TorchScript, an intermediate representation
    of a PyTorch model (subclass of `nn.Module`) that can then be run in a high-performance
    environment such as C++.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程是TorchScript的介绍，TorchScript是PyTorch模型（`nn.Module`子类）的中间表示，然后可以在高性能环境（如C++）中运行。
- en: 'In this tutorial we will cover:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将涵盖：
- en: 'The basics of model authoring in PyTorch, including:'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch中模型编写的基础，包括：
- en: Modules
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模块
- en: Defining `forward` functions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义`forward`函数
- en: Composing modules into a hierarchy of modules
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模块组合成模块层次结构
- en: Specific methods for converting PyTorch modules to TorchScript, our high-performance
    deployment runtime
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将PyTorch模块转换为TorchScript的特定方法，我们的高性能部署运行时
- en: Tracing an existing module
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪现有模块
- en: Using scripting to directly compile a module
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用脚本编译模块
- en: How to compose both approaches
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何组合这两种方法
- en: Saving and loading TorchScript modules
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存和加载TorchScript模块
- en: We hope that after you complete this tutorial, you will proceed to go through
    [the follow-on tutorial](https://pytorch.org/tutorials/advanced/cpp_export.html)
    which will walk you through an example of actually calling a TorchScript model
    from C++.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望在完成本教程后，您将继续阅读[后续教程](https://pytorch.org/tutorials/advanced/cpp_export.html)，该教程将指导您实际从C++中调用TorchScript模型的示例。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Basics of PyTorch Model Authoring
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch模型编写基础
- en: 'Let’s start out by defining a simple `Module`. A `Module` is the basic unit
    of composition in PyTorch. It contains:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义一个简单的`Module`开始。`Module`是PyTorch中的组合基本单元。它包含：
- en: A constructor, which prepares the module for invocation
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个构造函数，为调用准备模块
- en: A set of `Parameters` and sub-`Modules`. These are initialized by the constructor
    and can be used by the module during invocation.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一组`Parameters`和子`Modules`。这些由构造函数初始化，并且可以在调用期间被模块使用。
- en: A `forward` function. This is the code that is run when the module is invoked.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`forward`函数。这是在调用模块时运行的代码。
- en: 'Let’s examine a small example:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个小例子：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'So we’ve:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们：
- en: Created a class that subclasses `torch.nn.Module`.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个继承`torch.nn.Module`的类。
- en: Defined a constructor. The constructor doesn’t do much, just calls the constructor
    for `super`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义了一个构造函数。构造函数并没有做太多事情，只是调用了`super`的构造函数。
- en: Defined a `forward` function, which takes two inputs and returns two outputs.
    The actual contents of the `forward` function are not really important, but it’s
    sort of a fake [RNN cell](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)–that
    is–it’s a function that is applied on a loop.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义了一个`forward`函数，它接受两个输入并返回两个输出。`forward`函数的实际内容并不是很重要，但它有点像一个虚假的[RNN单元](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)——也就是说——它是一个在循环中应用的函数。
- en: We instantiated the module, and made `x` and `h`, which are just 3x4 matrices
    of random values. Then we invoked the cell with `my_cell(x, h)`. This in turn
    calls our `forward` function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化了模块，并创建了`x`和`h`，它们只是随机值的3x4矩阵。然后我们用`my_cell(x, h)`调用了这个单元。这反过来调用了我们的`forward`函数。
- en: 'Let’s do something a little more interesting:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些更有趣的事情：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We’ve redefined our module `MyCell`, but this time we’ve added a `self.linear`
    attribute, and we invoke `self.linear` in the forward function.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重新定义了我们的模块`MyCell`，但这次我们添加了一个`self.linear`属性，并在前向函数中调用了`self.linear`。
- en: What exactly is happening here? `torch.nn.Linear` is a `Module` from the PyTorch
    standard library. Just like `MyCell`, it can be invoked using the call syntax.
    We are building a hierarchy of `Module`s.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里到底发生了什么？`torch.nn.Linear`是PyTorch标准库中的一个`Module`。就像`MyCell`一样，它可以使用调用语法来调用。我们正在构建一个`Module`的层次结构。
- en: '`print` on a `Module` will give a visual representation of the `Module`’s subclass
    hierarchy. In our example, we can see our `Linear` subclass and its parameters.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Module`上使用`print`将给出`Module`子类层次结构的可视化表示。在我们的示例中，我们可以看到我们的`Linear`子类及其参数。
- en: By composing `Module`s in this way, we can succinctly and readably author models
    with reusable components.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式组合`Module`，我们可以简洁而易读地编写具有可重用组件的模型。
- en: You may have noticed `grad_fn` on the outputs. This is a detail of PyTorch’s
    method of automatic differentiation, called [autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html).
    In short, this system allows us to compute derivatives through potentially complex
    programs. The design allows for a massive amount of flexibility in model authoring.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '您可能已经注意到输出中的`grad_fn`。这是PyTorch自动微分方法的一个细节，称为[autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)。简而言之，这个系统允许我们通过可能复杂的程序计算导数。这种设计允许在模型编写中具有极大的灵活性。 '
- en: 'Now let’s examine said flexibility:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看这种灵活性：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We’ve once again redefined our `MyCell` class, but here we’ve defined `MyDecisionGate`.
    This module utilizes **control flow**. Control flow consists of things like loops
    and `if`-statements.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次重新定义了`MyCell`类，但这次我们定义了`MyDecisionGate`。这个模块利用**控制流**。控制流包括循环和`if`语句。
- en: Many frameworks take the approach of computing symbolic derivatives given a
    full program representation. However, in PyTorch, we use a gradient tape. We record
    operations as they occur, and replay them backwards in computing derivatives.
    In this way, the framework does not have to explicitly define derivatives for
    all constructs in the language.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 许多框架采用计算符号导数的方法，给定完整程序表示。然而，在PyTorch中，我们使用梯度磁带。我们记录操作的发生，并在计算导数时向后重放它们。通过这种方式，框架不必为语言中的所有构造显式定义导数。
- en: '![How autograd works](../Images/cfe229076c556327e1fd74c9b59490ad.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![自动求导的工作原理](../Images/cfe229076c556327e1fd74c9b59490ad.png)'
- en: How autograd works
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 自动求导的工作原理
- en: Basics of TorchScript
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TorchScript的基础知识
- en: Now let’s take our running example and see how we can apply TorchScript.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们拿我们正在运行的示例来看看我们如何应用TorchScript。
- en: In short, TorchScript provides tools to capture the definition of your model,
    even in light of the flexible and dynamic nature of PyTorch. Let’s begin by examining
    what we call **tracing**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，TorchScript提供了工具来捕获您模型的定义，即使在PyTorch灵活和动态的特性下。让我们开始检查我们所谓的**跟踪**。
- en: Tracing `Modules`
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪`模块`
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We’ve rewinded a bit and taken the second version of our `MyCell` class. As
    before, we’ve instantiated it, but this time, we’ve called `torch.jit.trace`,
    passed in the `Module`, and passed in *example inputs* the network might see.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经倒带了一点，拿到了我们`MyCell`类的第二个版本。和以前一样，我们已经实例化了它，但这次，我们调用了`torch.jit.trace`，传入了`Module`，并传入了*示例输入*网络可能会看到的。
- en: What exactly has this done? It has invoked the `Module`, recorded the operations
    that occurred when the `Module` was run, and created an instance of `torch.jit.ScriptModule`
    (of which `TracedModule` is an instance)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这到底做了什么？它调用了`Module`，记录了`Module`运行时发生的操作，并创建了`torch.jit.ScriptModule`的一个实例（其中`TracedModule`是一个实例）
- en: 'TorchScript records its definitions in an Intermediate Representation (or IR),
    commonly referred to in Deep learning as a *graph*. We can examine the graph with
    the `.graph` property:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: TorchScript将其定义记录在一个中间表示（IR）中，在深度学习中通常被称为*图*。我们可以使用`.graph`属性检查图：
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'However, this is a very low-level representation and most of the information
    contained in the graph is not useful for end users. Instead, we can use the `.code`
    property to give a Python-syntax interpretation of the code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这是一个非常低级的表示，图中包含的大部分信息对最终用户来说并不有用。相反，我们可以使用`.code`属性来给出代码的Python语法解释：
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'So **why** did we do all this? There are several reasons:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 那么**为什么**我们要做所有这些？有几个原因：
- en: TorchScript code can be invoked in its own interpreter, which is basically a
    restricted Python interpreter. This interpreter does not acquire the Global Interpreter
    Lock, and so many requests can be processed on the same instance simultaneously.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TorchScript代码可以在其自己的解释器中调用，这基本上是一个受限制的Python解释器。这个解释器不会获取全局解释器锁定，因此可以同时处理同一实例上的许多请求。
- en: This format allows us to save the whole model to disk and load it into another
    environment, such as in a server written in a language other than Python
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这种格式允许我们将整个模型保存到磁盘，并加载到另一个环境中，比如在一个不是Python语言编写的服务器中
- en: TorchScript gives us a representation in which we can do compiler optimizations
    on the code to provide more efficient execution
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TorchScript为我们提供了一个表示，我们可以对代码进行编译优化，以提供更高效的执行
- en: TorchScript allows us to interface with many backend/device runtimes that require
    a broader view of the program than individual operators.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TorchScript允许我们与许多需要比单个运算符更广泛视图的后端/设备运行时进行接口。
- en: 'We can see that invoking `traced_cell` produces the same results as the Python
    module:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到调用`traced_cell`产生与Python模块相同的结果：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using Scripting to Convert Modules
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用脚本化转换模块
- en: 'There’s a reason we used version two of our module, and not the one with the
    control-flow-laden submodule. Let’s examine that now:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之所以使用我们模块的第二个版本，而不是带有控制流的子模块的版本，是有原因的。现在让我们来检查一下：
- en: '[PRE16]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Looking at the `.code` output, we can see that the `if-else` branch is nowhere
    to be found! Why? Tracing does exactly what we said it would: run the code, record
    the operations *that happen* and construct a `ScriptModule` that does exactly
    that. Unfortunately, things like control flow are erased.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 查看`.code`输出，我们可以看到`if-else`分支不见了！为什么？跟踪确切地做了我们说过的事情：运行代码，记录发生的操作，并构建一个完全做同样操作的`ScriptModule`。不幸的是，像控制流这样的东西被擦除了。
- en: 'How can we faithfully represent this module in TorchScript? We provide a **script
    compiler**, which does direct analysis of your Python source code to transform
    it into TorchScript. Let’s convert `MyDecisionGate` using the script compiler:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在TorchScript中忠实地表示这个模块？我们提供了一个**脚本编译器**，它直接分析您的Python源代码，将其转换为TorchScript。让我们使用脚本编译器转换`MyDecisionGate`：
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Hooray! We’ve now faithfully captured the behavior of our program in TorchScript.
    Let’s now try running the program:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 万岁！我们现在已经忠实地捕获了我们程序在TorchScript中的行为。现在让我们尝试运行程序：
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Mixing Scripting and Tracing
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混合脚本化和跟踪
- en: 'Some situations call for using tracing rather than scripting (e.g. a module
    has many architectural decisions that are made based on constant Python values
    that we would like to not appear in TorchScript). In this case, scripting can
    be composed with tracing: `torch.jit.script` will inline the code for a traced
    module, and tracing will inline the code for a scripted module.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有些情况需要使用跟踪而不是脚本化（例如，一个模块有许多基于常量Python值做出的架构决策，我们希望这些值不会出现在TorchScript中）。在这种情况下，脚本化可以与跟踪组合使用：`torch.jit.script`将内联跟踪模块的代码，而跟踪将内联脚本化模块的代码。
- en: 'An example of the first case:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个案例的示例：
- en: '[PRE22]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And an example of the second case:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以及第二种情况的示例：
- en: '[PRE24]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This way, scripting and tracing can be used when the situation calls for each
    of them and used together.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，当情况需要时，可以同时使用脚本化和跟踪。
- en: Saving and Loading models
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存和加载模型
- en: 'We provide APIs to save and load TorchScript modules to/from disk in an archive
    format. This format includes code, parameters, attributes, and debug information,
    meaning that the archive is a freestanding representation of the model that can
    be loaded in an entirely separate process. Let’s save and load our wrapped RNN
    module:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供API来保存和加载TorchScript模块到/从磁盘的存档格式中。这种格式包括代码、参数、属性和调试信息，这意味着存档是模型的一个独立表示，可以在完全不同的进程中加载。让我们保存和加载我们包装的RNN模块：
- en: '[PRE26]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As you can see, serialization preserves the module hierarchy and the code we’ve
    been examining throughout. The model can also be loaded, for example, [into C++](https://pytorch.org/tutorials/advanced/cpp_export.html)
    for python-free execution.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，序列化保留了模块层次结构和我们一直在检查的代码。该模型也可以被加载，例如，[到C++中](https://pytorch.org/tutorials/advanced/cpp_export.html)以进行无Python执行。
- en: Further Reading
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'We’ve completed our tutorial! For a more involved demonstration, check out
    the NeurIPS demo for converting machine translation models using TorchScript:
    [https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ](https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了我们的教程！要进行更深入的演示，请查看NeurIPS演示，了解如何使用TorchScript转换机器翻译模型：[https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ](https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ)
- en: '**Total running time of the script:** ( 0 minutes 0.244 seconds)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚本的总运行时间：**（0分钟0.244秒）'
- en: '[`Download Python source code: Intro_to_TorchScript_tutorial.py`](../_downloads/07d05907b3ff859aeed5f76f1acc5df4/Intro_to_TorchScript_tutorial.py)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Python源代码：Intro_to_TorchScript_tutorial.py`](../_downloads/07d05907b3ff859aeed5f76f1acc5df4/Intro_to_TorchScript_tutorial.py)'
- en: '[`Download Jupyter notebook: Intro_to_TorchScript_tutorial.ipynb`](../_downloads/61a76849444a0a65d843361c26d1de16/Intro_to_TorchScript_tutorial.ipynb)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Jupyter笔记本：Intro_to_TorchScript_tutorial.ipynb`](../_downloads/61a76849444a0a65d843361c26d1de16/Intro_to_TorchScript_tutorial.ipynb)'
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sphinx-Gallery生成的画廊](https://sphinx-gallery.github.io)'
