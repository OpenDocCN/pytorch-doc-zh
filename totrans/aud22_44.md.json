["```py\nimport torch\nimport torchaudio\n\nprint(torch.__version__)\nprint([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\nimport matplotlib.pyplot as plt \n```", "```py\n2.2.0\n2.2.0 \n```", "```py\nfrom IPython.display import Audio\nfrom mir_eval import separation\nfrom torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS\nfrom torchaudio.utils import download_asset \n```", "```py\nbundle = HDEMUCS_HIGH_MUSDB_PLUS\n\nmodel = bundle.get_model()\n\n[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda:0\" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\")\n\n[model.to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to \"torch.nn.Module.to\")([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n\nprint(f\"Sample rate: {[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")}\") \n```", "```py\n 0%|          | 0.00/319M [00:00<?, ?B/s]\n 13%|#2        | 41.1M/319M [00:00<00:00, 431MB/s]\n 26%|##5       | 82.2M/319M [00:00<00:00, 411MB/s]\n 39%|###8      | 124M/319M [00:00<00:00, 422MB/s]\n 51%|#####1    | 164M/319M [00:00<00:00, 403MB/s]\n 63%|######3   | 203M/319M [00:00<00:00, 371MB/s]\n 75%|#######4  | 238M/319M [00:00<00:00, 369MB/s]\n 88%|########8 | 281M/319M [00:00<00:00, 394MB/s]\n100%|#########9| 319M/319M [00:00<00:00, 374MB/s]\n100%|##########| 319M/319M [00:00<00:00, 386MB/s]\nSample rate: 44100 \n```", "```py\nfrom torchaudio.transforms import [Fade](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")\n\ndef separate_sources(\n    model,\n    mix,\n    [segment](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=10.0,\n    [overlap](https://docs.python.org/3/library/functions.html#float \"builtins.float\")=0.1,\n    [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")=None,\n):\n  \"\"\"\n Apply model to a given mixture. Use fade, and add segments together in order to add model segment by segment.\n\n Args:\n segment (int): segment length in seconds\n device (torch.device, str, or None): if provided, device on which to\n execute the computation, otherwise `mix.device` is assumed.\n When `device` is different from `mix.device`, only local computations will\n be on `device`, while the entire tracks will be stored on `mix.device`.\n \"\"\"\n    if [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") is None:\n        [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = mix.[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")\n    else:\n        [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n    batch, channels, length = mix.shape\n\n    chunk_len = int([sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") * [segment](https://docs.python.org/3/library/functions.html#int \"builtins.int\") * (1 + [overlap](https://docs.python.org/3/library/functions.html#float \"builtins.float\")))\n    start = 0\n    end = chunk_len\n    overlap_frames = [overlap](https://docs.python.org/3/library/functions.html#float \"builtins.float\") * [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n    fade = [Fade](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(fade_in_len=0, fade_out_len=int(overlap_frames), fade_shape=\"linear\")\n\n    final = [torch.zeros](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros \"torch.zeros\")(batch, len([model.sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")), channels, length, [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\n    while start < length - overlap_frames:\n        chunk = mix[:, :, start:end]\n        with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n            out = [model.forward](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward \"torch.nn.Module.forward\")(chunk)\n        out = fade(out)\n        final[:, :, :, start:end] += out\n        if start == 0:\n            fade.fade_in_len = int(overlap_frames)\n            start += int(chunk_len - overlap_frames)\n        else:\n            start += chunk_len\n        end += chunk_len\n        if end >= length:\n            fade.fade_out_len = 0\n    return final\n\ndef plot_spectrogram(stft, title=\"Spectrogram\"):\n    magnitude = stft.abs()\n    spectrogram = 20 * [torch.log10](https://pytorch.org/docs/stable/generated/torch.log10.html#torch.log10 \"torch.log10\")(magnitude + 1e-8).numpy()\n    _, axis = plt.subplots(1, 1)\n    axis.imshow(spectrogram, cmap=\"viridis\", vmin=-60, vmax=0, origin=\"lower\", aspect=\"auto\")\n    axis.set_title(title)\n    plt.tight_layout() \n```", "```py\n# We download the audio file from our storage. Feel free to download another file and use audio from a specific path\n[SAMPLE_SONG](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/hdemucs_mix.wav\")\n[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([SAMPLE_SONG](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))  # replace SAMPLE_SONG with desired path for different song\n[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n[mixture](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n\n# parameters\n[segment](https://docs.python.org/3/library/functions.html#int \"builtins.int\"): int = 10\n[overlap](https://docs.python.org/3/library/functions.html#float \"builtins.float\") = 0.1\n\nprint(\"Separating track\")\n\n[ref](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").mean(0)\n[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = ([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") - [ref](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").mean()) / [ref](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").std()  # normalization\n\n[sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = separate_sources(\n    model,\n    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[None],\n    [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"),\n    [segment](https://docs.python.org/3/library/functions.html#int \"builtins.int\")=[segment](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n    [overlap](https://docs.python.org/3/library/functions.html#float \"builtins.float\")=[overlap](https://docs.python.org/3/library/functions.html#float \"builtins.float\"),\n)[0]\n[sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") * [ref](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").std() + [ref](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").mean()\n\n[sources_list](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = [model.sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")\n[sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\") = list([sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))\n\n[audios](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\") = dict(zip([sources_list](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), [sources](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))) \n```", "```py\n 0%|          | 0.00/28.8M [00:00<?, ?B/s]\n 27%|##6       | 7.72M/28.8M [00:00<00:00, 57.2MB/s]\n 57%|#####6    | 16.4M/28.8M [00:00<00:00, 43.3MB/s]\n 93%|#########3| 27.0M/28.8M [00:00<00:00, 59.3MB/s]\n100%|##########| 28.8M/28.8M [00:00<00:00, 58.7MB/s]\nSeparating track \n```", "```py\n[N_FFT](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = 4096\n[N_HOP](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = 4\nstft = [torchaudio.transforms.Spectrogram](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(\n    n_fft=[N_FFT](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n    hop_length=[N_HOP](https://docs.python.org/3/library/functions.html#int \"builtins.int\"),\n    power=None,\n) \n```", "```py\ndef output_results(original_source: [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), predicted_source: [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), source: str):\n    print(\n        \"SDR score is:\",\n        separation.bss_eval_sources(original_source.detach().numpy(), predicted_source.detach().numpy())[0].mean(),\n    )\n    plot_spectrogram(stft(predicted_source)[0], f\"Spectrogram - {source}\")\n    return Audio(predicted_source, rate=[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\"))\n\n[segment_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = 150\n[segment_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = 155\n\n[frame_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = [segment_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\") * [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n[frame_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = [segment_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\") * [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")\n\n[drums_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/hdemucs_drums_segment.wav\")\n[bass_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/hdemucs_bass_segment.wav\")\n[vocals_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/hdemucs_vocals_segment.wav\")\n[other_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/hdemucs_other_segment.wav\")\n\n[drums_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [audios](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[\"drums\"][:, [frame_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):[frame_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].cpu()\n[drums](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([drums_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[bass_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [audios](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[\"bass\"][:, [frame_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):[frame_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].cpu()\n[bass](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([bass_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[vocals_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [audios](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[\"vocals\"][:, [frame_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):[frame_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].cpu()\n[vocals](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([vocals_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[other_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [audios](https://docs.python.org/3/library/stdtypes.html#dict \"builtins.dict\")[\"other\"][:, [frame_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):[frame_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].cpu()\n[other](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([other_original](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[mix_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [mixture](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[:, [frame_start](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):[frame_end](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].cpu() \n```", "```py\n 0%|          | 0.00/1.68M [00:00<?, ?B/s]\n100%|##########| 1.68M/1.68M [00:00<00:00, 50.6MB/s]\n\n  0%|          | 0.00/1.68M [00:00<?, ?B/s]\n100%|##########| 1.68M/1.68M [00:00<00:00, 100MB/s]\n\n  0%|          | 0.00/1.68M [00:00<?, ?B/s]\n100%|##########| 1.68M/1.68M [00:00<00:00, 179MB/s]\n\n  0%|          | 0.00/1.68M [00:00<?, ?B/s]\n100%|##########| 1.68M/1.68M [00:00<00:00, 187MB/s] \n```", "```py\n# Mixture Clip\nplot_spectrogram(stft([mix_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))[0], \"Spectrogram - Mixture\")\nAudio([mix_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), rate=[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\n# Drums Clip\noutput_results([drums](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [drums_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"drums\") \n```", "```py\nSDR score is: 4.964103512281138 \n```", "```py\n# Bass Clip\noutput_results([bass](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [bass_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"bass\") \n```", "```py\nSDR score is: 18.905954431001057 \n```", "```py\n# Vocals Audio\noutput_results([vocals](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [vocals_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"vocals\") \n```", "```py\nSDR score is: 8.792216836345062 \n```", "```py\n# Other Clip\noutput_results([other](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [other_spec](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), \"other\") \n```", "```py\nSDR score is: 8.866916703002428 \n```", "```py\n# Optionally, the full audios can be heard in from running the next 5\n# cells. They will take a bit longer to load, so to run simply uncomment\n# out the ``Audio`` cells for the respective track to produce the audio\n# for the full song.\n#\n\n# Full Audio\n# Audio(mixture, rate=sample_rate)\n\n# Drums Audio\n# Audio(audios[\"drums\"], rate=sample_rate)\n\n# Bass Audio\n# Audio(audios[\"bass\"], rate=sample_rate)\n\n# Vocals Audio\n# Audio(audios[\"vocals\"], rate=sample_rate)\n\n# Other Audio\n# Audio(audios[\"other\"], rate=sample_rate) \n```"]