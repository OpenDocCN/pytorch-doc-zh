- en: Introduction to PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch简介
- en: 原文：[https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html)
- en: Note
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Click [here](#sphx-glr-download-beginner-introyt-introyt1-tutorial-py) to download
    the full example code
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[这里](#sphx-glr-download-beginner-introyt-introyt1-tutorial-py)下载完整的示例代码
- en: '**Introduction** || [Tensors](tensors_deeper_tutorial.html) || [Autograd](autogradyt_tutorial.html)
    || [Building Models](modelsyt_tutorial.html) || [TensorBoard Support](tensorboardyt_tutorial.html)
    || [Training Models](trainingyt.html) || [Model Understanding](captumyt.html)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介** || [张量](tensors_deeper_tutorial.html) || [Autograd](autogradyt_tutorial.html)
    || [构建模型](modelsyt_tutorial.html) || [TensorBoard支持](tensorboardyt_tutorial.html)
    || [训练模型](trainingyt.html) || [模型理解](captumyt.html)'
- en: Follow along with the video below or on [youtube](https://www.youtube.com/watch?v=IC0_FRiX-sw).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随下面的视频或在[youtube](https://www.youtube.com/watch?v=IC0_FRiX-sw)上跟随。
- en: '[https://www.youtube.com/embed/IC0_FRiX-sw](https://www.youtube.com/embed/IC0_FRiX-sw)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/embed/IC0_FRiX-sw](https://www.youtube.com/embed/IC0_FRiX-sw)'
- en: PyTorch Tensors
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch张量
- en: Follow along with the video beginning at [03:50](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=230s).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随视频从[03:50](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=230s)开始。
- en: First, we’ll import pytorch.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将导入pytorch。
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s see a few basic tensor manipulations. First, just a few of the ways to
    create tensors:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些基本的张量操作。首先，只是创建张量的几种方法：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Above, we create a 5x3 matrix filled with zeros, and query its datatype to find
    out that the zeros are 32-bit floating point numbers, which is the default PyTorch.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 上面，我们创建了一个填充了零的5x3矩阵，并查询其数据类型，以找出这些零是32位浮点数，这是PyTorch的默认值。
- en: 'What if you wanted integers instead? You can always override the default:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要整数怎么办？你总是可以覆盖默认值：
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can see that when we do change the default, the tensor helpfully reports
    this when printed.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到当我们改变默认值时，张量在打印时会报告这一点。
- en: 'It’s common to initialize learning weights randomly, often with a specific
    seed for the PRNG for reproducibility of results:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通常会随机初始化学习权重，通常使用特定的种子为PRNG以便结果可重现：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'PyTorch tensors perform arithmetic operations intuitively. Tensors of similar
    shapes may be added, multiplied, etc. Operations with scalars are distributed
    over the tensor:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch张量直观地执行算术运算。形状相似的张量可以相加、相乘等。与标量的操作分布在张量上：
- en: '[PRE7]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here’s a small sample of the mathematical operations available:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一小部分可用的数学运算：
- en: '[PRE9]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: There’s a good deal more to know about the power of PyTorch tensors, including
    how to set them up for parallel computations on GPU - we’ll be going into more
    depth in another video.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关于PyTorch张量的强大功能还有很多要了解，包括如何设置它们以在GPU上进行并行计算 - 我们将在另一个视频中深入探讨。
- en: PyTorch Models
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch模型
- en: Follow along with the video beginning at [10:00](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=600s).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随视频从[10:00](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=600s)开始。
- en: Let’s talk about how we can express models in PyTorch
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈如何在PyTorch中表达模型
- en: '[PRE11]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![le-net-5 diagram](../Images/3250cbba812d68265cf7815d987bcd1b.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![le-net-5 diagram](../Images/3250cbba812d68265cf7815d987bcd1b.png)'
- en: '*Figure: LeNet-5*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*图：LeNet-5*'
- en: Above is a diagram of LeNet-5, one of the earliest convolutional neural nets,
    and one of the drivers of the explosion in Deep Learning. It was built to read
    small images of handwritten numbers (the MNIST dataset), and correctly classify
    which digit was represented in the image.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上面是LeNet-5的图表，这是最早的卷积神经网络之一，也是深度学习爆炸的推动力之一。它被设计用来读取手写数字的小图像（MNIST数据集），并正确分类图像中代表的数字。
- en: 'Here’s the abridged version of how it works:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的简化版本是如何工作的：
- en: Layer C1 is a convolutional layer, meaning that it scans the input image for
    features it learned during training. It outputs a map of where it saw each of
    its learned features in the image. This “activation map” is downsampled in layer
    S2.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层C1是一个卷积层，意味着它在输入图像中扫描在训练期间学到的特征。它输出一个地图，显示它在图像中看到每个学到的特征的位置。这个“激活图”在S2层中进行降采样。
- en: Layer C3 is another convolutional layer, this time scanning C1’s activation
    map for *combinations* of features. It also puts out an activation map describing
    the spatial locations of these feature combinations, which is downsampled in layer
    S4.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层C3是另一个卷积层，这次是扫描C1的激活图以查找特征的*组合*。它还输出描述这些特征组合的空间位置的激活图，在S4层中进行降采样。
- en: Finally, the fully-connected layers at the end, F5, F6, and OUTPUT, are a *classifier*
    that takes the final activation map, and classifies it into one of ten bins representing
    the 10 digits.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，最后的全连接层F5、F6和OUTPUT是一个*分类器*，它接收最终的激活图，并将其分类为表示10个数字的十个箱子之一。
- en: How do we express this simple neural network in code?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何用代码表达这个简单的神经网络？
- en: '[PRE12]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Looking over this code, you should be able to spot some structural similarities
    with the diagram above.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这段代码，你应该能够发现与上面图表的一些结构相似之处。
- en: 'This demonstrates the structure of a typical PyTorch model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了典型PyTorch模型的结构：
- en: It inherits from `torch.nn.Module` - modules may be nested - in fact, even the
    `Conv2d` and `Linear` layer classes inherit from `torch.nn.Module`.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它继承自`torch.nn.Module` - 模块可以嵌套 - 实际上，甚至`Conv2d`和`Linear`层类也继承自`torch.nn.Module`。
- en: A model will have an `__init__()` function, where it instantiates its layers,
    and loads any data artifacts it might need (e.g., an NLP model might load a vocabulary).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型将有一个`__init__()`函数，在其中实例化其层，并加载可能需要的任何数据工件（例如，NLP模型可能加载一个词汇表）。
- en: 'A model will have a `forward()` function. This is where the actual computation
    happens: An input is passed through the network layers and various functions to
    generate an output.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型将有一个`forward()`函数。这是实际计算发生的地方：输入通过网络层和各种函数生成输出。
- en: Other than that, you can build out your model class like any other Python class,
    adding whatever properties and methods you need to support your model’s computation.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除此之外，你可以像构建任何其他Python类一样构建你的模型类，添加任何你需要支持模型计算的属性和方法。
- en: Let’s instantiate this object and run a sample input through it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实例化这个对象并运行一个样本输入。
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are a few important things happening above:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 上面发生了一些重要的事情：
- en: First, we instantiate the `LeNet` class, and we print the `net` object. A subclass
    of `torch.nn.Module` will report the layers it has created and their shapes and
    parameters. This can provide a handy overview of a model if you want to get the
    gist of its processing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们实例化`LeNet`类，并打印`net`对象。`torch.nn.Module`的子类将报告它已创建的层及其形状和参数。如果您想要了解其处理过程的要点，这可以提供一个方便的模型概述。
- en: Below that, we create a dummy input representing a 32x32 image with 1 color
    channel. Normally, you would load an image tile and convert it to a tensor of
    this shape.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们创建一个代表具有1个颜色通道的32x32图像的虚拟输入。通常，您会加载一个图像块并将其转换为这种形状的张量。
- en: You may have noticed an extra dimension to our tensor - the *batch dimension.*
    PyTorch models assume they are working on *batches* of data - for example, a batch
    of 16 of our image tiles would have the shape `(16, 1, 32, 32)`. Since we’re only
    using one image, we create a batch of 1 with shape `(1, 1, 32, 32)`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到我们的张量有一个额外的维度 - *批处理维度*。PyTorch模型假定它们正在处理*数据批次* - 例如，我们的图像块批次中的16个图像将具有形状`(16,
    1, 32, 32)`。由于我们只使用一个图像，我们创建一个形状为`(1, 1, 32, 32)`的批次。
- en: 'We ask the model for an inference by calling it like a function: `net(input)`.
    The output of this call represents the model’s confidence that the input represents
    a particular digit. (Since this instance of the model hasn’t learned anything
    yet, we shouldn’t expect to see any signal in the output.) Looking at the shape
    of `output`, we can see that it also has a batch dimension, the size of which
    should always match the input batch dimension. If we had passed in an input batch
    of 16 instances, `output` would have a shape of `(16, 10)`.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过像调用函数一样调用模型来请求推理：`net(input)`。此调用的输出表示模型对输入表示特定数字的信心程度。（由于此模型的实例尚未学习任何内容，我们不应该期望在输出中看到任何信号。）查看`output`的形状，我们可以看到它还具有一个批处理维度，其大小应始终与输入批处理维度匹配。如果我们传入了一个包含16个实例的输入批次，`output`的形状将为`(16,
    10)`。
- en: Datasets and Dataloaders
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集和数据加载器
- en: Follow along with the video beginning at [14:00](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=840s).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从[14:00](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=840s)开始观看视频。
- en: Below, we’re going to demonstrate using one of the ready-to-download, open-access
    datasets from TorchVision, how to transform the images for consumption by your
    model, and how to use the DataLoader to feed batches of data to your model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将演示如何使用TorchVision中准备好下载的开放访问数据集，将图像转换为模型可消费的形式，并如何使用DataLoader将数据批量提供给模型。
- en: The first thing we need to do is transform our incoming images into a PyTorch
    tensor.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是将我们的输入图像转换为PyTorch张量。
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here, we specify two transformations for our input:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为我们的输入指定了两个转换：
- en: '`transforms.ToTensor()` converts images loaded by Pillow into PyTorch tensors.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.ToTensor()` 将由Pillow加载的图像转换为PyTorch张量。'
- en: '`transforms.Normalize()` adjusts the values of the tensor so that their average
    is zero and their standard deviation is 1.0\. Most activation functions have their
    strongest gradients around x = 0, so centering our data there can speed learning.
    The values passed to the transform are the means (first tuple) and the standard
    deviations (second tuple) of the rgb values of the images in the dataset. You
    can calculate these values yourself by running these few lines of code:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.Normalize()` 调整张量的值，使其平均值为零，标准差为1.0。大多数激活函数在x = 0附近具有最强的梯度，因此将数据居中在那里可以加快学习速度。传递给变换的值是数据集中图像的rgb值的平均值（第一个元组）和标准差（第二个元组）。您可以通过运行以下几行代码自己计算这些值：'
- en: '[``](#id1)[`](#id3)'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[``](#id1)[`](#id3)'
- en: ''
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: from torch.utils.data import ConcatDataset transform = transforms.Compose([transforms.ToTensor()])
    trainset = torchvision.datasets.CIFAR10(root=’./data’, train=True,
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: from torch.utils.data import ConcatDataset transform = transforms.Compose([transforms.ToTensor()])
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
- en: ''
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: download=True, transform=transform)
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: download=True, transform=transform)
- en: ''
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '#stack all train images together into a tensor of shape #(50000, 3, 32, 32)
    x = torch.stack([sample[0] for sample in ConcatDataset([trainset])])'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '#将所有训练图像堆叠在一起，形成形状为(50000, 3, 32, 32)的张量 x = torch.stack([sample[0] for sample
    in ConcatDataset([trainset])])'
- en: ''
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '#get the mean of each channel mean = torch.mean(x, dim=(0,2,3)) #tensor([0.4914,
    0.4822, 0.4465]) std = torch.std(x, dim=(0,2,3)) #tensor([0.2470, 0.2435, 0.2616])'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '#获取每个通道的平均值 mean = torch.mean(x, dim=(0,2,3)) #tensor([0.4914, 0.4822, 0.4465])
    std = torch.std(x, dim=(0,2,3)) #tensor([0.2470, 0.2435, 0.2616])'
- en: ''
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[``](#id5)[`](#id7)'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[``](#id5)[`](#id7)'
- en: There are many more transforms available, including cropping, centering, rotation,
    and reflection.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他可用的转换，包括裁剪、居中、旋转和反射。
- en: 'Next, we’ll create an instance of the CIFAR10 dataset. This is a set of 32x32
    color image tiles representing 10 classes of objects: 6 of animals (bird, cat,
    deer, dog, frog, horse) and 4 of vehicles (airplane, automobile, ship, truck):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个CIFAR10数据集的实例。这是一个代表10类对象的32x32彩色图像块的集合：6种动物（鸟、猫、鹿、狗、青蛙、马）和4种车辆（飞机、汽车、船、卡车）：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When you run the cell above, it may take a little time for the dataset to download.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行上面的单元格时，数据集下载可能需要一些时间。
- en: This is an example of creating a dataset object in PyTorch. Downloadable datasets
    (like CIFAR-10 above) are subclasses of `torch.utils.data.Dataset`. `Dataset`
    classes in PyTorch include the downloadable datasets in TorchVision, Torchtext,
    and TorchAudio, as well as utility dataset classes such as `torchvision.datasets.ImageFolder`,
    which will read a folder of labeled images. You can also create your own subclasses
    of `Dataset`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在PyTorch中创建数据集对象的一个示例。可下载的数据集（如上面的CIFAR-10）是`torch.utils.data.Dataset`的子类。PyTorch中的`Dataset`类包括TorchVision、Torchtext和TorchAudio中的可下载数据集，以及实用程序数据集类，如`torchvision.datasets.ImageFolder`，它将读取一个带有标签的图像文件夹。您还可以创建自己的`Dataset`子类。
- en: 'When we instantiate our dataset, we need to tell it a few things:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们实例化数据集时，我们需要告诉它一些事情：
- en: The filesystem path to where we want the data to go.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望数据存储的文件系统路径。
- en: Whether or not we are using this set for training; most datasets will be split
    into training and test subsets.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论我们是否将此集合用于训练；大多数数据集都将被分割为训练和测试子集。
- en: Whether we would like to download the dataset if we haven’t already.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们还没有下载数据集，我们是否想要下载数据集。
- en: The transformations we want to apply to the data.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要应用于数据的转换。
- en: 'Once your dataset is ready, you can give it to the `DataLoader`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的数据集准备好了，您可以将其提供给`DataLoader`：
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: A `Dataset` subclass wraps access to the data, and is specialized to the type
    of data it’s serving. The `DataLoader` knows *nothing* about the data, but organizes
    the input tensors served by the `Dataset` into batches with the parameters you
    specify.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dataset`子类包装对数据的访问，并专门针对其提供的数据类型。`DataLoader`对数据一无所知，但会根据您指定的参数将`Dataset`提供的输入张量组织成批次。'
- en: In the example above, we’ve asked a `DataLoader` to give us batches of 4 images
    from `trainset`, randomizing their order (`shuffle=True`), and we told it to spin
    up two workers to load data from disk.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们要求`DataLoader`从`trainset`中给我们提供4个图像的批次，随机化它们的顺序（`shuffle=True`），并告诉它启动两个工作人员从磁盘加载数据。
- en: 'It’s good practice to visualize the batches your `DataLoader` serves:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 将`DataLoader`提供的批次可视化是一个好的做法：
- en: '[PRE19]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![introyt1 tutorial](../Images/dbae2a27ffbc37dd9f667972bb0475a9.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![introyt1教程](../Images/dbae2a27ffbc37dd9f667972bb0475a9.png)'
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Running the above cell should show you a strip of four images, and the correct
    label for each.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上面的单元格应该会显示一条包含四幅图像和每个图像的正确标签的条带。
- en: Training Your PyTorch Model
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练您的PyTorch模型
- en: Follow along with the video beginning at [17:10](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=1030s).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 从[17:10](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=1030s)开始，跟随视频进行。
- en: 'Let’s put all the pieces together, and train a model:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把所有的部分放在一起，训练一个模型：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: First, we’ll need training and test datasets. If you haven’t already, run the
    cell below to make sure the dataset is downloaded. (It may take a minute.)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要训练和测试数据集。如果还没有，请运行下面的单元格以确保数据集已下载。（可能需要一分钟。）
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We’ll run our check on the output from `DataLoader`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对来自`DataLoader`的输出运行检查：
- en: '[PRE24]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![introyt1 tutorial](../Images/bfc0f2dbc312832c813396902db25aee.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![introyt1教程](../Images/bfc0f2dbc312832c813396902db25aee.png)'
- en: '[PRE25]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This is the model we’ll train. If it looks familiar, that’s because it’s a variant
    of LeNet - discussed earlier in this video - adapted for 3-color images.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要训练的模型。如果看起来很熟悉，那是因为它是LeNet的一个变种-在本视频中之前讨论过-适用于3色图像。
- en: '[PRE26]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The last ingredients we need are a loss function and an optimizer:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的最后一些要素是损失函数和优化器：
- en: '[PRE27]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The loss function, as discussed earlier in this video, is a measure of how far
    from our ideal output the model’s prediction was. Cross-entropy loss is a typical
    loss function for classification models like ours.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数，正如在本视频中之前讨论的那样，是模型预测与理想输出之间的差距的度量。交叉熵损失是我们这种分类模型的典型损失函数。
- en: The **optimizer** is what drives the learning. Here we have created an optimizer
    that implements *stochastic gradient descent,* one of the more straightforward
    optimization algorithms. Besides parameters of the algorithm, like the learning
    rate (`lr`) and momentum, we also pass in `net.parameters()`, which is a collection
    of all the learning weights in the model - which is what the optimizer adjusts.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**优化器**是推动学习的关键。在这里，我们创建了一个实现*随机梯度下降*的优化器，这是更直接的优化算法之一。除了算法的参数，如学习率（`lr`）和动量，我们还传入`net.parameters()`，这是模型中所有学习权重的集合-这是优化器调整的内容。'
- en: 'Finally, all of this is assembled into the training loop. Go ahead and run
    this cell, as it will likely take a few minutes to execute:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，所有这些都被组装到训练循环中。继续运行此单元格，因为执行可能需要几分钟。
- en: '[PRE28]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here, we are doing only **2 training epochs** (line 1) - that is, two passes
    over the training dataset. Each pass has an inner loop that **iterates over the
    training data** (line 4), serving batches of transformed input images and their
    correct labels.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只进行**2个训练周期**（第1行）-也就是说，对训练数据集进行两次遍历。每次遍历都有一个内部循环，**遍历训练数据**（第4行），提供经过转换的输入图像的批次和它们的正确标签。
- en: '**Zeroing the gradients** (line 9) is an important step. Gradients are accumulated
    over a batch; if we do not reset them for every batch, they will keep accumulating,
    which will provide incorrect gradient values, making learning impossible.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**将梯度归零**（第9行）是一个重要的步骤。梯度在一个批次中累积；如果我们不为每个批次重置它们，它们将继续累积，这将提供不正确的梯度值，使学习变得不可能。'
- en: In line 12, we **ask the model for its predictions** on this batch. In the following
    line (13), we compute the loss - the difference between `outputs` (the model prediction)
    and `labels` (the correct output).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在第12行，我们**要求模型对这个批次进行预测**。在接下来的一行（第13行），我们计算损失-`outputs`（模型预测）和`labels`（正确输出）之间的差异。
- en: In line 14, we do the `backward()` pass, and calculate the gradients that will
    direct the learning.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在第14行，我们进行`backward()`传递，并计算将指导学习的梯度。
- en: In line 15, the optimizer performs one learning step - it uses the gradients
    from the `backward()` call to nudge the learning weights in the direction it thinks
    will reduce the loss.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在第15行，优化器执行一个学习步骤-它使用`backward()`调用的梯度来推动学习权重朝着它认为会减少损失的方向。
- en: The remainder of the loop does some light reporting on the epoch number, how
    many training instances have been completed, and what the collected loss is over
    the training loop.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 循环的其余部分对epoch数进行了一些轻量级的报告，已完成的训练实例数量，以及训练循环中收集的损失是多少。
- en: '**When you run the cell above,** you should see something like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**当您运行上面的单元格时**，您应该会看到类似于这样的内容：'
- en: '[PRE30]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note that the loss is monotonically descending, indicating that our model is
    continuing to improve its performance on the training dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，损失是单调递减的，表明我们的模型在训练数据集上继续改善其性能。
- en: As a final step, we should check that the model is actually doing *general*
    learning, and not simply “memorizing” the dataset. This is called **overfitting,**
    and usually indicates that the dataset is too small (not enough examples for general
    learning), or that the model has more learning parameters than it needs to correctly
    model the dataset.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们应该检查模型是否实际上正在进行*通用*学习，而不仅仅是“记忆”数据集。这被称为**过拟合**，通常表明数据集太小（没有足够的示例进行通用学习），或者模型具有比正确建模数据集所需的学习参数更多。
- en: 'This is the reason datasets are split into training and test subsets - to test
    the generality of the model, we ask it to make predictions on data it hasn’t trained
    on:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是数据集被分为训练和测试子集的原因 - 为了测试模型的普遍性，我们要求它对其未经训练的数据进行预测：
- en: '[PRE31]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If you followed along, you should see that the model is roughly 50% accurate
    at this point. That’s not exactly state-of-the-art, but it’s far better than the
    10% accuracy we’d expect from a random output. This demonstrates that some general
    learning did happen in the model.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您跟随进行，您应该看到模型在这一点上大约有50%的准确率。这并不是最先进的，但比我们从随机输出中期望的10%的准确率要好得多。这表明模型确实发生了一些通用学习。
- en: '**Total running time of the script:** ( 1 minutes 54.089 seconds)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚本的总运行时间：**（1分钟54.089秒）'
- en: '[`Download Python source code: introyt1_tutorial.py`](../../_downloads/0e4c2becda3dfc54e1816634d49f8e73/introyt1_tutorial.py)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Python源代码：introyt1_tutorial.py`](../../_downloads/0e4c2becda3dfc54e1816634d49f8e73/introyt1_tutorial.py)'
- en: '[`Download Jupyter notebook: introyt1_tutorial.ipynb`](../../_downloads/3195443a0ced3cabc0ad643537bdb5cd/introyt1_tutorial.ipynb)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Jupyter笔记本：introyt1_tutorial.ipynb`](../../_downloads/3195443a0ced3cabc0ad643537bdb5cd/introyt1_tutorial.ipynb)'
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sphinx-Gallery生成的画廊](https://sphinx-gallery.github.io)'
