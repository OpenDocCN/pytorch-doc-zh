["```py\n\"\"\"run.py:\"\"\"\n#!/usr/bin/env python\nimport os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank, size):\n  \"\"\" Distributed function to be implemented later. \"\"\"\n    pass\n\ndef init_process(rank, size, fn, backend='gloo'):\n  \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank, world_size=size)\n    fn(rank, size)\n\nif __name__ == \"__main__\":\n    size = 2\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join() \n```", "```py\n\"\"\"Blocking point-to-point communication.\"\"\"\n\ndef run(rank, size):\n    tensor = torch.zeros(1)\n    if rank == 0:\n        tensor += 1\n        # Send the tensor to process 1\n        dist.send(tensor=tensor, dst=1)\n    else:\n        # Receive tensor from process 0\n        dist.recv(tensor=tensor, src=0)\n    print('Rank ', rank, ' has data ', tensor[0]) \n```", "```py\n\"\"\"Non-blocking point-to-point communication.\"\"\"\n\ndef run(rank, size):\n    tensor = torch.zeros(1)\n    req = None\n    if rank == 0:\n        tensor += 1\n        # Send the tensor to process 1\n        req = dist.isend(tensor=tensor, dst=1)\n        print('Rank 0 started sending')\n    else:\n        # Receive tensor from process 0\n        req = dist.irecv(tensor=tensor, src=0)\n        print('Rank 1 started receiving')\n    req.wait()\n    print('Rank ', rank, ' has data ', tensor[0]) \n```", "```py\n\"\"\" All-Reduce example.\"\"\"\ndef run(rank, size):\n  \"\"\" Simple collective communication. \"\"\"\n    group = dist.new_group([0, 1])\n    tensor = torch.ones(1)\n    dist.all_reduce(tensor, op=dist.ReduceOp.SUM, group=group)\n    print('Rank ', rank, ' has data ', tensor[0]) \n```", "```py\n\"\"\" Dataset partitioning helper \"\"\"\nclass Partition(object):\n\n    def __init__(self, data, index):\n        self.data = data\n        self.index = index\n\n    def __len__(self):\n        return len(self.index)\n\n    def __getitem__(self, index):\n        data_idx = self.index[index]\n        return self.data[data_idx]\n\nclass DataPartitioner(object):\n\n    def __init__(self, data, sizes=[0.7, 0.2, 0.1], seed=1234):\n        self.data = data\n        self.partitions = []\n        rng = Random()\n        rng.seed(seed)\n        data_len = len(data)\n        indexes = [x for x in range(0, data_len)]\n        rng.shuffle(indexes)\n\n        for frac in sizes:\n            part_len = int(frac * data_len)\n            self.partitions.append(indexes[0:part_len])\n            indexes = indexes[part_len:]\n\n    def use(self, partition):\n        return Partition(self.data, self.partitions[partition]) \n```", "```py\n\"\"\" Partitioning MNIST \"\"\"\ndef partition_dataset():\n    dataset = datasets.MNIST('./data', train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.1307,), (0.3081,))\n                             ]))\n    size = dist.get_world_size()\n    bsz = 128 / float(size)\n    partition_sizes = [1.0 / size for _ in range(size)]\n    partition = DataPartitioner(dataset, partition_sizes)\n    partition = partition.use(dist.get_rank())\n    train_set = torch.utils.data.DataLoader(partition,\n                                         batch_size=bsz,\n                                         shuffle=True)\n    return train_set, bsz \n```", "```py\n\"\"\" Distributed Synchronous SGD Example \"\"\"\ndef run(rank, size):\n    torch.manual_seed(1234)\n    train_set, bsz = partition_dataset()\n    model = Net()\n    optimizer = optim.SGD(model.parameters(),\n                          lr=0.01, momentum=0.5)\n\n    num_batches = ceil(len(train_set.dataset) / float(bsz))\n    for epoch in range(10):\n        epoch_loss = 0.0\n        for data, target in train_set:\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            epoch_loss += loss.item()\n            loss.backward()\n            average_gradients(model)\n            optimizer.step()\n        print('Rank ', dist.get_rank(), ', epoch ',\n              epoch, ': ', epoch_loss / num_batches) \n```", "```py\n\"\"\" Gradient averaging. \"\"\"\ndef average_gradients(model):\n    size = float(dist.get_world_size())\n    for param in model.parameters():\n        dist.all_reduce(param.grad.data, op=dist.ReduceOp.SUM)\n        param.grad.data /= size \n```", "```py\n\"\"\" Implementation of a ring-reduce with addition. \"\"\"\ndef allreduce(send, recv):\n   rank = dist.get_rank()\n   size = dist.get_world_size()\n   send_buff = send.clone()\n   recv_buff = send.clone()\n   accum = send.clone()\n\n   left = ((rank - 1) + size) % size\n   right = (rank + 1) % size\n\n   for i in range(size - 1):\n       if i % 2 == 0:\n           # Send send_buff\n           send_req = dist.isend(send_buff, right)\n           dist.recv(recv_buff, left)\n           accum[:] += recv_buff[:]\n       else:\n           # Send recv_buff\n           send_req = dist.isend(recv_buff, right)\n           dist.recv(send_buff, left)\n           accum[:] += send_buff[:]\n       send_req.wait()\n   recv[:] = accum[:] \n```", "```py\ndist.init_process_group(\n    init_method='file:///mnt/nfs/sharedfile',\n    rank=args.rank,\n    world_size=4) \n```", "```py\ndist.init_process_group(\n    init_method='tcp://10.1.1.20:23456',\n    rank=args.rank,\n    world_size=4) \n```"]