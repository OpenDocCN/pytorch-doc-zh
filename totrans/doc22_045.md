# torch.export

> 原文：[https://pytorch.org/docs/stable/export.html](https://pytorch.org/docs/stable/export.html)

警告

这个功能是一个正在积极开发的原型，未来将会有重大变化。

## 概述

[`torch.export.export()`](#torch.export.export "torch.export.export") 接受一个任意的 Python 可调用对象（一个 [`torch.nn.Module`](generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")、一个函数或一个方法），并以 Ahead-of-Time (AOT) 方式生成一个表示函数的张量计算的追踪图，随后可以用不同的输出或序列化执行。

```py
import torch
from torch.export import export

def f(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    a = torch.sin(x)
    b = torch.cos(y)
    return a + b

example_args = (torch.randn(10, 10), torch.randn(10, 10))

exported_program: torch.export.ExportedProgram = export(
    f, args=example_args
)
print(exported_program) 
```

```py
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, arg0_1: f32[10, 10], arg1_1: f32[10, 10]):
            # code: a = torch.sin(x)
            sin: f32[10, 10] = torch.ops.aten.sin.default(arg0_1);

            # code: b = torch.cos(y)
            cos: f32[10, 10] = torch.ops.aten.cos.default(arg1_1);

            # code: return a + b
            add: f32[10, 10] = torch.ops.aten.add.Tensor(sin, cos);
            return (add,)

    Graph signature: ExportGraphSignature(
        parameters=[],
        buffers=[],
        user_inputs=['arg0_1', 'arg1_1'],
        user_outputs=['add'],
        inputs_to_parameters={},
        inputs_to_buffers={},
        buffers_to_mutate={},
        backward_signature=None,
        assertion_dep_token=None,
    )
    Range constraints: {}
    Equality constraints: [] 
```

`torch.export` 生成一个干净的中间表示（IR），具有以下不变性。关于 IR 的更多规范可以在[这里](export.ir_spec.html#export-ir-spec)找到。

+   **正确性**：它保证是原始程序的正确表示，并保持原始程序的相同调用约定。

+   **标准化**：图中没有 Python 语义。原始程序中的子模块被内联以形成一个完全扁平化的计算图。

+   **定义的操作集**：生成的图仅包含一个小的定义的 [Core ATen IR](torch.compiler_ir.html#torch-compiler-ir) 操作集和注册的自定义操作符。

+   **图属性**：图是纯函数的，意味着它不包含具有副作用的操作，比如突变或别名。它不会改变任何中间值、参数或缓冲区。

+   **元数据**：图中包含在追踪过程中捕获的元数据，比如用户代码的堆栈跟踪。

在幕后，`torch.export` 利用以下最新技术：

+   **TorchDynamo (torch._dynamo)** 是一个内部 API，使用了一个名为 Frame Evaluation API 的 CPython 特性来安全地追踪 PyTorch 图。这提供了一个大大改进的图捕获体验，几乎不需要进行大量重写以完全追踪 PyTorch 代码。

+   **AOT Autograd** 提供了一个功能化的 PyTorch 图，并确保图被分解/降低到小定义的 Core ATen 操作符集。

+   **Torch FX (torch.fx)** 是图的基础表示，允许灵活的基于 Python 的转换。

### 现有框架

[`torch.compile()`](generated/torch.compile.html#torch.compile "torch.compile") 也利用与 `torch.export` 相同的 PT2 栈，但略有不同：

+   **JIT vs. AOT**: [`torch.compile()`](generated/torch.compile.html#torch.compile "torch.compile") 是一个 JIT 编译器，而不是用来生成部署外编译成果的。

+   **部分 vs. 完整图捕获**：当 [`torch.compile()`](generated/torch.compile.html#torch.compile "torch.compile") 遇到模型中无法追踪的部分时，它将“图断裂”，并回退到在急切的 Python 运行时中运行程序。相比之下，`torch.export` 旨在获得 PyTorch 模型的完整图表示，因此当达到无法追踪的内容时会报错。由于 `torch.export` 生成的完整图与任何 Python 特性或运行时无关，因此该图可以保存、加载并在不同环境和语言中运行。

+   **可用性权衡**：由于 [`torch.compile()`](generated/torch.compile.html#torch.compile "torch.compile") 能够在遇到无法追踪的内容时回退到 Python 运行时，因此它更加灵活。相反，`torch.export` 将要求用户提供更多信息或重写他们的代码以使其可追踪。

与[`torch.fx.symbolic_trace()`](fx.html#torch.fx.symbolic_trace "torch.fx.symbolic_trace")相比，`torch.export`使用TorchDynamo进行跟踪，它在Python字节码级别操作，使其能够跟踪任意Python构造，不受Python运算符重载支持的限制。此外，`torch.export`精细跟踪张量元数据，因此对于像张量形状这样的条件语句不会导致跟踪失败。总的来说，预计`torch.export`能够处理更多用户程序，并生成更低级别的图（在`torch.ops.aten`运算符级别）。请注意，用户仍然可以在`torch.export`之前使用[`torch.fx.symbolic_trace()`](fx.html#torch.fx.symbolic_trace "torch.fx.symbolic_trace")作为预处理步骤。

与[`torch.jit.script()`](generated/torch.jit.script.html#torch.jit.script "torch.jit.script")相比，`torch.export`不捕获Python控制流或数据结构，但支持比TorchScript更多的Python语言特性（因为更容易对Python字节码进行全面覆盖）。生成的图更简单，只有直线控制流（除了显式控制流操作）。

与[`torch.jit.trace()`](generated/torch.jit.trace.html#torch.jit.trace "torch.jit.trace")相比，`torch.export`是可靠的：它能够跟踪对大小进行整数计算的代码，并记录所有必要的副条件，以表明特定跟踪对其他输入是有效的。

## 导出PyTorch模型

### 一个例子

主要入口点是通过[`torch.export.export()`](#torch.export.export "torch.export.export")，它接受一个可调用对象（[`torch.nn.Module`](generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")、函数或方法）和示例输入，并将计算图捕获到一个[`torch.export.ExportedProgram`](#torch.export.ExportedProgram "torch.export.ExportedProgram")中。一个例子：

```py
import torch
from torch.export import export

# Simple module for demonstration
class M(torch.nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv = torch.nn.Conv2d(
            in_channels=3, out_channels=16, kernel_size=3, padding=1
        )
        self.relu = torch.nn.ReLU()
        self.maxpool = torch.nn.MaxPool2d(kernel_size=3)

    def forward(self, x: torch.Tensor, *, constant=None) -> torch.Tensor:
        a = self.conv(x)
        a.add_(constant)
        return self.maxpool(self.relu(a))

example_args = (torch.randn(1, 3, 256, 256),)
example_kwargs = {"constant": torch.ones(1, 16, 256, 256)}

exported_program: torch.export.ExportedProgram = export(
    M(), args=example_args, kwargs=example_kwargs
)
print(exported_program) 
```

```py
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, arg0_1: f32[16, 3, 3, 3], arg1_1: f32[16], arg2_1: f32[1, 3, 256, 256], arg3_1: f32[1, 16, 256, 256]):

            # code: a = self.conv(x)
            convolution: f32[1, 16, 256, 256] = torch.ops.aten.convolution.default(
                arg2_1, arg0_1, arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1
            );

            # code: a.add_(constant)
            add: f32[1, 16, 256, 256] = torch.ops.aten.add.Tensor(convolution, arg3_1);

            # code: return self.maxpool(self.relu(a))
            relu: f32[1, 16, 256, 256] = torch.ops.aten.relu.default(add);
            max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(
                relu, [3, 3], [3, 3]
            );
            getitem: f32[1, 16, 85, 85] = max_pool2d_with_indices[0];
            return (getitem,)

    Graph signature: ExportGraphSignature(
        parameters=['L__self___conv.weight', 'L__self___conv.bias'],
        buffers=[],
        user_inputs=['arg2_1', 'arg3_1'],
        user_outputs=['getitem'],
        inputs_to_parameters={
            'arg0_1': 'L__self___conv.weight',
            'arg1_1': 'L__self___conv.bias',
        },
        inputs_to_buffers={},
        buffers_to_mutate={},
        backward_signature=None,
        assertion_dep_token=None,
    )
    Range constraints: {}
    Equality constraints: [] 
```

检查`ExportedProgram`，我们可以注意到以下内容：

+   [`torch.fx.Graph`](fx.html#torch.fx.Graph "torch.fx.Graph")包含原始程序的计算图，以及原始代码的记录，便于调试。

+   图中只包含在[Core ATen IR](torch.compiler_ir.html#torch-compiler-ir) opset中找到的`torch.ops.aten`运算符和自定义运算符，是完全功能的，没有任何像`torch.add_`这样的原位运算符。

+   参数（权重和卷积偏置）被提升为图的输入，导致图中没有`get_attr`节点，这在[`torch.fx.symbolic_trace()`](fx.html#torch.fx.symbolic_trace "torch.fx.symbolic_trace")的结果中以前存在。

+   [`torch.export.ExportGraphSignature`](#torch.export.ExportGraphSignature "torch.export.ExportGraphSignature")模型化了输入和输出签名，并指定了哪些输入是参数。

+   图中每个节点产生的张量的形状和数据类型都有记录。例如，`卷积`节点将产生一个数据类型为`torch.float32`，形状为（1, 16, 256, 256）的张量。

### 表达动态性

默认情况下，`torch.export`将跟踪程序，假设所有输入形状都是**静态**的，并将导出的程序专门化到这些维度。然而，一些维度，如批处理维度，可以是动态的，并且在每次运行时会有所变化。这些维度必须通过使用[`torch.export.Dim()`](#torch.export.Dim "torch.export.Dim") API来指定，并通过将它们传递给[`torch.export.export()`](#torch.export.export "torch.export.export")的`dynamic_shapes`参数来创建它们。例如：

```py
import torch
from torch.export import Dim, export

class M(torch.nn.Module):
    def __init__(self):
        super().__init__()

        self.branch1 = torch.nn.Sequential(
            torch.nn.Linear(64, 32), torch.nn.ReLU()
        )
        self.branch2 = torch.nn.Sequential(
            torch.nn.Linear(128, 64), torch.nn.ReLU()
        )
        self.buffer = torch.ones(32)

    def forward(self, x1, x2):
        out1 = self.branch1(x1)
        out2 = self.branch2(x2)
        return (out1 + self.buffer, out2)

example_args = (torch.randn(32, 64), torch.randn(32, 128))

# Create a dynamic batch size
batch = Dim("batch")
# Specify that the first dimension of each input is that batch size
dynamic_shapes = {"x1": {0: batch}, "x2": {0: batch}}

exported_program: torch.export.ExportedProgram = export(
    M(), args=example_args, dynamic_shapes=dynamic_shapes
)
print(exported_program) 
```

```py
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, arg0_1: f32[32, 64], arg1_1: f32[32], arg2_1: f32[64, 128], arg3_1: f32[64], arg4_1: f32[32], arg5_1: f32[s0, 64], arg6_1: f32[s0, 128]):

            # code: out1 = self.branch1(x1)
            permute: f32[64, 32] = torch.ops.aten.permute.default(arg0_1, [1, 0]);
            addmm: f32[s0, 32] = torch.ops.aten.addmm.default(arg1_1, arg5_1, permute);
            relu: f32[s0, 32] = torch.ops.aten.relu.default(addmm);

            # code: out2 = self.branch2(x2)
            permute_1: f32[128, 64] = torch.ops.aten.permute.default(arg2_1, [1, 0]);
            addmm_1: f32[s0, 64] = torch.ops.aten.addmm.default(arg3_1, arg6_1, permute_1);
            relu_1: f32[s0, 64] = torch.ops.aten.relu.default(addmm_1);  addmm_1 = None

            # code: return (out1 + self.buffer, out2)
            add: f32[s0, 32] = torch.ops.aten.add.Tensor(relu, arg4_1);
            return (add, relu_1)

    Graph signature: ExportGraphSignature(
        parameters=[
            'branch1.0.weight',
            'branch1.0.bias',
            'branch2.0.weight',
            'branch2.0.bias',
        ],
        buffers=['L__self___buffer'],
        user_inputs=['arg5_1', 'arg6_1'],
        user_outputs=['add', 'relu_1'],
        inputs_to_parameters={
            'arg0_1': 'branch1.0.weight',
            'arg1_1': 'branch1.0.bias',
            'arg2_1': 'branch2.0.weight',
            'arg3_1': 'branch2.0.bias',
        },
        inputs_to_buffers={'arg4_1': 'L__self___buffer'},
        buffers_to_mutate={},
        backward_signature=None,
        assertion_dep_token=None,
    )
    Range constraints: {s0: RangeConstraint(min_val=2, max_val=9223372036854775806)}
    Equality constraints: [(InputDim(input_name='arg5_1', dim=0), InputDim(input_name='arg6_1', dim=0))] 
```

一些额外需要注意的事项：

+   通过[`torch.export.Dim()`](#torch.export.Dim "torch.export.Dim") API和`dynamic_shapes`参数，我们指定了每个输入的第一个维度为动态。查看输入`arg5_1`和`arg6_1`，它们具有符号形状（s0，64）和（s0，128），而不是我们传入的示例输入的形状为（32，64）和（32，128）的张量。`s0`是一个表示这个维度可以是一系列值的符号。

+   `exported_program.range_constraints`描述了图中每个符号的范围。在这种情况下，我们看到`s0`的范围为[2，inf]。由于在这里很难解释的技术原因，它们被假定不是0或1。这不是一个错误，并不一定意味着导出的程序不适用于维度0或1。请参阅[0/1专门化问题](https://docs.google.com/document/d/16VPOa3d-Liikf48teAOmxLc92rgvJdfosIy-yoT38Io/edit?fbclid=IwAR3HNwmmexcitV0pbZm_x1a4ykdXZ9th_eJWK-3hBtVgKnrkmemz6Pm5jRQ#heading=h.ez923tomjvyk)以深入讨论这个主题。

+   `exported_program.equality_constraints`描述了哪些维度需要相等。由于我们在约束中指定了每个参数的第一个维度是等价的（`dynamic_dim(example_args[0], 0) == dynamic_dim(example_args[1], 0)`），我们在等式约束中看到了指定`arg5_1`维度0和`arg6_1`维度0相等的元组。

（一种用于指定动态形状的传统机制涉及使用[`torch.export.dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")API标记和约束动态维度，并通过`constraints`参数将它们传递给[`torch.export.export()`](#torch.export.export "torch.export.export")。该机制现在已经**弃用**，并且将来不会得到支持。）

### 序列化

为了保存`ExportedProgram`，用户可以使用[`torch.export.save()`](#torch.export.save "torch.export.save")和[`torch.export.load()`](#torch.export.load "torch.export.load")API。一个惯例是使用`.pt2`文件扩展名保存`ExportedProgram`。

一个例子：

```py
import torch
import io

class MyModule(torch.nn.Module):
    def forward(self, x):
        return x + 10

exported_program = torch.export.export(MyModule(), torch.randn(5))

torch.export.save(exported_program, 'exported_program.pt2')
saved_exported_program = torch.export.load('exported_program.pt2') 
```

### 专门化

#### 输入形状

如前所述，默认情况下，`torch.export`将跟踪程序，专门化输入张量的形状，除非通过[`torch.export.dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")API指定了一个维度为动态。这意味着如果存在形状相关的控制流，`torch.export`将专门化采取给定示例输入的分支。例如：

```py
import torch
from torch.export import export

def fn(x):
    if x.shape[0] > 5:
        return x + 1
    else:
        return x - 1

example_inputs = (torch.rand(10, 2),)
exported_program = export(fn, example_inputs)
print(exported_program) 
```

```py
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, arg0_1: f32[10, 2]):
            add: f32[10, 2] = torch.ops.aten.add.Tensor(arg0_1, 1);
            return (add,) 
```

（`x.shape[0] > 5`）的条件不会出现在`ExportedProgram`中，因为示例输入具有静态形状（10，2）。由于`torch.export`专门针对输入的静态形状，否则分支（`x - 1`）永远不会被执行。为了保留基于张量形状的动态分支行为，需要使用[`torch.export.dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")来指定输入张量（`x.shape[0]`）的维度为动态，并且源代码需要被[重写](#data-shape-dependent-control-flow)。

#### 非张量输入

`torch.export`还根据不是`torch.Tensor`的输入值（如`int`、`float`、`bool`和`str`）专门化跟踪图。然而，我们可能会在不久的将来更改这一点，不再专门化基本类型的输入。

例如：

```py
import torch
from torch.export import export

def fn(x: torch.Tensor, const: int, times: int):
    for i in range(times):
        x = x + const
    return x

example_inputs = (torch.rand(2, 2), 1, 3)
exported_program = export(fn, example_inputs)
print(exported_program) 
```

```py
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, arg0_1: f32[2, 2], arg1_1, arg2_1):
            add: f32[2, 2] = torch.ops.aten.add.Tensor(arg0_1, 1);
            add_1: f32[2, 2] = torch.ops.aten.add.Tensor(add, 1);
            add_2: f32[2, 2] = torch.ops.aten.add.Tensor(add_1, 1);
            return (add_2,) 
```

由于整数是专门化的，`torch.ops.aten.add.Tensor`操作都是使用内联常量`1`计算的，而不是`arg1_1`。此外，在`for`循环中使用的`times`迭代器也通过3个重复的`torch.ops.aten.add.Tensor`调用“内联”在图中，并且输入`arg2_1`从未被使用。

## torch.export[](#limitations-of-torch-export "此标题的永久链接")的限制

### 图中断

由于`torch.export`是从PyTorch程序中捕获计算图的一次性过程，因此最终可能会遇到程序的无法追踪部分，因为几乎不可能支持追踪所有PyTorch和Python功能。在`torch.compile`的情况下，不支持的操作将导致“图中断”，并且不支持的操作将使用默认的Python评估运行。相比之下，`torch.export`将要求用户提供额外信息或重写部分代码以使其可追踪。由于追踪基于TorchDynamo，在Python字节码级别进行评估，相比以前的追踪框架，需要进行的重写将大大减少。

当遇到图形中断时，[ExportDB](generated/exportdb/index.html#torch-export-db)是一个很好的资源，可以了解支持和不支持的程序类型，以及重写程序使其可追踪的方法。

### 数据/形状相关的控制流[](#data-shape-dependent-control-flow "跳转到此标题")

当遇到数据相关的控制流（`if x.shape[0] > 2`）时，也可能出现图形中断，因为在没有专门化形状的情况下，追踪编译器无法处理生成代码的组合爆炸路径。在这种情况下，用户需要使用特殊的控制流操作符重写他们的代码。目前，我们支持[torch.cond](cond.html#cond)来表达类似if-else的控制流（更多功能即将推出！）。

### 操作符缺失的元内核[](#missing-meta-kernels-for-operators "跳转到此标题")

在追踪时，所有操作符都需要一个META实现（或“元内核”）来推断该操作符的输入/输出形状。

要为C++自定义操作符注册一个元内核，请参考[此文档](https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit#heading=h.ahugy69p2jmz)。

目前正在开发用于在Python中实现自定义操作符的自定义元内核的官方API。在最终API得到完善之前，您可以参考[此文档](https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0)。

如果您的模型使用了尚未具有元内核实现的ATen操作符，请提交问题。

## 阅读更多

Export用户的其他链接

+   [torch.export IR规范](export.ir_spec.html)

+   [在ATen IR上编写图形转换](torch.compiler_transformations.html)

+   [IRs](torch.compiler_ir.html)

+   [ExportDB](generated/exportdb/index.html)

+   [控制流 - Cond](cond.html)

PyTorch开发者深入了解

+   [TorchDynamo深入了解](torch.compiler_deepdive.html)

+   [动态形状](torch.compiler_dynamic_shapes.html)

+   [虚假张量](torch.compiler_fake_tensor.html)

## API参考

```py
torch.export.export(f, args, kwargs=None, *, constraints=None, dynamic_shapes=None, strict=True, preserve_module_call_signature=())¶
```

[`export()`](#torch.export.export "torch.export.export")接受任意的Python可调用对象（nn.Module、函数或方法）以及示例输入，并以Ahead-of-Time（AOT）方式生成表示函数的张量计算的追踪图，随后可以使用不同的输入或序列化执行。追踪图（1）生成功能性ATen操作符集中的标准化操作符（以及任何用户指定的自定义操作符），（2）消除了所有Python控制流和数据结构（某些例外情况除外），（3）记录了为了证明这种标准化和控制流消除对未来输入是有效的所需的形状约束集。

**正确性保证**

在追踪过程中，[`export()`](#torch.export.export "torch.export.export")会注意用户程序和底层PyTorch操作符内核所做的与形状相关的假设。只有当这些假设成立时，输出的[`ExportedProgram`](#torch.export.ExportedProgram "torch.export.ExportedProgram")才被认为有效。

追踪对输入张量的形状（而不是值）做出假设。这些假设必须在图捕获时验证，以便[`export()`](#torch.export.export "torch.export.export")成功。具体来说：

+   对输入张量的静态形状的假设将自动验证，无需额外努力。

+   对输入张量的动态形状的假设需要通过使用[`Dim()`](#torch.export.Dim "torch.export.Dim") API显式指定，并通过将其与示例输入关联到`dynamic_shapes`参数中。

如果任何假设无法验证，将引发致命错误。当发生这种情况时，错误消息将包含建议的修复，以验证假设所需的规范。例如，[`export()`](#torch.export.export "torch.export.export")可能会建议以下修复动态维度`dim0_x`的定义，例如出现在与输入`x`相关联的形状中，先前定义为`Dim("dim0_x")`：

```py
dim = Dim("dim0_x", max=5) 
```

这个示例表示生成的代码要求输入`x`的维度0小于或等于5才有效。您可以检查动态维度定义的建议修复，并将其逐字复制到您的代码中，而无需更改对[`export()`](#torch.export.export "torch.export.export")的调用中的`dynamic_shapes`参数。

参数

+   **f**（[*Callable*](https://docs.python.org/3/library/typing.html#typing.Callable "(在Python v3.12版本)")）– 要追踪的可调用函数。

+   **args**（[*Tuple*](https://docs.python.org/3/library/typing.html#typing.Tuple "(在Python v3.12版本)")*[*[*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在Python v3.12版本)")*,* *...**]*) – 示例位置输入。

+   **kwargs**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12版本)")*[*[*Dict*](https://docs.python.org/3/library/typing.html#typing.Dict "(在Python v3.12版本)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12版本)")*,* [*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在Python v3.12版本)")*]**]*) – 可选的示例关键字输入。

+   **constraints**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12版本)")*[*[*List*](https://docs.python.org/3/library/typing.html#typing.List "(在Python v3.12版本)")*[*[*Constraint*](#torch.export.Constraint "torch.export.Constraint")*]**]*) – [已弃用：请改用`dynamic_shapes`，请参见下文] 动态参数的约束条件列表，指定它们可能的形状范围。默认情况下，假定输入torch.Tensors的形状是静态的。如果预期输入torch.Tensor具有动态形状，请使用[`dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")来定义[`Constraint`](#torch.export.Constraint "torch.export.Constraint")对象，指定动态性和可能的形状范围。查看[`dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")文档字符串，了解如何使用的示例。

+   **dynamic_shapes**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional "(在Python v3.12版本)")*[*[*Union*](https://docs.python.org/3/library/typing.html#typing.Union "(在Python v3.12版本)")*[*[*Dict*](https://docs.python.org/3/library/typing.html#typing.Dict "(在Python v3.12版本)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12版本)")*,* [*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在Python v3.12版本)")*]**,* [*Tuple*](https://docs.python.org/3/library/typing.html#typing.Tuple "(在Python v3.12版本)")*[*[*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在Python v3.12版本)")*]**]**]*) –

    应为：1）从`f`的参数名称到其动态形状规范的字典，2）指定原始顺序中每个输入的动态形状规范的元组。如果您在关键字参数上指定动态性，您需要按照原始函数签名中定义的顺序传递它们。

    张量参数的动态形状可以指定为（1）从动态维度索引到[`Dim()`](#torch.export.Dim "torch.export.Dim")类型的字典，其中在此字典中不需要包含静态维度索引，但当包含时，应将其映射到None；或（2）[`Dim()`](#torch.export.Dim "torch.export.Dim")类型或None的元组/列表，其中[`Dim()`](#torch.export.Dim "torch.export.Dim")类型对应于动态维度，静态维度用None表示。通过使用包含规范的映射或序列，递归指定为字典或张量的元组/列表的参数。

+   **strict**（[*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.12)")） - 启用时（默认），导出函数将通过TorchDynamo跟踪程序，确保生成的图的完整性。否则，导出的程序将不验证嵌入到图中的隐含假设，可能导致原始模型和导出模型之间的行为分歧。当用户需要解决跟踪器中的错误或希望逐步在其模型中启用安全性时，这是有用的。请注意，这不会影响生成的IR规范不同，无论传递什么值，模型都将以相同的方式序列化。警告：此选项是实验性的，请自行承担风险使用。

返回

包含跟踪可调用程序的[`ExportedProgram`](#torch.export.ExportedProgram "torch.export.ExportedProgram")。

返回类型

[*ExportedProgram*](#torch.export.ExportedProgram "torch.export.exported_program.ExportedProgram")

**可接受的输入/输出类型**

可接受的输入（对于`args`和`kwargs`）和输出类型包括：

+   原始类型，即`torch.Tensor`、`int`、`float`、`bool`和`str`。

+   数据类，但必须通过调用[`register_dataclass()`](#torch.export.register_dataclass "torch.export.register_dataclass")进行注册。

+   包含所有上述类型的`dict`、`list`、`tuple`、`namedtuple`和`OrderedDict`组成的（嵌套）数据结构。

```py
torch.export.dynamic_dim(t, index)¶
```

警告

（此功能已弃用。请改用[`Dim()`](#torch.export.Dim "torch.export.Dim")。）

[`dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")构造一个描述张量`t`的维度`index`的动态性的[`Constraint`](#torch.export.Constraint "torch.export.Constraint")对象。应将[`Constraint`](#torch.export.Constraint "torch.export.Constraint")对象传递给[`export()`](#torch.export.export "torch.export.export")的`constraints`参数。

参数

+   **t**（[*torch.Tensor*](tensors.html#torch.Tensor "torch.Tensor")） - 具有动态维度大小的示例输入张量

+   **index**（[*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")） - 动态维度的索引

返回

描述形状动态性的[`Constraint`](#torch.export.Constraint "torch.export.Constraint")对象。它可以传递给[`export()`](#torch.export.export "torch.export.export")，以便[`export()`](#torch.export.export "torch.export.export")不会假定指定张量的静态大小，即保持其动态作为符号大小，而不是根据示例跟踪输入的大小进行特化。

具体来说，[`dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")可用于表示以下类型的动态性。

+   维度大小是动态且无限制的：

    ```py
    t0 = torch.rand(2, 3)
    t1 = torch.rand(3, 4)

    # First dimension of t0 can be dynamic size rather than always being static size 2
    constraints = [dynamic_dim(t0, 0)]
    ep = export(fn, (t0, t1), constraints=constraints) 
    ```

+   维度大小是动态的，有一个下限：

    ```py
    t0 = torch.rand(10, 3)
    t1 = torch.rand(3, 4)

    # First dimension of t0 can be dynamic size with a lower bound of 5 (inclusive)
    # Second dimension of t1 can be dynamic size with a lower bound of 2 (exclusive)
    constraints = [
        dynamic_dim(t0, 0) >= 5,
        dynamic_dim(t1, 1) > 2,
    ]
    ep = export(fn, (t0, t1), constraints=constraints) 
    ```

+   维度大小是动态的，有一个上限：

    ```py
    t0 = torch.rand(10, 3)
    t1 = torch.rand(3, 4)

    # First dimension of t0 can be dynamic size with a upper bound of 16 (inclusive)
    # Second dimension of t1 can be dynamic size with a upper bound of 8 (exclusive)
    constraints = [
        dynamic_dim(t0, 0) <= 16,
        dynamic_dim(t1, 1) < 8,
    ]
    ep = export(fn, (t0, t1), constraints=constraints) 
    ```

+   维度的大小是动态的，它始终等于另一个动态维度的大小：

    ```py
    t0 = torch.rand(10, 3)
    t1 = torch.rand(3, 4)

    # Sizes of second dimension of t0 and first dimension are always equal
    constraints = [
        dynamic_dim(t0, 1) == dynamic_dim(t1, 0),
    ]
    ep = export(fn, (t0, t1), constraints=constraints) 
    ```

+   可以混合匹配上述所有类型，只要它们不表达冲突的要求

```py
torch.export.save(ep, f, *, extra_files=None, opset_version=None)¶
```

警告

正在积极开发中，保存的文件可能无法在较新版本的PyTorch中使用。

将[`ExportedProgram`](#torch.export.ExportedProgram "torch.export.ExportedProgram")保存到类似文件的对象中。然后可以使用Python API [`torch.export.load`](#torch.export.load "torch.export.load")加载它。

参数

+   **ep** ([*ExportedProgram*](#torch.export.ExportedProgram "torch.export.ExportedProgram")) – 要保存的导出程序。

+   **f** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")*,* [*pathlib.Path*](https://docs.python.org/3/library/pathlib.html#pathlib.Path "(in Python v3.12)")*,* [*io.BytesIO*](https://docs.python.org/3/library/io.html#io.BytesIO "(in Python v3.12)")) – 类似文件的对象（必须实现write和flush）或包含文件名的字符串。

+   **extra_files** (*Optional**[**Dict**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")*,* *Any**]**]*) – 从文件名到内容的映射，这些内容将作为f的一部分存储。

+   **opset_version** (*Optional**[**Dict**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")*]**]*) – opset名称与此opset版本的映射

示例：

```py
import torch
import io

class MyModule(torch.nn.Module):
    def forward(self, x):
        return x + 10

ep = torch.export.export(MyModule(), (torch.randn(5),))

# Save to file
torch.export.save(ep, 'exported_program.pt2')

# Save to io.BytesIO buffer
buffer = io.BytesIO()
torch.export.save(ep, buffer)

# Save with extra files
extra_files = {'foo.txt': b'bar'.decode('utf-8')}
torch.export.save(ep, 'exported_program.pt2', extra_files=extra_files) 
```

```py
torch.export.load(f, *, extra_files=None, expected_opset_version=None)¶
```

警告

正在积极开发中，保存的文件可能无法在较新版本的PyTorch中使用。

加载以前使用[`torch.export.save`](#torch.export.save "torch.export.save")保存的[`ExportedProgram`](#torch.export.ExportedProgram "torch.export.ExportedProgram")。

参数

+   **ep** ([*ExportedProgram*](#torch.export.ExportedProgram "torch.export.ExportedProgram")) – 要保存的导出程序。

+   **f** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")*,* [*pathlib.Path*](https://docs.python.org/3/library/pathlib.html#pathlib.Path "(in Python v3.12)")*,* [*io.BytesIO*](https://docs.python.org/3/library/io.html#io.BytesIO "(in Python v3.12)")) – 类似文件的对象（必须实现write和flush）或包含文件名的字符串。

+   **extra_files** (*Optional**[**Dict**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")*,* *Any**]**]*) – 此映射中提供的额外文件名将被加载，其内容将存储在提供的映射中。

+   **expected_opset_version** (*Optional**[**Dict**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.12)")*]**]*) – opset名称到预期opset版本的映射

返回

一个[`ExportedProgram`](#torch.export.ExportedProgram "torch.export.ExportedProgram")对象

返回类型

[*ExportedProgram*](#torch.export.ExportedProgram "torch.export.exported_program.ExportedProgram")

示例：

```py
import torch
import io

# Load ExportedProgram from file
ep = torch.export.load('exported_program.pt2')

# Load ExportedProgram from io.BytesIO object
with open('exported_program.pt2', 'rb') as f:
    buffer = io.BytesIO(f.read())
buffer.seek(0)
ep = torch.export.load(buffer)

# Load with extra files.
extra_files = {'foo.txt': ''}  # values will be replaced with data
ep = torch.export.load('exported_program.pt2', extra_files=extra_files)
print(extra_files['foo.txt'])
print(ep(torch.randn(5))) 
```

```py
torch.export.register_dataclass(cls)¶
```

将数据类注册为[`torch.export.export()`](#torch.export.export "torch.export.export")的有效输入/输出类型。

参数

**cls** ([*Type*](https://docs.python.org/3/library/typing.html#typing.Type "(in Python v3.12)")*[*[*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(in Python v3.12)")*]*) – 要注册的数据类类型

示例：

```py
@dataclass
class InputDataClass:
    feature: torch.Tensor
    bias: int

class OutputDataClass:
    res: torch.Tensor

torch.export.register_dataclass(InputDataClass)
torch.export.register_dataclass(OutputDataClass)

def fn(o: InputDataClass) -> torch.Tensor:
    res = res=o.feature + o.bias
    return OutputDataClass(res=res)

ep = torch.export.export(fn, (InputDataClass(torch.ones(2, 2), 1), ))
print(ep) 
```

```py
torch.export.Dim(name, *, min=None, max=None)¶
```

[`Dim()`](#torch.export.Dim "torch.export.Dim")构造类似于具有范围的命名符号整数的类型。它可用于描述动态张量维度的多个可能值。请注意，同一张量的不同动态维度，或不同张量的动态维度，可以由相同类型描述。

参数

+   **name** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")) – 用于调试的人类可读名称。

+   **min** (*可选**[*[*整数*](https://docs.python.org/3/library/functions.html#int "(在Python v3.12中)")*]*) – 给定符号的最小可能值（包括）

+   **max** (*可选**[*[*整数*](https://docs.python.org/3/library/functions.html#int "(在Python v3.12中)")*]*) – 给定符号的最大可能值（包括）

返回

可以在张量的动态形状规范中使用的类型。

```py
torch.export.dims(*names, min=None, max=None)¶
```

用于创建多个[`Dim()`](#torch.export.Dim "torch.export.Dim")类型的工具。

```py
class torch.export.Constraint(*args, **kwargs)¶
```

警告

不要直接构造[`Constraint`](#torch.export.Constraint "torch.export.Constraint")，而是使用[`dynamic_dim()`](#torch.export.dynamic_dim "torch.export.dynamic_dim")。

这代表了对输入张量维度的约束，例如，要求它们是完全多态的或在某个范围内。

```py
class torch.export.ExportedProgram(root, graph, graph_signature, state_dict, range_constraints, equality_constraints, module_call_graph, example_inputs=None, verifier=None, tensor_constants=None)¶
```

从[`export()`](#torch.export.export "torch.export.export")导出的程序的包。它包含一个表示张量计算的torch.fx.Graph，一个包含所有提升参数和缓冲区的张量值的state_dict，以及各种元数据。

您可以像使用[`export()`](#torch.export.export "torch.export.export")跟踪的原始可调用对象一样调用ExportedProgram，使用相同的调用约定。

要对图进行转换，请使用`.module`属性来访问[`torch.fx.GraphModule`](fx.html#torch.fx.GraphModule "torch.fx.GraphModule")。然后，您可以使用[FX转换](https://pytorch.org/docs/stable/fx.html#writing-transformations)来重写图。之后，您可以简单地再次使用[`export()`](#torch.export.export "torch.export.export")来构建一个正确的ExportedProgram。

```py
module(*, flat=True)¶
```

返回一个包含所有参数/缓冲区的自包含GraphModule。

返回类型

[*模块*](generated/torch.nn.Module.html#torch.nn.Module "torch.nn.modules.module.Module")

```py
buffers()¶
```

返回一个迭代器，遍历原始模块缓冲区。

警告

这个API是实验性的，*不*向后兼容。

返回类型

[*迭代器*](https://docs.python.org/3/library/typing.html#typing.Iterator "(在Python v3.12中)")[[*张量*](tensors.html#torch.Tensor "torch.Tensor")]

```py
named_buffers()¶
```

返回一个迭代器，遍历原始模块缓冲区，同时产生缓冲区的名称和缓冲区本身。

警告

这个API是实验性的，*不*向后兼容。

返回类型

[*迭代器*](https://docs.python.org/3/library/typing.html#typing.Iterator "(在Python v3.12中)")[[*元组*](https://docs.python.org/3/library/typing.html#typing.Tuple "(在Python v3.12中)")[[str](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)"), [*张量*](tensors.html#torch.Tensor "torch.Tensor")]]

```py
parameters()¶
```

返回一个迭代器，遍历原始模块的参数。

警告

这个API是实验性的，*不*向后兼容。

返回类型

[*迭代器*](https://docs.python.org/3/library/typing.html#typing.Iterator "(在Python v3.12中)")[[*参数*](generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter "torch.nn.parameter.Parameter")]

```py
named_parameters()¶
```

返回一个迭代器，遍历原始模块参数，同时产生参数的名称和参数本身。

警告

这个API是实验性的，*不*向后兼容。

返回类型

[*迭代器*](https://docs.python.org/3/library/typing.html#typing.Iterator "(在Python v3.12中)")[[*元组*](https://docs.python.org/3/library/typing.html#typing.Tuple "(在Python v3.12中)")[[str](https://docs.python.org/3/library/stdtypes.html#str "(在Python v3.12中)"), [*参数*](generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter "torch.nn.parameter.Parameter")]]

```py
class torch.export.ExportBackwardSignature(gradients_to_parameters: Dict[str, str], gradients_to_user_inputs: Dict[str, str], loss_output: str)¶
```

```py
class torch.export.ExportGraphSignature(input_specs, output_specs)¶
```

[`ExportGraphSignature`](#torch.export.ExportGraphSignature "torch.export.ExportGraphSignature") 模型化导出图的输入/输出签名，这是一个具有更强不变性保证的fx.Graph。

导出图是功能性的，不会通过`getattr`节点访问图中的“状态”（如参数或缓冲区）。相反，[`export()`](#torch.export.export "torch.export.export")保证参数、缓冲区和常量张量被提取出图形作为输入。同样，对缓冲区的任何突变也不包括在图中，而是将突变缓冲区的更新值建模为导出图的附加输出。

所有输入和输出的顺序是：

```py
Inputs = [*parameters_buffers_constant_tensors, *flattened_user_inputs]
Outputs = [*mutated_inputs, *flattened_user_outputs] 
```

例如，如果以下模块被导出：

```py
class CustomModule(nn.Module):
    def __init__(self):
        super(CustomModule, self).__init__()

        # Define a parameter
        self.my_parameter = nn.Parameter(torch.tensor(2.0))

        # Define two buffers
        self.register_buffer('my_buffer1', torch.tensor(3.0))
        self.register_buffer('my_buffer2', torch.tensor(4.0))

    def forward(self, x1, x2):
        # Use the parameter, buffers, and both inputs in the forward method
        output = (x1 + self.my_parameter) * self.my_buffer1 + x2 * self.my_buffer2

        # Mutate one of the buffers (e.g., increment it by 1)
        self.my_buffer2.add_(1.0) # In-place addition

        return output 
```

生成的图将是：

```py
graph():
    %arg0_1 := placeholder[target=arg0_1]
    %arg1_1 := placeholder[target=arg1_1]
    %arg2_1 := placeholder[target=arg2_1]
    %arg3_1 := placeholder[target=arg3_1]
    %arg4_1 := placeholder[target=arg4_1]
    %add_tensor := call_function[target=torch.ops.aten.add.Tensor](args = (%arg3_1, %arg0_1), kwargs = {})
    %mul_tensor := call_function[target=torch.ops.aten.mul.Tensor](args = (%add_tensor, %arg1_1), kwargs = {})
    %mul_tensor_1 := call_function[target=torch.ops.aten.mul.Tensor](args = (%arg4_1, %arg2_1), kwargs = {})
    %add_tensor_1 := call_function[target=torch.ops.aten.add.Tensor](args = (%mul_tensor, %mul_tensor_1), kwargs = {})
    %add_tensor_2 := call_function[target=torch.ops.aten.add.Tensor](args = (%arg2_1, 1.0), kwargs = {})
    return (add_tensor_2, add_tensor_1) 
```

生成的ExportGraphSignature将是：

```py
ExportGraphSignature(
    input_specs=[
        InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='arg0_1'), target='my_parameter'),
        InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='arg1_1'), target='my_buffer1'),
        InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='arg2_1'), target='my_buffer2'),
        InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='arg3_1'), target=None),
        InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='arg4_1'), target=None)
    ],
    output_specs=[
        OutputSpec(kind=<OutputKind.BUFFER_MUTATION: 3>, arg=TensorArgument(name='add_2'), target='my_buffer2'),
        OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='add_1'), target=None)
    ]
) 
```

```py
class torch.export.ModuleCallSignature(inputs: List[Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument]], outputs: List[Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument]], in_spec: torch.utils._pytree.TreeSpec, out_spec: torch.utils._pytree.TreeSpec)¶
```

```py
class torch.export.ModuleCallEntry(fqn: str, signature: Union[torch.export.exported_program.ModuleCallSignature, NoneType] = None)¶
```

```py
class torch.export.graph_signature.InputKind(value)¶
```

一个枚举。

```py
class torch.export.graph_signature.InputSpec(kind: torch.export.graph_signature.InputKind, arg: Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument], target: Union[str, NoneType])¶
```

```py
class torch.export.graph_signature.OutputKind(value)¶
```

一个枚举。

```py
class torch.export.graph_signature.OutputSpec(kind: torch.export.graph_signature.OutputKind, arg: Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument], target: Union[str, NoneType])¶
```

```py
class torch.export.graph_signature.ExportGraphSignature(input_specs, output_specs)¶
```

[`ExportGraphSignature`](#torch.export.graph_signature.ExportGraphSignature "torch.export.graph_signature.ExportGraphSignature")模拟了导出图的输入/输出签名，这是一个具有更强不变性保证的fx.Graph。

导出图是功能性的，不会通过`getattr`节点访问图中的“状态”（如参数或缓冲区）。相反，`export()`保证参数、缓冲区和常量张量被提取出图形作为输入。同样，对缓冲区的任何突变也不包括在图中，而是将突变缓冲区的更新值建模为导出图的附加输出。

所有输入和输出的顺序是：

```py
Inputs = [*parameters_buffers_constant_tensors, *flattened_user_inputs]
Outputs = [*mutated_inputs, *flattened_user_outputs] 
```

例如，如果以下模块被导出：

```py
class CustomModule(nn.Module):
    def __init__(self):
        super(CustomModule, self).__init__()

        # Define a parameter
        self.my_parameter = nn.Parameter(torch.tensor(2.0))

        # Define two buffers
        self.register_buffer('my_buffer1', torch.tensor(3.0))
        self.register_buffer('my_buffer2', torch.tensor(4.0))

    def forward(self, x1, x2):
        # Use the parameter, buffers, and both inputs in the forward method
        output = (x1 + self.my_parameter) * self.my_buffer1 + x2 * self.my_buffer2

        # Mutate one of the buffers (e.g., increment it by 1)
        self.my_buffer2.add_(1.0) # In-place addition

        return output 
```

生成的图将是：

```py
graph():
    %arg0_1 := placeholder[target=arg0_1]
    %arg1_1 := placeholder[target=arg1_1]
    %arg2_1 := placeholder[target=arg2_1]
    %arg3_1 := placeholder[target=arg3_1]
    %arg4_1 := placeholder[target=arg4_1]
    %add_tensor := call_function[target=torch.ops.aten.add.Tensor](args = (%arg3_1, %arg0_1), kwargs = {})
    %mul_tensor := call_function[target=torch.ops.aten.mul.Tensor](args = (%add_tensor, %arg1_1), kwargs = {})
    %mul_tensor_1 := call_function[target=torch.ops.aten.mul.Tensor](args = (%arg4_1, %arg2_1), kwargs = {})
    %add_tensor_1 := call_function[target=torch.ops.aten.add.Tensor](args = (%mul_tensor, %mul_tensor_1), kwargs = {})
    %add_tensor_2 := call_function[target=torch.ops.aten.add.Tensor](args = (%arg2_1, 1.0), kwargs = {})
    return (add_tensor_2, add_tensor_1) 
```

生成的ExportGraphSignature将是：

```py
ExportGraphSignature(
    input_specs=[
        InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='arg0_1'), target='my_parameter'),
        InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='arg1_1'), target='my_buffer1'),
        InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='arg2_1'), target='my_buffer2'),
        InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='arg3_1'), target=None),
        InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='arg4_1'), target=None)
    ],
    output_specs=[
        OutputSpec(kind=<OutputKind.BUFFER_MUTATION: 3>, arg=TensorArgument(name='add_2'), target='my_buffer2'),
        OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='add_1'), target=None)
    ]
) 
```

```py
replace_all_uses(old, new)¶
```

在签名中用新名称替换所有旧名称的用法。
