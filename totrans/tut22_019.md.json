["```py\nimport torch\n\nclass TinyModel([torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n\n    def __init__(self):\n        super([TinyModel](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n\n        self.linear1 = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(100, 200)\n        self.activation = [torch.nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \"torch.nn.ReLU\")()\n        self.linear2 = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(200, 10)\n        self.softmax = [torch.nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax \"torch.nn.Softmax\")()\n\n    def forward(self, [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")):\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = self.linear1([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = self.activation([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = self.linear2([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = self.softmax([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        return [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n\ntinymodel = [TinyModel](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")()\n\nprint('The model:')\nprint(tinymodel)\n\nprint('\\n\\nJust one layer:')\nprint([tinymodel.linear2](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\"))\n\nprint('\\n\\nModel params:')\nfor [param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\") in [tinymodel.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")():\n    print([param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\"))\n\nprint('\\n\\nLayer params:')\nfor [param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\") in [tinymodel.linear2.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")():\n    print([param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\")) \n```", "```py\nThe model:\nTinyModel(\n  (linear1): Linear(in_features=100, out_features=200, bias=True)\n  (activation): ReLU()\n  (linear2): Linear(in_features=200, out_features=10, bias=True)\n  (softmax): Softmax(dim=None)\n)\n\nJust one layer:\nLinear(in_features=200, out_features=10, bias=True)\n\nModel params:\nParameter containing:\ntensor([[ 0.0765,  0.0830, -0.0234,  ..., -0.0337, -0.0355, -0.0968],\n        [-0.0573,  0.0250, -0.0132,  ..., -0.0060,  0.0240,  0.0280],\n        [-0.0908, -0.0369,  0.0842,  ..., -0.0078, -0.0333, -0.0324],\n        ...,\n        [-0.0273, -0.0162, -0.0878,  ...,  0.0451,  0.0297, -0.0722],\n        [ 0.0833, -0.0874, -0.0020,  ..., -0.0215,  0.0356,  0.0405],\n        [-0.0637,  0.0190, -0.0571,  ..., -0.0874,  0.0176,  0.0712]],\n       requires_grad=True)\nParameter containing:\ntensor([ 0.0304, -0.0758, -0.0549, -0.0893, -0.0809, -0.0804, -0.0079, -0.0413,\n        -0.0968,  0.0888,  0.0239, -0.0659, -0.0560, -0.0060,  0.0660, -0.0319,\n        -0.0370,  0.0633, -0.0143, -0.0360,  0.0670, -0.0804,  0.0265, -0.0870,\n         0.0039, -0.0174, -0.0680, -0.0531,  0.0643,  0.0794,  0.0209,  0.0419,\n         0.0562, -0.0173, -0.0055,  0.0813,  0.0613, -0.0379,  0.0228,  0.0304,\n        -0.0354,  0.0609, -0.0398,  0.0410,  0.0564, -0.0101, -0.0790, -0.0824,\n        -0.0126,  0.0557,  0.0900,  0.0597,  0.0062, -0.0108,  0.0112, -0.0358,\n        -0.0203,  0.0566, -0.0816, -0.0633, -0.0266, -0.0624, -0.0746,  0.0492,\n         0.0450,  0.0530, -0.0706,  0.0308,  0.0533,  0.0202, -0.0469, -0.0448,\n         0.0548,  0.0331,  0.0257, -0.0764, -0.0892,  0.0783,  0.0062,  0.0844,\n        -0.0959, -0.0468, -0.0926,  0.0925,  0.0147,  0.0391,  0.0765,  0.0059,\n         0.0216, -0.0724,  0.0108,  0.0701, -0.0147, -0.0693, -0.0517,  0.0029,\n         0.0661,  0.0086, -0.0574,  0.0084, -0.0324,  0.0056,  0.0626, -0.0833,\n        -0.0271, -0.0526,  0.0842, -0.0840, -0.0234, -0.0898, -0.0710, -0.0399,\n         0.0183, -0.0883, -0.0102, -0.0545,  0.0706, -0.0646, -0.0841, -0.0095,\n        -0.0823, -0.0385,  0.0327, -0.0810, -0.0404,  0.0570,  0.0740,  0.0829,\n         0.0845,  0.0817, -0.0239, -0.0444, -0.0221,  0.0216,  0.0103, -0.0631,\n         0.0831, -0.0273,  0.0756,  0.0022,  0.0407,  0.0072,  0.0374, -0.0608,\n         0.0424, -0.0585,  0.0505, -0.0455,  0.0268, -0.0950, -0.0642,  0.0843,\n         0.0760, -0.0889, -0.0617, -0.0916,  0.0102, -0.0269, -0.0011,  0.0318,\n         0.0278, -0.0160,  0.0159, -0.0817,  0.0768, -0.0876, -0.0524, -0.0332,\n        -0.0583,  0.0053,  0.0503, -0.0342, -0.0319, -0.0562,  0.0376, -0.0696,\n         0.0735,  0.0222, -0.0775, -0.0072,  0.0294,  0.0994, -0.0355, -0.0809,\n        -0.0539,  0.0245,  0.0670,  0.0032,  0.0891, -0.0694, -0.0994,  0.0126,\n         0.0629,  0.0936,  0.0058, -0.0073,  0.0498,  0.0616, -0.0912, -0.0490],\n       requires_grad=True)\nParameter containing:\ntensor([[ 0.0504, -0.0203, -0.0573,  ...,  0.0253,  0.0642, -0.0088],\n        [-0.0078, -0.0608, -0.0626,  ..., -0.0350, -0.0028, -0.0634],\n        [-0.0317, -0.0202, -0.0593,  ..., -0.0280,  0.0571, -0.0114],\n        ...,\n        [ 0.0582, -0.0471, -0.0236,  ...,  0.0273,  0.0673,  0.0555],\n        [ 0.0258, -0.0706,  0.0315,  ..., -0.0663, -0.0133,  0.0078],\n        [-0.0062,  0.0544, -0.0280,  ..., -0.0303, -0.0326, -0.0462]],\n       requires_grad=True)\nParameter containing:\ntensor([ 0.0385, -0.0116,  0.0703,  0.0407, -0.0346, -0.0178,  0.0308, -0.0502,\n         0.0616,  0.0114], requires_grad=True)\n\nLayer params:\nParameter containing:\ntensor([[ 0.0504, -0.0203, -0.0573,  ...,  0.0253,  0.0642, -0.0088],\n        [-0.0078, -0.0608, -0.0626,  ..., -0.0350, -0.0028, -0.0634],\n        [-0.0317, -0.0202, -0.0593,  ..., -0.0280,  0.0571, -0.0114],\n        ...,\n        [ 0.0582, -0.0471, -0.0236,  ...,  0.0273,  0.0673,  0.0555],\n        [ 0.0258, -0.0706,  0.0315,  ..., -0.0663, -0.0133,  0.0078],\n        [-0.0062,  0.0544, -0.0280,  ..., -0.0303, -0.0326, -0.0462]],\n       requires_grad=True)\nParameter containing:\ntensor([ 0.0385, -0.0116,  0.0703,  0.0407, -0.0346, -0.0178,  0.0308, -0.0502,\n         0.0616,  0.0114], requires_grad=True) \n```", "```py\n[lin](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\") = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(3, 2)\n[x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(1, 3)\nprint('Input:')\nprint([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\nprint('\\n\\nWeight and Bias parameters:')\nfor [param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\") in [lin.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")():\n    print([param](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter \"torch.nn.parameter.Parameter\"))\n\n[y](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [lin](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint('\\n\\nOutput:')\nprint([y](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nInput:\ntensor([[0.8790, 0.9774, 0.2547]])\n\nWeight and Bias parameters:\nParameter containing:\ntensor([[ 0.1656,  0.4969, -0.4972],\n        [-0.2035, -0.2579, -0.3780]], requires_grad=True)\nParameter containing:\ntensor([0.3768, 0.3781], requires_grad=True)\n\nOutput:\ntensor([[ 0.8814, -0.1492]], grad_fn=<AddmmBackward0>) \n```", "```py\nimport torch.functional as F\n\nclass LeNet([torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n\n    def __init__(self):\n        super([LeNet](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(1, 6, 5)\n        self.conv2 = [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(6, 16, 3)\n        # an affine operation: y = Wx + b\n        self.fc1 = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(16 * 6 * 6, 120)  # 6*6 from image dimension\n        self.fc2 = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(120, 84)\n        self.fc3 = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(84, 10)\n\n    def forward(self, [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")):\n        # Max pooling over a (2, 2) window\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = F.max_pool2d(F.relu(self.conv1([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))), (2, 2))\n        # If the size is a square you can only specify a single number\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = F.max_pool2d(F.relu(self.conv2([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))), 2)\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").view(-1, self.num_flat_features([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = F.relu(self.fc1([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = F.relu(self.fc2([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\n        [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = self.fc3([x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n        return [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")\n\n    def num_flat_features(self, [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")):\n        size = [x](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features \n```", "```py\nclass LSTMTagger([torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n        super([LSTMTagger](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.hidden_dim = hidden_dim\n\n        self.word_embeddings = [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding \"torch.nn.Embedding\")(vocab_size, embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = [torch.nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM \"torch.nn.LSTM\")(embedding_dim, hidden_dim)\n\n        # The linear layer that maps from hidden state space to tag space\n        self.hidden2tag = [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(hidden_dim, tagset_size)\n\n    def forward(self, sentence):\n        embeds = self.word_embeddings(sentence)\n        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n        tag_scores = F.log_softmax(tag_space, dim=1)\n        return tag_scores \n```", "```py\n[my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(1, 6, 6)\nprint([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\n[maxpool_layer](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d \"torch.nn.MaxPool2d\") = [torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d \"torch.nn.MaxPool2d\")(3)\nprint([maxpool_layer](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d \"torch.nn.MaxPool2d\")([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))) \n```", "```py\ntensor([[[0.5036, 0.6285, 0.3460, 0.7817, 0.9876, 0.0074],\n         [0.3969, 0.7950, 0.1449, 0.4110, 0.8216, 0.6235],\n         [0.2347, 0.3741, 0.4997, 0.9737, 0.1741, 0.4616],\n         [0.3962, 0.9970, 0.8778, 0.4292, 0.2772, 0.9926],\n         [0.4406, 0.3624, 0.8960, 0.6484, 0.5544, 0.9501],\n         [0.2489, 0.8971, 0.7499, 0.1803, 0.9571, 0.6733]]])\ntensor([[[0.7950, 0.9876],\n         [0.9970, 0.9926]]]) \n```", "```py\n[my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(1, 4, 4) * 20 + 5\nprint([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\nprint([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").mean())\n\n[norm_layer](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d \"torch.nn.BatchNorm1d\") = [torch.nn.BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d \"torch.nn.BatchNorm1d\")(4)\n[normed_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [norm_layer](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d \"torch.nn.BatchNorm1d\")([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\nprint([normed_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))\n\nprint([normed_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").mean()) \n```", "```py\ntensor([[[ 7.7375, 23.5649,  6.8452, 16.3517],\n         [19.5792, 20.3254,  6.1930, 23.7576],\n         [23.7554, 20.8565, 18.4241,  8.5742],\n         [22.5100, 15.6154, 13.5698, 11.8411]]])\ntensor(16.2188)\ntensor([[[-0.8614,  1.4543, -0.9919,  0.3990],\n         [ 0.3160,  0.4274, -1.6834,  0.9400],\n         [ 1.0256,  0.5176,  0.0914, -1.6346],\n         [ 1.6352, -0.0663, -0.5711, -0.9978]]],\n       grad_fn=<NativeBatchNormBackward0>)\ntensor(3.3528e-08, grad_fn=<MeanBackward0>) \n```", "```py\n[my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand \"torch.rand\")(1, 4, 4)\n\n[dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\") = [torch.nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")(p=0.4)\nprint([dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")))\nprint([dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")([my_tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"))) \n```", "```py\ntensor([[[0.8869, 0.6595, 0.2098, 0.0000],\n         [0.5379, 0.0000, 0.0000, 0.0000],\n         [0.1950, 0.2424, 1.3319, 0.5738],\n         [0.5676, 0.8335, 0.0000, 0.2928]]])\ntensor([[[0.8869, 0.6595, 0.2098, 0.2878],\n         [0.5379, 0.0000, 0.4029, 0.0000],\n         [0.0000, 0.2424, 1.3319, 0.5738],\n         [0.0000, 0.8335, 0.9647, 0.0000]]]) \n```"]