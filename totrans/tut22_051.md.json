["```py\n[KEY:  >  input,  =  target,  <  output]\n\n>  il  est  en  train  de  peindre  un  tableau  .\n=  he  is  painting  a  picture  .\n<  he  is  painting  a  picture  .\n\n>  pourquoi  ne  pas  essayer  ce  vin  delicieux  ?\n=  why  not  try  that  delicious  wine  ?\n<  why  not  try  that  delicious  wine  ?\n\n>  elle  n  est  pas  poete  mais  romanciere  .\n=  she  is  not  a  poet  but  a  novelist  .\n<  she  not  not  a  poet  but  a  novelist  .\n\n>  vous  etes  trop  maigre  .\n=  you  re  too  skinny  .\n<  you  re  all  alone  . \n```", "```py\nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset \"torch.utils.data.TensorDataset\"), [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), [RandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler \"torch.utils.data.RandomSampler\")\n\n[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\") \n```", "```py\nI am cold.    J'ai froid. \n```", "```py\nSOS_token = 0\nEOS_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1 \n```", "```py\n# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip() \n```", "```py\ndef readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs \n```", "```py\nMAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)] \n```", "```py\ndef prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs)) \n```", "```py\nReading lines...\nRead 135842 sentence pairs\nTrimmed to 11445 sentence pairs\nCounting words...\nCounted words:\nfra 4601\neng 2991\n['tu preches une convaincue', 'you re preaching to the choir'] \n```", "```py\nclass EncoderRNN([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super([EncoderRNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding \"torch.nn.Embedding\")(input_size, hidden_size)\n        self.gru = [nn.GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU \"torch.nn.GRU\")(hidden_size, hidden_size, batch_first=True)\n        self.dropout = [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden \n```", "```py\nclass DecoderRNN([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, hidden_size, output_size):\n        super([DecoderRNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.embedding = [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding \"torch.nn.Embedding\")(output_size, hidden_size)\n        self.gru = [nn.GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU \"torch.nn.GRU\")(hidden_size, hidden_size, batch_first=True)\n        self.out = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = [torch.empty](https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty \"torch.empty\")(batch_size, 1, dtype=[torch.long](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\"), [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat \"torch.cat\")(decoder_outputs, dim=1)\n        decoder_outputs = [F.log_softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax \"torch.nn.functional.log_softmax\")(decoder_outputs, dim=-1)\n        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n\n    def forward_step(self, input, hidden):\n        output = self.embedding(input)\n        output = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu \"torch.nn.functional.relu\")(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.out(output)\n        return output, hidden \n```", "```py\nclass BahdanauAttention([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, hidden_size):\n        super([BahdanauAttention](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.Wa = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(hidden_size, hidden_size)\n        self.Ua = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(hidden_size, hidden_size)\n        self.Va = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va([torch.tanh](https://pytorch.org/docs/stable/generated/torch.tanh.html#torch.tanh \"torch.tanh\")(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = [F.softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax \"torch.nn.functional.softmax\")(scores, dim=-1)\n        context = [torch.bmm](https://pytorch.org/docs/stable/generated/torch.bmm.html#torch.bmm \"torch.bmm\")(weights, keys)\n\n        return context, weights\n\nclass AttnDecoderRNN([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super([AttnDecoderRNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\"), self).__init__()\n        self.embedding = [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding \"torch.nn.Embedding\")(output_size, hidden_size)\n        self.attention = [BahdanauAttention](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(hidden_size)\n        self.gru = [nn.GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU \"torch.nn.GRU\")(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear \"torch.nn.Linear\")(hidden_size, output_size)\n        self.dropout = [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout \"torch.nn.Dropout\")(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = [torch.empty](https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty \"torch.empty\")(batch_size, 1, dtype=[torch.long](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\"), [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat \"torch.cat\")(decoder_outputs, dim=1)\n        decoder_outputs = [F.log_softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax \"torch.nn.functional.log_softmax\")(decoder_outputs, dim=-1)\n        attentions = [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat \"torch.cat\")(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat \"torch.cat\")((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights \n```", "```py\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return [torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor \"torch.tensor\")(indexes, dtype=[torch.long](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype \"torch.dtype\"), [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)\n\ndef get_dataloader(batch_size):\n    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(input_lang, inp)\n        tgt_ids = indexesFromSentence(output_lang, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset \"torch.utils.data.TensorDataset\")(torch.LongTensor(input_ids).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")),\n                               torch.LongTensor(target_ids).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")))\n\n    train_sampler = [RandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler \"torch.utils.data.RandomSampler\")(train_data)\n    [train_dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")(train_data, sampler=train_sampler, batch_size=batch_size)\n    return input_lang, output_lang, [train_dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") \n```", "```py\ndef train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader) \n```", "```py\nimport time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs)) \n```", "```py\ndef train([train_dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = [optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam \"torch.optim.Adam\")([encoder.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")(), lr=learning_rate)\n    decoder_optimizer = [optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam \"torch.optim.Adam\")([decoder.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters \"torch.nn.Module.parameters\")(), lr=learning_rate)\n    criterion = [nn.NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss \"torch.nn.NLLLoss\")()\n\n    for epoch in range(1, n_epochs + 1):\n        loss = train_epoch([train_dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d  %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses) \n```", "```py\nimport matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points) \n```", "```py\ndef evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad \"torch.no_grad\")():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn \n```", "```py\ndef evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('') \n```", "```py\nhidden_size = 128\nbatch_size = 32\n\ninput_lang, output_lang, [train_dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\") = get_dataloader(batch_size)\n\nencoder = [EncoderRNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(input_lang.n_words, hidden_size).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\ndecoder = [AttnDecoderRNN](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(hidden_size, output_lang.n_words).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\ntrain([train_dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\"), encoder, decoder, 80, print_every=5, plot_every=5) \n```", "```py\nReading lines...\nRead 135842 sentence pairs\nTrimmed to 11445 sentence pairs\nCounting words...\nCounted words:\nfra 4601\neng 2991\n0m 27s (- 6m 53s) (5 6%) 1.5304\n0m 54s (- 6m 21s) (10 12%) 0.6776\n1m 21s (- 5m 52s) (15 18%) 0.3528\n1m 48s (- 5m 25s) (20 25%) 0.1946\n2m 15s (- 4m 57s) (25 31%) 0.1205\n2m 42s (- 4m 30s) (30 37%) 0.0841\n3m 9s (- 4m 3s) (35 43%) 0.0639\n3m 36s (- 3m 36s) (40 50%) 0.0521\n4m 2s (- 3m 8s) (45 56%) 0.0452\n4m 29s (- 2m 41s) (50 62%) 0.0395\n4m 56s (- 2m 14s) (55 68%) 0.0377\n5m 23s (- 1m 47s) (60 75%) 0.0349\n5m 50s (- 1m 20s) (65 81%) 0.0324\n6m 17s (- 0m 53s) (70 87%) 0.0316\n6m 44s (- 0m 26s) (75 93%) 0.0298\n7m 11s (- 0m 0s) (80 100%) 0.0291 \n```", "```py\n[encoder.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval \"torch.nn.Module.eval\")()\n[decoder.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval \"torch.nn.Module.eval\")()\nevaluateRandomly(encoder, decoder) \n```", "```py\n> il est si mignon !\n= he s so cute\n< he s so cute <EOS>\n\n> je vais me baigner\n= i m going to take a bath\n< i m going to take a bath <EOS>\n\n> c est un travailleur du batiment\n= he s a construction worker\n< he s a construction worker <EOS>\n\n> je suis representant de commerce pour notre societe\n= i m a salesman for our company\n< i m a salesman for our company <EOS>\n\n> vous etes grande\n= you re big\n< you are big <EOS>\n\n> tu n es pas normale\n= you re not normal\n< you re not normal <EOS>\n\n> je n en ai pas encore fini avec vous\n= i m not done with you yet\n< i m not done with you yet <EOS>\n\n> je suis desole pour ce malentendu\n= i m sorry about my mistake\n< i m sorry about my mistake <EOS>\n\n> nous ne sommes pas impressionnes\n= we re not impressed\n< we re not impressed <EOS>\n\n> tu as la confiance de tous\n= you are trusted by every one of us\n< you are trusted by every one of us <EOS> \n```", "```py\ndef showAttention(input_sentence, output_words, attentions):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # Set up axes\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # Show label at every tick\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n\nevaluateAndShowAttention('il n est pas aussi grand que son pere')\n\nevaluateAndShowAttention('je suis trop fatigue pour conduire')\n\nevaluateAndShowAttention('je suis desole si c est une question idiote')\n\nevaluateAndShowAttention('je suis reellement fiere de vous') \n```", "```py\ninput = il n est pas aussi grand que son pere\noutput = he is not as tall as his father <EOS>\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:823: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:825: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\ninput = je suis trop fatigue pour conduire\noutput = i m too tired to drive <EOS>\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:823: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:825: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\ninput = je suis desole si c est une question idiote\noutput = i m sorry if this is a stupid question <EOS>\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:823: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:825: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\ninput = je suis reellement fiere de vous\noutput = i m really proud of you guys <EOS>\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:823: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n/var/lib/jenkins/workspace/intermediate_source/seq2seq_translation_tutorial.py:825: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. \n```"]