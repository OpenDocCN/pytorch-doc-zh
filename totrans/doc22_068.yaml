- en: torch.nn.init
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: torch.nn.init
- en: 原文：[https://pytorch.org/docs/stable/nn.init.html](https://pytorch.org/docs/stable/nn.init.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/docs/stable/nn.init.html](https://pytorch.org/docs/stable/nn.init.html)
- en: Warning
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: All the functions in this module are intended to be used to initialize neural
    network parameters, so they all run in [`torch.no_grad()`](generated/torch.no_grad.html#torch.no_grad
    "torch.no_grad") mode and will not be taken into account by autograd.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块中的所有函数都旨在用于初始化神经网络参数，因此它们都在[`torch.no_grad()`](generated/torch.no_grad.html#torch.no_grad
    "torch.no_grad")模式下运行，并且不会被autograd考虑。
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Return the recommended gain value for the given nonlinearity function.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 返回给定非线性函数的推荐增益值。
- en: 'The values are as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 值如下：
- en: '| nonlinearity | gain |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 非线性 | 增益 |'
- en: '| --- | --- |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Linear / Identity | $1$1 |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| Linear / Identity | $1$1 |'
- en: '| Conv{1,2,3}D | $1$1 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| Conv{1,2,3}D | $1$1 |'
- en: '| Sigmoid | $1$1 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| Sigmoid | $1$1 |'
- en: '| Tanh | $\frac{5}{3}$35​ |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| Tanh | $\frac{5}{3}$35​ |'
- en: '| ReLU | $\sqrt{2}$2​ |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| ReLU | $\sqrt{2}$2​ |'
- en: '| Leaky Relu | $\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}$1+negative_slope22​​
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| Leaky Relu | $\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}$1+negative_slope22​​
    |'
- en: '| SELU | $\frac{3}{4}$43​ |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| SELU | $\frac{3}{4}$43​ |'
- en: Warning
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: In order to implement [Self-Normalizing Neural Networks](https://papers.nips.cc/paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html)
    , you should use `nonlinearity='linear'` instead of `nonlinearity='selu'`. This
    gives the initial weights a variance of `1 / N`, which is necessary to induce
    a stable fixed point in the forward pass. In contrast, the default gain for `SELU`
    sacrifices the normalization effect for more stable gradient flow in rectangular
    layers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现[自正则化神经网络](https://papers.nips.cc/paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html)，应该使用`nonlinearity='linear'`而不是`nonlinearity='selu'`。这样可以使初始权重的方差为`1
    / N`，这对于在前向传递中引入稳定的固定点是必要的。相比之下，`SELU`的默认增益牺牲了归一化效果，以获得更稳定的梯度流动在矩形层中。
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**nonlinearity** – the non-linear function (nn.functional name)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nonlinearity** - 非线性函数（nn.functional名称）'
- en: '**param** – optional parameter for the non-linear function'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**param** - 非线性函数的可选参数'
- en: Examples
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Fill the input Tensor with values drawn from the uniform distribution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用从均匀分布中抽取的值填充输入张量。
- en: $\mathcal{U}(a, b)$U(a,b).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathcal{U}(a, b)$U(a,b).
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**张量**（[*张量*](tensors.html#torch.Tensor "torch.Tensor")） - 一个n维torch张量'
- en: '**a** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the lower bound of the uniform distribution'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**a**（[*浮点数*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12)")） - 均匀分布的下界'
- en: '**b** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the upper bound of the uniform distribution'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**b**（[*浮点数*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12)")） - 均匀分布的上界'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - torch生成器用于采样（默认值：无）'
- en: Return type
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[*张量*](tensors.html#torch.Tensor "torch.Tensor")'
- en: Examples
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Fill the input Tensor with values drawn from the normal distribution.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 用从正态分布中抽取的值填充输入张量。
- en: $\mathcal{N}(\text{mean}, \text{std}^2)$N(mean,std2).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathcal{N}(\text{mean}, \text{std}^2)$N(mean,std2).
- en: Parameters
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**张量**（[*张量*](tensors.html#torch.Tensor "torch.Tensor")） - 一个n维torch张量'
- en: '**mean** ([*float*](https://docs.python.org/3/library/functions.html#float
    "(in Python v3.12)")) – the mean of the normal distribution'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mean**（[*浮点数*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12)")） - 正态分布的均值'
- en: '**std** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the standard deviation of the normal distribution'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**std**（[*浮点数*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12)")） - 正态分布的标准差'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - torch生成器用于采样（默认值：无）'
- en: Return type
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[*张量*](tensors.html#torch.Tensor "torch.Tensor")'
- en: Examples
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Fill the input Tensor with the value $\text{val}$val.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 用值$\text{val}$填充输入张量。
- en: Parameters
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**张量**（[*张量*](tensors.html#torch.Tensor "torch.Tensor")） - 一个n维torch张量'
- en: '**val** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the value to fill the tensor with'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**val**（[*浮点数*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12)")） - 用于填充张量的值'
- en: Return type
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[*张量*](tensors.html#torch.Tensor "torch.Tensor")'
- en: Examples
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Fill the input Tensor with the scalar value 1.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 用标量值1填充输入张量。
- en: Parameters
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**张量**（[*张量*](tensors.html#torch.Tensor "torch.Tensor")） - 一个n维torch张量'
- en: Return type
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[*张量*](tensors.html#torch.Tensor "torch.Tensor")'
- en: Examples
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Fill the input Tensor with the scalar value 0.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 用标量值0填充输入张量。
- en: Parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**张量**（[*张量*](tensors.html#torch.Tensor "torch.Tensor")） - 一个n维torch张量'
- en: Return type
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[*张量*](tensors.html#torch.Tensor "torch.Tensor")'
- en: Examples
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Fill the 2-dimensional input Tensor with the identity matrix.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 用单位矩阵填充2维输入张量。
- en: Preserves the identity of the inputs in Linear layers, where as many inputs
    are preserved as possible.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性层中保留输入的身份，尽可能保留多个输入。
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** – a 2-dimensional torch.Tensor'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**tensor** - 一个2维torch.Tensor'
- en: Examples
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Fill the {3, 4, 5}-dimensional input Tensor with the Dirac delta function.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Dirac delta函数填充{3, 4, 5}维度的输入张量。
- en: Preserves the identity of the inputs in Convolutional layers, where as many
    input channels are preserved as possible. In case of groups>1, each group of channels
    preserves identity
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层中保留输入的身份，尽可能保留多个输入通道。如果groups>1，则每组通道都保留身份
- en: Parameters
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** – a {3, 4, 5}-dimensional torch.Tensor'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor** - 一个{3, 4, 5}维度的torch.Tensor'
- en: '**groups** ([*int*](https://docs.python.org/3/library/functions.html#int "(in
    Python v3.12)")*,* *optional*) – number of groups in the conv layer (default:
    1)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**groups**（[*int*](https://docs.python.org/3/library/functions.html#int) *，*
    可选）- 卷积层中的组数（默认值：1）'
- en: Examples
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Fill the input Tensor with values using a Xavier uniform distribution.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Xavier均匀分布填充输入张量的值。
- en: The method is described in Understanding the difficulty of training deep feedforward
    neural networks - Glorot, X. & Bengio, Y. (2010). The resulting tensor will have
    values sampled from $\mathcal{U}(-a, a)$U(−a,a) where
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法在《理解深度前馈神经网络训练困难性》- Glorot, X. & Bengio, Y.（2010）中有描述。生成的张量将从$\mathcal{U}(-a,
    a)$中采样值，其中
- en: $a = \text{gain} \times \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}}$ a=gain×fan_in+fan_out6​​
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '$a = \text{gain} \times \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}}$ '
- en: Also known as Glorot initialization.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为Glorot初始化。
- en: Parameters
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor**（[*Tensor*](tensors.html#torch.Tensor)）- 一个n维torch.Tensor'
- en: '**gain** ([*float*](https://docs.python.org/3/library/functions.html#float
    "(in Python v3.12)")) – an optional scaling factor'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gain**（[*float*](https://docs.python.org/3/library/functions.html#float)）-
    可选的缩放因子'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional)
    *[*[*Generator*](generated/torch.Generator.html#torch.Generator)*]*) - 用于采样的torch生成器（默认值：无）'
- en: Return type
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Tensor*](tensors.html#torch.Tensor)'
- en: Examples
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Fill the input Tensor with values using a Xavier normal distribution.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Xavier正态分布填充输入张量的值。
- en: The method is described in Understanding the difficulty of training deep feedforward
    neural networks - Glorot, X. & Bengio, Y. (2010). The resulting tensor will have
    values sampled from $\mathcal{N}(0, \text{std}^2)$N(0,std2) where
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法在《理解深度前馈神经网络训练困难性》- Glorot, X. & Bengio, Y.（2010）中有描述。生成的张量将从$\mathcal{N}(0,
    \text{std}^2)$中采样值，其中
- en: $\text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}$
    std=gain×fan_in+fan_out2​​
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '$\text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}$ '
- en: Also known as Glorot initialization.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为Glorot初始化。
- en: Parameters
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor**（[*Tensor*](tensors.html#torch.Tensor)）- 一个n维torch.Tensor'
- en: '**gain** ([*float*](https://docs.python.org/3/library/functions.html#float
    "(in Python v3.12)")) – an optional scaling factor'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gain**（[*float*](https://docs.python.org/3/library/functions.html#float)）-
    可选的缩放因子'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional)
    *[*[*Generator*](generated/torch.Generator.html#torch.Generator)*]*) - 用于采样的torch生成器（默认值：无）'
- en: Return type
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Tensor*](tensors.html#torch.Tensor)'
- en: Examples
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Fill the input Tensor with values using a Kaiming uniform distribution.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kaiming均匀分布填充输入张量的值。
- en: 'The method is described in Delving deep into rectifiers: Surpassing human-level
    performance on ImageNet classification - He, K. et al. (2015). The resulting tensor
    will have values sampled from $\mathcal{U}(-\text{bound}, \text{bound})$U(−bound,bound)
    where'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法在《深入研究整流器：超越ImageNet分类的人类级性能》- He, K.等人（2015）中有描述。生成的张量将从$\mathcal{U}(-\text{bound},
    \text{bound})$中采样值，其中
- en: $\text{bound} = \text{gain} \times \sqrt{\frac{3}{\text{fan\_mode}}}$ bound=gain×fan_mode3​​
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '$\text{bound} = \text{gain} \times \sqrt{\frac{3}{\text{fan\_mode}}}$ '
- en: Also known as He initialization.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为He初始化。
- en: Parameters
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor**（[*Tensor*](tensors.html#torch.Tensor)）- 一个n维torch.Tensor'
- en: '**a** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the negative slope of the rectifier used after this layer (only
    used with `''leaky_relu''`)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**a**（[*float*](https://docs.python.org/3/library/functions.html#float)）- 此层后使用的整流器的负斜率（仅与''leaky_relu''一起使用）'
- en: '**mode** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)")) – either `''fan_in''` (default) or `''fan_out''`. Choosing `''fan_in''`
    preserves the magnitude of the variance of the weights in the forward pass. Choosing
    `''fan_out''` preserves the magnitudes in the backwards pass.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mode**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）- 要么''fan_in''（默认），要么''fan_out''。选择''fan_in''保留前向传播中权重方差的幅度。选择''fan_out''保留反向传播中的幅度。'
- en: '**nonlinearity** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – the non-linear function (nn.functional name), recommended
    to use only with `''relu''` or `''leaky_relu''` (default).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nonlinearity**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）-
    非线性函数（nn.functional名称），建议仅与''relu''或''leaky_relu''一起使用（默认）。'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12中)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - 用于抽样的torch生成器（默认值：无）'
- en: Examples
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE21]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Fill the input Tensor with values using a Kaiming normal distribution.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 用Kaiming正态分布填充输入张量的值。
- en: 'The method is described in Delving deep into rectifiers: Surpassing human-level
    performance on ImageNet classification - He, K. et al. (2015). The resulting tensor
    will have values sampled from $\mathcal{N}(0, \text{std}^2)$N(0,std2) where'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '该方法在Delving deep into rectifiers: Surpassing human-level performance on ImageNet
    classification - He, K.等人（2015）中有描述。生成的张量将具有从$\mathcal{N}(0, \text{std}^2)$N(0,std2)中抽样的值，其中'
- en: $\text{std} = \frac{\text{gain}}{\sqrt{\text{fan\_mode}}}$ std=fan_mode​gain​
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: $\text{std} = \frac{\text{gain}}{\sqrt{\text{fan\_mode}}}$ std=fan_mode​gain​
- en: Also known as He initialization.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为He初始化。
- en: Parameters
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor**（[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")）- 一个n维torch.Tensor'
- en: '**a** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the negative slope of the rectifier used after this layer (only
    used with `''leaky_relu''`)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**a**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12中)")）- 在此层后使用的整流器的负斜率（仅与`''leaky_relu''`一起使用）'
- en: '**mode** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)")) – either `''fan_in''` (default) or `''fan_out''`. Choosing `''fan_in''`
    preserves the magnitude of the variance of the weights in the forward pass. Choosing
    `''fan_out''` preserves the magnitudes in the backwards pass.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mode**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在Python
    v3.12中)")）- `''fan_in''`（默认）或`''fan_out''`。选择`''fan_in''`保留前向传播中权重方差的幅度。选择`''fan_out''`保留反向传播中的幅度。'
- en: '**nonlinearity** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – the non-linear function (nn.functional name), recommended
    to use only with `''relu''` or `''leaky_relu''` (default).'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nonlinearity**（[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")）- 非线性函数（nn.functional名称），建议仅与`''relu''`或`''leaky_relu''`一起使用（默认值）。'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12中)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - 用于抽样的torch生成器（默认值：无）'
- en: Examples
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Fill the input Tensor with values drawn from a truncated normal distribution.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 用截断正态分布中抽取的值填充输入张量。
- en: The values are effectively drawn from the normal distribution $\mathcal{N}(\text{mean},
    \text{std}^2)$N(mean,std2) with values outside $[a, b]$[a,b] redrawn until they
    are within the bounds. The method used for generating the random values works
    best when $a \leq \text{mean} \leq b$a≤mean≤b.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值实际上是从正态分布$\mathcal{N}(\text{mean}, \text{std}^2)$N(mean,std2)中抽取的，超出$[a,
    b]$[a,b]的值会被重新绘制，直到它们在范围内。用于生成随机值的方法在$a \leq \text{mean} \leq b$时效果最佳。
- en: Parameters
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** ([*Tensor*](tensors.html#torch.Tensor "torch.Tensor")) – an n-dimensional
    torch.Tensor'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor**（[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")）- 一个n维torch.Tensor'
- en: '**mean** ([*float*](https://docs.python.org/3/library/functions.html#float
    "(in Python v3.12)")) – the mean of the normal distribution'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mean**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12中)")）- 正态分布的均值'
- en: '**std** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the standard deviation of the normal distribution'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**std**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12中)")）- 正态分布的标准差'
- en: '**a** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the minimum cutoff value'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**a**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12中)")）- 最小截断值'
- en: '**b** ([*float*](https://docs.python.org/3/library/functions.html#float "(in
    Python v3.12)")) – the maximum cutoff value'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**b**（[*float*](https://docs.python.org/3/library/functions.html#float "(在Python
    v3.12中)")）- 最大截断值'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12中)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - 用于抽样的torch生成器（默认值：无）'
- en: Return type
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型
- en: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Tensor*](tensors.html#torch.Tensor "torch.Tensor")'
- en: Examples
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE25]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Fill the input Tensor with a (semi) orthogonal matrix.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 用（半）正交矩阵填充输入张量。
- en: Described in Exact solutions to the nonlinear dynamics of learning in deep linear
    neural networks - Saxe, A. et al. (2013). The input tensor must have at least
    2 dimensions, and for tensors with more than 2 dimensions the trailing dimensions
    are flattened.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在Exact solutions to the nonlinear dynamics of learning in deep linear neural
    networks - Saxe, A.等人（2013）中有描述。输入张量必须至少有2个维度，对于超过2个维度的张量，尾部维度会被展平。
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** – an n-dimensional torch.Tensor, where $n \geq 2$n≥2'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor** - 一个n维torch.Tensor，其中$n \geq 2$'
- en: '**gain** – optional scaling factor'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gain** - 可选的缩放因子'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12中)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - 用于抽样的torch生成器（默认值：无）'
- en: Examples
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE27]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Fill the 2D input Tensor as a sparse matrix.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 将2D输入张量填充为稀疏矩阵。
- en: The non-zero elements will be drawn from the normal distribution $\mathcal{N}(0,
    0.01)$N(0,0.01), as described in Deep learning via Hessian-free optimization -
    Martens, J. (2010).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 非零元素将从正态分布$\mathcal{N}(0, 0.01)$N(0,0.01)中抽取，如Deep learning via Hessian-free
    optimization - Martens, J.（2010）中所述。
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '**tensor** – an n-dimensional torch.Tensor'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tensor** - 一个n维torch张量'
- en: '**sparsity** – The fraction of elements in each column to be set to zero'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**sparsity** - 每列中要设置为零的元素比例'
- en: '**std** – the standard deviation of the normal distribution used to generate
    the non-zero values'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**std** - 用于生成非零值的正态分布的标准差'
- en: '**generator** ([*Optional*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(in Python v3.12)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) – the torch Generator to sample from (default: None)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generator**（[*可选*](https://docs.python.org/3/library/typing.html#typing.Optional
    "(在Python v3.12中)")*[*[*Generator*](generated/torch.Generator.html#torch.Generator
    "torch._C.Generator")*]*) - 用于采样的torch生成器（默认值：无）'
- en: Examples
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE29]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
