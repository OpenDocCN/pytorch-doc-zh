["```py\nclass torch.distributed.algorithms.Join(joinables, enable=True, throw_on_early_termination=False, **kwargs)\u00b6\n```", "```py\n>>> import os\n>>> import torch\n>>> import torch.distributed as dist\n>>> import torch.multiprocessing as mp\n>>> import torch.nn.parallel.DistributedDataParallel as DDP\n>>> import torch.distributed.optim.ZeroRedundancyOptimizer as ZeRO\n>>> from torch.distributed.algorithms.join import Join\n>>>\n>>> # On each spawned worker\n>>> def worker(rank):\n>>>     dist.init_process_group(\"nccl\", rank=rank, world_size=2)\n>>>     model = DDP(torch.nn.Linear(1, 1).to(rank), device_ids=[rank])\n>>>     optim = ZeRO(model.parameters(), torch.optim.Adam, lr=0.01)\n>>>     # Rank 1 gets one more input than rank 0\n>>>     inputs = [torch.tensor([1.]).to(rank) for _ in range(10 + rank)]\n>>>     with Join([model, optim]):\n>>>         for input in inputs:\n>>>             loss = model(input).sum()\n>>>             loss.backward()\n>>>             optim.step()\n>>>     # All ranks reach here without hanging/erroring \n```", "```py\nstatic notify_join_context(joinable)\u00b6\n```", "```py\nclass torch.distributed.algorithms.Joinable\u00b6\n```", "```py\nabstract property join_device: device\u00b6\n```", "```py\nabstract join_hook(**kwargs)\u00b6\n```", "```py\nabstract property join_process_group: Any\u00b6\n```", "```py\nclass torch.distributed.algorithms.JoinHook\u00b6\n```", "```py\nmain_hook()\u00b6\n```", "```py\npost_hook(is_last_joiner)\u00b6\n```"]