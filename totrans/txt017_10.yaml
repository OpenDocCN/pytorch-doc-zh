- en: torchtext.vocab
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pytorch.org/text/stable/vocab.html](https://pytorch.org/text/stable/vocab.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '## Vocab[](#vocab "Permalink to this heading")'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**token** – The token for which to check the membership.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: Whether the token is member of vocab or not.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**token** – The token used to lookup the corresponding index.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: The index corresponding to the associated token.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Initialize internal Module state, shared by both nn.Module and ScriptModule.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Creates a vocab object which maps tokens to indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**vocab** (*torch.classes.torchtext.Vocab* *or* *torchtext._torchtext.Vocab*)
    – a cpp vocab object.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: The length of the vocab.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Return a JITable Vocab.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**token** – The token used to lookup the corresponding index.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Raises:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError
    "(in Python v3.12)") – If token already exists in the vocab'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Calls the lookup_indices method
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**tokens** – a list of tokens used to lookup their corresponding indices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: The indices associated with a list of tokens.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: Value of default index if it is set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: List mapping indices to tokens.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary mapping tokens to indices.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**token** – The token used to lookup the corresponding index.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**index** – The index corresponding to the associated token.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Raises:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError
    "(in Python v3.12)") – If index is not in range [0, Vocab.size()] or if token
    already exists in the vocab.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**tokens** – the tokens used to lookup their corresponding indices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: The ‘indices` associated with tokens.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**index** – The index corresponding to the associated token.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: The token used to lookup the corresponding index.
  prefs: []
  type: TYPE_NORMAL
- en: 'Return type:'
  prefs: []
  type: TYPE_NORMAL
- en: token
  prefs: []
  type: TYPE_NORMAL
- en: 'Raises:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError
    "(in Python v3.12)") – If index not in range [0, itos.size()).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**indices** – The indices used to lookup their corresponding`tokens`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: The tokens associated with indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Raises:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError
    "(in Python v3.12)") – If an index within indices is not int range [0, itos.size()).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**index** – Value of default index. This index will be returned when OOV token
    is queried.'
  prefs: []
  type: TYPE_NORMAL
- en: vocab[](#id1 "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Factory method for creating a vocab object which maps tokens to indices.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the ordering in which key value pairs were inserted in the ordered_dict
    will be respected when building the vocab. Therefore if sorting by token frequency
    is important to the user, the ordered_dict should be created in a way to reflect
    this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ordered_dict** – Ordered Dictionary mapping tokens to their corresponding
    occurance frequencies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**min_freq** – The minimum frequency needed to include a token in the vocabulary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**specials** – Special symbols to add. The order of supplied tokens will be
    preserved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**special_first** – Indicates whether to insert symbols at the beginning or
    at the end.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: A Vocab object
  prefs: []
  type: TYPE_NORMAL
- en: 'Return type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[torchtext.vocab.Vocab](#torchtext.vocab.Vocab "torchtext.vocab.Vocab")'
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: build_vocab_from_iterator[](#build-vocab-from-iterator "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Build a Vocab from an iterator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**iterator** – Iterator used to build Vocab. Must yield list or iterator of
    tokens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**min_freq** – The minimum frequency needed to include a token in the vocabulary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**specials** – Special symbols to add. The order of supplied tokens will be
    preserved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**special_first** – Indicates whether to insert symbols at the beginning or
    at the end.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_tokens** – If provided, creates the vocab from the max_tokens - len(specials)
    most frequent tokens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: A Vocab object
  prefs: []
  type: TYPE_NORMAL
- en: 'Return type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[torchtext.vocab.Vocab](#torchtext.vocab.Vocab "torchtext.vocab.Vocab")'
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Vectors[](#vectors "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**name** – name of the file that contains the vectors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache** – directory for cached vectors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**url** – url for download if vectors not found in cache'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unk_init** (*callback*) – by default, initialize out-of-vocabulary word vectors
    to zero vectors; can be any function that takes in a Tensor and returns a Tensor
    of the same size'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_vectors** ([*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")) – this can be used to limit the number of pre-trained vectors
    loaded. Most pre-trained vector sets are sorted in the descending order of word
    frequency. Thus, in situations where the entire set doesn’t fit in memory, or
    is not needed for another reason, passing max_vectors can limit the size of the
    loaded set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Look up embedding vectors of tokens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**tokens** – a token or a list of tokens. if tokens is a string, returns a
    1-D tensor of shape self.dim; if tokens is a list of strings, returns a 2-D tensor
    of shape=(len(tokens), self.dim).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lower_case_backup** – Whether to look up the token in the lower case. If
    False, each token in the original case will be looked up; if True, each token
    in the original case will be looked up first, if not found in the keys of the
    property stoi, the token in the lower case will be looked up. Default: False.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Pretrained Word Embeddings[](#pretrained-word-embeddings "Permalink to this
    heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GloVe[](#glove "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: FastText[](#fasttext "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: CharNGram[](#charngram "Permalink to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
