["```py\nimport torch\nimport torchvision\n\n# An instance of your model.\nmodel = torchvision.models.resnet18()\n\n# An example input you would normally provide to your model's forward() method.\nexample = torch.rand(1, 3, 224, 224)\n\n# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\ntraced_script_module = torch.jit.trace(model, example) \n```", "```py\nIn[1]: output = traced_script_module(torch.ones(1, 3, 224, 224))\nIn[2]: output[0, :5]\nOut[2]: tensor([-0.2698, -0.0381,  0.4023, -0.3010, -0.0448], grad_fn=<SliceBackward>) \n```", "```py\nimport torch\n\nclass MyModule(torch.nn.Module):\n    def __init__(self, N, M):\n        super(MyModule, self).__init__()\n        self.weight = torch.nn.Parameter(torch.rand(N, M))\n\n    def forward(self, input):\n        if input.sum() > 0:\n          output = self.weight.mv(input)\n        else:\n          output = self.weight + input\n        return output \n```", "```py\nclass MyModule(torch.nn.Module):\n    def __init__(self, N, M):\n        super(MyModule, self).__init__()\n        self.weight = torch.nn.Parameter(torch.rand(N, M))\n\n    def forward(self, input):\n        if input.sum() > 0:\n          output = self.weight.mv(input)\n        else:\n          output = self.weight + input\n        return output\n\nmy_module = MyModule(10,20)\nsm = torch.jit.script(my_module) \n```", "```py\ntraced_script_module.save(\"traced_resnet_model.pt\") \n```", "```py\n#include  <torch/script.h> // One-stop header.\n\n#include  <iostream>\n#include  <memory>\n\nint  main(int  argc,  const  char*  argv[])  {\n  if  (argc  !=  2)  {\n  std::cerr  <<  \"usage: example-app <path-to-exported-script-module>\\n\";\n  return  -1;\n  }\n\n  torch::jit::script::Module  module;\n  try  {\n  // Deserialize the ScriptModule from a file using torch::jit::load().\n  module  =  torch::jit::load(argv[1]);\n  }\n  catch  (const  c10::Error&  e)  {\n  std::cerr  <<  \"error loading the model\\n\";\n  return  -1;\n  }\n\n  std::cout  <<  \"ok\\n\";\n} \n```", "```py\ncmake_minimum_required(VERSION  3.0  FATAL_ERROR)\nproject(custom_ops)\n\nfind_package(Torch  REQUIRED)\n\nadd_executable(example-app  example-app.cpp)\ntarget_link_libraries(example-app  \"${TORCH_LIBRARIES}\")\nset_property(TARGET  example-app  PROPERTY  CXX_STANDARD  14) \n```", "```py\nlibtorch/\n  bin/\n  include/\n  lib/\n  share/ \n```", "```py\nexample-app/\n  CMakeLists.txt\n  example-app.cpp \n```", "```py\nmkdir  build\ncd  build\ncmake  -DCMAKE_PREFIX_PATH=/path/to/libtorch  ..\ncmake  --build  .  --config  Release \n```", "```py\nroot@4b5a67132e81:/example-app#  mkdir  build\nroot@4b5a67132e81:/example-app#  cd  build\nroot@4b5a67132e81:/example-app/build#  cmake  -DCMAKE_PREFIX_PATH=/path/to/libtorch  ..\n--  The  C  compiler  identification  is  GNU  5.4.0\n--  The  CXX  compiler  identification  is  GNU  5.4.0\n--  Check  for  working  C  compiler:  /usr/bin/cc\n--  Check  for  working  C  compiler:  /usr/bin/cc  --  works\n--  Detecting  C  compiler  ABI  info\n--  Detecting  C  compiler  ABI  info  -  done\n--  Detecting  C  compile  features\n--  Detecting  C  compile  features  -  done\n--  Check  for  working  CXX  compiler:  /usr/bin/c++\n--  Check  for  working  CXX  compiler:  /usr/bin/c++  --  works\n--  Detecting  CXX  compiler  ABI  info\n--  Detecting  CXX  compiler  ABI  info  -  done\n--  Detecting  CXX  compile  features\n--  Detecting  CXX  compile  features  -  done\n--  Looking  for  pthread.h\n--  Looking  for  pthread.h  -  found\n--  Looking  for  pthread_create\n--  Looking  for  pthread_create  -  not  found\n--  Looking  for  pthread_create  in  pthreads\n--  Looking  for  pthread_create  in  pthreads  -  not  found\n--  Looking  for  pthread_create  in  pthread\n--  Looking  for  pthread_create  in  pthread  -  found\n--  Found  Threads:  TRUE\n--  Configuring  done\n--  Generating  done\n--  Build  files  have  been  written  to:  /example-app/build\nroot@4b5a67132e81:/example-app/build#  make\nScanning  dependencies  of  target  example-app\n[  50%]  Building  CXX  object  CMakeFiles/example-app.dir/example-app.cpp.o\n[100%]  Linking  CXX  executable  example-app\n[100%]  Built  target  example-app \n```", "```py\nroot@4b5a67132e81:/example-app/build#  ./example-app  <path_to_model>/traced_resnet_model.pt\nok \n```", "```py\n// Create a vector of inputs.\nstd::vector<torch::jit::IValue>  inputs;\ninputs.push_back(torch::ones({1,  3,  224,  224}));\n\n// Execute the model and turn its output into a tensor.\nat::Tensor  output  =  module.forward(inputs).toTensor();\nstd::cout  <<  output.slice(/*dim=*/1,  /*start=*/0,  /*end=*/5)  <<  '\\n'; \n```", "```py\nroot@4b5a67132e81:/example-app/build#  make\nScanning  dependencies  of  target  example-app\n[  50%]  Building  CXX  object  CMakeFiles/example-app.dir/example-app.cpp.o\n[100%]  Linking  CXX  executable  example-app\n[100%]  Built  target  example-app\nroot@4b5a67132e81:/example-app/build#  ./example-app  traced_resnet_model.pt\n-0.2698  -0.0381  0.4023  -0.3010  -0.0448\n[  Variable[CPUFloatType]{1,5}  ] \n```", "```py\ntensor([-0.2698, -0.0381,  0.4023, -0.3010, -0.0448], grad_fn=<SliceBackward>) \n```"]