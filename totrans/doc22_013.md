# 分布式数据并行

> 原文：[https://pytorch.org/docs/stable/notes/ddp.html](https://pytorch.org/docs/stable/notes/ddp.html)

警告

[`torch.nn.parallel.DistributedDataParallel`](../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel "torch.nn.parallel.DistributedDataParallel")的实现随时间推移而发展。本设计说明是基于v1.4状态编写的。

[`torch.nn.parallel.DistributedDataParallel`](../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel "torch.nn.parallel.DistributedDataParallel")（DDP）透明地执行分布式数据并行训练。本页描述了它的工作原理并揭示了实现细节。

## 示例

让我们从一个简单的[`torch.nn.parallel.DistributedDataParallel`](../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel "torch.nn.parallel.DistributedDataParallel")示例开始。这个示例使用一个[`torch.nn.Linear`](../generated/torch.nn.Linear.html#torch.nn.Linear "torch.nn.Linear")作为本地模型，将其与DDP包装起来，然后在DDP模型上运行一次前向传递，一次反向传递和一个优化器步骤。之后，本地模型上的参数将被更新，并且不同进程上的所有模型应该完全相同。

```py
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
import torch.nn as nn
import torch.optim as optim
import os
from torch.nn.parallel import DistributedDataParallel as DDP

def example(rank, world_size):
    # create default process group
    dist.init_process_group("gloo", rank=rank, world_size=world_size)
    # create local model
    model = nn.Linear(10, 10).to(rank)
    # construct DDP model
    ddp_model = DDP(model, device_ids=[rank])
    # define loss function and optimizer
    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

    # forward pass
    outputs = ddp_model(torch.randn(20, 10).to(rank))
    labels = torch.randn(20, 10).to(rank)
    # backward pass
    loss_fn(outputs, labels).backward()
    # update parameters
    optimizer.step()

def main():
    world_size = 2
    mp.spawn(example,
        args=(world_size,),
        nprocs=world_size,
        join=True)

if __name__=="__main__":
    # Environment variables which need to be
    # set when using c10d's default "env"
    # initialization mode.
    os.environ["MASTER_ADDR"] = "localhost"
    os.environ["MASTER_PORT"] = "29500"
    main() 
```

DDP与TorchDynamo一起使用。当与TorchDynamo一起使用时，在编译模型之前应用DDP模型包装器，以便torchdynamo可以根据DDP桶大小应用`DDPOptimizer`（基于DDP桶大小的图断点优化）。 （有关更多信息，请参见[TorchDynamo DDPOptimizer](./ddp.html#torchdynamo-ddpoptimizer)。）

```py
ddp_model = DDP(model, device_ids=[rank])
ddp_model = torch.compile(ddp_model) 
```

## 内部设计

本节通过深入探讨每个迭代步骤的细节，揭示了[`torch.nn.parallel.DistributedDataParallel`](../generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel "torch.nn.parallel.DistributedDataParallel")的内部工作原理。

+   **先决条件**：DDP依赖于c10d`ProcessGroup`进行通信。因此，应用程序在构造DDP之前必须创建`ProcessGroup`实例。

+   **构造**：DDP构造函数接受对本地模块的引用，并从排名为0的进程向组中的所有其他进程广播`state_dict()`，以确保所有模型副本从完全相同的状态开始。然后，每个DDP进程创建一个本地的`Reducer`，后者将在反向传递期间负责梯度同步。为了提高通信效率，`Reducer`将参数梯度组织成桶，并一次减少一个桶。可以通过在DDP构造函数中设置bucket_cap_mb参数来配置桶大小。参数梯度到桶的映射是在构造时确定的，基于桶大小限制和参数大小。模型参数按照给定模型的`Model.parameters()`的（大致）相反顺序分配到桶中。使用相反顺序的原因是因为DDP期望梯度在反向传递期间以大致相同的顺序准备就绪。下面的图显示了一个示例。请注意，`grad0`和`grad1`在`bucket1`中，另外两个梯度在`bucket0`中。当然，这种假设可能并不总是正确，当发生这种情况时，可能会影响DDP反向传递速度，因为`Reducer`无法在可能的最早时间开始通信。除了分桶，`Reducer`还在构造过程中注册自动求导钩子，每个参数一个钩子。这些钩子将在梯度准备就绪时在反向传递期间触发。

+   **前向传播**：DDP接受输入并将其传递给本地模型，然后分析本地模型的输出，如果`find_unused_parameters`设置为`True`。此模式允许在模型的子图上运行反向传播，DDP通过从模型输出遍历自动求导图并标记所有未使用的参数为准备好进行减少。在反向传播期间，`Reducer`只会等待未准备好的参数，但仍会减少所有桶。将参数梯度标记为准备好不会帮助DDP跳过桶，但它将防止DDP在反向传播期间永远等待缺失的梯度。请注意，遍历自动求导图会引入额外的开销，因此应用程序只应在必要时将`find_unused_parameters`设置为`True`。

+   **反向传播**：`backward()`函数直接在损失`Tensor`上调用，这是DDP无法控制的，DDP在构造时使用的自动求导钩子来触发梯度同步。当一个梯度准备就绪时，其对应的DDP钩子将触发该梯度累加器上的梯度，并且DDP将标记该参数梯度为准备好进行减少。当一个桶中的梯度都准备就绪时，`Reducer`会在该桶上启动一个异步的`allreduce`来计算所有进程中梯度的平均值。当所有桶都准备就绪时，`Reducer`将阻塞等待所有`allreduce`操作完成。完成后，平均梯度将写入所有参数的`param.grad`字段。因此，在反向传播之后，不同DDP进程中相应参数的grad字段应该是相同的。

+   **优化器步骤**：从优化器的角度来看，它正在优化一个本地模型。所有DDP进程上的模型副本可以保持同步，因为它们都从相同的状态开始，并且它们在每次迭代中具有相同的平均梯度。

[![ddp_grad_sync.png](../Images/7fd0c1da1ad18ef7e8187a73ace04695.png)](https://user-images.githubusercontent.com/16999635/72401724-d296d880-371a-11ea-90ab-737f86543df9.png)

注意

DDP要求所有进程上的`Reducer`实例以完全相同的顺序调用`allreduce`，这是通过始终按照桶索引顺序而不是实际桶准备就绪顺序来运行`allreduce`来实现的。跨进程的`allreduce`顺序不匹配可能导致错误的结果或DDP反向传播挂起。

## 实现

以下是DDP实现组件的指针。堆叠图显示了代码的结构。

### ProcessGroup

+   [ProcessGroup.hpp](https://github.com/pytorch/pytorch/blob/v1.7.0/torch/lib/c10d/ProcessGroup.hpp)：包含所有进程组实现的抽象API。`c10d`库提供了3种开箱即用的实现，即ProcessGroupGloo、ProcessGroupNCCL和ProcessGroupMPI。`DistributedDataParallel`使用`ProcessGroup::broadcast()`在初始化期间从排名为0的进程向其他进程发送模型状态，并使用`ProcessGroup::allreduce()`来求和梯度。

+   [Store.hpp](https://github.com/pytorch/pytorch/blob/v1.7.0/torch/lib/c10d/Store.hpp)：协助进程组实例的会合服务找到彼此。

### DistributedDataParallel

+   [distributed.py](https://github.com/pytorch/pytorch/blob/v1.7.0/torch/nn/parallel/distributed.py)：是DDP的Python入口点。它实现了初始化步骤和`nn.parallel.DistributedDataParallel`模块的`forward`函数，该函数调用C++库。其`_sync_param`函数在一个DDP进程在多个设备上工作时执行进程内参数同步，并且它还会将模型缓冲区从排名为0的进程广播到所有其他进程。进程间参数同步发生在`Reducer.cpp`中。

+   [comm.h](https://github.com/pytorch/pytorch/blob/v1.7.0/torch/csrc/distributed/c10d/comm.h)：实现了合并广播辅助函数，用于在初始化期间广播模型状态并在前向传递之前同步模型缓冲区。

+   [reducer.h](https://github.com/pytorch/pytorch/blob/v1.7.0/torch/csrc/distributed/c10d/reducer.h)：提供了在反向传递中进行梯度同步的核心实现。它有三个入口点函数：

    +   `Reducer`：构造函数在`distributed.py`中被调用，注册`Reducer::autograd_hook()`到梯度累加器。

    +   `autograd_hook()`函数将在梯度准备就绪时被自动求导引擎调用。

    +   `prepare_for_backward()`在`distributed.py`中的DDP前向传递结束时被调用。当在DDP构造函数中将`find_unused_parameters`设置为`True`时，它会遍历自动求导图以找到未使用的参数。

[![ddp_code.png](../Images/0b2511513fe6a3326d13ebd545cfb730.png)](https://user-images.githubusercontent.com/16999635/72313120-4e7c1c80-3658-11ea-9c6d-44336b2daeac.png)

### TorchDynamo DDPOptimizer

DDP的性能优势来自在反向传递期间将allreduce集体操作与计算重叠。当与TorchDynamo一起使用时，AotAutograd会阻止这种重叠，因为它用于编译整个前向和整个反向图形，这会导致在整个优化的反向计算完成后，梯度同步操作由自动求导钩子在之后启动。

TorchDynamo的DDPOptimizer通过在反向传递期间在DDP的allreduce桶的逻辑边界处中断前向图来帮助。注意：目标是在反向传递期间中断图形，最简单的实现方式是在前向图形中断，然后在每个部分上调用AotAutograd和编译。这允许DDP的allreduce钩子在反向传递的各个部分之间触发，并安排通信与计算重叠。

查看[这篇博客文章](https://dev-discuss.pytorch.org/t/torchdynamo-update-9-making-ddp-work-with-torchdynamo/860/1)以获取更深入的解释和实验结果，或者在[torch/_dynamo/optimizations/distributed.py](https://github.com/pytorch/pytorch/blob/4908a12542798a3e8641faae6b74f068fdfc6778/torch/_dynamo/optimizations/distributed.py#L56)中阅读文档和代码

要调试DDPOptimizer，请将torch._dynamo.config.log_level设置为DEBUG（用于完整图形转储）或INFO（用于有关桶边界的基本信息）。要禁用DDPOptimizer，请将torch._dynamo.config.optimize_ddp设置为False。DDP和TorchDynamo应该在没有DDPOptimizer的情况下仍能正常工作，但性能会下降。
