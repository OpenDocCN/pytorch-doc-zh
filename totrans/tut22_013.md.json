["```py\nimport torch\nimport torchvision.models as models \n```", "```py\nmodel = [models.vgg16](https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16 \"torchvision.models.vgg16\")(weights='IMAGENET1K_V1')\n[torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save \"torch.save\")([model.state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict \"torch.nn.Module.state_dict\")(), 'model_weights.pth') \n```", "```py\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /var/lib/jenkins/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n\n  0%|          | 0.00/528M [00:00<?, ?B/s]\n  2%|2         | 12.7M/528M [00:00<00:04, 133MB/s]\n  5%|4         | 25.9M/528M [00:00<00:03, 136MB/s]\n  8%|7         | 40.3M/528M [00:00<00:03, 143MB/s]\n 10%|#         | 54.0M/528M [00:00<00:03, 141MB/s]\n 13%|#2        | 67.4M/528M [00:00<00:03, 138MB/s]\n 15%|#5        | 81.8M/528M [00:00<00:03, 142MB/s]\n 18%|#8        | 96.2M/528M [00:00<00:03, 145MB/s]\n 21%|##        | 110M/528M [00:00<00:03, 145MB/s]\n 24%|##3       | 124M/528M [00:00<00:02, 147MB/s]\n 26%|##6       | 139M/528M [00:01<00:02, 148MB/s]\n 29%|##9       | 153M/528M [00:01<00:02, 149MB/s]\n 32%|###1      | 168M/528M [00:01<00:02, 150MB/s]\n 35%|###4      | 182M/528M [00:01<00:02, 151MB/s]\n 37%|###7      | 197M/528M [00:01<00:02, 123MB/s]\n 40%|###9      | 210M/528M [00:01<00:02, 127MB/s]\n 42%|####2     | 223M/528M [00:01<00:02, 113MB/s]\n 44%|####4     | 234M/528M [00:01<00:02, 112MB/s]\n 47%|####6     | 248M/528M [00:01<00:02, 119MB/s]\n 50%|####9     | 262M/528M [00:02<00:02, 128MB/s]\n 52%|#####2    | 275M/528M [00:02<00:02, 129MB/s]\n 55%|#####4    | 288M/528M [00:02<00:01, 132MB/s]\n 57%|#####7    | 302M/528M [00:02<00:01, 136MB/s]\n 60%|#####9    | 316M/528M [00:02<00:01, 140MB/s]\n 63%|######2   | 331M/528M [00:02<00:01, 144MB/s]\n 65%|######5   | 345M/528M [00:02<00:01, 146MB/s]\n 68%|######8   | 360M/528M [00:02<00:01, 148MB/s]\n 71%|#######   | 374M/528M [00:02<00:01, 149MB/s]\n 74%|#######3  | 389M/528M [00:02<00:00, 150MB/s]\n 76%|#######6  | 403M/528M [00:03<00:00, 151MB/s]\n 79%|#######9  | 418M/528M [00:03<00:00, 151MB/s]\n 82%|########1 | 432M/528M [00:03<00:00, 151MB/s]\n 85%|########4 | 447M/528M [00:03<00:00, 152MB/s]\n 87%|########7 | 461M/528M [00:03<00:00, 152MB/s]\n 90%|######### | 476M/528M [00:03<00:00, 152MB/s]\n 93%|#########2| 490M/528M [00:03<00:00, 152MB/s]\n 96%|#########5| 505M/528M [00:03<00:00, 151MB/s]\n 98%|#########8| 519M/528M [00:03<00:00, 151MB/s]\n100%|##########| 528M/528M [00:03<00:00, 142MB/s] \n```", "```py\nmodel = [models.vgg16](https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16 \"torchvision.models.vgg16\")() # we do not specify ``weights``, i.e. create untrained model\n[model.load_state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict \"torch.nn.Module.load_state_dict\")([torch.load](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load \"torch.load\")('model_weights.pth'))\n[model.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval \"torch.nn.Module.eval\")() \n```", "```py\nVGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n) \n```", "```py\n[torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save \"torch.save\")(model, 'model.pth') \n```", "```py\nmodel = [torch.load](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load \"torch.load\")('model.pth') \n```"]