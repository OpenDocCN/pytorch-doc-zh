# torch.cuda

> 原文：[https://pytorch.org/docs/stable/cuda.html](https://pytorch.org/docs/stable/cuda.html)

此软件包添加了对CUDA张量类型的支持。

它实现了与CPU张量相同的功能，但利用GPU进行计算。

它是懒惰初始化的，所以您可以随时导入它，并使用[`is_available()`](generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available")来确定您的系统是否支持CUDA。

[CUDA语义](notes/cuda.html#cuda-semantics)有关使用CUDA的更多详细信息。

| [`StreamContext`](generated/torch.cuda.StreamContext.html#torch.cuda.StreamContext "torch.cuda.StreamContext") | 选择给定流的上下文管理器。 |
| --- | --- |
| [`can_device_access_peer`](generated/torch.cuda.can_device_access_peer.html#torch.cuda.can_device_access_peer "torch.cuda.can_device_access_peer") | 检查两个设备之间是否可以进行对等访问。 |
| [`current_blas_handle`](generated/torch.cuda.current_blas_handle.html#torch.cuda.current_blas_handle "torch.cuda.current_blas_handle") | 返回当前cuBLAS句柄的cublasHandle_t指针 |
| [`current_device`](generated/torch.cuda.current_device.html#torch.cuda.current_device "torch.cuda.current_device") | 返回当前选择设备的索引。 |
| [`current_stream`](generated/torch.cuda.current_stream.html#torch.cuda.current_stream "torch.cuda.current_stream") | 返回给定设备当前选择的[`Stream`](generated/torch.cuda.Stream.html#torch.cuda.Stream "torch.cuda.Stream")。 |
| [`default_stream`](generated/torch.cuda.default_stream.html#torch.cuda.default_stream "torch.cuda.default_stream") | 返回给定设备的默认[`Stream`](generated/torch.cuda.Stream.html#torch.cuda.Stream "torch.cuda.Stream")。 |
| [`device`](generated/torch.cuda.device.html#torch.cuda.device "torch.cuda.device") | 上下文管理器，更改所选设备。 |
| [`device_count`](generated/torch.cuda.device_count.html#torch.cuda.device_count "torch.cuda.device_count") | 返回可用的GPU数量。 |
| [`device_of`](generated/torch.cuda.device_of.html#torch.cuda.device_of "torch.cuda.device_of") | 上下文管理器，将当前设备更改为给定对象的设备。 |
| [`get_arch_list`](generated/torch.cuda.get_arch_list.html#torch.cuda.get_arch_list "torch.cuda.get_arch_list") | 返回此库编译的CUDA架构列表。 |
| [`get_device_capability`](generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability "torch.cuda.get_device_capability") | 获取设备的cuda能力。 |
| [`get_device_name`](generated/torch.cuda.get_device_name.html#torch.cuda.get_device_name "torch.cuda.get_device_name") | 获取设备的名称。 |
| [`get_device_properties`](generated/torch.cuda.get_device_properties.html#torch.cuda.get_device_properties "torch.cuda.get_device_properties") | 获取设备的属性。 |
| [`get_gencode_flags`](generated/torch.cuda.get_gencode_flags.html#torch.cuda.get_gencode_flags "torch.cuda.get_gencode_flags") | 返回此库编译时使用的NVCC gencode标志。 |
| [`get_sync_debug_mode`](generated/torch.cuda.get_sync_debug_mode.html#torch.cuda.get_sync_debug_mode "torch.cuda.get_sync_debug_mode") | 返回cuda同步操作的调试模式的当前值。 |
| [`init`](generated/torch.cuda.init.html#torch.cuda.init "torch.cuda.init") | 初始化PyTorch的CUDA状态。 |
| [`ipc_collect`](generated/torch.cuda.ipc_collect.html#torch.cuda.ipc_collect "torch.cuda.ipc_collect") | 在CUDA IPC释放GPU内存后强制收集。 |
| [`is_available`](generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available") | 返回一个布尔值，指示当前是否可用CUDA。 |
| [`is_initialized`](generated/torch.cuda.is_initialized.html#torch.cuda.is_initialized "torch.cuda.is_initialized") | 返回PyTorch的CUDA状态是否已初始化。 |
| [`memory_usage`](generated/torch.cuda.memory_usage.html#torch.cuda.memory_usage "torch.cuda.memory_usage") | 返回过去采样周期内全局（设备）内存被读取或写入的时间百分比，由 nvidia-smi 给出。 |
| [`set_device`](generated/torch.cuda.set_device.html#torch.cuda.set_device "torch.cuda.set_device") | 设置当前设备。 |
| [`set_stream`](generated/torch.cuda.set_stream.html#torch.cuda.set_stream "torch.cuda.set_stream") | 设置当前流。这是一个包装 API，用于设置流。 |
| [`set_sync_debug_mode`](generated/torch.cuda.set_sync_debug_mode.html#torch.cuda.set_sync_debug_mode "torch.cuda.set_sync_debug_mode") | 设置 cuda 同步操作的调试模式。 |
| [`stream`](generated/torch.cuda.stream.html#torch.cuda.stream "torch.cuda.stream") | 包装上下文管理器 StreamContext，选择给定的流。 |
| [`synchronize`](generated/torch.cuda.synchronize.html#torch.cuda.synchronize "torch.cuda.synchronize") | 等待 CUDA 设备上所有流中的所有内核完成。 |
| [`utilization`](generated/torch.cuda.utilization.html#torch.cuda.utilization "torch.cuda.utilization") | 返回过去采样周期内 GPU 上一个或多个内核执行的时间百分比，由 nvidia-smi 给出。 |
| [`temperature`](generated/torch.cuda.temperature.html#torch.cuda.temperature "torch.cuda.temperature") | 返回 GPU 传感器的平均温度，单位为摄氏度（C）。 |
| [`power_draw`](generated/torch.cuda.power_draw.html#torch.cuda.power_draw "torch.cuda.power_draw") | 返回 GPU 传感器的平均功耗，单位为毫瓦（mW） |
| [`clock_rate`](generated/torch.cuda.clock_rate.html#torch.cuda.clock_rate "torch.cuda.clock_rate") | 返回 GPU SM 的时钟速度，单位为赫兹（Hz），在过去的采样周期内由 nvidia-smi 给出。 |
| [`OutOfMemoryError`](generated/torch.cuda.OutOfMemoryError.html#torch.cuda.OutOfMemoryError "torch.cuda.OutOfMemoryError") | 当 CUDA 内存不足时引发的异常 |

## 随机数生成器

| [`get_rng_state`](generated/torch.cuda.get_rng_state.html#torch.cuda.get_rng_state "torch.cuda.get_rng_state") | 返回指定 GPU 的随机数生成器状态，作为 ByteTensor。 |
| --- | --- |
| [`get_rng_state_all`](generated/torch.cuda.get_rng_state_all.html#torch.cuda.get_rng_state_all "torch.cuda.get_rng_state_all") | 返回表示所有设备的随机数状态的 ByteTensor 列表。 |
| [`set_rng_state`](generated/torch.cuda.set_rng_state.html#torch.cuda.set_rng_state "torch.cuda.set_rng_state") | 设置指定 GPU 的随机数生成器状态。 |
| [`set_rng_state_all`](generated/torch.cuda.set_rng_state_all.html#torch.cuda.set_rng_state_all "torch.cuda.set_rng_state_all") | 设置所有设备的随机数生成器状态。 |
| [`manual_seed`](generated/torch.cuda.manual_seed.html#torch.cuda.manual_seed "torch.cuda.manual_seed") | 为当前 GPU 设置生成随机数的种子。 |
| [`manual_seed_all`](generated/torch.cuda.manual_seed_all.html#torch.cuda.manual_seed_all "torch.cuda.manual_seed_all") | 在所有 GPU 上设置生成随机数的种子。 |
| [`seed`](generated/torch.cuda.seed.html#torch.cuda.seed "torch.cuda.seed") | 为当前 GPU 将生成随机数的种子设置为随机数。 |
| [`seed_all`](generated/torch.cuda.seed_all.html#torch.cuda.seed_all "torch.cuda.seed_all") | 将生成随机数的种子设置为所有 GPU 上的随机数。 |
| [`initial_seed`](generated/torch.cuda.initial_seed.html#torch.cuda.initial_seed "torch.cuda.initial_seed") | 返回当前 GPU 的当前随机种子。 |

## 通信集合

| [`comm.broadcast`](generated/torch.cuda.comm.broadcast.html#torch.cuda.comm.broadcast "torch.cuda.comm.broadcast") | 将张量广播到指定的 GPU 设备。 |
| --- | --- |
| [`comm.broadcast_coalesced`](generated/torch.cuda.comm.broadcast_coalesced.html#torch.cuda.comm.broadcast_coalesced "torch.cuda.comm.broadcast_coalesced") | 将一系列张量广播到指定的 GPU。 |
| [`comm.reduce_add`](generated/torch.cuda.comm.reduce_add.html#torch.cuda.comm.reduce_add "torch.cuda.comm.reduce_add") | 对多个 GPU 的张量求和。 |
| [`comm.scatter`](generated/torch.cuda.comm.scatter.html#torch.cuda.comm.scatter "torch.cuda.comm.scatter") | 在多个 GPU 上分散张量。 |
| [`comm.gather`](generated/torch.cuda.comm.gather.html#torch.cuda.comm.gather "torch.cuda.comm.gather") | 从多个 GPU 设备中收集张量。 |

## 流和事件

| [`Stream`](generated/torch.cuda.Stream.html#torch.cuda.Stream "torch.cuda.Stream") | CUDA 流的包装器。 |
| --- | --- |
| [`ExternalStream`](generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream "torch.cuda.ExternalStream") | 外部分配的 CUDA 流的包装器。 |
| [`Event`](generated/torch.cuda.Event.html#torch.cuda.Event "torch.cuda.Event") | CUDA 事件的包装器。 |

## 图（测试版）

| [`is_current_stream_capturing`](generated/torch.cuda.is_current_stream_capturing.html#torch.cuda.is_current_stream_capturing "torch.cuda.is_current_stream_capturing") | 如果当前 CUDA 流正在进行 CUDA 图捕获，则返回 True，否则返回 False。 |
| --- | --- |
| [`graph_pool_handle`](generated/torch.cuda.graph_pool_handle.html#torch.cuda.graph_pool_handle "torch.cuda.graph_pool_handle") | 返回表示图形内存池 id 的不透明令牌。 |
| [`CUDAGraph`](generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph "torch.cuda.CUDAGraph") | CUDA 图的包装器。 |
| [`graph`](generated/torch.cuda.graph.html#torch.cuda.graph "torch.cuda.graph") | 上下文管理器，将 CUDA 工作捕获到一个 [`torch.cuda.CUDAGraph`](generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph "torch.cuda.CUDAGraph") 对象中以供以后重播。 |
| [`make_graphed_callables`](generated/torch.cuda.make_graphed_callables.html#torch.cuda.make_graphed_callables "torch.cuda.make_graphed_callables") | 接受可调用对象（函数或 [`nn.Module`](generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")）并返回图形化版本。 |

## 内存管理

| [`empty_cache`](generated/torch.cuda.empty_cache.html#torch.cuda.empty_cache "torch.cuda.empty_cache") | 释放缓存分配器当前持有的所有未使用内存，以便其他 GPU 应用程序可以使用，并在 nvidia-smi 中可见。 |
| --- | --- |
| [`list_gpu_processes`](generated/torch.cuda.list_gpu_processes.html#torch.cuda.list_gpu_processes "torch.cuda.list_gpu_processes") | 返回给定设备的正在运行进程及其 GPU 内存使用情况的人类可读打印输出。 |
| [`mem_get_info`](generated/torch.cuda.mem_get_info.html#torch.cuda.mem_get_info "torch.cuda.mem_get_info") | 使用 cudaMemGetInfo 返回给定设备的全局空闲和总 GPU 内存。 |
| [`memory_stats`](generated/torch.cuda.memory_stats.html#torch.cuda.memory_stats "torch.cuda.memory_stats") | 返回给定设备的 CUDA 内存分配器统计信息字典。 |
| [`memory_summary`](generated/torch.cuda.memory_summary.html#torch.cuda.memory_summary "torch.cuda.memory_summary") | 返回给定设备的当前内存分配器统计信息的人类可读打印输出。 |
| [`memory_snapshot`](generated/torch.cuda.memory_snapshot.html#torch.cuda.memory_snapshot "torch.cuda.memory_snapshot") | 返回跨所有设备的 CUDA 内存分配器状态的快照。 |
| [`memory_allocated`](generated/torch.cuda.memory_allocated.html#torch.cuda.memory_allocated "torch.cuda.memory_allocated") | 返回给定设备上张量占用的当前 GPU 内存（以字节为单位）。 |
| [`max_memory_allocated`](generated/torch.cuda.max_memory_allocated.html#torch.cuda.max_memory_allocated "torch.cuda.max_memory_allocated") | 返回给定设备张量占用的最大GPU内存（以字节为单位）。 |
| [`reset_max_memory_allocated`](generated/torch.cuda.reset_max_memory_allocated.html#torch.cuda.reset_max_memory_allocated "torch.cuda.reset_max_memory_allocated") | 重置跟踪给定设备张量占用的最大GPU内存的起始点。 |
| [`memory_reserved`](generated/torch.cuda.memory_reserved.html#torch.cuda.memory_reserved "torch.cuda.memory_reserved") | 返回由缓存分配器管理的给定设备的当前GPU内存（以字节为单位）。 |
| [`max_memory_reserved`](generated/torch.cuda.max_memory_reserved.html#torch.cuda.max_memory_reserved "torch.cuda.max_memory_reserved") | 返回由缓存分配器管理的给定设备的最大GPU内存（以字节为单位）。 |
| [`set_per_process_memory_fraction`](generated/torch.cuda.set_per_process_memory_fraction.html#torch.cuda.set_per_process_memory_fraction "torch.cuda.set_per_process_memory_fraction") | 为进程设置内存分数。 |
| [`memory_cached`](generated/torch.cuda.memory_cached.html#torch.cuda.memory_cached "torch.cuda.memory_cached") | 已弃用；请参阅 [`memory_reserved()`](generated/torch.cuda.memory_reserved.html#torch.cuda.memory_reserved "torch.cuda.memory_reserved")。 |
| [`max_memory_cached`](generated/torch.cuda.max_memory_cached.html#torch.cuda.max_memory_cached "torch.cuda.max_memory_cached") | 已弃用；请参阅 [`max_memory_reserved()`](generated/torch.cuda.max_memory_reserved.html#torch.cuda.max_memory_reserved "torch.cuda.max_memory_reserved")。 |
| [`reset_max_memory_cached`](generated/torch.cuda.reset_max_memory_cached.html#torch.cuda.reset_max_memory_cached "torch.cuda.reset_max_memory_cached") | 重置跟踪由缓存分配器管理的给定设备的最大GPU内存的起始点。 |
| [`reset_peak_memory_stats`](generated/torch.cuda.reset_peak_memory_stats.html#torch.cuda.reset_peak_memory_stats "torch.cuda.reset_peak_memory_stats") | 重置CUDA内存分配器跟踪的“峰值”统计信息。 |
| [`caching_allocator_alloc`](generated/torch.cuda.caching_allocator_alloc.html#torch.cuda.caching_allocator_alloc "torch.cuda.caching_allocator_alloc") | 使用CUDA内存分配器执行内存分配。 |
| [`caching_allocator_delete`](generated/torch.cuda.caching_allocator_delete.html#torch.cuda.caching_allocator_delete "torch.cuda.caching_allocator_delete") | 删除使用CUDA内存分配器分配的内存。 |
| [`get_allocator_backend`](generated/torch.cuda.get_allocator_backend.html#torch.cuda.get_allocator_backend "torch.cuda.get_allocator_backend") | 返回一个描述由 `PYTORCH_CUDA_ALLOC_CONF` 设置的活动分配器后端的字符串。 |
| [`CUDAPluggableAllocator`](generated/torch.cuda.CUDAPluggableAllocator.html#torch.cuda.CUDAPluggableAllocator "torch.cuda.CUDAPluggableAllocator") | 从so文件加载的CUDA内存分配器。 |
| [`change_current_allocator`](generated/torch.cuda.change_current_allocator.html#torch.cuda.change_current_allocator "torch.cuda.change_current_allocator") | 将当前使用的内存分配器更改为提供的内存分配器。 |

## NVIDIA工具扩展（NVTX）[](#nvidia-tools-extension-nvtx "跳转到此标题")

| [`nvtx.mark`](generated/torch.cuda.nvtx.mark.html#torch.cuda.nvtx.mark "torch.cuda.nvtx.mark") | 描述在某个时间点发生的瞬时事件。 |
| --- | --- |
| [`nvtx.range_push`](generated/torch.cuda.nvtx.range_push.html#torch.cuda.nvtx.range_push "torch.cuda.nvtx.range_push") | 将范围推送到嵌套范围跨度的堆栈上。 |
| [`nvtx.range_pop`](generated/torch.cuda.nvtx.range_pop.html#torch.cuda.nvtx.range_pop "torch.cuda.nvtx.range_pop") | 从嵌套范围跨度堆栈中弹出范围。 |

## Jiterator（beta）

| [`jiterator._create_jit_fn`](generated/torch.cuda.jiterator._create_jit_fn.html#torch.cuda.jiterator._create_jit_fn "torch.cuda.jiterator._create_jit_fn") | 创建一个由jiterator生成的cuda内核，用于逐元素操作。 |
| --- | --- |
| [`jiterator._create_multi_output_jit_fn`](generated/torch.cuda.jiterator._create_multi_output_jit_fn.html#torch.cuda.jiterator._create_multi_output_jit_fn "torch.cuda.jiterator._create_multi_output_jit_fn") | 创建一个由jiterator生成的cuda内核，用于支持返回一个或多个输出的逐元素操作。 |

## 流消毒器（原型）[](#stream-sanitizer-prototype "跳转到此标题的永久链接")

CUDA消毒器是一个用于检测PyTorch中流之间同步错误的原型工具。请查看[文档](cuda._sanitizer.html)以获取如何使用它的信息。
