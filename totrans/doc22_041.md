# torch.cuda

> 原文：[`pytorch.org/docs/stable/cuda.html`](https://pytorch.org/docs/stable/cuda.html)

此软件包添加了对 CUDA 张量类型的支持。

它实现了与 CPU 张量相同的功能，但利用 GPU 进行计算。

它是懒惰初始化的，所以您可以随时导入它，并使用`is_available()`来确定您的系统是否支持 CUDA。

CUDA 语义有关使用 CUDA 的更多详细信息。

| `StreamContext` | 选择给定流的上下文管理器。 |
| --- | --- |
| `can_device_access_peer` | 检查两个设备之间是否可以进行对等访问。 |
| `current_blas_handle` | 返回当前 cuBLAS 句柄的 cublasHandle_t 指针 |
| `current_device` | 返回当前选择设备的索引。 |
| `current_stream` | 返回给定设备当前选择的`Stream`。 |
| `default_stream` | 返回给定设备的默认`Stream`。 |
| `device` | 上下文管理器，更改所选设备。 |
| `device_count` | 返回可用的 GPU 数量。 |
| `device_of` | 上下文管理器，将当前设备更改为给定对象的设备。 |
| `get_arch_list` | 返回此库编译的 CUDA 架构列表。 |
| `get_device_capability` | 获取设备的 cuda 能力。 |
| `get_device_name` | 获取设备的名称。 |
| `get_device_properties` | 获取设备的属性。 |
| `get_gencode_flags` | 返回此库编译时使用的 NVCC gencode 标志。 |
| `get_sync_debug_mode` | 返回 cuda 同步操作的调试模式的当前值。 |
| `init` | 初始化 PyTorch 的 CUDA 状态。 |
| `ipc_collect` | 在 CUDA IPC 释放 GPU 内存后强制收集。 |
| `is_available` | 返回一个布尔值，指示当前是否可用 CUDA。 |
| `is_initialized` | 返回 PyTorch 的 CUDA 状态是否已初始化。 |
| `memory_usage` | 返回过去采样周期内全局（设备）内存被读取或写入的时间百分比，由 nvidia-smi 给出。 |
| `set_device` | 设置当前设备。 |
| `set_stream` | 设置当前流。这是一个包装 API，用于设置流。 |
| `set_sync_debug_mode` | 设置 cuda 同步操作的调试模式。 |
| `stream` | 包装上下文管理器 StreamContext，选择给定的流。 |
| `synchronize` | 等待 CUDA 设备上所有流中的所有内核完成。 |
| `utilization` | 返回过去采样周期内 GPU 上一个或多个内核执行的时间百分比，由 nvidia-smi 给出。 |
| `temperature` | 返回 GPU 传感器的平均温度，单位为摄氏度（C）。 |
| `power_draw` | 返回 GPU 传感器的平均功耗，单位为毫瓦（mW） |
| `clock_rate` | 返回 GPU SM 的时钟速度，单位为赫兹（Hz），在过去的采样周期内由 nvidia-smi 给出。 |
| `OutOfMemoryError` | 当 CUDA 内存不足时引发的异常 |

## 随机数生成器

| `get_rng_state` | 返回指定 GPU 的随机数生成器状态，作为 ByteTensor。 |
| --- | --- |
| `get_rng_state_all` | 返回表示所有设备的随机数状态的 ByteTensor 列表。 |
| `set_rng_state` | 设置指定 GPU 的随机数生成器状态。 |
| `set_rng_state_all` | 设置所有设备的随机数生成器状态。 |
| `manual_seed` | 为当前 GPU 设置生成随机数的种子。 |
| `manual_seed_all` | 在所有 GPU 上设置生成随机数的种子。 |
| `seed` | 为当前 GPU 将生成随机数的种子设置为随机数。 |
| `seed_all` | 将生成随机数的种子设置为所有 GPU 上的随机数。 |
| `initial_seed` | 返回当前 GPU 的当前随机种子。 |

## 通信集合

| `comm.broadcast` | 将张量广播到指定的 GPU 设备。 |
| --- | --- |
| `comm.broadcast_coalesced` | 将一系列张量广播到指定的 GPU。 |
| `comm.reduce_add` | 对多个 GPU 的张量求和。 |
| `comm.scatter` | 在多个 GPU 上分散张量。 |
| `comm.gather` | 从多个 GPU 设备中收集张量。 |

## 流和事件

| `Stream` | CUDA 流的包装器。 |
| --- | --- |
| `ExternalStream` | 外部分配的 CUDA 流的包装器。 |
| `Event` | CUDA 事件的包装器。 |

## 图（测试版）

| `is_current_stream_capturing` | 如果当前 CUDA 流正在进行 CUDA 图捕获，则返回 True，否则返回 False。 |
| --- | --- |
| `graph_pool_handle` | 返回表示图形内存池 id 的不透明令牌。 |
| `CUDAGraph` | CUDA 图的包装器。 |
| `graph` | 上下文管理器，将 CUDA 工作捕获到一个 `torch.cuda.CUDAGraph` 对象中以供以后重播。 |
| `make_graphed_callables` | 接受可调用对象（函数或 `nn.Module`）并返回图形化版本。 |

## 内存管理

| `empty_cache` | 释放缓存分配器当前持有的所有未使用内存，以便其他 GPU 应用程序可以使用，并在 nvidia-smi 中可见。 |
| --- | --- |
| `list_gpu_processes` | 返回给定设备的正在运行进程及其 GPU 内存使用情况的人类可读打印输出。 |
| `mem_get_info` | 使用 cudaMemGetInfo 返回给定设备的全局空闲和总 GPU 内存。 |
| `memory_stats` | 返回给定设备的 CUDA 内存分配器统计信息字典。 |
| `memory_summary` | 返回给定设备的当前内存分配器统计信息的人类可读打印输出。 |
| `memory_snapshot` | 返回跨所有设备的 CUDA 内存分配器状态的快照。 |
| `memory_allocated` | 返回给定设备上张量占用的当前 GPU 内存（以字节为单位）。 |
| `max_memory_allocated` | 返回给定设备张量占用的最大 GPU 内存（以字节为单位）。 |
| `reset_max_memory_allocated` | 重置跟踪给定设备张量占用的最大 GPU 内存的起始点。 |
| `memory_reserved` | 返回由缓存分配器管理的给定设备的当前 GPU 内存（以字节为单位）。 |
| `max_memory_reserved` | 返回由缓存分配器管理的给定设备的最大 GPU 内存（以字节为单位）。 |
| `set_per_process_memory_fraction` | 为进程设置内存分数。 |
| `memory_cached` | 已弃用；请参阅 `memory_reserved()`。 |
| `max_memory_cached` | 已弃用；请参阅 `max_memory_reserved()`。 |
| `reset_max_memory_cached` | 重置跟踪由缓存分配器管理的给定设备的最大 GPU 内存的起始点。 |
| `reset_peak_memory_stats` | 重置 CUDA 内存分配器跟踪的“峰值”统计信息。 |
| `caching_allocator_alloc` | 使用 CUDA 内存分配器执行内存分配。 |
| `caching_allocator_delete` | 删除使用 CUDA 内存分配器分配的内存。 |
| `get_allocator_backend` | 返回一个描述由 `PYTORCH_CUDA_ALLOC_CONF` 设置的活动分配器后端的字符串。 |
| `CUDAPluggableAllocator` | 从 so 文件加载的 CUDA 内存分配器。 |
| `change_current_allocator` | 将当前使用的内存分配器更改为提供的内存分配器。 |

## NVIDIA 工具扩展（NVTX）[](#nvidia-tools-extension-nvtx "跳转到此标题")

| `nvtx.mark` | 描述在某个时间点发生的瞬时事件。 |
| --- | --- |
| `nvtx.range_push` | 将范围推送到嵌套范围跨度的堆栈上。 |
| `nvtx.range_pop` | 从嵌套范围跨度堆栈中弹出范围。 |

## Jiterator（beta）

| `jiterator._create_jit_fn` | 创建一个由 jiterator 生成的 cuda 内核，用于逐元素操作。 |
| --- | --- |
| `jiterator._create_multi_output_jit_fn` | 创建一个由 jiterator 生成的 cuda 内核，用于支持返回一个或多个输出的逐元素操作。 |

## 流消毒器（原型）[](#stream-sanitizer-prototype "跳转到此标题的永久链接")

CUDA 消毒器是一个用于检测 PyTorch 中流之间同步错误的原型工具。请查看文档以获取如何使用它的信息。
