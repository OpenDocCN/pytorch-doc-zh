["```py\n>>> import torch.quantization as quant\n>>> import torchrec.quant as trec_quant\n>>> import torchrec as trec\n>>> qconfig = quant.QConfig(\n>>>     activation=quant.PlaceholderObserver,\n>>>     weight=quant.PlaceholderObserver.with_args(dtype=torch.qint8),\n>>> )\n>>> quantized = quant.quantize_dynamic(\n>>>     module,\n>>>     qconfig_spec={\n>>>         trec.EmbeddingBagCollection: qconfig,\n>>>     },\n>>>     mapping={\n>>>         trec.EmbeddingBagCollection: trec_quant.EmbeddingBagCollection,\n>>>     },\n>>>     inplace=inplace,\n>>> ) \n```", "```py\nclass torchrec.quant.embedding_modules.EmbeddingBagCollection(tables: List[EmbeddingBagConfig], is_weighted: bool, device: device, output_dtype: dtype = torch.float32, table_name_to_quantized_weights: Optional[Dict[str, Tuple[Tensor, Tensor]]] = None, register_tbes: bool = False, quant_state_dict_split_scale_bias: bool = False, row_alignment: int = 16)\u00b6\n```", "```py\ntable_0 = EmbeddingBagConfig(\n    name=\"t1\", embedding_dim=3, num_embeddings=10, feature_names=[\"f1\"]\n)\ntable_1 = EmbeddingBagConfig(\n    name=\"t2\", embedding_dim=4, num_embeddings=10, feature_names=[\"f2\"]\n)\nebc = EmbeddingBagCollection(tables=[eb1_config, eb2_config])\n\n#        0       1        2  <-- batch\n# \"f1\"   [0,1] None    [2]\n# \"f2\"   [3]    [4]    [5,6,7]\n#  ^\n# feature\nfeatures = KeyedJaggedTensor(\n    keys=[\"f1\", \"f2\"],\n    values=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7]),\n    offsets=torch.tensor([0, 2, 2, 3, 4, 5, 8]),\n)\n\nebc.qconfig = torch.quantization.QConfig(\n    activation=torch.quantization.PlaceholderObserver.with_args(\n        dtype=torch.qint8\n    ),\n    weight=torch.quantization.PlaceholderObserver.with_args(dtype=torch.qint8),\n)\n\nqebc = QuantEmbeddingBagCollection.from_float(ebc)\nquantized_embeddings = qebc(features) \n```", "```py\nproperty device: device\u00b6\n```", "```py\nembedding_bag_configs() \u2192 List[EmbeddingBagConfig]\u00b6\n```", "```py\nforward(features: KeyedJaggedTensor) \u2192 KeyedTensor\u00b6\n```", "```py\nclassmethod from_float(module: EmbeddingBagCollection) \u2192 EmbeddingBagCollection\u00b6\n```", "```py\nis_weighted() \u2192 bool\u00b6\n```", "```py\noutput_dtype() \u2192 dtype\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.quant.embedding_modules.EmbeddingCollection(tables: List[EmbeddingConfig], device: device, need_indices: bool = False, output_dtype: dtype = torch.float32, table_name_to_quantized_weights: Optional[Dict[str, Tuple[Tensor, Tensor]]] = None, register_tbes: bool = False, quant_state_dict_split_scale_bias: bool = False, row_alignment: int = 16)\u00b6\n```", "```py\ne1_config = EmbeddingConfig(\n    name=\"t1\", embedding_dim=3, num_embeddings=10, feature_names=[\"f1\"]\n)\ne2_config = EmbeddingConfig(\n    name=\"t2\", embedding_dim=3, num_embeddings=10, feature_names=[\"f2\"]\n)\n\nec = EmbeddingCollection(tables=[e1_config, e2_config])\n\n#     0       1        2  <-- batch\n# 0   [0,1] None    [2]\n# 1   [3]    [4]    [5,6,7]\n# ^\n# feature\n\nfeatures = KeyedJaggedTensor.from_offsets_sync(\n    keys=[\"f1\", \"f2\"],\n    values=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7]),\n    offsets=torch.tensor([0, 2, 2, 3, 4, 5, 8]),\n)\nfeature_embeddings = ec(features)\nprint(feature_embeddings['f2'].values())\ntensor([[-0.2050,  0.5478,  0.6054],\n[ 0.7352,  0.3210, -3.0399],\n[ 0.1279, -0.1756, -0.4130],\n[ 0.7519, -0.4341, -0.0499],\n[ 0.9329, -1.0697, -0.8095]], grad_fn=<EmbeddingBackward>) \n```", "```py\nproperty device: device\u00b6\n```", "```py\nembedding_configs() \u2192 List[EmbeddingConfig]\u00b6\n```", "```py\nembedding_dim() \u2192 int\u00b6\n```", "```py\nembedding_names_by_table() \u2192 List[List[str]]\u00b6\n```", "```py\nforward(features: KeyedJaggedTensor) \u2192 Dict[str, JaggedTensor]\u00b6\n```", "```py\nclassmethod from_float(module: EmbeddingCollection) \u2192 EmbeddingCollection\u00b6\n```", "```py\nneed_indices() \u2192 bool\u00b6\n```", "```py\noutput_dtype() \u2192 dtype\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\nclass torchrec.quant.embedding_modules.FeatureProcessedEmbeddingBagCollection(tables: List[EmbeddingBagConfig], is_weighted: bool, device: device, output_dtype: dtype = torch.float32, table_name_to_quantized_weights: Optional[Dict[str, Tuple[Tensor, Tensor]]] = None, register_tbes: bool = False, quant_state_dict_split_scale_bias: bool = False, row_alignment: int = 16, feature_processor: Optional[FeatureProcessorsCollection] = None)\u00b6\n```", "```py\nembedding_bags: nn.ModuleDict\u00b6\n```", "```py\nforward(features: KeyedJaggedTensor) \u2192 KeyedTensor\u00b6\n```", "```py\nclassmethod from_float(module: FeatureProcessedEmbeddingBagCollection) \u2192 FeatureProcessedEmbeddingBagCollection\u00b6\n```", "```py\ntbes: torch.nn.ModuleList\u00b6\n```", "```py\ntraining: bool\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.for_each_module_of_type_do(module: Module, module_types: List[Type[Module]], op: Callable[[Module], None]) \u2192 None\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.pruned_num_embeddings(pruning_indices_mapping: Tensor) \u2192 int\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.quant_prep_customize_row_alignment(module: Module, module_types: List[Type[Module]], row_alignment: int) \u2192 None\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.quant_prep_enable_quant_state_dict_split_scale_bias(module: Module) \u2192 None\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.quant_prep_enable_quant_state_dict_split_scale_bias_for_types(module: Module, module_types: List[Type[Module]]) \u2192 None\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.quant_prep_enable_register_tbes(module: Module, module_types: List[Type[Module]]) \u2192 None\u00b6\n```", "```py\ntorchrec.quant.embedding_modules.quantize_state_dict(module: Module, table_name_to_quantized_weights: Dict[str, Tuple[Tensor, Tensor]], table_name_to_data_type: Dict[str, DataType], table_name_to_pruning_indices_mapping: Optional[Dict[str, Tensor]] = None) \u2192 device\u00b6\n```", "```py\n>>> import torch.quantization as quant\n>>> import torchrec.quant as trec_quant\n>>> import torchrec as trec\n>>> qconfig = quant.QConfig(\n>>>     activation=quant.PlaceholderObserver,\n>>>     weight=quant.PlaceholderObserver.with_args(dtype=torch.qint8),\n>>> )\n>>> quantized = quant.quantize_dynamic(\n>>>     module,\n>>>     qconfig_spec={\n>>>         trec.EmbeddingBagCollection: qconfig,\n>>>     },\n>>>     mapping={\n>>>         trec.EmbeddingBagCollection: trec_quant.EmbeddingBagCollection,\n>>>     },\n>>>     inplace=inplace,\n>>> ) \n```"]