["```py\nclass torch.TypedStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\nbfloat16()\u00b6\n```", "```py\nbool()\u00b6\n```", "```py\nbyte()\u00b6\n```", "```py\nchar()\u00b6\n```", "```py\nclone()\u00b6\n```", "```py\ncomplex_double()\u00b6\n```", "```py\ncomplex_float()\u00b6\n```", "```py\ncopy_(source, non_blocking=None)\u00b6\n```", "```py\ncpu()\u00b6\n```", "```py\ncuda(device=None, non_blocking=False, **kwargs)\u00b6\n```", "```py\ndata_ptr()\u00b6\n```", "```py\nproperty device\u00b6\n```", "```py\ndouble()\u00b6\n```", "```py\ndtype: dtype\u00b6\n```", "```py\nelement_size()\u00b6\n```", "```py\nproperty filename: Optional[str]\u00b6\n```", "```py\nfill_(value)\u00b6\n```", "```py\nfloat()\u00b6\n```", "```py\nfloat8_e4m3fn()\u00b6\n```", "```py\nfloat8_e5m2()\u00b6\n```", "```py\nclassmethod from_buffer(*args, **kwargs)\u00b6\n```", "```py\nclassmethod from_file(filename, shared=False, size=0) \u2192 Storage\u00b6\n```", "```py\nget_device()\u00b6\n```", "```py\nhalf()\u00b6\n```", "```py\nhpu(device=None, non_blocking=False, **kwargs)\u00b6\n```", "```py\nint()\u00b6\n```", "```py\nproperty is_cuda\u00b6\n```", "```py\nproperty is_hpu\u00b6\n```", "```py\nis_pinned(device='cuda')\u00b6\n```", "```py\nis_shared()\u00b6\n```", "```py\nis_sparse = False\u00b6\n```", "```py\nlong()\u00b6\n```", "```py\nnbytes()\u00b6\n```", "```py\npickle_storage_type()\u00b6\n```", "```py\npin_memory(device='cuda')\u00b6\n```", "```py\nresize_(size)\u00b6\n```", "```py\nshare_memory_()\u00b6\n```", "```py\nshort()\u00b6\n```", "```py\nsize()\u00b6\n```", "```py\ntolist()\u00b6\n```", "```py\ntype(dtype=None, non_blocking=False)\u00b6\n```", "```py\nuntyped()\u00b6\n```", "```py\nclass torch.UntypedStorage(*args, **kwargs)\u00b6\n```", "```py\nbfloat16()\u00b6\n```", "```py\nbool()\u00b6\n```", "```py\nbyte()\u00b6\n```", "```py\nbyteswap(dtype)\u00b6\n```", "```py\nchar()\u00b6\n```", "```py\nclone()\u00b6\n```", "```py\ncomplex_double()\u00b6\n```", "```py\ncomplex_float()\u00b6\n```", "```py\ncopy_()\u00b6\n```", "```py\ncpu()\u00b6\n```", "```py\ncuda(device=None, non_blocking=False, **kwargs)\u00b6\n```", "```py\ndata_ptr()\u00b6\n```", "```py\ndevice: device\u00b6\n```", "```py\ndouble()\u00b6\n```", "```py\nelement_size()\u00b6\n```", "```py\nproperty filename: Optional[str]\u00b6\n```", "```py\nfill_()\u00b6\n```", "```py\nfloat()\u00b6\n```", "```py\nfloat8_e4m3fn()\u00b6\n```", "```py\nfloat8_e5m2()\u00b6\n```", "```py\nstatic from_buffer()\u00b6\n```", "```py\nstatic from_file(filename, shared=False, size=0) \u2192 Storage\u00b6\n```", "```py\nget_device()\u00b6\n```", "```py\nhalf()\u00b6\n```", "```py\nhpu(device=None, non_blocking=False, **kwargs)\u00b6\n```", "```py\nint()\u00b6\n```", "```py\nproperty is_cuda\u00b6\n```", "```py\nproperty is_hpu\u00b6\n```", "```py\nis_pinned(device='cuda')\u00b6\n```", "```py\nis_shared()\u00b6\n```", "```py\nis_sparse: bool = False\u00b6\n```", "```py\nis_sparse_csr: bool = False\u00b6\n```", "```py\nlong()\u00b6\n```", "```py\nmps()\u00b6\n```", "```py\nnbytes()\u00b6\n```", "```py\nnew()\u00b6\n```", "```py\npin_memory(device='cuda')\u00b6\n```", "```py\nresize_()\u00b6\n```", "```py\nshare_memory_(*args, **kwargs)\u00b6\n```", "```py\nshort()\u00b6\n```", "```py\nsize()\u00b6\n```", "```py\ntolist()\u00b6\n```", "```py\ntype(dtype=None, non_blocking=False, **kwargs)\u00b6\n```", "```py\nuntyped()\u00b6\n```", "```py\nclass torch.DoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.float64\u00b6\n```", "```py\nclass torch.FloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.float32\u00b6\n```", "```py\nclass torch.HalfStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.float16\u00b6\n```", "```py\nclass torch.LongStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.int64\u00b6\n```", "```py\nclass torch.IntStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.int32\u00b6\n```", "```py\nclass torch.ShortStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.int16\u00b6\n```", "```py\nclass torch.CharStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.int8\u00b6\n```", "```py\nclass torch.ByteStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.uint8\u00b6\n```", "```py\nclass torch.BoolStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.bool\u00b6\n```", "```py\nclass torch.BFloat16Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.bfloat16\u00b6\n```", "```py\nclass torch.ComplexDoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.complex128\u00b6\n```", "```py\nclass torch.ComplexFloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.complex64\u00b6\n```", "```py\nclass torch.QUInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.quint8\u00b6\n```", "```py\nclass torch.QInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.qint8\u00b6\n```", "```py\nclass torch.QInt32Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.qint32\u00b6\n```", "```py\nclass torch.QUInt4x2Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.quint4x2\u00b6\n```", "```py\nclass torch.QUInt2x4Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\u00b6\n```", "```py\ndtype: dtype = torch.quint2x4\u00b6\n```"]