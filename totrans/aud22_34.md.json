["```py\nimport torch\nimport torchaudio\n\nprint(torch.__version__)\nprint([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n\n[torch.random.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed \"torch.manual_seed\")(0)\n[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")(\"cuda\" if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available \"torch.cuda.is_available\")() else \"cpu\")\n\nprint([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\")) \n```", "```py\n2.2.0\n2.2.0\ncuda \n```", "```py\nimport IPython\nimport matplotlib.pyplot as plt\nfrom torchaudio.utils import download_asset\n\n[SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\") \n```", "```py\n 0%|          | 0.00/106k [00:00<?, ?B/s]\n100%|##########| 106k/106k [00:00<00:00, 51.7MB/s] \n```", "```py\nbundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n\nprint(\"Sample Rate:\", bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\"))\n\nprint(\"Labels:\", bundle.get_labels()) \n```", "```py\nSample Rate: 16000\nLabels: ('-', '|', 'E', 'T', 'A', 'O', 'N', 'I', 'H', 'S', 'R', 'D', 'L', 'U', 'M', 'W', 'C', 'F', 'G', 'Y', 'P', 'B', 'V', 'K', \"'\", 'X', 'J', 'Q', 'Z') \n```", "```py\nmodel = bundle.get_model().to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\nprint(model.__class__) \n```", "```py\nDownloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n\n  0%|          | 0.00/360M [00:00<?, ?B/s]\n  3%|2         | 10.5M/360M [00:00<00:03, 110MB/s]\n  6%|6         | 22.9M/360M [00:00<00:02, 121MB/s]\n 17%|#6        | 60.7M/360M [00:00<00:01, 247MB/s]\n 29%|##8       | 103M/360M [00:00<00:00, 323MB/s]\n 37%|###7      | 134M/360M [00:00<00:00, 325MB/s]\n 47%|####7     | 170M/360M [00:00<00:00, 342MB/s]\n 57%|#####6    | 204M/360M [00:00<00:00, 348MB/s]\n 70%|######9   | 250M/360M [00:00<00:00, 391MB/s]\n 80%|#######9  | 288M/360M [00:00<00:00, 374MB/s]\n 90%|########9 | 323M/360M [00:01<00:00, 366MB/s]\n100%|#########9| 358M/360M [00:01<00:00, 309MB/s]\n100%|##########| 360M/360M [00:01<00:00, 317MB/s]\n<class 'torchaudio.models.wav2vec2.model.Wav2Vec2Model'> \n```", "```py\nIPython.display.Audio([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\n[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") = torchaudio.load([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\n[waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\").to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device \"torch.device\"))\n\nif [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\") != bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\"):\n    [waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = torchaudio.functional.resample([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), [sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), bundle.[sample_rate](https://docs.python.org/3/library/functions.html#int \"builtins.int\")) \n```", "```py\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [features](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"), _ = model.extract_features([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nfig, [ax](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"numpy.ndarray\") = plt.subplots(len([features](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")), 1, figsize=(16, 4.3 * len([features](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\"))))\nfor [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\"), [feats](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") in enumerate([features](https://docs.python.org/3/library/stdtypes.html#list \"builtins.list\")):\n    [ax](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"numpy.ndarray\")[[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].imshow([feats](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].cpu(), interpolation=\"nearest\")\n    [ax](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"numpy.ndarray\")[[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].set_title(f\"Feature from transformer layer {[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")+1}\")\n    [ax](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"numpy.ndarray\")[[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].set_xlabel(\"Feature dimension\")\n    [ax](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"numpy.ndarray\")[[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")].set_ylabel(\"Frame (time-axis)\")\nfig.tight_layout() \n```", "```py\nwith [torch.inference_mode](https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode \"torch.inference_mode\")():\n    [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), _ = model([waveform](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) \n```", "```py\nplt.imshow([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0].cpu().T, interpolation=\"nearest\")\nplt.title(\"Classification result\")\nplt.xlabel(\"Frame (time-axis)\")\nplt.ylabel(\"Class\")\nplt.tight_layout()\nprint(\"Class labels:\", bundle.get_labels()) \n```", "```py\nClass labels: ('-', '|', 'E', 'T', 'A', 'O', 'N', 'I', 'H', 'S', 'R', 'D', 'L', 'U', 'M', 'W', 'C', 'F', 'G', 'Y', 'P', 'B', 'V', 'K', \"'\", 'X', 'J', 'Q', 'Z') \n```", "```py\nclass GreedyCTCDecoder([torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, labels, blank=0):\n        super().__init__()\n        self.labels = labels\n        self.blank = blank\n\n    def forward(self, [emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"): [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")) -> str:\n  \"\"\"Given a sequence emission over labels, get the best path string\n Args:\n emission (Tensor): Logit tensors. Shape `[num_seq, num_label]`.\n\n Returns:\n str: The resulting transcript\n \"\"\"\n        indices = [torch.argmax](https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax \"torch.argmax\")([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\"), dim=-1)  # [num_seq,]\n        indices = [torch.unique_consecutive](https://pytorch.org/docs/stable/generated/torch.unique_consecutive.html#torch.unique_consecutive \"torch.unique_consecutive\")(indices, dim=-1)\n        indices = [[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") for [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in indices if [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") != self.blank]\n        return \"\".join([self.labels[[i](https://docs.python.org/3/library/functions.html#int \"builtins.int\")] for [i](https://docs.python.org/3/library/functions.html#int \"builtins.int\") in indices]) \n```", "```py\ndecoder = [GreedyCTCDecoder](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")(labels=bundle.get_labels())\n[transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\") = decoder([emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\")[0]) \n```", "```py\nprint([transcript](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\"))\nIPython.display.Audio([SPEECH_FILE](https://docs.python.org/3/library/stdtypes.html#str \"builtins.str\")) \n```", "```py\nI|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT| \n```", "```py\nmodel = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H.get_model()\n[emission](https://pytorch.org/docs/stable/tensors.html#torch.Tensor \"torch.Tensor\") = model(waveforms, ...) \n```"]