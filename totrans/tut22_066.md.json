["```py\n%%bash\npip  install  onnx  onnxruntime \n```", "```py\n# Some standard imports\nimport numpy as np\n\nfrom torch import nn\nimport torch.utils.model_zoo as model_zoo\nimport torch.onnx \n```", "```py\n# Super Resolution model definition in PyTorch\nimport torch.nn as nn\nimport torch.nn.init as init\n\nclass SuperResolutionNet([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module \"torch.nn.Module\")):\n    def __init__(self, upscale_factor, inplace=False):\n        super(SuperResolutionNet, self).__init__()\n\n        self.relu = [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \"torch.nn.ReLU\")(inplace=inplace)\n        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(1, 64, (5, 5), (1, 1), (2, 2))\n        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(64, 64, (3, 3), (1, 1), (1, 1))\n        self.conv3 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(64, 32, (3, 3), (1, 1), (1, 1))\n        self.conv4 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \"torch.nn.Conv2d\")(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n        self.pixel_shuffle = [nn.PixelShuffle](https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html#torch.nn.PixelShuffle \"torch.nn.PixelShuffle\")(upscale_factor)\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.pixel_shuffle(self.conv4(x))\n        return x\n\n    def _initialize_weights(self):\n        [init.orthogonal_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.orthogonal_ \"torch.nn.init.orthogonal_\")(self.conv1.weight, [init.calculate_gain](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain \"torch.nn.init.calculate_gain\")('relu'))\n        [init.orthogonal_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.orthogonal_ \"torch.nn.init.orthogonal_\")(self.conv2.weight, [init.calculate_gain](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain \"torch.nn.init.calculate_gain\")('relu'))\n        [init.orthogonal_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.orthogonal_ \"torch.nn.init.orthogonal_\")(self.conv3.weight, [init.calculate_gain](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain \"torch.nn.init.calculate_gain\")('relu'))\n        [init.orthogonal_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.orthogonal_ \"torch.nn.init.orthogonal_\")(self.conv4.weight)\n\n# Create the super-resolution model by using the above model definition.\ntorch_model = SuperResolutionNet(upscale_factor=3) \n```", "```py\n# Load pretrained model weights\nmodel_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\nbatch_size = 1    # just a random number\n\n# Initialize model with the pretrained weights\nmap_location = lambda storage, loc: storage\nif torch.cuda.is_available():\n    map_location = None\ntorch_model.load_state_dict([model_zoo.load_url](https://pytorch.org/docs/stable/model_zoo.html#torch.utils.model_zoo.load_url \"torch.utils.model_zoo.load_url\")(model_url, map_location=map_location))\n\n# set the model to inference mode\ntorch_model.eval() \n```", "```py\n# Input to the model\nx = torch.randn(batch_size, 1, 224, 224, requires_grad=True)\ntorch_out = torch_model(x)\n\n# Export the model\n[torch.onnx.export](https://pytorch.org/docs/stable/onnx_torchscript.html#torch.onnx.export \"torch.onnx.export\")(torch_model,               # model being run\n                  x,                         # model input (or a tuple for multiple inputs)\n                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n                  export_params=True,        # store the trained parameter weights inside the model file\n                  opset_version=10,          # the ONNX version to export the model to\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\n                  input_names = ['input'],   # the model's input names\n                  output_names = ['output'], # the model's output names\n                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n                                'output' : {0 : 'batch_size'}}) \n```", "```py\nimport onnx\n\nonnx_model = onnx.load(\"super_resolution.onnx\")\nonnx.checker.check_model(onnx_model) \n```", "```py\nimport onnxruntime\n\nort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\", providers=[\"CPUExecutionProvider\"])\n\ndef to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n\n# compute ONNX Runtime output prediction\nort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\nort_outs = ort_session.run(None, ort_inputs)\n\n# compare ONNX Runtime and PyTorch results\nnp.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n\nprint(\"Exported model has been tested with ONNXRuntime, and the result looks good!\") \n```", "```py\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\nimg = Image.open(\"./_static/img/cat.jpg\")\n\nresize = [transforms.Resize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize \"torchvision.transforms.Resize\")([224, 224])\nimg = resize(img)\n\nimg_ycbcr = img.convert('YCbCr')\nimg_y, img_cb, img_cr = img_ycbcr.split()\n\nto_tensor = [transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor \"torchvision.transforms.ToTensor\")()\nimg_y = to_tensor(img_y)\nimg_y.unsqueeze_(0) \n```", "```py\nort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\nort_outs = ort_session.run(None, ort_inputs)\nimg_out_y = ort_outs[0] \n```", "```py\nimg_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n\n# get the output image follow post-processing step from PyTorch implementation\nfinal_img = Image.merge(\n    \"YCbCr\", [\n        img_out_y,\n        img_cb.resize(img_out_y.size, Image.BICUBIC),\n        img_cr.resize(img_out_y.size, Image.BICUBIC),\n    ]).convert(\"RGB\")\n\n# Save the image, we will compare this with the output image from mobile device\nfinal_img.save(\"./_static/img/cat_superres_with_ort.jpg\") \n```"]