- en: torchaudio.transforms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: torchaudio.transforms
- en: 原文：[https://pytorch.org/audio/stable/transforms.html](https://pytorch.org/audio/stable/transforms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/audio/stable/transforms.html](https://pytorch.org/audio/stable/transforms.html)
- en: '`torchaudio.transforms` module contains common audio processings and feature
    extractions. The following diagram shows the relationship between some of the
    available transforms.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '`torchaudio.transforms`模块包含常见的音频处理和特征提取。以下图表显示了一些可用变换之间的关系。'
- en: '![https://download.pytorch.org/torchaudio/tutorial-assets/torchaudio_feature_extractions.png](../Images/82ba49f78e3cd14b6e337acaf57b11e2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![https://download.pytorch.org/torchaudio/tutorial-assets/torchaudio_feature_extractions.png](../Images/82ba49f78e3cd14b6e337acaf57b11e2.png)'
- en: Transforms are implemented using [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module
    "(in PyTorch v2.1)"). Common ways to build a processing pipeline are to define
    custom Module class or chain Modules together using [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential
    "(in PyTorch v2.1)"), then move it to a target device and data type.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 变换是使用[`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module
    "(在PyTorch v2.1中)")实现的。构建处理流程的常见方法是定义自定义Module类或使用[`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential
    "(在PyTorch v2.1中)")链接模块，然后将其移动到目标设备和数据类型。
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Please check out tutorials that cover in-depth usage of trasforms.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看涵盖变换深入使用的教程。
- en: '![Audio Feature Extractions](../Images/fc6b9ddc12696e086aaac0cd46a41785.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![音频特征提取](../Images/fc6b9ddc12696e086aaac0cd46a41785.png)'
- en: '[Audio Feature Extractions](tutorials/audio_feature_extractions_tutorial.html#sphx-glr-tutorials-audio-feature-extractions-tutorial-py)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[音频特征提取](tutorials/audio_feature_extractions_tutorial.html#sphx-glr-tutorials-audio-feature-extractions-tutorial-py)'
- en: Audio Feature Extractions
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 音频特征提取
- en: Utility[](#utility "Permalink to this heading")
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实用工具[](#utility "跳转到此标题")
- en: '| [`AmplitudeToDB`](generated/torchaudio.transforms.AmplitudeToDB.html#torchaudio.transforms.AmplitudeToDB
    "torchaudio.transforms.AmplitudeToDB") | Turn a tensor from the power/amplitude
    scale to the decibel scale. |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [`AmplitudeToDB`](generated/torchaudio.transforms.AmplitudeToDB.html#torchaudio.transforms.AmplitudeToDB
    "torchaudio.transforms.AmplitudeToDB") | 将张量从功率/幅度比例转换为分贝比例。 |'
- en: '| [`MuLawEncoding`](generated/torchaudio.transforms.MuLawEncoding.html#torchaudio.transforms.MuLawEncoding
    "torchaudio.transforms.MuLawEncoding") | Encode signal based on mu-law companding.
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [`MuLawEncoding`](generated/torchaudio.transforms.MuLawEncoding.html#torchaudio.transforms.MuLawEncoding
    "torchaudio.transforms.MuLawEncoding") | 基于mu-law压缩对信号进行编码。 |'
- en: '| [`MuLawDecoding`](generated/torchaudio.transforms.MuLawDecoding.html#torchaudio.transforms.MuLawDecoding
    "torchaudio.transforms.MuLawDecoding") | Decode mu-law encoded signal. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [`MuLawDecoding`](generated/torchaudio.transforms.MuLawDecoding.html#torchaudio.transforms.MuLawDecoding
    "torchaudio.transforms.MuLawDecoding") | 解码mu-law编码的信号。 |'
- en: '| [`Resample`](generated/torchaudio.transforms.Resample.html#torchaudio.transforms.Resample
    "torchaudio.transforms.Resample") | Resample a signal from one frequency to another.
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [`Resample`](generated/torchaudio.transforms.Resample.html#torchaudio.transforms.Resample
    "torchaudio.transforms.Resample") | 将信号从一个频率重新采样到另一个频率。 |'
- en: '| [`Fade`](generated/torchaudio.transforms.Fade.html#torchaudio.transforms.Fade
    "torchaudio.transforms.Fade") | Add a fade in and/or fade out to an waveform.
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [`Fade`](generated/torchaudio.transforms.Fade.html#torchaudio.transforms.Fade
    "torchaudio.transforms.Fade") | 为波形添加淡入和/或淡出。 |'
- en: '| [`Vol`](generated/torchaudio.transforms.Vol.html#torchaudio.transforms.Vol
    "torchaudio.transforms.Vol") | Adjust volume of waveform. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [`Vol`](generated/torchaudio.transforms.Vol.html#torchaudio.transforms.Vol
    "torchaudio.transforms.Vol") | 调整波形的音量。 |'
- en: '| [`Loudness`](generated/torchaudio.transforms.Loudness.html#torchaudio.transforms.Loudness
    "torchaudio.transforms.Loudness") | Measure audio loudness according to the ITU-R
    BS.1770-4 recommendation. |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| [`Loudness`](generated/torchaudio.transforms.Loudness.html#torchaudio.transforms.Loudness
    "torchaudio.transforms.Loudness") | 根据ITU-R BS.1770-4建议测量音频响度。 |'
- en: '| [`AddNoise`](generated/torchaudio.transforms.AddNoise.html#torchaudio.transforms.AddNoise
    "torchaudio.transforms.AddNoise") | Scales and adds noise to waveform per signal-to-noise
    ratio. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [`AddNoise`](generated/torchaudio.transforms.AddNoise.html#torchaudio.transforms.AddNoise
    "torchaudio.transforms.AddNoise") | 根据信噪比对波形进行缩放和添加噪音。 |'
- en: '| [`Convolve`](generated/torchaudio.transforms.Convolve.html#torchaudio.transforms.Convolve
    "torchaudio.transforms.Convolve") | Convolves inputs along their last dimension
    using the direct method. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [`Convolve`](generated/torchaudio.transforms.Convolve.html#torchaudio.transforms.Convolve
    "torchaudio.transforms.Convolve") | 使用直接方法沿着它们的最后一个维度对输入进行卷积。 |'
- en: '| [`FFTConvolve`](generated/torchaudio.transforms.FFTConvolve.html#torchaudio.transforms.FFTConvolve
    "torchaudio.transforms.FFTConvolve") | Convolves inputs along their last dimension
    using FFT. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [`FFTConvolve`](generated/torchaudio.transforms.FFTConvolve.html#torchaudio.transforms.FFTConvolve
    "torchaudio.transforms.FFTConvolve") | 使用FFT沿着它们的最后一个维度对输入进行卷积。 |'
- en: '| [`Speed`](generated/torchaudio.transforms.Speed.html#torchaudio.transforms.Speed
    "torchaudio.transforms.Speed") | Adjusts waveform speed. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [`Speed`](generated/torchaudio.transforms.Speed.html#torchaudio.transforms.Speed
    "torchaudio.transforms.Speed") | 调整波形速度。 |'
- en: '| [`SpeedPerturbation`](generated/torchaudio.transforms.SpeedPerturbation.html#torchaudio.transforms.SpeedPerturbation
    "torchaudio.transforms.SpeedPerturbation") | Applies the speed perturbation augmentation
    introduced in *Audio augmentation for speech recognition* [[Ko *et al.*, 2015](references.html#id58
    "Tom Ko, Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur. Audio augmentation
    for speech recognition. In Proc. Interspeech 2015, 3586–3589\. 2015\. doi:10.21437/Interspeech.2015-711.")].
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [`SpeedPerturbation`](generated/torchaudio.transforms.SpeedPerturbation.html#torchaudio.transforms.SpeedPerturbation
    "torchaudio.transforms.SpeedPerturbation") | 应用于*语音识别的音频增强*中引入的速度扰动增强[[Ko等，2015](references.html#id58
    "Tom Ko，Vijayaditya Peddinti，Daniel Povey和Sanjeev Khudanpur。语音识别的音频增强。在Proc. Interspeech
    2015中，3586-3589。2015。doi:10.21437/Interspeech.2015-711。")]. |'
- en: '| [`Deemphasis`](generated/torchaudio.transforms.Deemphasis.html#torchaudio.transforms.Deemphasis
    "torchaudio.transforms.Deemphasis") | De-emphasizes a waveform along its last
    dimension. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| [`Deemphasis`](generated/torchaudio.transforms.Deemphasis.html#torchaudio.transforms.Deemphasis
    "torchaudio.transforms.Deemphasis") | 沿着其最后一个维度减弱波形。 |'
- en: '| [`Preemphasis`](generated/torchaudio.transforms.Preemphasis.html#torchaudio.transforms.Preemphasis
    "torchaudio.transforms.Preemphasis") | Pre-emphasizes a waveform along its last
    dimension. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| [`Preemphasis`](generated/torchaudio.transforms.Preemphasis.html#torchaudio.transforms.Preemphasis
    "torchaudio.transforms.Preemphasis") | 沿着最后一个维度对波形进行预强调。 |'
- en: Feature Extractions[](#feature-extractions "Permalink to this heading")
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征提取[](#feature-extractions "跳转到此标题")
- en: '| [`Spectrogram`](generated/torchaudio.transforms.Spectrogram.html#torchaudio.transforms.Spectrogram
    "torchaudio.transforms.Spectrogram") | Create a spectrogram from a audio signal.
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| [`Spectrogram`](generated/torchaudio.transforms.Spectrogram.html#torchaudio.transforms.Spectrogram
    "torchaudio.transforms.Spectrogram") | 从音频信号创建频谱图。 |'
- en: '| [`InverseSpectrogram`](generated/torchaudio.transforms.InverseSpectrogram.html#torchaudio.transforms.InverseSpectrogram
    "torchaudio.transforms.InverseSpectrogram") | Create an inverse spectrogram to
    recover an audio signal from a spectrogram. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| [`InverseSpectrogram`](generated/torchaudio.transforms.InverseSpectrogram.html#torchaudio.transforms.InverseSpectrogram
    "torchaudio.transforms.InverseSpectrogram") | 创建一个逆频谱图，从频谱图中恢复音频信号。 |'
- en: '| [`MelScale`](generated/torchaudio.transforms.MelScale.html#torchaudio.transforms.MelScale
    "torchaudio.transforms.MelScale") | Turn a normal STFT into a mel frequency STFT
    with triangular filter banks. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| [`MelScale`](generated/torchaudio.transforms.MelScale.html#torchaudio.transforms.MelScale
    "torchaudio.transforms.MelScale") | 将普通STFT转换为带有三角滤波器组的梅尔频率STFT。 |'
- en: '| [`InverseMelScale`](generated/torchaudio.transforms.InverseMelScale.html#torchaudio.transforms.InverseMelScale
    "torchaudio.transforms.InverseMelScale") | Estimate a STFT in normal frequency
    domain from mel frequency domain. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| [`InverseMelScale`](generated/torchaudio.transforms.InverseMelScale.html#torchaudio.transforms.InverseMelScale
    "torchaudio.transforms.InverseMelScale") | 从梅尔频率域估计正常频率域中的STFT。 |'
- en: '| [`MelSpectrogram`](generated/torchaudio.transforms.MelSpectrogram.html#torchaudio.transforms.MelSpectrogram
    "torchaudio.transforms.MelSpectrogram") | Create MelSpectrogram for a raw audio
    signal. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| [`MelSpectrogram`](generated/torchaudio.transforms.MelSpectrogram.html#torchaudio.transforms.MelSpectrogram
    "torchaudio.transforms.MelSpectrogram") | 为原始音频信号创建MelSpectrogram。 |'
- en: '| [`GriffinLim`](generated/torchaudio.transforms.GriffinLim.html#torchaudio.transforms.GriffinLim
    "torchaudio.transforms.GriffinLim") | Compute waveform from a linear scale magnitude
    spectrogram using the Griffin-Lim transformation. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| [`GriffinLim`](generated/torchaudio.transforms.GriffinLim.html#torchaudio.transforms.GriffinLim
    "torchaudio.transforms.GriffinLim") | 使用Griffin-Lim变换从线性幅度频谱图计算波形。 |'
- en: '| [`MFCC`](generated/torchaudio.transforms.MFCC.html#torchaudio.transforms.MFCC
    "torchaudio.transforms.MFCC") | Create the Mel-frequency cepstrum coefficients
    from an audio signal. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| [`MFCC`](generated/torchaudio.transforms.MFCC.html#torchaudio.transforms.MFCC
    "torchaudio.transforms.MFCC") | 从音频信号创建梅尔频率倒谱系数。 |'
- en: '| [`LFCC`](generated/torchaudio.transforms.LFCC.html#torchaudio.transforms.LFCC
    "torchaudio.transforms.LFCC") | Create the linear-frequency cepstrum coefficients
    from an audio signal. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| [`LFCC`](generated/torchaudio.transforms.LFCC.html#torchaudio.transforms.LFCC
    "torchaudio.transforms.LFCC") | 从音频信号创建线性频率倒谱系数。 |'
- en: '| [`ComputeDeltas`](generated/torchaudio.transforms.ComputeDeltas.html#torchaudio.transforms.ComputeDeltas
    "torchaudio.transforms.ComputeDeltas") | Compute delta coefficients of a tensor,
    usually a spectrogram. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| [`ComputeDeltas`](generated/torchaudio.transforms.ComputeDeltas.html#torchaudio.transforms.ComputeDeltas
    "torchaudio.transforms.ComputeDeltas") | 计算张量的增量系数，通常是频谱图。 |'
- en: '| [`PitchShift`](generated/torchaudio.transforms.PitchShift.html#torchaudio.transforms.PitchShift
    "torchaudio.transforms.PitchShift") | Shift the pitch of a waveform by `n_steps`
    steps. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| [`PitchShift`](generated/torchaudio.transforms.PitchShift.html#torchaudio.transforms.PitchShift
    "torchaudio.transforms.PitchShift") | 将波形的音调移动`n_steps`步。 |'
- en: '| [`SlidingWindowCmn`](generated/torchaudio.transforms.SlidingWindowCmn.html#torchaudio.transforms.SlidingWindowCmn
    "torchaudio.transforms.SlidingWindowCmn") | Apply sliding-window cepstral mean
    (and optionally variance) normalization per utterance. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| [`SlidingWindowCmn`](generated/torchaudio.transforms.SlidingWindowCmn.html#torchaudio.transforms.SlidingWindowCmn
    "torchaudio.transforms.SlidingWindowCmn") | 对每个话语应用滑动窗口倾斜均值（和可选的方差）归一化。 |'
- en: '| [`SpectralCentroid`](generated/torchaudio.transforms.SpectralCentroid.html#torchaudio.transforms.SpectralCentroid
    "torchaudio.transforms.SpectralCentroid") | Compute the spectral centroid for
    each channel along the time axis. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| [`SpectralCentroid`](generated/torchaudio.transforms.SpectralCentroid.html#torchaudio.transforms.SpectralCentroid
    "torchaudio.transforms.SpectralCentroid") | 计算每个通道沿时间轴的频谱中心。 |'
- en: '| [`Vad`](generated/torchaudio.transforms.Vad.html#torchaudio.transforms.Vad
    "torchaudio.transforms.Vad") | Voice Activity Detector. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| [`Vad`](generated/torchaudio.transforms.Vad.html#torchaudio.transforms.Vad
    "torchaudio.transforms.Vad") | 语音活动检测器。 |'
- en: Augmentations[](#augmentations "Permalink to this heading")
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强[](#augmentations "跳转到此标题")
- en: 'The following transforms implement popular augmentation techniques known as
    *SpecAugment* [[Park *et al.*, 2019](references.html#id6 "Daniel S. Park, William
    Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D. Cubuk, and Quoc V. Le.
    Specaugment: a simple data augmentation method for automatic speech recognition.
    Interspeech 2019, Sep 2019\. URL: http://dx.doi.org/10.21437/Interspeech.2019-2680,
    doi:10.21437/interspeech.2019-2680.")].'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '以下转换实现了众所周知的增强技术，称为*SpecAugment* [[Park *et al.*, 2019](references.html#id6
    "Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D.
    Cubuk, and Quoc V. Le. Specaugment: a simple data augmentation method for automatic
    speech recognition. Interspeech 2019, Sep 2019\. URL: http://dx.doi.org/10.21437/Interspeech.2019-2680,
    doi:10.21437/interspeech.2019-2680.")].'
- en: '| [`FrequencyMasking`](generated/torchaudio.transforms.FrequencyMasking.html#torchaudio.transforms.FrequencyMasking
    "torchaudio.transforms.FrequencyMasking") | Apply masking to a spectrogram in
    the frequency domain. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| [`FrequencyMasking`](generated/torchaudio.transforms.FrequencyMasking.html#torchaudio.transforms.FrequencyMasking
    "torchaudio.transforms.FrequencyMasking") | 在频率域中对频谱图应用掩蔽。 |'
- en: '| [`TimeMasking`](generated/torchaudio.transforms.TimeMasking.html#torchaudio.transforms.TimeMasking
    "torchaudio.transforms.TimeMasking") | Apply masking to a spectrogram in the time
    domain. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| [`TimeMasking`](generated/torchaudio.transforms.TimeMasking.html#torchaudio.transforms.TimeMasking
    "torchaudio.transforms.TimeMasking") | 在时间域中对频谱图应用掩蔽。 |'
- en: '| [`TimeStretch`](generated/torchaudio.transforms.TimeStretch.html#torchaudio.transforms.TimeStretch
    "torchaudio.transforms.TimeStretch") | Stretch stft in time without modifying
    pitch for a given rate. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| [`TimeStretch`](generated/torchaudio.transforms.TimeStretch.html#torchaudio.transforms.TimeStretch
    "torchaudio.transforms.TimeStretch") | 在不改变音调的情况下拉伸时间的stft。 |'
- en: Loss[](#loss "Permalink to this heading")
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 损失[](#loss "到这个标题的永久链接")
- en: '| [`RNNTLoss`](generated/torchaudio.transforms.RNNTLoss.html#torchaudio.transforms.RNNTLoss
    "torchaudio.transforms.RNNTLoss") | Compute the RNN Transducer loss from *Sequence
    Transduction with Recurrent Neural Networks* [[Graves, 2012](references.html#id18
    "Alex Graves. Sequence transduction with recurrent neural networks. 2012\. arXiv:1211.3711.")].
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| [`RNNTLoss`](generated/torchaudio.transforms.RNNTLoss.html#torchaudio.transforms.RNNTLoss
    "torchaudio.transforms.RNNTLoss") | 计算来自*使用循环神经网络进行序列转导*[[Graves, 2012](references.html#id18
    "Alex Graves. Sequence transduction with recurrent neural networks. 2012\. arXiv:1211.3711.")]的RNN
    Transducer损失。 |'
- en: Multi-channel[](#multi-channel "Permalink to this heading")
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多通道[](#multi-channel "到这个标题的永久链接")
- en: '| [`PSD`](generated/torchaudio.transforms.PSD.html#torchaudio.transforms.PSD
    "torchaudio.transforms.PSD") | Compute cross-channel power spectral density (PSD)
    matrix. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| [`PSD`](generated/torchaudio.transforms.PSD.html#torchaudio.transforms.PSD
    "torchaudio.transforms.PSD") | 计算跨通道功率谱密度（PSD）矩阵。 |'
- en: '| [`MVDR`](generated/torchaudio.transforms.MVDR.html#torchaudio.transforms.MVDR
    "torchaudio.transforms.MVDR") | Minimum Variance Distortionless Response (MVDR)
    module that performs MVDR beamforming with Time-Frequency masks. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| [`MVDR`](generated/torchaudio.transforms.MVDR.html#torchaudio.transforms.MVDR
    "torchaudio.transforms.MVDR") | 执行带有时频掩模的MVDR波束形成的最小方差无失真响应（MVDR）模块。 |'
- en: '| [`RTFMVDR`](generated/torchaudio.transforms.RTFMVDR.html#torchaudio.transforms.RTFMVDR
    "torchaudio.transforms.RTFMVDR") | Minimum Variance Distortionless Response (*MVDR*
    [[Capon, 1969](references.html#id34 "Jack Capon. High-resolution frequency-wavenumber
    spectrum analysis. Proceedings of the IEEE, 57(8):1408–1418, 1969.")]) module
    based on the relative transfer function (RTF) and power spectral density (PSD)
    matrix of noise. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| [`RTFMVDR`](generated/torchaudio.transforms.RTFMVDR.html#torchaudio.transforms.RTFMVDR
    "torchaudio.transforms.RTFMVDR") | 基于相对传递函数（RTF）和噪声的功率谱密度（PSD）矩阵的最小方差无失真响应（*MVDR*[[Capon,
    1969](references.html#id34 "Jack Capon. High-resolution frequency-wavenumber spectrum
    analysis. Proceedings of the IEEE, 57(8):1408–1418, 1969.")])模块。 |'
- en: '| [`SoudenMVDR`](generated/torchaudio.transforms.SoudenMVDR.html#torchaudio.transforms.SoudenMVDR
    "torchaudio.transforms.SoudenMVDR") | Minimum Variance Distortionless Response
    (*MVDR* [[Capon, 1969](references.html#id34 "Jack Capon. High-resolution frequency-wavenumber
    spectrum analysis. Proceedings of the IEEE, 57(8):1408–1418, 1969.")]) module
    based on the method proposed by *Souden et, al.* [[Souden *et al.*, 2009](references.html#id28
    "Mehrez Souden, Jacob Benesty, and Sofiene Affes. On optimal frequency-domain
    multichannel linear filtering for noise reduction. In IEEE Transactions on audio,
    speech, and language processing, volume 18, 260–276\. IEEE, 2009.")]. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| [`SoudenMVDR`](generated/torchaudio.transforms.SoudenMVDR.html#torchaudio.transforms.SoudenMVDR
    "torchaudio.transforms.SoudenMVDR") | 基于*Souden等人*[[Souden *et al.*, 2009](references.html#id28
    "Mehrez Souden, Jacob Benesty, and Sofiene Affes. On optimal frequency-domain
    multichannel linear filtering for noise reduction. In IEEE Transactions on audio,
    speech, and language processing, volume 18, 260–276\. IEEE, 2009.")]提出的方法的最小方差无失真响应（*MVDR*[[Capon,
    1969](references.html#id34 "Jack Capon. High-resolution frequency-wavenumber spectrum
    analysis. Proceedings of the IEEE, 57(8):1408–1418, 1969.")])模块。 |'
