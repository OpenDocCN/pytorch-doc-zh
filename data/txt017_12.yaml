- en: torchtext.transforms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: torchtext.transforms
- en: 原文：[https://pytorch.org/text/stable/transforms.html](https://pytorch.org/text/stable/transforms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/text/stable/transforms.html](https://pytorch.org/text/stable/transforms.html)
- en: Transforms are common text transforms. They can be chained together using [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential
    "(in PyTorch v2.1)") or using [`torchtext.transforms.Sequential`](#torchtext.transforms.Sequential
    "torchtext.transforms.Sequential") to support torch-scriptability.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 转换是常见的文本转换。它们可以使用[`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)链接在一起，或者使用[`torchtext.transforms.Sequential`](#torchtext.transforms.Sequential)来支持torch-scriptability。
- en: SentencePieceTokenizer[](#sentencepiecetokenizer "Permalink to this heading")
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SentencePieceTokenizer[](#sentencepiecetokenizer)
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Transform for Sentence Piece tokenizer from pre-trained sentencepiece model
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练sentencepiece模型转换为Sentence Piece标记器
- en: 'Additional details: [https://github.com/google/sentencepiece](https://github.com/google/sentencepiece)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 附加细节：[https://github.com/google/sentencepiece](https://github.com/google/sentencepiece)
- en: 'Parameters:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**sp_model_path** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – Path to pre-trained sentencepiece model'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**sp_model_path**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）
    - 预训练sentencepiece模型的路径'
- en: Example
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Tutorials using `SentencePieceTokenizer`:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`SentencePieceTokenizer`的教程：
- en: '![SST-2 Binary text classification with XLM-RoBERTa model](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![SST-2二进制文本分类与XLM-RoBERTa模型](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
- en: '[SST-2 Binary text classification with XLM-RoBERTa model](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[SST-2二进制文本分类与XLM-RoBERTa模型](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
- en: SST-2 Binary text classification with XLM-RoBERTa model
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: SST-2二进制文本分类与XLM-RoBERTa模型
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Parameters:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* *List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – Input sentence or list of sentences on which to
    apply tokenizer.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*Union*[[*str*](https://docs.python.org/3/library/stdtypes.html#str),
    *List*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str)]]） - 要应用标记器的输入句子或句子列表。'
- en: 'Returns:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tokenized text
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化文本
- en: 'Return type:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python
    v3.12)")], List[List[[str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")]]]
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[str], List[List[str]]]
- en: GPT2BPETokenizer[](#gpt2bpetokenizer "Permalink to this heading")
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT2BPETokenizer[](#gpt2bpetokenizer)
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Transform for GPT-2 BPE Tokenizer.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用于GPT-2 BPE标记器的转换。
- en: Reimplements openai GPT-2 BPE in TorchScript. Original openai implementation
    [https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在TorchScript中重新实现openai GPT-2 BPE。原始openai实现[https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)
- en: 'Parameters:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**encoder_json_path** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – Path to GPT-2 BPE encoder json file.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**encoder_json_path**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）
    - GPT-2 BPE编码器json文件的路径。'
- en: '**vocab_bpe_path** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – Path to bpe vocab file.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**vocab_bpe_path**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）
    - bpe词汇文件的路径。'
- en: '**return_tokens** – Indicate whether to return split tokens. If False, it will
    return encoded token IDs as strings (default: False)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**return_tokens** - 指示是否返回拆分的标记。如果为False，则将返回编码的标记ID作为字符串（默认值：False）'
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Parameters:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* *List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – Input sentence or list of sentences on which to
    apply tokenizer.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*Union*[[*str*](https://docs.python.org/3/library/stdtypes.html#str),
    *List*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str)]]） - 要应用标记器的输入句子或句子列表。'
- en: 'Returns:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tokenized text
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化文本
- en: 'Return type:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python
    v3.12)")], List[List([str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"))]]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[str], List[List[str]]]
- en: CLIPTokenizer[](#cliptokenizer "Permalink to this heading")
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CLIPTokenizer[](#cliptokenizer)
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Transform for CLIP Tokenizer. Based on Byte-Level BPE.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 用于CLIP Tokenizer的转换。基于字节级BPE。
- en: 'Reimplements CLIP Tokenizer in TorchScript. Original implementation: [https://github.com/mlfoundations/open_clip/blob/main/src/clip/tokenizer.py](https://github.com/mlfoundations/open_clip/blob/main/src/clip/tokenizer.py)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在TorchScript中重新实现CLIP Tokenizer。原始实现：[https://github.com/mlfoundations/open_clip/blob/main/src/clip/tokenizer.py](https://github.com/mlfoundations/open_clip/blob/main/src/clip/tokenizer.py)
- en: This tokenizer has been trained to treat spaces like parts of the tokens (a
    bit like sentencepiece) so a word will be encoded differently whether it is at
    the beginning of the sentence (without space) or not.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个标记器已经训练成将空格视为标记的一部分（有点像sentencepiece），因此一个单词将根据它是否在句子开头（没有空格）而被编码为不同的方式。
- en: The below code snippet shows how to use the CLIP tokenizer with encoder and
    merges file taken from the original paper implementation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段显示了如何使用来自原始论文实现的编码器和合并文件的CLIP标记器。
- en: Example
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Parameters:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**merges_path** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – Path to bpe merges file.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**merges_path**（[*str*](https://docs.python.org/3/library/stdtypes.html#str)）
    - bpe合并文件的路径。'
- en: '**encoder_json_path** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – Optional, path to BPE encoder json file. When specified,
    this is used to infer num_merges.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**encoder_json_path**（[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")）- 可选，BPE编码器json文件的路径。当指定时，用于推断num_merges。'
- en: '**num_merges** ([*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")) – Optional, number of merges to read from the bpe merges
    file.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**num_merges**（[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")）- 可选，从bpe合并文件中读取的合并次数。'
- en: '**return_tokens** – Indicate whether to return split tokens. If False, it will
    return encoded token IDs as strings (default: False)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**return_tokens** - 指示是否返回拆分的标记。如果为False，它将返回编码的标记ID作为字符串（默认值：False）'
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Parameters:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* *List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – Input sentence or list of sentences on which to
    apply tokenizer.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**input**（*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* *List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*）- 要应用分词器的输入句子或句子列表。'
- en: 'Returns:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tokenized text
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化文本
- en: 'Return type:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python
    v3.12)")], List[List([str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"))]]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python
    v3.12)")], List[List([str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"))]]
- en: RegexTokenizer[](#regextokenizer "Permalink to this heading")
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则表达式分词器[](#regextokenizer "跳转到此标题")
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Regex tokenizer for a string sentence that applies all regex replacements defined
    in patterns_list. It is backed by the [C++ RE2 regular expression engine](https://github.com/google/re2)
    from Google.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 基于patterns_list中定义的所有正则表达式替换的字符串句子的正则表达式分词器。它由Google的[C++ RE2正则表达式引擎](https://github.com/google/re2)支持。
- en: 'Parameters:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**patterns_list** (*List**[**Tuple**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – a list of tuples (ordered pairs) which contain the
    regex pattern string'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**patterns_list**（*List**[**Tuple**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*）- 包含正则表达式模式字符串的元组（有序对）列表'
- en: '**element.** (*as the first element and the replacement string as the second*)
    –'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**element.**（作为第一个元素和替换字符串作为第二个）-'
- en: Caveats
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项
- en: The RE2 library does not support arbitrary lookahead or lookbehind assertions,
    nor does it support backreferences. Look at the [docs](https://swtch.com/~rsc/regexp/regexp3.html#caveats)
    here for more info.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RE2库不支持任意的前瞻或后顾断言，也不支持反向引用。查看这里的[文档](https://swtch.com/~rsc/regexp/regexp3.html#caveats)以获取更多信息。
- en: The final tokenization step always uses spaces as separators. To split strings
    based on a specific regex pattern, similar to Python’s [re.split](https://docs.python.org/3/library/re.html#re.split),
    a tuple of `('<regex_pattern>', ' ')` can be provided.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终的标记化步骤总是使用空格作为分隔符。要根据特定的正则表达式模式拆分字符串，类似于Python的[re.split](https://docs.python.org/3/library/re.html#re.split)，可以提供一个元组`('<regex_pattern>',
    ' ')`。
- en: Example
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: Regex tokenization based on `(patterns, replacements)` list.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基于`(patterns, replacements)`列表的正则表达式标记化。
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Regex tokenization based on `(single_pattern, ' ')` list.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 基于`(single_pattern, ' ')`列表的正则表达式标记化。
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Parameters:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**lines** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)")) – a text string to tokenize.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**lines**（[*str*](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)")）- 要分词的文本字符串。'
- en: 'Returns:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: a token list after regex.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式后的标记列表。
- en: 'Return type:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")]
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")]
- en: BERTTokenizer[](#berttokenizer "Permalink to this heading")
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BERT分词器[](#berttokenizer "跳转到此标题")
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Transform for BERT Tokenizer.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 用于BERT分词器的转换。
- en: 'Based on WordPiece algorithm introduced in paper: [https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 基于WordPiece算法的论文：[https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf)
- en: The backend kernel implementation is taken and modified from [https://github.com/LieluoboAi/radish](https://github.com/LieluoboAi/radish).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 后端内核实现取自[https://github.com/LieluoboAi/radish](https://github.com/LieluoboAi/radish)并进行了修改。
- en: See PR [https://github.com/pytorch/text/pull/1707](https://github.com/pytorch/text/pull/1707)
    summary for more details.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 查看PR [https://github.com/pytorch/text/pull/1707](https://github.com/pytorch/text/pull/1707)摘要以获取更多详细信息。
- en: The below code snippet shows how to use the BERT tokenizer using the pre-trained
    vocab files.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段显示了如何使用预训练的词汇文件来使用BERT分词器。
- en: Example
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Parameters:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**vocab_path** ([*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")) – Path to pre-trained vocabulary file. The path can be either
    local or URL.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**vocab_path**（[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")）- 预训练词汇文件的路径。路径可以是本地的或URL。'
- en: '**do_lower_case** (*Optional**[*[*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")*]*) – Indicate whether to do lower case. (default: True)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**do_lower_case**（*可选**[*[*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")*]*）- 指示是否进行小写处理。（默认值：True）'
- en: '**strip_accents** (*Optional**[*[*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")*]*) – Indicate whether to strip accents. (default: None)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**strip_accents**（*可选**[*[*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")*]*）- 指示是否去除重音符号。（默认值：None）'
- en: '**return_tokens** ([*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")) – Indicate whether to return tokens. If false, returns corresponding
    token IDs as strings (default: False)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**return_tokens**（[*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")）- 指示是否返回标记。如果为false，则返回相应的标记ID作为字符串（默认值：False）'
- en: '**never_split** (*Optional**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – Collection of tokens which will not be split during
    tokenization. (default: None)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**never_split** (*可选**[**列表**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**]*) – 在标记化过程中不会被分割的标记集合。（默认值：无）'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Parameters:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* *List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – Input sentence or list of sentences on which to
    apply tokenizer.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*,* *列表**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**]*) – 要应用标记器的输入句子或句子列表。'
- en: 'Returns:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: tokenized text
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化文本
- en: 'Return type:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[[str](https://docs.python.org/3/library/stdtypes.html#str "(in Python
    v3.12)")], List[List([str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"))]]
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[[str](https://docs.python.org/3/library/stdtypes.html#str "(在Python
    v3.12中)")], List[List([str](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)"))]]
- en: VocabTransform[](#vocabtransform "Permalink to this heading")
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VocabTransform[](#vocabtransform "跳转到此标题的永久链接")
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Vocab transform to convert input batch of tokens into corresponding token ids
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入标记批次转换为相应的标记ID的词汇转换
- en: 'Parameters:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**vocab** – an instance of [`torchtext.vocab.Vocab`](vocab.html#torchtext.vocab.Vocab
    "torchtext.vocab.Vocab") class.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**vocab** – [`torchtext.vocab.Vocab`](vocab.html#torchtext.vocab.Vocab "torchtext.vocab.Vocab")类的实例。'
- en: Example
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Tutorials using `VocabTransform`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`VocabTransform`的教程：
- en: '![SST-2 Binary text classification with XLM-RoBERTa model](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![SST-2使用XLM-RoBERTa模型进行二进制文本分类](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
- en: '[SST-2 Binary text classification with XLM-RoBERTa model](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[SST-2使用XLM-RoBERTa模型进行二进制文本分类](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
- en: SST-2 Binary text classification with XLM-RoBERTa model
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: SST-2使用XLM-RoBERTa模型进行二进制文本分类
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Parameters:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**,* *List**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]**]*) – Input batch of token to convert to correspnding
    token ids'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*Union**[**列表**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**,* *列表**[**列表**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**]**]*) – 要转换为相应标记ID的输入标记批次'
- en: 'Returns:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: Converted input into corresponding token ids
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入转换为相应的标记ID
- en: 'Return type:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[[int](https://docs.python.org/3/library/functions.html#int "(in Python
    v3.12)")], List[List[[int](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")]]]
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[[int](https://docs.python.org/3/library/functions.html#int "(在Python
    v3.12中)")], List[List[[int](https://docs.python.org/3/library/functions.html#int
    "(在Python v3.12中)")]]]
- en: ToTensor[](#totensor "Permalink to this heading")
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ToTensor[](#totensor "跳转到此标题的永久链接")
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Convert input to torch tensor
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入转换为torch张量
- en: 'Parameters:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**padding_value** (*Optional**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – Pad value to make each input in the batch of length
    equal to the longest sequence in the batch.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**padding_value** (*可选**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(在Python v3.12中)")*]*) – 用于使批次中每个输入的长度等于批次中最长序列的填充值。'
- en: '**dtype** ([`torch.dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype
    "(in PyTorch v2.1)")) – [`torch.dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype
    "(in PyTorch v2.1)") of output tensor'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**dtype** ([`torch.dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype
    "(在PyTorch v2.1中)")) – 输出张量的[`torch.dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype
    "(在PyTorch v2.1中)")'
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Parameters:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[**List**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**,* *List**[**List**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**]*) – Sequence or batch of token ids'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*Union**[**列表**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(在Python v3.12中)")*]**,* *列表**[**列表**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(在Python v3.12中)")*]**]**]*) – 标记ID的序列或批次'
- en: 'Return type:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Tensor
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 张量
- en: LabelToIndex[](#labeltoindex "Permalink to this heading")
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LabelToIndex[](#labeltoindex "跳转到此标题的永久链接")
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Transform labels from string names to ids.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 将标签从字符串名称转换为ID。
- en: 'Parameters:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**label_names** (*Optional**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – a list of unique label names'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**label_names** (*可选**[**列表**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**]*) – 一个唯一标签名称的列表'
- en: '**label_path** (*Optional**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]*) – a path to file containing unique label names containing
    1 label per line. Note that either label_names or label_path should be supplied
    but not both.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**label_path** (*可选**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]*) – 包含每行一个唯一标签名称的文件路径。请注意，应提供label_names或label_path之一，而不是两者都提供。'
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Parameters:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* *List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]*) – Input labels to convert to corresponding ids'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*,* *列表**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**]*) – 要转换为相应ID的输入标签'
- en: 'Return type:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[[int](https://docs.python.org/3/library/functions.html#int "(in Python
    v3.12)"), List[[int](https://docs.python.org/3/library/functions.html#int "(in
    Python v3.12)")]]
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Union[[int](https://docs.python.org/3/library/functions.html#int "(在Python v3.12中)"),
    List[[int](https://docs.python.org/3/library/functions.html#int "(在Python v3.12中)")]]
- en: Truncate[](#truncate "Permalink to this heading")
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Truncate[](#truncate "跳转到此标题的永久链接")
- en: '[PRE22]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Truncate input sequence
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 截断输入序列
- en: 'Parameters:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**max_seq_len** ([*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")) – The maximum allowable length for input sequence'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**max_seq_len** ([*int*](https://docs.python.org/3/library/functions.html#int
    "(在Python v3.12中)")) – 输入序列的最大允许长度'
- en: 'Tutorials using `Truncate`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Truncate`的教程：
- en: '![SST-2 Binary text classification with XLM-RoBERTa model](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![SST-2二进制文本分类与XLM-RoBERTa模型](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
- en: '[SST-2 Binary text classification with XLM-RoBERTa model](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[SST-2二进制文本分类与XLM-RoBERTa模型](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
- en: SST-2 Binary text classification with XLM-RoBERTa model
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: SST-2二进制文本分类与XLM-RoBERTa模型
- en: '[PRE23]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Parameters:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**,* *List**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**]**]*) – Input sequence or batch of sequence to be
    truncated'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*Union**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**,* *List**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**]**]*) – 要截断的输入序列或批处理序列'
- en: 'Returns:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: Truncated sequence
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 截断序列
- en: 'Return type:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[Union[[str](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)"), [int](https://docs.python.org/3/library/functions.html#int "(in
    Python v3.12)")]], List[List[Union[[str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"), [int](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")]]]]
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[Union[[str](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)"), [int](https://docs.python.org/3/library/functions.html#int "(in
    Python v3.12)")]], List[List[Union[[str](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"), [int](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")]]]]
- en: AddToken[](#addtoken "Permalink to this heading")
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AddToken[](#addtoken "Permalink to this heading")
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Add token to beginning or end of sequence
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在序列的开头或结尾添加标记
- en: 'Parameters:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**token** (*Union**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*,* [*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]*) – The token to be added'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**token** (*Union**[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*,* [*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]*) – 要添加的标记'
- en: '**begin** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in
    Python v3.12)")*,* *optional*) – Whether to insert token at start or end or sequence,
    defaults to True'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**begin** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in
    Python v3.12)")*,* *optional*) – 是否在序列的开头或结尾插入标记，默认为True'
- en: 'Tutorials using `AddToken`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`AddToken`的教程：
- en: '![SST-2 Binary text classification with XLM-RoBERTa model](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![SST-2二进制文本分类与XLM-RoBERTa模型](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
- en: '[SST-2 Binary text classification with XLM-RoBERTa model](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[SST-2二进制文本分类与XLM-RoBERTa模型](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
- en: SST-2 Binary text classification with XLM-RoBERTa model
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: SST-2二进制文本分类与XLM-RoBERTa模型
- en: '[PRE25]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Parameters:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**,* *List**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**]**]*) – Input sequence or batch'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (*Union**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**,* *List**[**List**[**Union**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*,* [*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]**]**]**]*) – 输入序列或批处理'
- en: Sequential[](#sequential "Permalink to this heading")
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sequential[](#sequential "Permalink to this heading")
- en: '[PRE26]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: A container to host a sequence of text transforms.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一个容器，用于存储文本转换的序列。
- en: 'Tutorials using `Sequential`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Sequential`的教程：
- en: '![SST-2 Binary text classification with XLM-RoBERTa model](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![SST-2二进制文本分类与XLM-RoBERTa模型](../Images/98241cb68ab73fa3d56bc87944e16fd8.png)'
- en: '[SST-2 Binary text classification with XLM-RoBERTa model](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[SST-2二进制文本分类与XLM-RoBERTa模型](tutorials/sst2_classification_non_distributed.html#sphx-glr-tutorials-sst2-classification-non-distributed-py)'
- en: SST-2 Binary text classification with XLM-RoBERTa model
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: SST-2二进制文本分类与XLM-RoBERTa模型
- en: '[PRE28]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Parameters:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (Any) – Input sequence or batch. The input type must be supported
    by the first transform in the sequence.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**input** (任意) – 输入序列或批处理。输入类型必须受到序列中第一个转换的支持。'
- en: PadTransform[](#padtransform "Permalink to this heading")
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PadTransform[](#padtransform "Permalink to this heading")
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Pad tensor to a fixed length with given padding value.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定的填充值将张量填充到固定长度。
- en: 'Parameters:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**max_length** ([*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")) – Maximum length to pad to'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**max_length** ([*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")) – 要填充到的最大长度'
- en: '**pad_value** ([*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")) – Value to pad the tensor with'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pad_value** ([*bool*](https://docs.python.org/3/library/functions.html#bool
    "(in Python v3.12)")) – 用于填充张量的值'
- en: '[PRE30]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Parameters:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**x** (*Tensor*) – The tensor to pad'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**x** (*张量*) – 要填充的张量'
- en: 'Returns:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: Tensor padded up to max_length with pad_value
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 张量使用填充值填充到最大长度
- en: 'Return type:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Tensor
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 张量
- en: StrToIntTransform[](#strtointtransform "Permalink to this heading")
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StrToIntTransform[](#strtointtransform "Permalink to this heading")
- en: '[PRE31]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Convert string tokens to integers (either single sequence or batch).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串标记转换为整数（单个序列或批处理）。
- en: '[PRE32]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Parameters:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** (*Union**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**,* *List**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")*]**]**]*) – sequence or batch of string tokens to convert'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入**（*Union**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**,* *List**[**List**[*[*str*](https://docs.python.org/3/library/stdtypes.html#str
    "(在Python v3.12中)")*]**]**]*) - 要转换的字符串标记的序列或批次'
- en: 'Returns:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: sequence or batch converted into corresponding token ids
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 转换为相应标记ID的序列或批次
- en: 'Return type:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 返回类型：
- en: Union[List[[int](https://docs.python.org/3/library/functions.html#int "(in Python
    v3.12)")], List[List[[int](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")]]]
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Union[List[[int](https://docs.python.org/3/library/functions.html#int "(在Python
    v3.12中)")], List[List[[int](https://docs.python.org/3/library/functions.html#int
    "(在Python v3.12中)")]]]
- en: CharBPETokenizer[](#charbpetokenizer "Permalink to this heading")
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CharBPETokenizer[](#charbpetokenizer "到这个标题的永久链接")
- en: '[PRE33]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Transform for a Character Byte-Pair-Encoding Tokenizer.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 字符字节对编码分词器的转换。
- en: ':param : param bpe_encoder_path: Path to the BPE encoder json file. :param
    : type bpe_encoder_path: str :param : param bpe_merges_path: Path to the BPE merges
    text file. :param : type bpe_merges_path: str :param : param return_tokens: Indicate
    whether to return split tokens. If False, it will return encoded token IDs (default:
    False). :param : type return_tokens: bool :param : param unk_token: The unknown
    token. If provided, it must exist in encoder. :param : type unk_token: Optional[str]
    :param : param suffix: The suffix to be used for every subword that is an end-of-word.
    :param : type suffix: Optional[str] :param : param special_tokens: Special tokens
    which should not be split into individual characters. If provided, these must
    exist in encoder. :param : type special_tokens: Optional[List[str]]'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: :param：参数bpe_encoder_path：BPE编码器json文件的路径。:param：类型bpe_encoder_path：str：param：参数bpe_merges_path：BPE合并文本文件的路径。:param：类型bpe_merges_path：str：param：参数return_tokens：指示是否返回拆分的标记。如果为False，则将返回编码的标记ID（默认值：False）。:param：类型return_tokens：bool：param：参数unk_token：未知标记。如果提供，它必须存在于编码器中。:param：类型unk_token：Optional[str]：param：参数suffix：要用于每个作为单词结尾的子词的后缀。:param：类型suffix：Optional[str]：param：参数special_tokens：不应拆分为单个字符的特殊标记。如果提供，这些标记必须存在于编码器中。:param：类型special_tokens：Optional[List[str]]
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Forward method of module encodes strings or list of strings into token ids
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 模块的前向方法将字符串或字符串列表编码为标记ID
- en: 'Parameters:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**input** – Input sentence or list of sentences on which to apply tokenizer.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入** - 要应用分词器的输入句子或句子列表。'
- en: 'Returns:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: A list or list of lists of token IDs
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 一个标记ID的列表或列表的列表
