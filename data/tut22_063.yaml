- en: Deploying PyTorch in Python via a REST API with Flask
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Flask在Python中部署PyTorch的REST API
- en: 原文：[https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html](https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html](https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html)
- en: Note
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Click [here](#sphx-glr-download-intermediate-flask-rest-api-tutorial-py) to
    download the full example code
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[这里](#sphx-glr-download-intermediate-flask-rest-api-tutorial-py)下载完整的示例代码
- en: '**Author**: [Avinash Sajjanshetty](https://avi.im)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者**：[Avinash Sajjanshetty](https://avi.im)'
- en: In this tutorial, we will deploy a PyTorch model using Flask and expose a REST
    API for model inference. In particular, we will deploy a pretrained DenseNet 121
    model which detects the image.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用Flask部署PyTorch模型，并为模型推理暴露一个REST API。特别是，我们将部署一个预训练的DenseNet 121模型来检测图像。
- en: Tip
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: All the code used here is released under MIT license and is available on [Github](https://github.com/avinassh/pytorch-flask-api).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的所有代码都是根据MIT许可发布的，并且可以在[Github](https://github.com/avinassh/pytorch-flask-api)上找到。
- en: 'This represents the first in a series of tutorials on deploying PyTorch models
    in production. Using Flask in this way is by far the easiest way to start serving
    your PyTorch models, but it will not work for a use case with high performance
    requirements. For that:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这代表了一系列关于在生产中部署PyTorch模型的教程中的第一篇。以这种方式使用Flask是迄今为止最简单的开始为您的PyTorch模型提供服务的方法，但对于高性能要求的用例不适用。为此：
- en: If you’re already familiar with TorchScript, you can jump straight into our
    [Loading a TorchScript Model in C++](https://pytorch.org/tutorials/advanced/cpp_export.html)
    tutorial.
  id: totrans-9
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您已经熟悉TorchScript，可以直接查看我们的[C++中加载TorchScript模型](https://pytorch.org/tutorials/advanced/cpp_export.html)教程。
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: If you first need a refresher on TorchScript, check out our [Intro a TorchScript](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)
    tutorial.
  id: totrans-12
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您需要关于TorchScript的复习，请查看我们的[TorchScript简介](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)教程。
- en: API Definition
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: API定义
- en: 'We will first define our API endpoints, the request and response types. Our
    API endpoint will be at `/predict` which takes HTTP POST requests with a `file`
    parameter which contains the image. The response will be of JSON response containing
    the prediction:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先定义我们的API端点、请求和响应类型。我们的API端点将位于`/predict`，接受带有`file`参数的HTTP POST请求，该参数包含图像。响应将是一个包含预测的JSON响应：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Dependencies
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 依赖项
- en: 'Install the required dependencies by running the following command:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令安装所需的依赖项：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Simple Web Server
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单的Web服务器
- en: Following is a simple web server, taken from Flask’s documentation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简单的Web服务器，摘自Flask的文档
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will also change the response type, so that it returns a JSON response containing
    ImageNet class id and name. The updated `app.py` file will be now:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将更改响应类型，以便返回一个包含ImageNet类别ID和名称的JSON响应。更新后的`app.py`文件将是：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Inference
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: In the next sections we will focus on writing the inference code. This will
    involve two parts, one where we prepare the image so that it can be fed to DenseNet
    and next, we will write the code to get the actual prediction from the model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将专注于编写推理代码。这将涉及两个部分，一个是我们准备图像以便它可以被馈送到DenseNet中，接下来，我们将编写代码从模型中获取实际预测。
- en: Preparing the image
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备图像
- en: DenseNet model requires the image to be of 3 channel RGB image of size 224 x
    224\. We will also normalize the image tensor with the required mean and standard
    deviation values. You can read more about it [here](https://pytorch.org/vision/stable/models.html).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: DenseNet模型要求图像为尺寸为224 x 224的3通道RGB图像。我们还将使用所需的均值和标准差值对图像张量进行归一化。您可以在[这里](https://pytorch.org/vision/stable/models.html)了解更多信息。
- en: We will use `transforms` from `torchvision` library and build a transform pipeline,
    which transforms our images as required. You can read more about transforms [here](https://pytorch.org/vision/stable/transforms.html).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`torchvision`库中的`transforms`构建一个转换管道，根据需要转换我们的图像。您可以在[这里](https://pytorch.org/vision/stable/transforms.html)了解更多关于转换的信息。
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The above method takes image data in bytes, applies the series of transforms
    and returns a tensor. To test the above method, read an image file in bytes mode
    (first replacing ../_static/img/sample_file.jpeg with the actual path to the file
    on your computer) and see if you get a tensor back:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法接受字节形式的图像数据，应用一系列转换并返回一个张量。要测试上述方法，请以字节模式读取图像文件（首先用您计算机上文件的实际路径替换../_static/img/sample_file.jpeg），看看是否返回一个张量：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Prediction
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测
- en: Now will use a pretrained DenseNet 121 model to predict the image class. We
    will use one from `torchvision` library, load the model and get an inference.
    While we’ll be using a pretrained model in this example, you can use this same
    approach for your own models. See more about loading your models in this [tutorial](../beginner/saving_loading_models.html).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用一个预训练的DenseNet 121模型来预测图像类别。我们将使用`torchvision`库中的一个模型，加载模型并进行推理。虽然在此示例中我们将使用一个预训练模型，但您可以使用相同的方法来加载您自己的模型。在这个[tutorial](../beginner/saving_loading_models.html)中了解更多关于加载您的模型的信息。
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The tensor `y_hat` will contain the index of the predicted class id. However,
    we need a human readable class name. For that we need a class id to name mapping.
    Download [this file](https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json)
    as `imagenet_class_index.json` and remember where you saved it (or, if you are
    following the exact steps in this tutorial, save it in tutorials/_static). This
    file contains the mapping of ImageNet class id to ImageNet class name. We will
    load this JSON file and get the class name of the predicted index.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 张量`y_hat`将包含预测类别ID的索引。然而，我们需要一个可读的类别名称。为此，我们需要一个类别ID到名称的映射。下载[此文件](https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json)作为`imagenet_class_index.json`并记住保存的位置（或者，如果您按照本教程中的确切步骤进行操作，请将其保存在tutorials/_static中）。该文件包含ImageNet类别ID到ImageNet类别名称的映射。我们将加载此JSON文件并获取预测索引的类别名称。
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Before using `imagenet_class_index` dictionary, first we will convert tensor
    value to a string value, since the keys in the `imagenet_class_index` dictionary
    are strings. We will test our above method:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`imagenet_class_index`字典之前，我们将首先将张量值转换为字符串值，因为`imagenet_class_index`字典中的键是字符串。我们将测试我们上面的方法：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should get a response like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会收到这样的响应：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first item in array is ImageNet class id and second item is the human readable
    name.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数组中的第一项是ImageNet类别ID，第二项是可读的名称。
- en: Integrating the model in our API Server
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型集成到我们的API服务器中
- en: 'In this final part we will add our model to our Flask API server. Since our
    API server is supposed to take an image file, we will update our `predict` method
    to read files from the requests:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一部分中，我们将把我们的模型添加到我们的Flask API服务器中。由于我们的API服务器应该接受一个图像文件，我们将更新我们的`predict`方法以从请求中读取文件：
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'library to send a POST request to our app:'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 发送POST请求到我们的应用程序的库：
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Printing resp.json() will now show the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在打印resp.json()将显示以下内容：
- en: '[PRE14]'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The server we wrote is quite trivial and may not do everything you need for
    your production application. So, here are some things you can do to make it better:'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们编写的服务器相当简单，可能无法满足您的生产应用程序的所有需求。因此，以下是一些可以改进的事项：
- en: ''
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The endpoint `/predict` assumes that always there will be a image file in the
    request. This may not hold true for all requests. Our user may send image with
    a different parameter or send no images at all.
  id: totrans-54
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端点`/predict`假定请求中始终会有一个图像文件。这可能并非对所有请求都成立。我们的用户可能使用不同的参数发送图像，或者根本不发送图像。
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-56
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The user may send non-image type files too. Since we are not handling errors,
    this will break our server. Adding an explicit error handing path that will throw
    an exception would allow us to better handle the bad inputs
  id: totrans-57
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户也可以发送非图像类型的文件。由于我们没有处理错误，这将破坏我们的服务器。添加一个明确的错误处理路径，将抛出异常，这样我们就可以更好地处理不良输入。
- en: ''
  id: totrans-58
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Even though the model can recognize a large number of classes of images, it
    may not be able to recognize all images. Enhance the implementation to handle
    cases when the model does not recognize anything in the image.
  id: totrans-60
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管模型可以识别大量图像类别，但可能无法识别所有图像。增强实现以处理模型无法识别图像的情况。
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-62
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: We run the Flask server in the development mode, which is not suitable for deploying
    in production. You can check out [this tutorial](https://flask.palletsprojects.com/en/1.1.x/tutorial/deploy/)
    for deploying a Flask server in production.
  id: totrans-63
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们以开发模式运行Flask服务器，这不适合在生产中部署。您可以查看[此教程](https://flask.palletsprojects.com/en/1.1.x/tutorial/deploy/)以在生产中部署Flask服务器。
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-65
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also add a UI by creating a page with a form which takes the image and
    displays the prediction. Check out the [demo](https://pytorch-imagenet.herokuapp.com/)
    of a similar project and its [source code](https://github.com/avinassh/pytorch-flask-api-heroku).
  id: totrans-66
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您还可以通过创建一个带有表单的页面来添加UI，该表单接受图像并显示预测结果。查看类似项目的[演示](https://pytorch-imagenet.herokuapp.com/)及其[源代码](https://github.com/avinassh/pytorch-flask-api-heroku)。
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: In this tutorial, we only showed how to build a service that could return predictions
    for a single image at a time. We could modify our service to be able to return
    predictions for multiple images at once. In addition, the [service-streamer](https://github.com/ShannonAI/service-streamer)
    library automatically queues requests to your service and samples them into mini-batches
    that can be fed into your model. You can check out [this tutorial](https://github.com/ShannonAI/service-streamer/wiki/Vision-Recognition-Service-with-Flask-and-service-streamer).
  id: totrans-69
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本教程中，我们仅展示了如何构建一个可以一次返回单个图像预测的服务。我们可以修改我们的服务，使其能够一次返回多个图像的预测。此外，[service-streamer](https://github.com/ShannonAI/service-streamer)库会自动将请求排入您的服务队列，并将其抽样成可以馈送到模型中的小批次。您可以查看[此教程](https://github.com/ShannonAI/service-streamer/wiki/Vision-Recognition-Service-with-Flask-and-service-streamer)。
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-71
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, we encourage you to check out our other tutorials on deploying PyTorch
    models linked-to at the top of the page.
  id: totrans-72
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们鼓励您查看我们在页面顶部链接的其他部署PyTorch模型的教程。
- en: '**Total running time of the script:** ( 0 minutes 0.000 seconds)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚本的总运行时间：**（0分钟0.000秒）'
- en: '[`Download Python source code: flask_rest_api_tutorial.py`](../_downloads/b45d95b1d38fe556c77d1ee548809d28/flask_rest_api_tutorial.py)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Python源代码：flask_rest_api_tutorial.py`](../_downloads/b45d95b1d38fe556c77d1ee548809d28/flask_rest_api_tutorial.py)'
- en: '[`Download Jupyter notebook: flask_rest_api_tutorial.ipynb`](../_downloads/786469bd4d28fe2528b92a6d12fb189e/flask_rest_api_tutorial.ipynb)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[`下载Jupyter笔记本：flask_rest_api_tutorial.ipynb`](../_downloads/786469bd4d28fe2528b92a6d12fb189e/flask_rest_api_tutorial.ipynb)'
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sphinx-Gallery生成的图库](https://sphinx-gallery.github.io)'
