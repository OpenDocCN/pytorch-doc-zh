- en: Grokking PyTorch Intel CPU performance from first principles
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从第一原则理解PyTorch Intel CPU性能
- en: 原文：[https://pytorch.org/tutorials/intermediate/torchserve_with_ipex.html](https://pytorch.org/tutorials/intermediate/torchserve_with_ipex.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[原文链接](https://pytorch.org/tutorials/intermediate/torchserve_with_ipex.html)'
- en: A case study on the TorchServe inference framework optimized with [Intel® Extension
    for PyTorch*](https://github.com/intel/intel-extension-for-pytorch).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关于使用[Intel® PyTorch扩展*](https://github.com/intel/intel-extension-for-pytorch)优化的TorchServe推理框架的案例研究。
- en: 'Authors: Min Jean Cho, Mark Saroufim'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Min Jean Cho, Mark Saroufim
- en: 'Reviewers: Ashok Emani, Jiong Gong'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 审阅者：Ashok Emani, Jiong Gong
- en: Getting a strong out-of-box performance for deep learning on CPUs can be tricky
    but it’s much easier if you’re aware of the main problems that affect performance,
    how to measure them and how to solve them.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在CPU上获得强大的深度学习开箱即用性能可能有些棘手，但如果您了解影响性能的主要问题，如何衡量它们以及如何解决它们，那么就会更容易。
- en: TL;DR
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之
- en: '| Problem | How to measure it | Solution |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 如何衡量 | 解决方案 |'
- en: '| Bottlenecked GEMM execution units |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 瓶颈的GEMM执行单元 |'
- en: '[Imbalance or Serial Spinning](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/spin-time/imbalance-or-serial-spinning-1.html)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[不平衡或串行旋转](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/spin-time/imbalance-or-serial-spinning-1.html)'
- en: '[Front-End Bound](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/front-end-bound.html)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前端受限](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/front-end-bound.html)'
- en: '[Core Bound](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/back-end-bound.html)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[核心受限](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/back-end-bound.html)'
- en: '| Avoid using logical cores by setting thread affinity to physical cores via
    core pinning |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 通过核心固定将线程亲和性设置为物理核心以避免使用逻辑核心 |'
- en: '| Non Uniform Memory Access (NUMA) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 非均匀内存访问（NUMA） |'
- en: Local vs. remote memory access
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地与远程内存访问
- en: '[UPI Utilization](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/memory-bound/dram-bound/upi-utilization-bound.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UPI利用率](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/memory-bound/dram-bound/upi-utilization-bound.html)'
- en: Latency in memory accesses
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存访问延迟
- en: Thread migration
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程迁移
- en: '| Avoid cross-socket computation by setting thread affinity to a specific socket
    via core pinning |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 通过核心固定将线程亲和性设置为特定插槽以避免跨插槽计算 |'
- en: '*GEMM (General Matrix Multiply)* run on fused-multiply-add (FMA) or dot-product
    (DP) execution units which will be bottlenecked and cause delays in thread waiting/*spinning
    at synchronization* barrier when *hyperthreading* is enabled - because using logical
    cores causes insufficient concurrency for all working threads as each logical
    thread *contends for the same core resources*. Instead, if we use 1 thread per
    physical core, we avoid this contention. So we generally recommend *avoiding logical
    cores* by setting CPU *thread affinity* to physical cores via *core pinning*.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*GEMM（通用矩阵乘法）*在融合乘加（FMA）或点积（DP）执行单元上运行，这将成为瓶颈，并在启用*超线程*时导致线程等待/*旋转在同步*屏障时出现延迟
    - 因为使用逻辑核心会导致所有工作线程的并发性不足，因为每个逻辑线程*争夺相同的核心资源*。相反，如果我们每个物理核心使用1个线程，我们就可以避免这种争夺。因此，我们通常建议通过*核心固定*将CPU
    *线程亲和性*设置为物理核心，从而*避免逻辑核心*。'
- en: Multi-socket systems have *Non-Uniform Memory Access (NUMA)* which is a shared
    memory architecture that describes the placement of main memory modules with respect
    to processors. But if a process is not NUMA-aware, slow *remote memory* is frequently
    accessed when *threads migrate* cross socket via *Intel Ultra Path Interconnect
    (UPI)* during run time. We address this problem by setting CPU *thread affinity*
    to a specific socket via *core pinning*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 多插槽系统具有*非均匀内存访问（NUMA）*，这是一种共享内存架构，描述了主存储模块相对于处理器的放置方式。但是，如果一个进程不是NUMA感知的，那么在运行时，当*线程通过*Intel
    Ultra Path Interconnect (UPI)*跨插槽迁移*时，会频繁访问慢*远程内存*。我们通过将CPU *线程亲和性*设置为特定插槽以通过*核心固定*解决这个问题。
- en: Knowing these principles in mind, proper CPU runtime configuration can significantly
    boost out-of-box performance.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这些原则，适当的CPU运行时配置可以显著提升开箱即用的性能。
- en: In this blog, we’ll walk you through the important runtime configurations you
    should be aware of from [CPU Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#cpu-specific-optimizations),
    explain how they work, how to profile them and how to integrate them within a
    model serving framework like [TorchServe](https://github.com/pytorch/serve) via
    an easy to use [launch script](https://github.com/intel/intel-extension-for-pytorch/blob/master/docs/tutorials/performance_tuning/launch_script.md)
    which we’ve [integrated](https://github.com/pytorch/serve/pull/1354) ¹ natively.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将带您了解[CPU性能调优指南](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#cpu-specific-optimizations)中应该注意的重要运行时配置，解释它们的工作原理，如何对其进行分析以及如何将其集成到像[TorchServe](https://github.com/pytorch/serve)这样的模型服务框架中，通过一个易于使用的[启动脚本](https://github.com/intel/intel-extension-for-pytorch/blob/master/docs/tutorials/performance_tuning/launch_script.md)，我们已经[原生地集成](https://github.com/pytorch/serve/pull/1354)了。
- en: We’ll explain all of these ideas **visually** from **first principles** with
    lots of **profiles** and show you how we applied our learnings to make out of
    the box CPU performance on TorchServe better.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从**第一原则**以及大量**概要**中**直观**地解释所有这些想法，并向您展示我们如何应用我们的学习，以改善TorchServe的开箱即用CPU性能。
- en: The feature has to be explicitly enabled by setting *cpu_launcher_enable=true*
    in *config.properties*.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须通过在*config.properties*中设置*cpu_launcher_enable=true*来显式启用该功能。
- en: Avoid logical cores for deep learning
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免逻辑核心进行深度学习
- en: Avoiding logical cores for deep learning workloads generally improves performance.
    To understand this, let us take a step back to GEMM.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，避免逻辑核心进行深度学习工作负载会提高性能。为了理解这一点，让我们回到GEMM。
- en: '**Optimizing GEMM optimizes deep learning**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**优化GEMM优化深度学习**'
- en: The majority of time in deep learning training or inference is spent on millions
    of repeated operations of GEMM which is at the core of fully connected layers.
    Fully connected layers have been used for decades since multi-layer perceptrons
    (MLP) [proved to be a universal approximator of any continuous function](https://en.wikipedia.org/wiki/Universal_approximation_theorem).
    Any MLP can be entirely represented as GEMM. And even a convolution can be represented
    as a GEMM by using a [Toepliz matrix](https://en.wikipedia.org/wiki/Toeplitz_matrix).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习训练或推断中的大部分时间都花在了GEMM的数百万次重复操作上，这是完全连接层的核心。自从多层感知器（MLP）[被证明是任何连续函数的通用逼近器](https://en.wikipedia.org/wiki/Universal_approximation_theorem)以来，完全连接层已经被使用了几十年。任何MLP都可以完全表示为GEMM。甚至卷积也可以通过使用[Toepliz矩阵](https://en.wikipedia.org/wiki/Toeplitz_matrix)表示为GEMM。
- en: Returning to the original topic, most GEMM operators benefit from using non-hyperthreading,
    because the majority of time in deep learning training or inference is spent on
    millions of repeated operations of GEMM running on fused-multiply-add (FMA) or
    dot-product (DP) execution units shared by hyperthreading cores. With hyperthreading
    enabled, OpenMP threads will contend for the same GEMM execution units.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 回到原来的话题，大多数GEMM运算符受益于使用非超线程，因为深度学习训练或推断中的大部分时间都花在了运行在超线程核心上的融合乘加（FMA）或点积（DP）执行单元上的数百万次重复操作上。启用超线程后，OpenMP线程将争夺相同的GEMM执行单元。
- en: '![../_images/1_.png](../Images/155a9f07e52c325ee9b974697797746c.png)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/1_.png](../Images/155a9f07e52c325ee9b974697797746c.png)'
- en: And if 2 logical threads run GEMM at the same time, they will be sharing the
    same core resources causing front end bound, such that the overhead from this
    front end bound is greater than the gain from running both logical threads at
    the same time.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果2个逻辑线程同时运行GEMM，它们将共享相同的核心资源，导致前端绑定，这样前端绑定带来的开销大于同时运行两个逻辑线程带来的收益。
- en: Therefore we generally recommend avoiding using logical cores for deep learning
    workloads to achieve good performance. The launch script by default uses physical
    cores only; however, users can easily experiment with logical vs. physical cores
    by simply toggling the `--use_logical_core` launch script knob.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通常建议避免在深度学习工作负载中使用逻辑核心以获得良好的性能。默认情况下，启动脚本仅使用物理核心；但是，用户可以通过简单切换`--use_logical_core`启动脚本旋钮来轻松尝试逻辑核心与物理核心。
- en: '**Exercise**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**'
- en: 'We’ll use the following example of feeding ResNet50 dummy tensor:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下示例来提供ResNet50虚拟张量：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Throughout the blog, we’ll use [Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html#gs.v4egjg)
    to profile and verify optimizations. And we’ll run all exercises on a machine
    with two Intel(R) Xeon(R) Platinum 8180M CPUs. The CPU information is shown in
    Figure 2.1.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在博客中，我们将使用[Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html#gs.v4egjg)来进行分析和验证优化。我们将在一台配备两个Intel(R)
    Xeon(R) Platinum 8180M CPU的机器上运行所有练习。CPU信息如图2.1所示。
- en: Environment variable `OMP_NUM_THREADS` is used to set the number of threads
    for parallel region. We’ll compare `OMP_NUM_THREADS=2` with (1) use of logical
    cores and (2) use of physical cores only.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量`OMP_NUM_THREADS`用于设置并行区域的线程数。我们将比较`OMP_NUM_THREADS=2`与（1）使用逻辑核心和（2）仅使用物理核心。
- en: Both OpenMP threads trying to utilize the same GEMM execution units shared by
    hyperthreading cores (0, 56)
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个OpenMP线程尝试利用由超线程核心（0, 56）共享的相同GEMM执行单元
- en: We can visualize this by running `htop` command on Linux as shown below.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在Linux上运行`htop`命令来可视化这一点。
- en: '![../_images/2.png](../Images/ea54206cf91398975d9ffa16edf04058.png)![../_images/3.png](../Images/ea77107db83563dd38651a1cd5831c9c.png)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/2.png](../Images/ea54206cf91398975d9ffa16edf04058.png)![../_images/3.png](../Images/ea77107db83563dd38651a1cd5831c9c.png)'
- en: We notice that the Spin Time is flagged, and Imbalance or Serial Spinning contributed
    to the majority of it - 4.980 seconds out of the 8.982 seconds total. The Imbalance
    or Serial Spinning when using logical cores is due to insufficient concurrency
    of working threads as each logical thread contends for the same core resources.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到旋转时间被标记，并且不平衡或串行旋转占据了大部分时间 - 在总共8.982秒中的4.980秒。使用逻辑核心时的不平衡或串行旋转是由于工作线程的并发性不足，因为每个逻辑线程争夺相同的核心资源。
- en: The Top Hotspots section of the execution summary indicates that `__kmp_fork_barrier`
    took 4.589 seconds of CPU time - during 9.33% of the CPU execution time, threads
    were just spinning at this barrier due to thread synchronization.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 执行摘要的Top Hotspots部分显示，`__kmp_fork_barrier`占用了4.589秒的CPU时间 - 在CPU执行时间的9.33%期间，线程在这个屏障处旋转以进行线程同步。
- en: Each OpenMP thread utilizing GEMM execution units in respective physical cores
    (0,1)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个OpenMP线程利用各自物理核心（0,1）中的GEMM执行单元
- en: '![../_images/4.png](../Images/709b5ac62c0252784e8beaf785047853.png)![../_images/5.png](../Images/6803d67e46cc078fee10a753e7e95e0f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/4.png](../Images/709b5ac62c0252784e8beaf785047853.png)![../_images/5.png](../Images/6803d67e46cc078fee10a753e7e95e0f.png)'
- en: We first note that the execution time dropped from 32 seconds to 23 seconds
    by avoiding logical cores. While there’s still some non-negligible Imbalance or
    Serial Spinning, we note relative improvement from 4.980 seconds to 3.887 seconds.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先注意到，通过避免逻辑核心，执行时间从32秒降至23秒。虽然仍存在一些不可忽略的不平衡或串行旋转，但我们注意到从4.980秒到3.887秒的相对改善。
- en: By not using logical threads (instead, using 1 thread per physical core), we
    avoid logical threads contending for the same core resources. The Top Hotspots
    section also indicates relative improvement of `__kmp_fork_barrier` time from
    4.589 seconds to 3.530 seconds.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过不使用逻辑线程（而是每个物理核心使用1个线程），我们避免了逻辑线程争夺相同核心资源。Top Hotspots部分还显示了`__kmp_fork_barrier`时间从4.589秒改善到3.530秒的相对改善。
- en: Local memory access is always faster than remote memory access
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地内存访问始终比远程内存访问快。
- en: We generally recommend binding a process to a local socket such that the process
    does not migrate across sockets. Generally the goal of doing so is to utilize
    high speed cache on local memory and to avoid remote memory access which can be
    ~2x slower.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们建议将一个进程绑定到本地插槽，以便该进程不会在不同插槽之间迁移。通常这样做的目的是利用本地内存上的高速缓存，并避免远程内存访问，后者可能慢大约2倍。
- en: '![../_images/6.png](../Images/4883ee88dea607f56c62f6bd09501713.png)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/6.png](../Images/4883ee88dea607f56c62f6bd09501713.png)'
- en: Figure 1\. Two-socket configuration
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 双插槽配置
- en: Figure 1\. shows a typical two-socket configuration. Notice that each socket
    has its own local memory. Sockets are connected to each other via Intel Ultra
    Path Interconnect (UPI) which allows each socket to access the local memory of
    another socket called remote memory. Local memory access is always faster than
    remote memory access.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 显示了一个典型的双插槽配置。请注意，每个插槽都有自己的本地内存。插槽通过Intel Ultra Path Interconnect (UPI)连接到彼此，这允许每个插槽访问另一个插槽的本地内存，称为远程内存。本地内存访问始终比远程内存访问快。
- en: '![../_images/7.png](../Images/9f8fe3672209c49d3625946847233f4b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/7.png](../Images/9f8fe3672209c49d3625946847233f4b.png)'
- en: Figure 2.1\. CPU information
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1. CPU信息
- en: Users can get their CPU information by running `lscpu` command on their Linux
    machine. Figure 2.1\. shows an example of `lscpu` execution on a machine with
    two Intel(R) Xeon(R) Platinum 8180M CPUs. Notice that there are 28 cores per socket,
    and 2 threads per core (i.e., hyperthreading is enabled). In other words, there
    are 28 logical cores in addition to 28 physical cores, giving a total of 56 cores
    per socket. And there are 2 sockets, giving a total of 112 cores (`Thread(s) per
    core` x `Core(s) per socket` x `Socket(s)`).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以通过在他们的Linux机器上运行`lscpu`命令来获取他们的CPU信息。图2.1. 显示了在一台装有两个Intel(R) Xeon(R) Platinum
    8180M CPU的机器上执行`lscpu`的示例。请注意，每个插槽有28个核心，每个核心有2个线程（即启用了超线程）。换句话说，除了28个物理核心外，还有28个逻辑核心，每个插槽总共有56个核心。而且有2个插槽，总共有112个核心（`每个核心的线程数`
    x `每个插槽的核心数` x `插槽数`）。
- en: '![../_images/8.png](../Images/401010f7117d9febf2003c41ba5c4559.png)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/8.png](../Images/401010f7117d9febf2003c41ba5c4559.png)'
- en: Figure 2.2\. CPU information
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2. CPU信息
- en: The 2 sockets are mapped to 2 NUMA nodes (NUMA node 0, NUMA node 1) respectively.
    Physical cores are indexed prior to logical cores. As shown in Figure 2.2., the
    first 28 physical cores (0-27) and the first 28 logical cores (56-83) on the first
    socket are on NUMA node 0\. And the second 28 physical cores (28-55) and the second
    28 logical cores (84-111) on the second socket are on NUMA node 1\. Cores on the
    same socket share local memory and last level cache (LLC) which is much faster
    than cross-socket communication via Intel UPI.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这2个插槽分别映射到2个NUMA节点（NUMA节点0，NUMA节点1）。物理核心在逻辑核心之前进行索引。如图2.2.所示，第一个插槽上的前28个物理核心（0-27）和前28个逻辑核心（56-83）位于NUMA节点0。第二个插槽上的第28个物理核心（28-55）和第二个插槽上的第28个逻辑核心（84-111）位于NUMA节点1。同一插槽上的核心共享本地内存和最后一级缓存（LLC），比通过Intel
    UPI进行跨插槽通信要快得多。
- en: Now that we understand NUMA, cross-socket (UPI) traffic, local vs. remote memory
    access in multi-processor systems, let’s profile and verify our understanding.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了NUMA、跨插槽（UPI）流量、多处理器系统中的本地与远程内存访问，让我们对其进行分析和验证。
- en: '**Exercise**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**'
- en: We’ll reuse the ResNet50 example above.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用上面的ResNet50示例。
- en: As we did not pin threads to processor cores of a specific socket, the operating
    system periodically schedules threads on processor cores located in different
    sockets.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有将线程固定到特定插槽的处理器核心上，操作系统会定期将线程调度到位于不同插槽中的处理器核心上。
- en: '![../_images/9.gif](../Images/34e582c1c262c693f8472ce4254570ba.png)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/9.gif](../Images/34e582c1c262c693f8472ce4254570ba.png)'
- en: Figure 3\. CPU usage of non NUMA-aware application. 1 main worker thread was
    launched, then it launched a physical core number (56) of threads on all cores,
    including logical cores.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 非NUMA感知应用程序的CPU使用情况。启动了1个主工作线程，然后在所有核心上启动了一个物理核心编号（56）的线程，包括逻辑核心。
- en: '(Aside: If the number of threads is not set by [torch.set_num_threads](https://pytorch.org/docs/stable/generated/torch.set_num_threads.html),
    the default number of threads is the number of physical cores in a hyperthreading
    enabled system. This can be verified by [torch.get_num_threads](https://pytorch.org/docs/stable/generated/torch.get_num_threads.html).
    Hence we see above about half of the cores busy running the example script.)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: （附注：如果线程数未通过[torch.set_num_threads](https://pytorch.org/docs/stable/generated/torch.set_num_threads.html)设置，那么默认线程数是启用超线程系统中的物理核心数。这可以通过[torch.get_num_threads](https://pytorch.org/docs/stable/generated/torch.get_num_threads.html)来验证。因此，我们看到大约一半的核心忙于运行示例脚本。）
- en: '![../_images/10.png](../Images/19d05986d8f0236e3463065f779359e1.png)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/10.png](../Images/19d05986d8f0236e3463065f779359e1.png)'
- en: Figure 4\. Non-Uniform Memory Access Analysis graph
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. 非均匀内存访问分析图
- en: Figure 4\. compares local vs. remote memory access over time. We verify usage
    of remote memory which could result in sub-optimal performance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. 比较了随时间变化的本地与远程内存访问。我们验证了远程内存的使用，这可能导致性能不佳。
- en: '**Set thread affinity to reduce remote memory access and cross-socket (UPI)
    traffic**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**设置线程亲和性以减少远程内存访问和跨插槽（UPI）流量**'
- en: Pinning threads to cores on the same socket helps maintain locality of memory
    access. In this example, we’ll pin to the physical cores on the first NUMA node
    (0-27). With the launch script, users can easily experiment with NUMA nodes configuration
    by simply toggling the `--node_id` launch script knob.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 将线程固定到同一插槽上的核心有助于保持内存访问的局部性。在这个例子中，我们将固定到第一个NUMA节点上的物理核心（0-27）。通过启动脚本，用户可以通过简单切换`--node_id`启动脚本旋钮来轻松尝试NUMA节点配置。
- en: Let’s visualize the CPU usage now.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在来可视化CPU使用情况。
- en: '![../_images/11.gif](../Images/7dad920dd5537d51cf51649c1e4da9d5.png)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/11.gif](../Images/7dad920dd5537d51cf51649c1e4da9d5.png)'
- en: Figure 5\. CPU usage of NUMA-aware application
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图5. NUMA感知应用程序的CPU使用情况
- en: 1 main worker thread was launched, then it launched threads on all physical
    cores on the first numa node.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 启动了1个主要工作线程，然后在第一个NUMA节点上的所有物理核心上启动了线程。
- en: '![../_images/12.png](../Images/cf04e2e8d9070f5a2606fb137b9e383f.png)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/12.png](../Images/cf04e2e8d9070f5a2606fb137b9e383f.png)'
- en: Figure 6\. Non-Uniform Memory Access Analysis graph
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图6. 非均匀内存访问分析图
- en: As shown in Figure 6., now almost all memory accesses are local accesses.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如图6所示，现在几乎所有的内存访问都是本地访问。
- en: Efficient CPU usage with core pinning for multi-worker inference
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过核心固定实现多工作线程推理的高效CPU使用率
- en: When running multi-worker inference, cores are overlapped (or shared) between
    workers causing inefficient CPU usage. To address this problem, the launch script
    equally divides the number of available cores by the number of workers such that
    each worker is pinned to assigned cores during runtime.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行多工作线程推理时，核心在工作线程之间重叠（或共享），导致CPU使用效率低下。为了解决这个问题，启动脚本将可用核心数均等地分配给每个工作线程，使每个工作线程在运行时固定到分配的核心。
- en: '**Exercise with TorchServe**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用TorchServe进行练习**'
- en: For this exercise, let’s apply the CPU performance tuning principles and recommendations
    that we have discussed so far to [TorchServe apache-bench benchmarking](https://github.com/pytorch/serve/tree/master/benchmarks#benchmarking-with-apache-bench).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，让我们将我们迄今讨论过的CPU性能调优原则和建议应用到[TorchServe apache-bench基准测试](https://github.com/pytorch/serve/tree/master/benchmarks#benchmarking-with-apache-bench)。
- en: We’ll use ResNet50 with 4 workers, concurrency 100, requests 10,000\. All other
    parameters (e.g., batch_size, input, etc) are the same as the [default parameters](https://github.com/pytorch/serve/blob/master/benchmarks/benchmark-ab.py#L18).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用ResNet50进行4个工作线程，并发数为100，请求为10,000。所有其他参数（例如，batch_size，输入等）与[默认参数](https://github.com/pytorch/serve/blob/master/benchmarks/benchmark-ab.py#L18)相同。
- en: 'We’ll compare the following three configurations:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将比较以下三种配置：
- en: default TorchServe setting (no core pinning)
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认的TorchServe设置（没有核心固定）
- en: '[torch.set_num_threads](https://pytorch.org/docs/stable/generated/torch.set_num_threads.html)
    = `number of physical cores / number of workers` (no core pinning)'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[torch.set_num_threads](https://pytorch.org/docs/stable/generated/torch.set_num_threads.html)
    = `物理核心数 / 工作线程数`（没有核心固定）'
- en: core pinning via the launch script (Required Torchserve>=0.6.1)
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过启动脚本进行核心固定（要求Torchserve>=0.6.1）
- en: After this exercise, we’ll have verified that we prefer avoiding logical cores
    and prefer local memory access via core pinning with a real TorchServe use case.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这个练习，我们将验证我们更喜欢避免逻辑核心，而是通过核心固定实现本地内存访问，使用真实的TorchServe用例。
- en: 1\. Default TorchServe setting (no core pinning)
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 默认的TorchServe设置（没有核心固定）
- en: The [base_handler](https://github.com/pytorch/serve/blob/master/ts/torch_handler/base_handler.py)
    doesn’t explicitly set [torch.set_num_threads](https://pytorch.org/docs/stable/generated/torch.set_num_threads.html).
    Hence the default number of threads is the number of physical CPU cores as described
    [here](https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html#runtime-api).
    Users can check the number of threads by [torch.get_num_threads](https://pytorch.org/docs/stable/generated/torch.get_num_threads.html)
    in the base_handler. Each of the 4 main worker threads launches a physical core
    number (56) of threads, launching a total of 56x4 = 224 threads, which is more
    than the total number of cores 112\. Therefore cores are guaranteed to be heavily
    overlapped with high logical core utilization- multiple workers using multiple
    cores at the same time. Furthermore, because threads are not affinitized to specific
    CPU cores, the operating system periodically schedules threads to cores located
    in different sockets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[base_handler](https://github.com/pytorch/serve/blob/master/ts/torch_handler/base_handler.py)没有明确设置[torch.set_num_threads](https://pytorch.org/docs/stable/generated/torch.set_num_threads.html)。因此，默认线程数是物理CPU核心数，如[这里](https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html#runtime-api)所述。用户可以通过在base_handler中使用[torch.get_num_threads](https://pytorch.org/docs/stable/generated/torch.get_num_threads.html)来检查线程数。每个4个主要工作线程启动了一个物理核心数（56）的线程，总共启动了56x4
    = 224个线程，这比总核心数112多。因此，核心肯定会严重重叠，逻辑核心利用率高-多个工作线程同时使用多个核心。此外，由于线程没有固定到特定的CPU核心，操作系统会定期将线程调度到位于不同插槽中的核心。'
- en: CPU usage
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU使用率
- en: '![../_images/13.png](../Images/2b07d65eadf8e98357f803af1877fdcd.png)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/13.png](../Images/2b07d65eadf8e98357f803af1877fdcd.png)'
- en: 4 main worker threads were launched, then each launched a physical core number
    (56) of threads on all cores, including logical cores.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 启动了4个主要工作线程，然后每个线程在所有核心上启动了一个物理核心数（56）的线程，包括逻辑核心。
- en: Core Bound stalls
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核心绑定停顿
- en: '![../_images/14.png](../Images/c748ce77da86cac08e077037f7461454.png)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/14.png](../Images/c748ce77da86cac08e077037f7461454.png)'
- en: We observe a very high Core Bound stall of 88.4%, decreasing pipeline efficiency.
    Core Bound stalls indicate sub-optimal use of available execution units in the
    CPU. For example, several GEMM instructions in a row competing for fused-multiply-add
    (FMA) or dot-product (DP) execution units shared by hyperthreading cores could
    cause Core Bound stalls. And as described in the previous section, use of logical
    cores amplifies this problem.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到88.4%的非均匀内存访问，降低了管道效率。核心绑定停顿表示CPU中可用执行单元的使用不佳。例如，连续的几个GEMM指令竞争由超线程核心共享的融合乘加（FMA）或点积（DP）执行单元可能导致核心绑定停顿。正如前一节所述，逻辑核心的使用加剧了这个问题。
- en: '![../_images/15.png](../Images/bdcd9079d5ed8138caf487ade7a083bc.png)![../_images/16.png](../Images/3db21e6b9c932a6387171481b4cc4d0f.png)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/15.png](../Images/bdcd9079d5ed8138caf487ade7a083bc.png)![../_images/16.png](../Images/3db21e6b9c932a6387171481b4cc4d0f.png)'
- en: An empty pipeline slot not filled with micro-ops (uOps) is attributed to a stall.
    For example, without core pinning CPU usage may not effectively be on compute
    but on other operations like thread scheduling from Linux kernel. We see above
    that `__sched_yield` contributed to the majority of the Spin Time.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 未填充微操作（uOps）的空管道槽位被归因于停顿。例如，没有核心固定时，CPU使用率可能不会有效地用于计算，而是用于来自Linux内核的其他操作，如线程调度。我们可以看到`__sched_yield`贡献了大部分自旋时间。
- en: Thread Migration
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程迁移
- en: Without core pinning, scheduler may migrate thread executing on a core to a
    different core. Thread migration can disassociate the thread from data that has
    already been fetched into the caches resulting in longer data access latencies.
    This problem is exacerbated in NUMA systems when thread migrates across sockets.
    Data that has been fetched to high speed cache on local memory now becomes remote
    memory, which is much slower.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 没有核心固定，调度程序可能会将在一个核心上执行的线程迁移到另一个核心。线程迁移可能会使线程与已经获取到缓存中的数据分离，导致更长的数据访问延迟。在NUMA系统中，当线程在插座之间迁移时，这个问题会加剧。已经获取到本地内存高速缓存的数据现在变成了远程内存，速度要慢得多。
- en: '![../_images/17.png](../Images/2a12b3c78a1e37b95144e879414c7bee.png)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/17.png](../Images/2a12b3c78a1e37b95144e879414c7bee.png)'
- en: Generally the total number of threads should be less than or equal to the total
    number of threads supported by the core. In the above example, we notice a large
    number of threads executing on core_51 instead of the expected 2 threads (since
    hyperthreading is enabled in Intel(R) Xeon(R) Platinum 8180 CPUs) . This indicates
    thread migration.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，总线程数应小于或等于核心支持的总线程数。在上面的示例中，我们注意到大量线程在core_51上执行，而不是预期的2个线程（因为Intel(R) Xeon(R)
    Platinum 8180 CPU启用了超线程）。这表明线程迁移。
- en: '![../_images/18.png](../Images/3b6d2c15f792114de5f771ac3eabe97e.png)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/18.png](../Images/3b6d2c15f792114de5f771ac3eabe97e.png)'
- en: Additionally, notice that thread (TID:97097) was executing on a large number
    of CPU cores, indicating CPU migration. For example, this thread was executing
    on cpu_81, then migrated to cpu_14, then migrated to cpu_5, and so on. Furthermore,
    note that this thread migrated cross socket back and forth many times, resulting
    in very inefficient memory access. For example, this thread executed on cpu_70
    (NUMA node 0), then migrated to cpu_100 (NUMA node 1), then migrated to cpu_24
    (NUMA node 0).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意线程（TID:97097）正在大量CPU核心上执行，表明CPU迁移。例如，此线程在cpu_81上执行，然后迁移到cpu_14，然后迁移到cpu_5，依此类推。此外，请注意此线程多次在不同插槽之间迁移，导致内存访问非常低效。例如，此线程在cpu_70（NUMA节点0）上执行，然后迁移到cpu_100（NUMA节点1），然后迁移到cpu_24（NUMA节点0）。
- en: Non Uniform Memory Access Analysis
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非均匀内存访问分析
- en: '![../_images/19.png](../Images/eb535b6f0a49e85a2f6c69b3307eb58d.png)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/19.png](../Images/eb535b6f0a49e85a2f6c69b3307eb58d.png)'
- en: Compare local vs. remote memory access over time. We observe that about half,
    51.09%, of the memory accesses were remote accesses, indicating sub-optimal NUMA
    configuration.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 比较随时间变化的本地与远程内存访问。我们观察到大约一半，即51.09%，的内存访问是远程访问，表明NUMA配置不佳。
- en: 2\. torch.set_num_threads = `number of physical cores / number of workers` (no
    core pinning)
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. torch.set_num_threads = `物理核心数/工作线程数`（无核心固定）
- en: 'For an apple-to-apple comparison with launcher’s core pinning, we’ll set the
    number of threads to the number of cores divided by the number of workers (launcher
    does this internally). Add the following code snippet in the [base_handler](https://github.com/pytorch/serve/blob/master/ts/torch_handler/base_handler.py):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与启动器的核心固定进行苹果对苹果的比较，我们将将线程数设置为核心数除以工作线程数（启动器在内部执行此操作）。在[base_handler](https://github.com/pytorch/serve/blob/master/ts/torch_handler/base_handler.py)中添加以下代码片段：
- en: '[PRE1]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As before without core pinning, these threads are not affinitized to specific
    CPU cores, causing the operating system to periodically schedule threads on cores
    located in different sockets.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，没有核心固定，这些线程没有与特定CPU核心关联，导致操作系统周期性地在位于不同插座的核心上调度线程。
- en: CPU usage
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU使用率
- en: '![../_images/20.gif](../Images/324a4abab610044d4447be1f203420e5.png)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/20.gif](../Images/324a4abab610044d4447be1f203420e5.png)'
- en: 4 main worker threads were launched, then each launched a `num_physical_cores/num_workers`
    number (14) of threads on all cores, including logical cores.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 启动了4个主要工作线程，然后每个线程在所有核心上启动了`num_physical_cores/num_workers`（14）个线程，包括逻辑核心。
- en: Core Bound stalls
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核心绑定停顿
- en: '![../_images/21.png](../Images/c8d610422cd75e7798fb7a63febc2cf1.png)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/21.png](../Images/c8d610422cd75e7798fb7a63febc2cf1.png)'
- en: Although the percentage of Core Bound stalls has decreased from 88.4% to 73.5%,
    the Core Bound is still very high.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管核心绑定停顿的百分比从88.4%降至73.5%，但核心绑定仍然非常高。
- en: '![../_images/22.png](../Images/38f5ccd2ad70dfa738cd25d4795a2103.png)![../_images/23.png](../Images/27c04f2268b595a2bd5299b190141526.png)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/22.png](../Images/38f5ccd2ad70dfa738cd25d4795a2103.png)![../_images/23.png](../Images/27c04f2268b595a2bd5299b190141526.png)'
- en: Thread Migration
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程迁移
- en: '![../_images/24.png](../Images/f5b0a04ed3cae12a3b77548c56420027.png)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/24.png](../Images/f5b0a04ed3cae12a3b77548c56420027.png)'
- en: Similar as before, without core pinning thread (TID:94290) was executing on
    a large number of CPU cores, indicating CPU migration. We notice again cross-socket
    thread migration, resulting in very inefficient memory access. For example, this
    thread executed on cpu_78 (NUMA node 0), then migrated to cpu_108 (NUMA node 1).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前类似，没有核心固定时，线程（TID:94290）在大量CPU核心上执行，表明CPU迁移。我们再次注意到跨插槽的线程迁移，导致内存访问非常低效。例如，此线程在cpu_78（NUMA节点0）上执行，然后迁移到cpu_108（NUMA节点1）。
- en: Non Uniform Memory Access Analysis
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非均匀内存访问分析
- en: '![../_images/25.png](../Images/6d7d4b4277221a27dd70ad2125f77d31.png)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/25.png](../Images/6d7d4b4277221a27dd70ad2125f77d31.png)'
- en: Although an improvement from the original 51.09%, still 40.45% of memory access
    is remote, indicating sub-optimal NUMA configuration.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管相比原始的51.09%有所改善，但仍然有40.45%的内存访问是远程的，表明NUMA配置不够理想。
- en: 3\. launcher core pinning
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 启动器核心绑定
- en: Launcher will internally equally distribute physical cores to workers, and bind
    them to each worker. As a reminder, launcher by default uses physical cores only.
    In this example, launcher will bind worker 0 to cores 0-13 (NUMA node 0), worker
    1 to cores 14-27 (NUMA node 0), worker 2 to cores 28-41 (NUMA node 1), and worker
    3 to cores 42-55 (NUMA node 1). Doing so ensures that cores are not overlapped
    among workers and avoids logical core usage.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 启动器将内部将物理核心均匀分配给工作线程，并将它们绑定到每个工作线程。提醒一下，默认情况下，启动器仅使用物理核心。在此示例中，启动器将工作线程0绑定到核心0-13（NUMA节点0），工作线程1绑定到核心14-27（NUMA节点0），工作线程2绑定到核心28-41（NUMA节点1），工作线程3绑定到核心42-55（NUMA节点1）。这样做可以确保核心在工作线程之间不重叠，并避免逻辑核心的使用。
- en: CPU usage
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU使用率
- en: '![../_images/26.gif](../Images/cc975550a4d7909f0f03f76326e46cd3.png)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/26.gif](../Images/cc975550a4d7909f0f03f76326e46cd3.png)'
- en: 4 main worker threads were launched, then each launched a `num_physical_cores/num_workers`
    number (14) of threads affinitized to the assigned physical cores.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 启动了4个主要工作线程，然后每个工作线程启动了`num_physical_cores/num_workers`数量（14）的线程，这些线程与分配的物理核心亲和。
- en: Core Bound stalls
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核心绑定的停顿
- en: '![../_images/27.png](../Images/a577ea5b668f5f85e0da983e9c1a599e.png)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/27.png](../Images/a577ea5b668f5f85e0da983e9c1a599e.png)'
- en: Core Bound stalls has decreased significantly from the original 88.4% to 46.2%
    - almost a 2x improvement.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 核心绑定的停顿从原始的88.4%显著减少到46.2% - 几乎提高了2倍。
- en: '![../_images/28.png](../Images/59c95d60c58a4d7c0419a746f14eabcb.png)![../_images/29.png](../Images/f2d4511f210f226a6c6e025502e82080.png)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/28.png](../Images/59c95d60c58a4d7c0419a746f14eabcb.png)![../_images/29.png](../Images/f2d4511f210f226a6c6e025502e82080.png)'
- en: We verify that with core binding, most CPU time is effectively used on compute
    - Spin Time of 0.256s.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证了通过核心绑定，大部分CPU时间有效地用于计算 - 自旋时间为0.256秒。
- en: Thread Migration
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程迁移
- en: '![../_images/30.png](../Images/84fcb0c473094ff12e9703650eecaa18.png)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/30.png](../Images/84fcb0c473094ff12e9703650eecaa18.png)'
- en: 'We verify that OMP Primary Thread #0 was bound to assigned physical cores (42-55),
    and did not migrate cross-socket.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证了OMP主线程＃0绑定到分配的物理核心（42-55），并且没有跨插槽迁移。
- en: Non Uniform Memory Access Analysis
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非均匀内存访问分析
- en: '![../_images/31.png](../Images/9fb87b733977c7fb231442b0a54ea406.png)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/31.png](../Images/9fb87b733977c7fb231442b0a54ea406.png)'
- en: Now almost all, 89.52%, memory accesses are local accesses.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在几乎所有，89.52%，内存访问都是本地访问。
- en: Conclusion
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this blog, we’ve showcased that properly setting your CPU runtime configuration
    can significantly boost out-of-box CPU performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本博客中，我们展示了正确设置CPU运行时配置如何显著提升开箱即用的CPU性能。
- en: 'We have walked through some general CPU performance tuning principles and recommendations:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了一些通用的CPU性能调优原则和建议：
- en: In a hyperthreading enabled system, avoid logical cores by setting thread affinity
    to physical cores only via core pinning.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在启用超线程的系统中，通过核心绑定将线程亲和性设置为仅在物理核心上，避免逻辑核心。
- en: In a multi-socket system with NUMA, avoid cross-socket remote memory access
    by setting thread affinity to a specific socket via core pinning.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在具有NUMA的多插槽系统中，通过将线程亲和性设置为特定插槽，避免跨插槽的远程内存访问。
- en: We have visually explained these ideas from first principles and have verified
    the performance boost with profiling. And finally, we have applied all of our
    learnings to TorchServe to boost out-of-box TorchServe CPU performance.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从基本原理上直观地解释了这些想法，并通过性能分析验证了性能提升。最后，我们将所有学到的东西应用到TorchServe中，以提升开箱即用的TorchServe
    CPU性能。
- en: These principles can be automatically configured via an easy to use launch script
    which has already been integrated into TorchServe.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原则可以通过一个易于使用的启动脚本自动配置，该脚本已经集成到TorchServe中。
- en: 'For interested readers, please check out the following documents:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于感兴趣的读者，请查看以下文档：
- en: '[CPU specific optimizations](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#cpu-specific-optimizations)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CPU特定优化](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#cpu-specific-optimizations)'
- en: '[Maximize Performance of Intel® Software Optimization for PyTorch* on CPU](https://www.intel.com/content/www/us/en/developer/articles/technical/how-to-get-better-performance-on-pytorchcaffe2-with-intel-acceleration.html)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最大化Intel®软件优化对CPU上PyTorch*性能的影响](https://www.intel.com/content/www/us/en/developer/articles/technical/how-to-get-better-performance-on-pytorchcaffe2-with-intel-acceleration.html)'
- en: '[Performance Tuning Guide](https://intel.github.io/intel-extension-for-pytorch/tutorials/performance_tuning/tuning_guide.html)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[性能调优指南](https://intel.github.io/intel-extension-for-pytorch/tutorials/performance_tuning/tuning_guide.html)'
- en: '[Launch Script Usage Guide](https://intel.github.io/intel-extension-for-pytorch/tutorials/performance_tuning/launch_script.html)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[启动脚本使用指南](https://intel.github.io/intel-extension-for-pytorch/tutorials/performance_tuning/launch_script.html)'
- en: '[Top-down Microarchitecture Analysis Method](https://www.intel.com/content/www/us/en/develop/documentation/vtune-cookbook/top/methodologies/top-down-microarchitecture-analysis-method.html)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自上而下的微体系结构分析方法](https://www.intel.com/content/www/us/en/develop/documentation/vtune-cookbook/top/methodologies/top-down-microarchitecture-analysis-method.html)'
- en: '[Configuring oneDNN for Benchmarking](https://oneapi-src.github.io/oneDNN/dev_guide_performance_settings.html#benchmarking-settings)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为基准测试配置oneDNN](https://oneapi-src.github.io/oneDNN/dev_guide_performance_settings.html#benchmarking-settings)'
- en: '[Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html#gs.tcbgpa)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html#gs.tcbgpa)'
- en: '[Intel® VTune™ Profiler User Guide](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top.html)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Intel® VTune™ Profiler用户指南](https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top.html)'
- en: And stay tuned for a follow-up posts on optimized kernels on CPU via [Intel®
    Extension for PyTorch*](https://github.com/intel/intel-extension-for-pytorch)
    and advanced launcher configurations such as memory allocator.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 请继续关注有关通过[Intel® Extension for PyTorch*](https://github.com/intel/intel-extension-for-pytorch)优化CPU内核和高级启动器配置（如内存分配器）的后续文章。
- en: Acknowledgement
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank Ashok Emani (Intel) and Jiong Gong (Intel) for their
    immense guidance and support, and thorough feedback and reviews throughout many
    steps of this blog. We would also like to thank Hamid Shojanazeri (Meta), Li Ning
    (AWS) and Jing Xu (Intel) for helpful feedback in code review. And Suraj Subramanian
    (Meta) and Geeta Chauhan (Meta) for helpful feedback on the blog.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢Ashok Emani（Intel）和Jiong Gong（Intel）在这篇博客的许多步骤中给予我们巨大的指导和支持，以及详尽的反馈和审查。我们还要感谢Hamid
    Shojanazeri（Meta）、Li Ning（AWS）和Jing Xu（Intel）在代码审查中提供的有用反馈。以及Suraj Subramanian（Meta）和Geeta
    Chauhan（Meta）在博客中提供的有用反馈。
