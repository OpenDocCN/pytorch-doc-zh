- en: Tensor Attributes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量属性
- en: 原文：[https://pytorch.org/docs/stable/tensor_attributes.html](https://pytorch.org/docs/stable/tensor_attributes.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/docs/stable/tensor_attributes.html](https://pytorch.org/docs/stable/tensor_attributes.html)
- en: Each `torch.Tensor` has a [`torch.dtype`](#torch.dtype "torch.dtype"), [`torch.device`](#torch.device
    "torch.device"), and [`torch.layout`](#torch.layout "torch.layout").
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`torch.Tensor`都有一个[`torch.dtype`](#torch.dtype "torch.dtype")、[`torch.device`](#torch.device
    "torch.device")和[`torch.layout`](#torch.layout "torch.layout")。
- en: '## torch.dtype'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '## torch.dtype'
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A [`torch.dtype`](#torch.dtype "torch.dtype") is an object that represents
    the data type of a [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor").
    PyTorch has twelve different data types:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[`torch.dtype`](#torch.dtype "torch.dtype")是表示[`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor")的数据类型的对象。PyTorch有12种不同的数据类型：'
- en: '| Data type | dtype | Legacy Constructors |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | dtype | 旧构造函数 |'
- en: '| --- | --- | --- |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 32-bit floating point | `torch.float32` or `torch.float` | `torch.*.FloatTensor`
    |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 32位浮点数 | `torch.float32`或`torch.float` | `torch.*.FloatTensor` |'
- en: '| 64-bit floating point | `torch.float64` or `torch.double` | `torch.*.DoubleTensor`
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 64位浮点数 | `torch.float64`或`torch.double` | `torch.*.DoubleTensor` |'
- en: '| 64-bit complex | `torch.complex64` or `torch.cfloat` |  |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 64位复数 | `torch.complex64`或`torch.cfloat` |  |'
- en: '| 128-bit complex | `torch.complex128` or `torch.cdouble` |  |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 128位复数 | `torch.complex128`或`torch.cdouble` |  |'
- en: '| 16-bit floating point [1](#id3) | `torch.float16` or `torch.half` | `torch.*.HalfTensor`
    |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 16位浮点数[1](#id3) | `torch.float16`或`torch.half` | `torch.*.HalfTensor` |'
- en: '| 16-bit floating point [2](#id4) | `torch.bfloat16` | `torch.*.BFloat16Tensor`
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 16位浮点数[2](#id4) | `torch.bfloat16` | `torch.*.BFloat16Tensor` |'
- en: '| 8-bit integer (unsigned) | `torch.uint8` | `torch.*.ByteTensor` |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 8位整数（无符号） | `torch.uint8` | `torch.*.ByteTensor` |'
- en: '| 8-bit integer (signed) | `torch.int8` | `torch.*.CharTensor` |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 8位整数（有符号） | `torch.int8` | `torch.*.CharTensor` |'
- en: '| 16-bit integer (signed) | `torch.int16` or `torch.short` | `torch.*.ShortTensor`
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 16位整数（有符号） | `torch.int16`或`torch.short` | `torch.*.ShortTensor` |'
- en: '| 32-bit integer (signed) | `torch.int32` or `torch.int` | `torch.*.IntTensor`
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 32位整数（有符号） | `torch.int32`或`torch.int` | `torch.*.IntTensor` |'
- en: '| 64-bit integer (signed) | `torch.int64` or `torch.long` | `torch.*.LongTensor`
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 64位整数（有符号） | `torch.int64`或`torch.long` | `torch.*.LongTensor` |'
- en: '| Boolean | `torch.bool` | `torch.*.BoolTensor` |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 布尔值 | `torch.bool` | `torch.*.BoolTensor` |'
- en: '[1](#id1)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[1](#id1)'
- en: 'Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand
    bits. Useful when precision is important.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有时被称为binary16：使用1个符号位，5个指数位和10个有效数字位。当精度重要时很有用。
- en: '[2](#id2)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[2](#id2)'
- en: 'Sometimes referred to as Brain Floating Point: use 1 sign, 8 exponent and 7
    significand bits. Useful when range is important, since it has the same number
    of exponent bits as `float32`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有时被称为Brain Floating Point：使用1个符号位，8个指数位和7个有效数字位。当范围重要时很有用，因为它具有与`float32`相同数量的指数位。
- en: To find out if a [`torch.dtype`](#torch.dtype "torch.dtype") is a floating point
    data type, the property [`is_floating_point`](generated/torch.is_floating_point.html#torch.is_floating_point
    "torch.is_floating_point") can be used, which returns `True` if the data type
    is a floating point data type.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定[`torch.dtype`](#torch.dtype "torch.dtype")是否为浮点数据类型，可以使用属性[`is_floating_point`](generated/torch.is_floating_point.html#torch.is_floating_point
    "torch.is_floating_point")，如果数据类型是浮点数据类型，则返回`True`。
- en: To find out if a [`torch.dtype`](#torch.dtype "torch.dtype") is a complex data
    type, the property [`is_complex`](generated/torch.is_complex.html#torch.is_complex
    "torch.is_complex") can be used, which returns `True` if the data type is a complex
    data type.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定[`torch.dtype`](#torch.dtype "torch.dtype")是否为复数数据类型，可以使用属性[`is_complex`](generated/torch.is_complex.html#torch.is_complex
    "torch.is_complex")，如果数据类型是复数数据类型，则返回`True`。
- en: 'When the dtypes of inputs to an arithmetic operation (add, sub, div, mul) differ,
    we promote by finding the minimum dtype that satisfies the following rules:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入到算术操作（add、sub、div、mul）的dtype不同时，我们通过找到满足以下规则的最小dtype来提升：
- en: If the type of a scalar operand is of a higher category than tensor operands
    (where complex > floating > integral > boolean), we promote to a type with sufficient
    size to hold all scalar operands of that category.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果标量操作数的类型高于张量操作数的类型（其中复数 > 浮点 > 整数 > 布尔），则提升为具有足够大小以容纳该类别的所有标量操作数的类型。
- en: If a zero-dimension tensor operand has a higher category than dimensioned operands,
    we promote to a type with sufficient size and category to hold all zero-dim tensor
    operands of that category.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果零维张量操作数的类别高于有尺寸的操作数，则提升为具有足够大小和类别以容纳该类别的所有零维张量操作数的类型。
- en: If there are no higher-category zero-dim operands, we promote to a type with
    sufficient size and category to hold all dimensioned operands.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有更高类别的零维操作数，则提升为具有足够大小和类别以容纳所有有尺寸的操作数的类型。
- en: A floating point scalar operand has dtype torch.get_default_dtype() and an integral
    non-boolean scalar operand has dtype torch.int64. Unlike numpy, we do not inspect
    values when determining the minimum dtypes of an operand. Quantized and complex
    types are not yet supported.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点标量操作数具有dtype torch.get_default_dtype()，整数非布尔标量操作数具有dtype torch.int64。与numpy不同，我们在确定操作数的最小dtype时不检查值。目前不支持量化和复杂类型。
- en: 'Promotion Examples:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 提升示例：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When the output tensor of an arithmetic operation is specified, we allow casting
    to its dtype except that:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当指定算术操作的输出张量时，我们允许将其转换为其dtype，除非：
- en: An integral output tensor cannot accept a floating point tensor.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数输出张量不能接受浮点张量。
- en: A boolean output tensor cannot accept a non-boolean tensor.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔输出张量不能接受非布尔张量。
- en: A non-complex output tensor cannot accept a complex tensor
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非复数输出张量不能接受复数张量
- en: 'Casting Examples:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 转换示例：
- en: '[PRE2]  ## torch.device'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE2]  ## torch.device'
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A [`torch.device`](#torch.device "torch.device") is an object representing the
    device on which a [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") is
    or will be allocated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[`torch.device`](#torch.device "torch.device")是表示[`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor")分配或将要分配的设备的对象。'
- en: The [`torch.device`](#torch.device "torch.device") contains a device type (`'cpu'`,
    `'cuda'` or `'mps'`) and optional device ordinal for the device type. If the device
    ordinal is not present, this object will always represent the current device for
    the device type, even after [`torch.cuda.set_device()`](generated/torch.cuda.set_device.html#torch.cuda.set_device
    "torch.cuda.set_device") is called; e.g., a [`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor") constructed with device `'cuda'` is equivalent to `'cuda:X'` where
    X is the result of [`torch.cuda.current_device()`](generated/torch.cuda.current_device.html#torch.cuda.current_device
    "torch.cuda.current_device").
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[`torch.device`](#torch.device "torch.device") 包含设备类型（`''cpu''`、`''cuda''`
    或 `''mps''`）和设备类型的可选设备序数。如果设备序数不存在，这个对象将始终表示设备类型的当前设备，即使调用了 [`torch.cuda.set_device()`](generated/torch.cuda.set_device.html#torch.cuda.set_device
    "torch.cuda.set_device")；例如，使用设备 `''cuda''` 构造的 [`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor") 等同于 `''cuda:X''`，其中 X 是 [`torch.cuda.current_device()`](generated/torch.cuda.current_device.html#torch.cuda.current_device
    "torch.cuda.current_device") 的结果。'
- en: A [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor")’s device can be
    accessed via the [`Tensor.device`](generated/torch.Tensor.device.html#torch.Tensor.device
    "torch.Tensor.device") property.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 [`Tensor.device`](generated/torch.Tensor.device.html#torch.Tensor.device
    "torch.Tensor.device") 属性访问 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor")
    的设备。
- en: A [`torch.device`](#torch.device "torch.device") can be constructed via a string
    or via a string and device ordinal
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过字符串或字符串和设备序数构造 [`torch.device`](#torch.device "torch.device")。
- en: 'Via a string:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过字符串：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Via a string and device ordinal:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过字符串和设备序数：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The device object can also be used as a context manager to change the default
    device tensors are allocated on:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 设备对象也可以用作上下文管理器，以更改分配张量的默认设备：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This context manager has no effect if a factory function is passed an explicit,
    non-None device argument. To globally change the default device, see also [`torch.set_default_device()`](generated/torch.set_default_device.html#torch.set_default_device
    "torch.set_default_device").
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工厂函数传递了显式的、非 None 的设备参数，则此上下文管理器不起作用。要全局更改默认设备，请参见 [`torch.set_default_device()`](generated/torch.set_default_device.html#torch.set_default_device
    "torch.set_default_device")。
- en: Warning
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: This function imposes a slight performance cost on every Python call to the
    torch API (not just factory functions). If this is causing problems for you, please
    comment on [https://github.com/pytorch/pytorch/issues/92701](https://github.com/pytorch/pytorch/issues/92701)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数会对每次调用 torch API（不仅是工厂函数）产生轻微的性能成本。如果这给您带来问题，请在 [https://github.com/pytorch/pytorch/issues/92701](https://github.com/pytorch/pytorch/issues/92701)
    上发表评论。
- en: Note
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The [`torch.device`](#torch.device "torch.device") argument in functions can
    generally be substituted with a string. This allows for fast prototyping of code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 函数中的 [`torch.device`](#torch.device "torch.device") 参数通常可以用字符串替换。这样可以快速原型化代码。
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For legacy reasons, a device can be constructed via a single device ordinal,
    which is treated as a cuda device. This matches [`Tensor.get_device()`](generated/torch.Tensor.get_device.html#torch.Tensor.get_device
    "torch.Tensor.get_device"), which returns an ordinal for cuda tensors and is not
    supported for cpu tensors.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 出于传统原因，可以通过单个设备序数构造设备，该设备被视为 cuda 设备。这与 [`Tensor.get_device()`](generated/torch.Tensor.get_device.html#torch.Tensor.get_device
    "torch.Tensor.get_device") 相匹配，它返回 cuda 张量的序数，不支持 cpu 张量。
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Methods which take a device will generally accept a (properly formatted) string
    or (legacy) integer device ordinal, i.e. the following are all equivalent:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接受设备的方法通常会接受（格式正确的）字符串或（传统的）整数设备序数，即以下都是等价的：
- en: '[PRE10]  ## torch.layout'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE10]  ## torch.layout'
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Warning
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The `torch.layout` class is in beta and subject to change.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.layout` 类处于 beta 阶段，可能会发生变化。'
- en: A [`torch.layout`](#torch.layout "torch.layout") is an object that represents
    the memory layout of a [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor").
    Currently, we support `torch.strided` (dense Tensors) and have beta support for
    `torch.sparse_coo` (sparse COO Tensors).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[`torch.layout`](#torch.layout "torch.layout") 是一个表示 [`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor") 的内存布局的对象。目前，我们支持 `torch.strided`（稠密张量），并且对 `torch.sparse_coo`（稀疏
    COO 张量）提供 beta 支持。'
- en: '`torch.strided` represents dense Tensors and is the memory layout that is most
    commonly used. Each strided tensor has an associated `torch.Storage`, which holds
    its data. These tensors provide multi-dimensional, [strided](https://en.wikipedia.org/wiki/Stride_of_an_array)
    view of a storage. Strides are a list of integers: the k-th stride represents
    the jump in the memory necessary to go from one element to the next one in the
    k-th dimension of the Tensor. This concept makes it possible to perform many tensor
    operations efficiently.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.strided` 表示稠密张量，是最常用的内存布局。每个步幅张量都有一个关联的 `torch.Storage`，用于保存其数据。这些张量提供了一个多维、[步幅](https://en.wikipedia.org/wiki/Stride_of_an_array)
    视图的存储。步幅是一个整数列表：第 k 个步幅表示在张量的第 k 维中从一个元素到下一个元素所需的内存跳跃。这个概念使得能够高效地执行许多张量操作。'
- en: 'Example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For more information on `torch.sparse_coo` tensors, see [torch.sparse](sparse.html#sparse-docs).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 `torch.sparse_coo` 张量的更多信息，请参阅 [torch.sparse](sparse.html#sparse-docs)。
- en: torch.memory_format
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: torch.memory_format
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: A [`torch.memory_format`](#torch.memory_format "torch.memory_format") is an
    object representing the memory format on which a [`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor") is or will be allocated.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[`torch.memory_format`](#torch.memory_format "torch.memory_format") 是一个表示 [`torch.Tensor`](tensors.html#torch.Tensor
    "torch.Tensor") 分配或将要分配的内存格式的对象。'
- en: 'Possible values are:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的值有：
- en: '`torch.contiguous_format`: Tensor is or will be allocated in dense non-overlapping
    memory. Strides represented by values in decreasing order.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.contiguous_format`：张量被分配在稠密、非重叠的内存中。步幅由值按降序表示。'
- en: '`torch.channels_last`: Tensor is or will be allocated in dense non-overlapping
    memory. Strides represented by values in `strides[0] > strides[2] > strides[3]
    > strides[1] == 1` aka NHWC order.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.channels_last`：张量被分配在稠密、非重叠的内存中。步幅由 `strides[0] > strides[2] > strides[3]
    > strides[1] == 1` 表示，即 NHWC 顺序。'
- en: '`torch.channels_last_3d`: Tensor is or will be allocated in dense non-overlapping
    memory. Strides represented by values in `strides[0] > strides[2] > strides[3]
    > strides[4] > strides[1] == 1` aka NDHWC order.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.channels_last_3d`: 张量将被分配在稠密且不重叠的内存中。步幅由`strides[0] > strides[2] > strides[3]
    > strides[4] > strides[1] == 1`中的值表示，也称为NDHWC顺序。'
- en: '`torch.preserve_format`: Used in functions like clone to preserve the memory
    format of the input tensor. If input tensor is allocated in dense non-overlapping
    memory, the output tensor strides will be copied from the input. Otherwise output
    strides will follow `torch.contiguous_format`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.preserve_format`: 在像克隆这样的函数中使用，以保留输入张量的内存格式。如果输入张量是在稠密且不重叠的内存中分配的，则输出张量的步幅将从输入中复制。否则，输出步幅将遵循`torch.contiguous_format`。'
