- en: Knowledge Distillation Tutorial
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识蒸馏教程
- en: 原文：[https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html](https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html](https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html)
- en: Note
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Click [here](#sphx-glr-download-beginner-knowledge-distillation-tutorial-py)
    to download the full example code
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[这里](#sphx-glr-download-beginner-knowledge-distillation-tutorial-py)下载完整示例代码
- en: '**Author**: [Alexandros Chariton](https://github.com/AlexandrosChrtn)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者**：[Alexandros Chariton](https://github.com/AlexandrosChrtn)'
- en: Knowledge distillation is a technique that enables knowledge transfer from large,
    computationally expensive models to smaller ones without losing validity. This
    allows for deployment on less powerful hardware, making evaluation faster and
    more efficient.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 知识蒸馏是一种技术，它可以实现从大型、计算昂贵的模型向较小的模型进行知识转移，而不会失去有效性。这使得在性能较弱的硬件上部署成为可能，从而使评估更快速、更高效。
- en: In this tutorial, we will run a number of experiments focused at improving the
    accuracy of a lightweight neural network, using a more powerful network as a teacher.
    The computational cost and the speed of the lightweight network will remain unaffected,
    our intervention only focuses on its weights, not on its forward pass. Applications
    of this technology can be found in devices such as drones or mobile phones. In
    this tutorial, we do not use any external packages as everything we need is available
    in `torch` and `torchvision`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将进行一系列旨在提高轻量级神经网络准确性的实验，使用更强大的网络作为教师。轻量级网络的计算成本和速度将保持不变，我们的干预仅关注其权重，而不是其前向传递。这项技术的应用可以在无人机或手机等设备中找到。在本教程中，我们不使用任何外部包，因为我们需要的一切都可以在`torch`和`torchvision`中找到。
- en: 'In this tutorial, you will learn:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，您将学习：
- en: How to modify model classes to extract hidden representations and use them for
    further calculations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何修改模型类以提取隐藏表示并将其用于进一步计算
- en: How to modify regular train loops in PyTorch to include additional losses on
    top of, for example, cross-entropy for classification
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何修改PyTorch中的常规训练循环，以包含额外的损失，例如用于分类的交叉熵
- en: How to improve the performance of lightweight models by using more complex models
    as teachers
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过使用更复杂的模型作为教师来提高轻量级模型的性能
- en: Prerequisites
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 先决条件
- en: 1 GPU, 4GB of memory
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 GPU，4GB内存
- en: PyTorch v2.0 or later
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch v2.0或更高版本
- en: CIFAR-10 dataset (downloaded by the script and saved in a directory called `/data`)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CIFAR-10 数据集（通过脚本下载并保存在名为 `/data` 的目录中）
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loading CIFAR-10
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载 CIFAR-10
- en: CIFAR-10 is a popular image dataset with ten classes. Our objective is to predict
    one of the following classes for each input image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10 是一个包含十个类别的流行图像数据集。我们的目标是为每个输入图像预测以下类别之一。
- en: '![../_static/img/cifar10.png](../Images/e9c54fc1ecf781fe52a58b9630b3174d.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![../_static/img/cifar10.png](../Images/e9c54fc1ecf781fe52a58b9630b3174d.png)'
- en: Example of CIFAR-10 images
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10 图像示例
- en: The input images are RGB, so they have 3 channels and are 32x32 pixels. Basically,
    each image is described by 3 x 32 x 32 = 3072 numbers ranging from 0 to 255. A
    common practice in neural networks is to normalize the input, which is done for
    multiple reasons, including avoiding saturation in commonly used activation functions
    and increasing numerical stability. Our normalization process consists of subtracting
    the mean and dividing by the standard deviation along each channel. The tensors
    “mean=[0.485, 0.456, 0.406]” and “std=[0.229, 0.224, 0.225]” were already computed,
    and they represent the mean and standard deviation of each channel in the predefined
    subset of CIFAR-10 intended to be the training set. Notice how we use these values
    for the test set as well, without recomputing the mean and standard deviation
    from scratch. This is because the network was trained on features produced by
    subtracting and dividing the numbers above, and we want to maintain consistency.
    Furthermore, in real life, we would not be able to compute the mean and standard
    deviation of the test set since, under our assumptions, this data would not be
    accessible at that point.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像是RGB格式的，因此它们有3个通道，尺寸为32x32像素。基本上，每个图像由3 x 32 x 32 = 3072个数字描述，取值范围从0到255。神经网络中的常见做法是对输入进行归一化，这样做有多种原因，包括避免常用激活函数中的饱和现象，增加数值稳定性。我们的归一化过程包括沿每个通道减去平均值并除以标准差。张量“mean=[0.485,
    0.456, 0.406]”和“std=[0.229, 0.224, 0.225]”已经计算出来，它们代表了CIFAR-10预定义子集中用作训练集的每个通道的平均值和标准差。请注意，我们也在测试集中使用这些值，而不是从头开始重新计算平均值和标准差。这是因为网络是在减去和除以上述数字产生的特征上进行训练的，我们希望保持一致性。此外，在现实生活中，我们无法计算测试集的平均值和标准差，因为根据我们的假设，在那时这些数据将不可访问。
- en: As a closing point, we often refer to this held-out set as the validation set,
    and we use a separate set, called the test set, after optimizing a model’s performance
    on the validation set. This is done to avoid selecting a model based on the greedy
    and biased optimization of a single metric.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们经常将这个留出的集合称为验证集，并在优化模型在验证集上的性能后使用一个单独的集合，称为测试集。这样做是为了避免基于单一指标的贪婪和偏见优化选择模型。
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This section is for CPU users only who are interested in quick results. Use
    this option only if you’re interested in a small scale experiment. Keep in mind
    the code should run fairly quickly using any GPU. Select only the first `num_images_to_keep`
    images from the train/test dataset
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分仅适用于对快速结果感兴趣的CPU用户。只有在您对小规模实验感兴趣时才使用此选项。请记住，代码应该在任何GPU上都能运行得相当快速。从训练/测试数据集中仅选择前`num_images_to_keep`张图片
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Defining model classes and utility functions
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义模型类和实用函数
- en: Next, we need to define our model classes. Several user-defined parameters need
    to be set here. We use two different architectures, keeping the number of filters
    fixed across our experiments to ensure fair comparisons. Both architectures are
    Convolutional Neural Networks (CNNs) with a different number of convolutional
    layers that serve as feature extractors, followed by a classifier with 10 classes.
    The number of filters and neurons is smaller for the students.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义我们的模型类。这里需要设置几个用户定义的参数。我们使用两种不同的架构，保持在实验中固定滤波器的数量，以确保公平比较。这两种架构都是卷积神经网络（CNN），具有不同数量的卷积层作为特征提取器，然后是一个具有10个类别的分类器。对于学生，滤波器和神经元的数量较小。
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We employ 2 functions to help us produce and evaluate the results on our original
    classification task. One function is called `train` and takes the following arguments:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用2个函数来帮助我们在原始分类任务上生成和评估结果。一个函数名为`train`，接受以下参数：
- en: '`model`: A model instance to train (update its weights) via this function.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`: 通过这个函数训练（更新其权重）的模型实例。'
- en: '`train_loader`: We defined our `train_loader` above, and its job is to feed
    the data into the model.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_loader`: 我们在上面定义了我们的`train_loader`，它的工作是将数据馈送到模型中。'
- en: '`epochs`: How many times we loop over the dataset.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`: 我们循环遍历数据集的次数。'
- en: '`learning_rate`: The learning rate determines how large our steps towards convergence
    should be. Too large or too small steps can be detrimental.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`: 学习率决定了我们朝着收敛的步长应该有多大。步长太大或太小都可能有害。'
- en: '`device`: Determines the device to run the workload on. Can be either CPU or
    GPU depending on availability.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`: 确定要在哪个设备上运行工作负载。可以根据可用性选择CPU或GPU。'
- en: Our test function is similar, but it will be invoked with `test_loader` to load
    images from the test set.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的测试函数类似，但将使用`test_loader`来从测试集中加载图像。
- en: '![../_static/img/knowledge_distillation/ce_only.png](../Images/6a91b76a26e4f8f13401e7cac418ebaf.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![../_static/img/knowledge_distillation/ce_only.png](../Images/6a91b76a26e4f8f13401e7cac418ebaf.png)'
- en: 'Train both networks with Cross-Entropy. The student will be used as a baseline:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉熵训练两个网络。学生将被用作基准：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Cross-entropy runs
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉熵运行
- en: 'For reproducibility, we need to set the torch manual seed. We train networks
    using different methods, so to compare them fairly, it makes sense to initialize
    the networks with the same weights. Start by training the teacher network using
    cross-entropy:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可重现性，我们需要设置torch手动种子。我们使用不同的方法训练网络，因此为了公平比较它们，最好使用相同的权重初始化网络。首先通过交叉熵训练教师网络：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We instantiate one more lightweight network model to compare their performances.
    Back propagation is sensitive to weight initialization, so we need to make sure
    these two networks have the exact same initialization.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化了另一个轻量级网络模型来比较它们的性能。反向传播对权重初始化很敏感，因此我们需要确保这两个网络具有完全相同的初始化。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To ensure we have created a copy of the first network, we inspect the norm of
    its first layer. If it matches, then we are safe to conclude that the networks
    are indeed the same.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们已经创建了第一个网络的副本，我们检查其第一层的范数。如果匹配，则我们可以安全地得出结论，这些网络确实是相同的。
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Print the total number of parameters in each model:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 打印每个模型中的参数总数：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Train and test the lightweight network with cross entropy loss:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉熵损失训练和测试轻量级网络：
- en: '[PRE14]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As we can see, based on test accuracy, we can now compare the deeper network
    that is to be used as a teacher with the lightweight network that is our supposed
    student. So far, our student has not intervened with the teacher, therefore this
    performance is achieved by the student itself. The metrics so far can be seen
    with the following lines:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，根据测试准确性，我们现在可以比较将作为教师使用的更深层网络与我们假定的学生的轻量级网络。到目前为止，我们的学生尚未干预教师，因此这种性能是学生本身实现的。到目前为止的指标可以在以下行中看到：
- en: '[PRE16]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Knowledge distillation run
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识蒸馏运行
- en: Now let’s try to improve the test accuracy of the student network by incorporating
    the teacher. Knowledge distillation is a straightforward technique to achieve
    this, based on the fact that both networks output a probability distribution over
    our classes. Therefore, the two networks share the same number of output neurons.
    The method works by incorporating an additional loss into the traditional cross
    entropy loss, which is based on the softmax output of the teacher network. The
    assumption is that the output activations of a properly trained teacher network
    carry additional information that can be leveraged by a student network during
    training. The original work suggests that utilizing ratios of smaller probabilities
    in the soft targets can help achieve the underlying objective of deep neural networks,
    which is to create a similarity structure over the data where similar objects
    are mapped closer together. For example, in CIFAR-10, a truck could be mistaken
    for an automobile or airplane, if its wheels are present, but it is less likely
    to be mistaken for a dog. Therefore, it makes sense to assume that valuable information
    resides not only in the top prediction of a properly trained model but in the
    entire output distribution. However, cross entropy alone does not sufficiently
    exploit this information as the activations for non-predicted classes tend to
    be so small that propagated gradients do not meaningfully change the weights to
    construct this desirable vector space.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试通过将教师纳入来提高学生网络的测试准确性。知识蒸馏是一种直接的技术，基于这样一个事实，即两个网络都输出一个关于我们的类别的概率分布。因此，这两个网络共享相同数量的输出神经元。该方法通过将一个额外的损失纳入传统的交叉熵损失来实现，这个额外的损失是基于教师网络的softmax输出的。假设是，一个经过适当训练的教师网络的输出激活包含了额外的信息，可以在训练过程中被学生网络利用。原始工作表明，利用软目标中较小概率的比率可以帮助实现深度神经网络的基本目标，即在数据上创建一个相似对象映射在一起的结构。例如，在CIFAR-10中，如果卡车的轮子存在，它可能被误认为是汽车或飞机，但不太可能被误认为是狗。因此，合理地假设有价值的信息不仅存在于一个经过适当训练模型的顶部预测中，而且存在于整个输出分布中。然而，仅仅使用交叉熵并不能充分利用这些信息，因为对于未预测类别的激活往往非常小，传播的梯度不能有意义地改变权重以构建这种理想的向量空间。
- en: 'As we continue defining our first helper function that introduces a teacher-student
    dynamic, we need to include a few extra parameters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续定义引入师生动态的第一个辅助函数时，我们需要包含一些额外的参数：
- en: '`T`: Temperature controls the smoothness of the output distributions. Larger
    `T` leads to smoother distributions, thus smaller probabilities get a larger boost.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T`: 温度控制输出分布的平滑度。较大的`T`会导致更平滑的分布，因此较小的概率会得到更大的提升。'
- en: '`soft_target_loss_weight`: A weight assigned to the extra objective we’re about
    to include.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`soft_target_loss_weight`: 为即将包含的额外目标分配的权重。'
- en: '`ce_loss_weight`: A weight assigned to cross-entropy. Tuning these weights
    pushes the network towards optimizing for either objective.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ce_loss_weight`: 分配给交叉熵的权重。调整这些权重会推动网络朝着优化任一目标的方向。'
- en: '![../_static/img/knowledge_distillation/distillation_output_loss.png](../Images/e0a3b6adfc1d2e8ec1b2fe1db307bdc9.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![../_static/img/knowledge_distillation/distillation_output_loss.png](../Images/e0a3b6adfc1d2e8ec1b2fe1db307bdc9.png)'
- en: 'Distillation loss is calculated from the logits of the networks. It only returns
    gradients to the student:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 蒸馏损失是从网络的logits计算的。它只返回梯度给学生：
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Cosine loss minimization run
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 余弦损失最小化运行
- en: 'Feel free to play around with the temperature parameter that controls the softness
    of the softmax function and the loss coefficients. In neural networks, it is easy
    to include to include additional loss functions to the main objectives to achieve
    goals like better generalization. Let’s try including an objective for the student,
    but now let’s focus on their hidden states rather than their output layers. Our
    goal is to convey information from the teacher’s representation to the student
    by including a naive loss function, whose minimization implies that the flattened
    vectors that are subsequently passed to the classifiers have become more *similar*
    as the loss decreases. Of course, the teacher does not update its weights, so
    the minimization depends only on the student’s weights. The rationale behind this
    method is that we are operating under the assumption that the teacher model has
    a better internal representation that is unlikely to be achieved by the student
    without external intervention, therefore we artificially push the student to mimic
    the internal representation of the teacher. Whether or not this will end up helping
    the student is not straightforward, though, because pushing the lightweight network
    to reach this point could be a good thing, assuming that we have found an internal
    representation that leads to better test accuracy, but it could also be harmful
    because the networks have different architectures and the student does not have
    the same learning capacity as the teacher. In other words, there is no reason
    for these two vectors, the student’s and the teacher’s to match per component.
    The student could reach an internal representation that is a permutation of the
    teacher’s and it would be just as efficient. Nonetheless, we can still run a quick
    experiment to figure out the impact of this method. We will be using the `CosineEmbeddingLoss`
    which is given by the following formula:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 随意调整控制softmax函数软度和损失系数的温度参数。在神经网络中，很容易包含额外的损失函数到主要目标中，以实现更好的泛化。让我们尝试为学生包含一个目标，但现在让我们专注于他们的隐藏状态而不是输出层。我们的目标是通过包含一个天真的损失函数，使得随着损失的减少，传递给分类器的后续展平向量变得更加“相似”，从而将信息从教师的表示传达给学生。当然，教师不会更新其权重，因此最小化仅取决于学生的权重。这种方法背后的理念是，我们假设教师模型具有更好的内部表示，学生不太可能在没有外部干预的情况下实现，因此我们人为地推动学生模仿教师的内部表示。这是否最终会帮助学生并不明显，因为推动轻量级网络达到这一点可能是一件好事，假设我们已经找到了导致更好测试准确性的内部表示，但也可能是有害的，因为网络具有不同的架构，学生没有与教师相同的学习能力。换句话说，没有理由要求这两个向量，学生的和教师的，每个分量都匹配。学生可能达到教师的一个排列的内部表示，这样同样有效。尽管如此，我们仍然可以运行一个快速实验来了解这种方法的影响。我们将使用`CosineEmbeddingLoss`，其公式如下：
- en: '![../_static/img/knowledge_distillation/cosine_embedding_loss.png](../Images/cdd423a58df099c1510863f187b76089.png)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_static/img/knowledge_distillation/cosine_embedding_loss.png](../Images/cdd423a58df099c1510863f187b76089.png)'
- en: Formula for CosineEmbeddingLoss
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: CosineEmbeddingLoss的公式
- en: Obviously, there is one thing that we need to resolve first. When we applied
    distillation to the output layer we mentioned that both networks have the same
    number of neurons, equal to the number of classes. However, this is not the case
    for the layer following our convolutional layers. Here, the teacher has more neurons
    than the student after the flattening of the final convolutional layer. Our loss
    function accepts two vectors of equal dimensionality as inputs, therefore we need
    to somehow match them. We will solve this by including an average pooling layer
    after the teacher’s convolutional layer to reduce its dimensionality to match
    that of the student.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们首先需要解决一件事情。当我们将蒸馏应用于输出层时，我们提到两个网络具有相同数量的神经元，等于类的数量。然而，在跟随我们的卷积层之后的层中并非如此。在这里，老师在最终卷积层展平后拥有比学生更多的神经元。我们的损失函数接受两个相同维度的向量作为输入，因此我们需要以某种方式将它们匹配。我们将通过在老师的卷积层后包含一个平均池化层来解决这个问题，以减少其维度以匹配学生的维度。
- en: To proceed, we will modify our model classes, or create new ones. Now, the forward
    function returns not only the logits of the network but also the flattened hidden
    representation after the convolutional layer. We include the aforementioned pooling
    for the modified teacher.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了继续，我们将修改我们的模型类，或者创建新的类。现在，前向函数不仅返回网络的logits，还返回卷积层后的扁平化隐藏表示。我们为修改后的教师包括了上述的池化操作。
- en: '[PRE20]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Naturally, we need to change the train loop because now the model returns a
    tuple `(logits, hidden_representation)`. Using a sample input tensor we can print
    their shapes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们需要改变训练循环，因为现在模型返回一个元组`(logits, hidden_representation)`。使用一个示例输入张量，我们可以打印它们的形状。
- en: '[PRE22]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In our case, `hidden_representation_size` is `1024`. This is the flattened
    feature map of the final convolutional layer of the student and as you can see,
    it is the input for its classifier. It is `1024` for the teacher too, because
    we made it so with `avg_pool1d` from `2048`. The loss applied here only affects
    the weights of the student prior to the loss calculation. In other words, it does
    not affect the classifier of the student. The modified training loop is the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，`hidden_representation_size`是`1024`。这是学生最终卷积层的扁平化特征图，正如你所看到的，它是其分类器的输入。对于教师来说也是`1024`，因为我们使用`avg_pool1d`从`2048`得到了这个结果。这里应用的损失只影响了在损失计算之前的学生权重。换句话说，它不会影响学生的分类器。修改后的训练循环如下：
- en: '![../_static/img/knowledge_distillation/cosine_loss_distillation.png](../Images/242a4a47e1f987f8a68f5ee867ce4a88.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![../_static/img/knowledge_distillation/cosine_loss_distillation.png](../Images/242a4a47e1f987f8a68f5ee867ce4a88.png)'
- en: 'In Cosine Loss minimization, we want to maximize the cosine similarity of the
    two representations by returning gradients to the student:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在余弦损失最小化中，我们希望通过向学生返回梯度来最大化两个表示的余弦相似度：
- en: '[PRE24]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We need to modify our test function for the same reason. Here we ignore the
    hidden representation returned by the model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 出于同样的原因，我们需要修改我们的测试函数。在这里，我们忽略模型返回的隐藏表示。
- en: '[PRE25]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this case, we could easily include both knowledge distillation and cosine
    loss minimization in the same function. It is common to combine methods to achieve
    better performance in teacher-student paradigms. For now, we can run a simple
    train-test session.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以很容易地在同一个函数中包含知识蒸馏和余弦损失最小化。在师生范式中，结合不同方法以获得更好的性能是很常见的。现在，我们可以运行一个简单的训练-测试会话。
- en: '[PRE26]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Intermediate regressor run
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中间回归器运行
- en: 'Our naive minimization does not guarantee better results for several reasons,
    one being the dimensionality of the vectors. Cosine similarity generally works
    better than Euclidean distance for vectors of higher dimensionality, but we were
    dealing with vectors with 1024 components each, so it is much harder to extract
    meaningful similarities. Furthermore, as we mentioned, pushing towards a match
    of the hidden representation of the teacher and the student is not supported by
    theory. There are no good reasons why we should be aiming for a 1:1 match of these
    vectors. We will provide a final example of training intervention by including
    an extra network called regressor. The objective is to first extract the feature
    map of the teacher after a convolutional layer, then extract a feature map of
    the student after a convolutional layer, and finally try to match these maps.
    However, this time, we will introduce a regressor between the networks to facilitate
    the matching process. The regressor will be trainable and ideally will do a better
    job than our naive cosine loss minimization scheme. Its main job is to match the
    dimensionality of these feature maps so that we can properly define a loss function
    between the teacher and the student. Defining such a loss function provides a
    teaching “path,” which is basically a flow to back-propagate gradients that will
    change the student’s weights. Focusing on the output of the convolutional layers
    right before each classifier for our original networks, we have the following
    shapes:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们天真的最小化并不保证更好的结果，其中一个原因是向量的维度。余弦相似性通常比欧氏距离在更高维度的向量上效果更好，但我们处理的是每个具有1024个分量的向量，因此更难提取有意义的相似性。此外，正如我们提到的，朝着老师和学生的隐藏表示匹配并不受理论支持。我们没有充分的理由去追求这些向量的一一匹配。我们将通过引入一个额外的网络称为回归器来提供最终的训练干预示例。目标是首先在卷积层之后提取老师的特征图，然后在卷积层之后提取学生的特征图，最后尝试匹配这些特征图。然而，这一次，我们将在网络之间引入一个回归器来促进匹配过程。回归器将是可训练的，并且理想情况下将比我们天真的余弦损失最小化方案做得更好。它的主要任务是匹配这些特征图的维度，以便我们可以正确定义老师和学生之间的损失函数。定义这样一个损失函数提供了一个教学“路径”，基本上是一个用于反向传播梯度的流程，这将改变学生的权重。针对我们原始网络的每个分类器之前的卷积层的输出，我们有以下形状：
- en: '[PRE28]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We have 32 filters for the teacher and 16 filters for the student. We will include
    a trainable layer that converts the feature map of the student to the shape of
    the feature map of the teacher. In practice, we modify the lightweight class to
    return the hidden state after an intermediate regressor that matches the sizes
    of the convolutional feature maps and the teacher class to return the output of
    the final convolutional layer without pooling or flattening.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为教师模型有32个滤波器，为学生模型有16个滤波器。我们将包括一个可训练的层，将学生模型的特征图转换为教师模型的特征图的形状。在实践中，我们修改轻量级类以在中间回归器之后返回隐藏状态，以匹配卷积特征图的大小，并且教师类返回最终卷积层的输出，不包括池化或展平。
- en: '![../_static/img/knowledge_distillation/fitnets_knowledge_distill.png](../Images/074251205eec65bfcc3d0281d0de9abf.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![../_static/img/knowledge_distillation/fitnets_knowledge_distill.png](../Images/074251205eec65bfcc3d0281d0de9abf.png)'
- en: 'The trainable layer matches the shapes of the intermediate tensors and Mean
    Squared Error (MSE) is properly defined:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 可训练的层匹配中间张量的形状，并且均方误差（MSE）被正确定义：
- en: '[PRE30]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: After that, we have to update our train loop again. This time, we extract the
    regressor output of the student, the feature map of the teacher, we calculate
    the `MSE` on these tensors (they have the exact same shape so it’s properly defined)
    and we back propagate gradients based on that loss, in addition to the regular
    cross entropy loss of the classification task.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在那之后，我们必须再次更新我们的训练循环。这一次，我们提取学生的回归器输出，老师的特征图，我们计算这些张量上的`MSE`（它们具有完全相同的形状，因此它被正确定义），并且基于该损失反向传播梯度，除了分类任务的常规交叉熵损失。
- en: '[PRE31]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: It is expected that the final method will work better than `CosineLoss` because
    now we have allowed a trainable layer between the teacher and the student, which
    gives the student some wiggle room when it comes to learning, rather than pushing
    the student to copy the teacher’s representation. Including the extra network
    is the idea behind hint-based distillation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 预计最终的方法将比`CosineLoss`更好，因为现在我们允许在老师和学生之间有一个可训练的层，这给了学生一些学习的余地，而不是推动学生复制老师的表示。包括额外的网络是提示驱动蒸馏背后的想法。
- en: '[PRE33]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Conclusion
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: None of the methods above increases the number of parameters for the network
    or inference time, so the performance increase comes at the little cost of calculating
    gradients during training. In ML applications, we mostly care about inference
    time because training happens before the model deployment. If our lightweight
    model is still too heavy for deployment, we can apply different ideas, such as
    post-training quantization. Additional losses can be applied in many tasks, not
    just classification, and you can experiment with quantities like coefficients,
    temperature, or number of neurons. Feel free to tune any numbers in the tutorial
    above, but keep in mind, if you change the number of neurons / filters chances
    are a shape mismatch might occur.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以上方法都不会增加网络或推理时间的参数数量，因此性能的提升只是在训练过程中计算梯度的小成本。在机器学习应用中，我们主要关心推理时间，因为训练是在模型部署之前进行的。如果我们的轻量级模型仍然太重以至于无法部署，我们可以应用不同的想法，比如后训练量化。额外的损失可以应用在许多任务中，不仅仅是分类，您可以尝试不同的量，比如系数、温度或神经元的数量。请随意调整上面教程中的任何数字，但请记住，如果您改变神经元/滤波器的数量，可能会发生形状不匹配的情况。
- en: 'For more information, see:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请参见：
- en: '[Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network.
    In: Neural Information Processing System Deep Learning Workshop (2015)](https://arxiv.org/abs/1503.02531)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network.
    In: Neural Information Processing System Deep Learning Workshop (2015)](https://arxiv.org/abs/1503.02531)'
- en: '[Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y.:
    Fitnets: Hints for thin deep nets. In: Proceedings of the International Conference
    on Learning Representations (2015)](https://arxiv.org/abs/1412.6550)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y.:
    Fitnets: Hints for thin deep nets. In: Proceedings of the International Conference
    on Learning Representations (2015)](https://arxiv.org/abs/1412.6550)'
- en: '**Total running time of the script:** ( 7 minutes 32.632 seconds)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚本的总运行时间：**（7分钟32.632秒）'
- en: '[`Download Python source code: knowledge_distillation_tutorial.py`](../_downloads/19879e6777280194639314bd79851483/knowledge_distillation_tutorial.py)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[下载Python源代码：knowledge_distillation_tutorial.py](../_downloads/19879e6777280194639314bd79851483/knowledge_distillation_tutorial.py)'
- en: '[`Download Jupyter notebook: knowledge_distillation_tutorial.ipynb`](../_downloads/a19d8941b0ebb13c102e41c7e24bc5fb/knowledge_distillation_tutorial.ipynb)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[下载Jupyter笔记本：knowledge_distillation_tutorial.ipynb](../_downloads/a19d8941b0ebb13c102e41c7e24bc5fb/knowledge_distillation_tutorial.ipynb)'
- en: '[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sphinx-Gallery生成的画廊](https://sphinx-gallery.github.io)'
