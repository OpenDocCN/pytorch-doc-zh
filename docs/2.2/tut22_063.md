# 通过 Flask 在 Python 中部署 PyTorch 的 REST API

> 原文：[`pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html`](https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html)
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)

注意

点击这里下载完整的示例代码

**作者**：[Avinash Sajjanshetty](https://avi.im)

在本教程中，我们将使用 Flask 部署 PyTorch 模型，并为模型推理暴露一个 REST API。特别是，我们将部署一个预训练的 DenseNet 121 模型来检测图像。

提示

这里使用的所有代码都是根据 MIT 许可发布的，并且可以在[Github](https://github.com/avinassh/pytorch-flask-api)上找到。

这代表了一系列关于在生产中部署 PyTorch 模型的教程中的第一篇。以这种方式使用 Flask 是迄今为止最简单的开始为您的 PyTorch 模型提供服务的方法，但对于高性能要求的用例不适用。为此：

> +   如果您已经熟悉 TorchScript，可以直接查看我们的[C++中加载 TorchScript 模型](https://pytorch.org/tutorials/advanced/cpp_export.html)教程。
> +   
> +   如果您需要关于 TorchScript 的复习，请查看我们的[TorchScript 简介](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)教程。

## API 定义

我们将首先定义我们的 API 端点、请求和响应类型。我们的 API 端点将位于`/predict`，接受带有`file`参数的 HTTP POST 请求，该参数包含图像。响应将是一个包含预测的 JSON 响应：

```py
{"class_id":  "n02124075",  "class_name":  "Egyptian_cat"} 
```

## 依赖项

通过运行以下命令安装所需的依赖项：

```py
pip  install  Flask==2.0.1  torchvision==0.10.0 
```

## 简单的 Web 服务器

以下是一个简单的 Web 服务器，摘自 Flask 的文档

```py
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello():
    return 'Hello World!' 
```

我们还将更改响应类型，以便返回一个包含 ImageNet 类别 ID 和名称的 JSON 响应。更新后的`app.py`文件将是：

```py
from flask import Flask, jsonify
app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    return jsonify({'class_id': 'IMAGE_NET_XXX', 'class_name': 'Cat'}) 
```

## 推理

在接下来的部分中，我们将专注于编写推理代码。这将涉及两个部分，一个是我们准备图像以便它可以被馈送到 DenseNet 中，接下来，我们将编写代码从模型中获取实际预测。

### 准备图像

DenseNet 模型要求图像为尺寸为 224 x 224 的 3 通道 RGB 图像。我们还将使用所需的均值和标准差值对图像张量进行归一化。您可以在[这里](https://pytorch.org/vision/stable/models.html)了解更多信息。

我们将使用`torchvision`库中的`transforms`构建一个转换管道，根据需要转换我们的图像。您可以在[这里](https://pytorch.org/vision/stable/transforms.html)了解更多关于转换的信息。

```py
import io

import torchvision.transforms as transforms
from PIL import Image

def transform_image(image_bytes):
    my_transforms = transforms.Compose([transforms.Resize(255),
                                        transforms.CenterCrop(224),
                                        transforms.ToTensor(),
                                        transforms.Normalize(
                                            [0.485, 0.456, 0.406],
                                            [0.229, 0.224, 0.225])])
    image = Image.open(io.BytesIO(image_bytes))
    return my_transforms(image).unsqueeze(0) 
```

上述方法接受字节形式的图像数据，应用一系列转换并返回一个张量。要测试上述方法，请以字节模式读取图像文件（首先用您计算机上文件的实际路径替换../_static/img/sample_file.jpeg），看看是否返回一个张量：

```py
with open("../_static/img/sample_file.jpeg", 'rb') as f:
    image_bytes = f.read()
    tensor = transform_image(image_bytes=image_bytes)
    print(tensor) 
```

### 预测

现在我们将使用一个预训练的 DenseNet 121 模型来预测图像类别。我们将使用`torchvision`库中的一个模型，加载模型并进行推理。虽然在此示例中我们将使用一个预训练模型，但您可以使用相同的方法来加载您自己的模型。在这个 tutorial 中了解更多关于加载您的模型的信息。

```py
from torchvision import models

# Make sure to set `weights` as `'IMAGENET1K_V1'` to use the pretrained weights:
model = models.densenet121(weights='IMAGENET1K_V1')
# Since we are using our model only for inference, switch to `eval` mode:
model.eval()

def get_prediction(image_bytes):
    tensor = transform_image(image_bytes=image_bytes)
    outputs = model.forward(tensor)
    _, y_hat = outputs.max(1)
    return y_hat 
```

张量`y_hat`将包含预测类别 ID 的索引。然而，我们需要一个可读的类别名称。为此，我们需要一个类别 ID 到名称的映射。下载[此文件](https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json)作为`imagenet_class_index.json`并记住保存的位置（或者，如果您按照本教程中的确切步骤进行操作，请将其保存在 tutorials/_static 中）。该文件包含 ImageNet 类别 ID 到 ImageNet 类别名称的映射。我们将加载此 JSON 文件并获取预测索引的类别名称。

```py
import json

imagenet_class_index = json.load(open('../_static/imagenet_class_index.json'))

def get_prediction(image_bytes):
    tensor = transform_image(image_bytes=image_bytes)
    outputs = model.forward(tensor)
    _, y_hat = outputs.max(1)
    predicted_idx = str(y_hat.item())
    return imagenet_class_index[predicted_idx] 
```

在使用`imagenet_class_index`字典之前，我们将首先将张量值转换为字符串值，因为`imagenet_class_index`字典中的键是字符串。我们将测试我们上面的方法：

```py
with open("../_static/img/sample_file.jpeg", 'rb') as f:
    image_bytes = f.read()
    print(get_prediction(image_bytes=image_bytes)) 
```

您应该会收到这样的响应：

```py
['n02124075', 'Egyptian_cat'] 
```

数组中的第一项是 ImageNet 类别 ID，第二项是可读的名称。

将模型集成到我们的 API 服务器中

在最后一部分中，我们将把我们的模型添加到我们的 Flask API 服务器中。由于我们的 API 服务器应该接受一个图像文件，我们将更新我们的`predict`方法以从请求中读取文件：

```py
from flask import request

@app.route('/predict', methods=['POST'])
def predict():
    if request.method == 'POST':
        # we will get the file from the request
        file = request.files['file']
        # convert that to bytes
        img_bytes = file.read()
        class_id, class_name = get_prediction(image_bytes=img_bytes)
        return jsonify({'class_id': class_id, 'class_name': class_name}) 
```

> ```py
> import io
> import json
> 
> from torchvision import models
> import torchvision.transforms as transforms
> from PIL import Image
> from flask import Flask, jsonify, request
> 
> app = Flask(__name__)
> imagenet_class_index = json.load(open('<PATH/TO/.json/FILE>/imagenet_class_index.json'))
> model = models.densenet121(weights='IMAGENET1K_V1')
> model.eval()
> 
> def transform_image(image_bytes):
>     my_transforms = transforms.Compose([transforms.Resize(255),
>                                         transforms.CenterCrop(224),
>                                         transforms.ToTensor(),
>                                         transforms.Normalize(
>                                             [0.485, 0.456, 0.406],
>                                             [0.229, 0.224, 0.225])])
>     image = Image.open(io.BytesIO(image_bytes))
>     return my_transforms(image).unsqueeze(0)
> 
> def get_prediction(image_bytes):
>     tensor = transform_image(image_bytes=image_bytes)
>     outputs = model.forward(tensor)
>     _, y_hat = outputs.max(1)
>     predicted_idx = str(y_hat.item())
>     return imagenet_class_index[predicted_idx]
> 
> @app.route('/predict', methods=['POST'])
> def predict():
>     if request.method == 'POST':
>         file = request.files['file']
>         img_bytes = file.read()
>         class_id, class_name = get_prediction(image_bytes=img_bytes)
>         return jsonify({'class_id': class_id, 'class_name': class_name})
> 
> if __name__ == '__main__':
>     app.run() 
> ```
> 
> ```py
> FLASK_ENV=development  FLASK_APP=app.py  flask  run 
> ```
> 
> 发送 POST 请求到我们的应用程序的库：
> 
> ```py
> import requests
> 
> resp = requests.post("http://localhost:5000/predict",
>                      files={"file": open('<PATH/TO/.jpg/FILE>/cat.jpg','rb')}) 
> ```

现在打印 resp.json()将显示以下内容：

> ```py
> {"class_id":  "n02124075",  "class_name":  "Egyptian_cat"} 
> ```
> 
> 我们编写的服务器相当简单，可能无法满足您的生产应用程序的所有需求。因此，以下是一些可以改进的事项：
> 
> +   端点`/predict`假定请求中始终会有一个图像文件。这可能并非对所有请求都成立。我们的用户可能使用不同的参数发送图像，或者根本不发送图像。
> +   
> +   用户也可以发送非图像类型的文件。由于我们没有处理错误，这将破坏我们的服务器。添加一个明确的错误处理路径，将抛出异常，这样我们就可以更好地处理不良输入。
> +   
> +   尽管模型可以识别大量图像类别，但可能无法识别所有图像。增强实现以处理模型无法识别图像的情况。
> +   
> +   我们以开发模式运行 Flask 服务器，这不适合在生产中部署。您可以查看[此教程](https://flask.palletsprojects.com/en/1.1.x/tutorial/deploy/)以在生产中部署 Flask 服务器。
> +   
> +   您还可以通过创建一个带有表单的页面来添加 UI，该表单接受图像并显示预测结果。查看类似项目的[演示](https://pytorch-imagenet.herokuapp.com/)及其[源代码](https://github.com/avinassh/pytorch-flask-api-heroku)。
> +   
> +   在本教程中，我们仅展示了如何构建一个可以一次返回单个图像预测的服务。我们可以修改我们的服务，使其能够一次返回多个图像的预测。此外，[service-streamer](https://github.com/ShannonAI/service-streamer)库会自动将请求排入您的服务队列，并将其抽样成可以馈送到模型中的小批次。您可以查看[此教程](https://github.com/ShannonAI/service-streamer/wiki/Vision-Recognition-Service-with-Flask-and-service-streamer)。
> +   
> +   最后，我们鼓励您查看我们在页面顶部链接的其他部署 PyTorch 模型的教程。

**脚本的总运行时间：**（0 分钟 0.000 秒）

`下载 Python 源代码：flask_rest_api_tutorial.py`

`下载 Jupyter 笔记本：flask_rest_api_tutorial.ipynb`

[Sphinx-Gallery 生成的图库](https://sphinx-gallery.github.io)
