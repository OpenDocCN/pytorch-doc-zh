# PyTorch 分布式概述

> 原文：[`pytorch.org/tutorials/beginner/dist_overview.html`](https://pytorch.org/tutorials/beginner/dist_overview.html)

**作者**：[Shen Li](https://mrshenli.github.io/)

注意

![edit](img/a8aa37bcc5edbf2ba5fcf18dba1e55f9.png) 在 [github](https://github.com/pytorch/tutorials/blob/main/beginner_source/dist_overview.rst) 中查看并编辑本教程。

这是 `torch.distributed` 包的概述页面。本页面的目标是将文档分类为不同主题，并简要描述每个主题。如果这是您第一次使用 PyTorch 构建分布式训练应用程序，建议使用本文档导航到最适合您用例的技术。

## 介绍

截至 PyTorch v1.6.0，`torch.distributed` 中的功能可以分为三个主要组件：

+   [分布式数据并行训练](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)（DDP）是一种广泛采用的单程序多数据训练范式。使用 DDP，模型在每个进程上被复制，并且每个模型副本将被提供不同的输入数据样本。DDP 负责梯度通信以保持模型副本同步，并将其与梯度计算重叠以加快训练速度。

+   [基于 RPC 的分布式训练](https://pytorch.org/docs/stable/rpc.html)（RPC）支持无法适应数据并行训练的一般训练结构，如分布式管道并行性、参数服务器范式以及 DDP 与其他训练范式的组合。它有助于管理远程对象的生命周期，并将[autograd 引擎](https://pytorch.org/docs/stable/autograd.html)扩展到机器边界之外。

+   [集体通信](https://pytorch.org/docs/stable/distributed.html)（c10d）库支持在组内的进程之间发送张量。它提供了集体通信 API（例如，[all_reduce](https://pytorch.org/docs/stable/distributed.html#torch.distributed.all_reduce)和[all_gather](https://pytorch.org/docs/stable/distributed.html#torch.distributed.all_gather)）以及 P2P 通信 API（例如，[send](https://pytorch.org/docs/stable/distributed.html#torch.distributed.send)和[isend](https://pytorch.org/docs/stable/distributed.html#torch.distributed.isend)）。DDP 和 RPC（[ProcessGroup Backend](https://pytorch.org/docs/stable/rpc.html#process-group-backend)）构建在 c10d 之上，前者使用集体通信，后者使用 P2P 通信。通常，开发人员不需要直接使用这个原始通信 API，因为 DDP 和 RPC API 可以满足许多分布式训练场景。然而，仍有一些用例可以从这个 API 中获益。一个例子是分布式参数平均化，应用程序希望在反向传播后计算所有模型参数的平均值，而不是使用 DDP 来通信梯度。这可以将通信与计算分离，并允许更精细地控制要通信的内容，但另一方面，也放弃了 DDP 提供的性能优化。使用 PyTorch 编写分布式应用程序展示了使用 c10d 通信 API 的示例。

## 数据并行训练

PyTorch 提供了几种数据并行训练的选项。对于从简单到复杂、从原型到生产逐渐增长的应用程序，常见的开发轨迹是：

1.  如果数据和模型可以适应一个 GPU，并且训练速度不是问题，可以使用单设备训练。

1.  使用单机多 GPU [DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html) 来利用单台机器上的多个 GPU 加速训练，只需进行最少的代码更改。

1.  如果您希望进一步加快训练速度并愿意写更多代码来设置，可以使用单机多 GPU [DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)。

1.  如果应用程序需要跨机器边界扩展，请使用多机器[DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)和[启动脚本](https://github.com/pytorch/examples/blob/master/distributed/ddp/README.md)。

1.  当数据和模型无法放入一个 GPU 时，在单机或多机上使用多 GPU 的[FullyShardedDataParallel](https://pytorch.org/docs/stable/fsdp.html)训练。

1.  使用[torch.distributed.elastic](https://pytorch.org/docs/stable/distributed.elastic.html)来启动分布式训练，如果预期会出现错误（例如，内存不足），或者在训练过程中资源可以动态加入和离开。

注意

数据并行训练也可以与[Automatic Mixed Precision (AMP)](https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-multiple-gpus)一起使用。

### `torch.nn.DataParallel`

[DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html) 包能够在单机多 GPU 上实现并行计算，且编码难度最低。只需要在应用代码中进行一行更改。教程 Optional: Data Parallelism 展示了一个例子。虽然 `DataParallel` 很容易使用，但通常性能不是最佳的，因为它在每次前向传播中都会复制模型，并且其单进程多线程并行自然受到 [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) 的影响。为了获得更好的性能，考虑使用 [DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)。

### `torch.nn.parallel.DistributedDataParallel`

与[DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html)相比，[DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)需要多一步设置，即调用[init_process_group](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group)。 DDP 使用多进程并行，因此模型副本之间没有 GIL 争用。此外，模型在 DDP 构建时进行广播，而不是在每次前向传递中进行广播，这也有助于加快训练速度。 DDP 配备了几种性能优化技术。有关更深入的解释，请参考这篇[论文](http://www.vldb.org/pvldb/vol13/p3005-li.pdf)（VLDB’20）。

DDP 材料如下：

1.  [DDP 笔记](https://pytorch.org/docs/stable/notes/ddp.html) 提供了一个入门示例以及对其设计和实现的简要描述。如果这是您第一次使用 DDP，请从这个文档开始。

1.  使用分布式数据并行开始 解释了 DDP 训练中的一些常见问题，包括负载不平衡、检查点和多设备模型。请注意，DDP 可以很容易地与单机多设备模型并行结合，该模型并行在单机模型并行最佳实践教程中有描述。

1.  [启动和配置分布式数据并行应用程序](https://github.com/pytorch/examples/blob/main/distributed/ddp/README.md) 文档展示了如何使用 DDP 启动脚本。

1.  Shard Optimizer States With ZeroRedundancyOptimizer 配方演示了如何使用[ZeroRedundancyOptimizer](https://pytorch.org/docs/stable/distributed.optim.html)来减少优化器的内存占用。

1.  Distributed Training with Uneven Inputs Using the Join Context Manager 教程介绍了如何使用通用的连接上下文管理器进行不均匀输入的分布式训练。

### `torch.distributed.FullyShardedDataParallel`

[FullyShardedDataParallel](https://pytorch.org/docs/stable/fsdp.html)（FSDP）是一种数据并行范例，它在每个 GPU 上维护模型参数、梯度和优化器状态的副本，将所有这些状态分片到数据并行工作器中。对 FSDP 的支持从 PyTorch v1.11 开始添加。教程[Getting Started with FSDP](https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html)提供了关于 FSDP 如何工作的深入解释和示例。

### torch.distributed.elastic

随着应用程序复杂性和规模的增长，故障恢复变得必不可少。在使用 DDP 时，有时会不可避免地遇到诸如内存溢出（OOM）等错误，但 DDP 本身无法从这些错误中恢复，也无法使用标准的`try-except`结构来处理它们。这是因为 DDP 要求所有进程以密切同步的方式运行，并且在不同进程中启动的所有`AllReduce`通信必须匹配。如果组中的一个进程抛出异常，很可能会导致不同步（不匹配的`AllReduce`操作），从而导致崩溃或挂起。[torch.distributed.elastic](https://pytorch.org/docs/stable/distributed.elastic.html) 添加了容错性和利用动态机器池（弹性）的能力。

## 基于 RPC 的分布式训练

许多训练范式不适合数据并行 ism，例如参数服务器范式、分布式管道并行 ism、具有多个观察者或代理的强化学习应用等。[torch.distributed.rpc](https://pytorch.org/docs/stable/rpc.html) 旨在支持一般的分布式训练场景。

[torch.distributed.rpc](https://pytorch.org/docs/stable/rpc.html) 有四个主要支柱：

+   [RPC](https://pytorch.org/docs/stable/rpc.html#rpc) 支持在远程工作节点上运行给定函数。

+   [RRef](https://pytorch.org/docs/stable/rpc.html#rref) 帮助管理远程对象的生命周期。引用计数协议在[RRef 笔记](https://pytorch.org/docs/stable/rpc/rref.html#remote-reference-protocol)中介绍。

+   [Distributed Autograd](https://pytorch.org/docs/stable/rpc.html#distributed-autograd-framework) 将自动求导引擎扩展到机器边界之外。更多细节请参考[Distributed Autograd Design](https://pytorch.org/docs/stable/rpc/distributed_autograd.html#distributed-autograd-design)。

+   [Distributed Optimizer](https://pytorch.org/docs/stable/rpc.html#module-torch.distributed.optim) 自动联系所有参与的工作节点，使用分布式自动求导引擎计算的梯度来更新参数。

RPC 教程如下：

1.  使用分布式 RPC 框架入门 教程首先使用一个简单的强化学习（RL）示例来演示 RPC 和 RRef。然后，它将基本的分布式模型并行应用到一个 RNN 示例中，展示如何使用分布式自动求导和分布式优化器。

1.  使用分布式 RPC 框架实现参数服务器 教程借鉴了[HogWild!训练](https://people.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf)的精神，并将其应用于异步参数服务器（PS）训练应用。

1.  使用 RPC 实现分布式管道并行性 教程将单机管道并行示例（在单机模型并行最佳实践中介绍）扩展到分布式环境，并展示如何使用 RPC 实现它。

1.  使用异步执行实现批量 RPC 处理的教程演示了如何使用[@rpc.functions.async_execution](https://pytorch.org/docs/stable/rpc.html#torch.distributed.rpc.functions.async_execution)装饰器实现 RPC 批处理，这可以帮助加速推理和训练。它使用了类似于上述教程 1 和 2 中的 RL 和 PS 示例。

1.  将分布式数据并行与分布式 RPC 框架相结合的教程演示了如何将 DDP 与 RPC 结合起来，使用分布式数据并行性和分布式模型并行性来训练模型。

## PyTorch 分布式开发者

如果您想为 PyTorch 分布式做出贡献，请参考我们的[开发者指南](https://github.com/pytorch/pytorch/blob/master/torch/distributed/CONTRIBUTING.md)。
