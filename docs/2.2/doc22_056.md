# torch.func

> 原文：[`pytorch.org/docs/stable/func.html`](https://pytorch.org/docs/stable/func.html)> 
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


torch.func，以前称为“functorch”，是 PyTorch 的[JAX-like](https://github.com/google/jax)可组合函数变换。

注意

该库目前处于[测试版](https://pytorch.org/blog/pytorch-feature-classification-changes/#beta)。这意味着功能通常可用（除非另有说明），我们（PyTorch 团队）致力于推进该库。但是，API 可能会根据用户反馈进行更改，我们对 PyTorch 操作的覆盖范围不完整。

如果您对 API 或用例有建议，请打开 GitHub 问题或联系我们。我们很乐意听听您如何使用库。

## 什么是可组合的函数变换？

+   “函数变换”是一个高阶函数，接受一个数值函数并返回一个计算不同量的新函数。

+   `torch.func`具有自动微分变换（`grad(f)`返回一个计算`f`梯度的函数），矢量化/批处理变换（`vmap(f)`返回一个计算输入批次上的`f`的函数）等。

+   这些函数变换可以任意组合。例如，组合`vmap(grad(f))`计算一种称为每样本梯度的量，目前原始 PyTorch 无法高效计算。

## 为什么使用可组合的函数变换？

目前在 PyTorch 中有一些棘手的用例：

+   计算每样本梯度（或其他每样本量）

+   在单台机器上运行模型集合

+   在 MAML 的内循环中高效批处理任务

+   高效计算雅可比矩阵和海森矩阵

+   高效计算批量雅可比矩阵和海森矩阵

组合`vmap()`、`grad()`和`vjp()`变换使我们能够表达上述内容，而无需为每个设计单独的子系统。这种可组合函数变换的想法来自[JAX 框架](https://github.com/google/jax)。

## 阅读更多

+   torch.func 快速浏览

    +   什么是 torch.func？

    +   为什么使用可组合的函数变换？

    +   什么是变换？

+   torch.func API 参考

    +   函数变换

    +   与 torch.nn.Modules 一起工作的实用程序

+   用户体验限制

    +   一般限制

    +   torch.autograd API

    +   vmap 限制

    +   随机性

+   从 functorch 迁移到 torch.func

    +   函数变换

    +   NN 模块实用程序

    +   functorch.compile
