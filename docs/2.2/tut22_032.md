# DCGAN教程

> 原文：[https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)

注意

点击[这里](#sphx-glr-download-beginner-dcgan-faces-tutorial-py)下载完整示例代码

**作者**：[Nathan Inkawhich](https://github.com/inkawhich)

## 介绍

本教程将通过一个示例介绍DCGAN。我们将训练一个生成对抗网络(GAN)，向其展示许多真实名人的照片后，生成新的名人。这里的大部分代码来自[pytorch/examples](https://github.com/pytorch/examples)，本文档将对实现进行详细解释，并阐明这个模型是如何工作的。但不用担心，不需要对GAN有任何先验知识，但可能需要初学者花一些时间思考底层实际发生的事情。另外，为了节省时间，最好有一个GPU，或两个。让我们从头开始。

## 生成对抗网络

### 什么是GAN？

GAN是一个框架，用于教授深度学习模型捕获训练数据分布，以便我们可以从相同分布生成新数据。GAN是由Ian Goodfellow于2014年发明的，并首次在论文[生成对抗网络](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)中描述。它们由两个不同的模型组成，一个*生成器*和一个*判别器*。生成器的任务是生成看起来像训练图像的“假”图像。判别器的任务是查看图像并输出它是来自真实训练图像还是来自生成器的假图像的概率。在训练过程中，生成器不断尝试欺骗判别器，生成越来越好的假图像，而判别器则努力成为更好的侦探，并正确分类真实和假图像。这个游戏的平衡是当生成器生成完美的假图像，看起来就像直接来自训练数据时，判别器总是以50%的置信度猜测生成器的输出是真实的还是假的。

现在，让我们定义一些符号，这些符号将在整个教程中使用，从判别器开始。让\(x\)表示代表图像的数据。\(D(x)\)是判别器网络，它输出\(x\)来自训练数据而不是生成器的(标量)概率。在这里，由于我们处理的是图像，\(D(x)\)的输入是CHW大小为3x64x64的图像。直观地说，当\(x\)来自训练数据时，\(D(x)\)应该是高的，当\(x\)来自生成器时，\(D(x)\)应该是低的。\(D(x)\)也可以被视为传统的二元分类器。

对于生成器的表示，让\(z\)是从标准正态分布中采样的潜在空间向量。\(G(z)\)表示生成器函数，它将潜在向量\(z\)映射到数据空间。生成器\(G\)的目标是估计训练数据来自的分布(\(p_{data}\))，以便可以从该估计分布(\(p_g\))生成假样本。

因此，\(D(G(z))\)是生成器\(G\)的输出是真实图像的概率(标量)。如[Goodfellow的论文](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)所述，\(D\)和\(G\)在一个最小最大游戏中发挥作用，其中\(D\)试图最大化它正确分类真实和假图像的概率(\(logD(x)\))，而\(G\)试图最小化\(D\)预测其输出是假的概率(\(log(1-D(G(z)))\))。从论文中，GAN的损失函数为：

\[ \underset{G}{\text{min}} \underset{D}{\text{max}}V(D,G) = \mathbb{E}_{x\sim p_{data}(x)}\big[logD(x)\big] + \mathbb{E}_{z\sim p_{z}(z)}\big[log(1-D(G(z)))\big] \]

理论上，这个极小极大博弈的解是当\(p_g = p_{data}\)时，如果输入是真实的还是伪造的，鉴别器会随机猜测。然而，GAN的收敛理论仍在积极研究中，实际上模型并不总是训练到这一点。

### 什么是DCGAN？

DCGAN是上述GAN的直接扩展，除了明确在鉴别器和生成器中使用卷积和卷积转置层。它首次由Radford等人在论文[使用深度卷积生成对抗网络进行无监督表示学习](https://arxiv.org/pdf/1511.06434.pdf)中描述。鉴别器由步进的[卷积](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)层、[批量归一化](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d)层和[LeakyReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU)激活组成。输入是一个3x64x64的输入图像，输出是一个标量概率，表示输入来自真实数据分布。生成器由[卷积转置](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d)层、批量归一化层和[ReLU](https://pytorch.org/docs/stable/nn.html#relu)激活组成。输入是一个从标准正态分布中抽取的潜在向量\(z\)，输出是一个3x64x64的RGB图像。步进的卷积转置层允许将潜在向量转换为与图像形状相同的体积。在论文中，作者还提供了一些建议，关于如何设置优化器、如何计算损失函数以及如何初始化模型权重，所有这些将在接下来的章节中解释。

```py
#%matplotlib inline
import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML

# Set random seed for reproducibility
manualSeed = 999
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
[torch.manual_seed](https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed "torch.manual_seed")(manualSeed)
[torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms "torch.use_deterministic_algorithms")(True) # Needed for reproducible results 
```

```py
Random Seed:  999 
```

## 输入

让我们为运行定义一些输入：

+   `dataroot` - 数据集文件夹根目录的路径。我们将在下一节详细讨论数据集。

+   `workers` - 用于使用`DataLoader`加载数据的工作线程数。

+   `batch_size` - 训练中使用的批量大小。DCGAN论文使用批量大小为128。

+   `image_size` - 用于训练的图像的空间尺寸。此实现默认为64x64。如果需要其他尺寸，则必须更改D和G的结构。有关更多详细信息，请参见[这里](https://github.com/pytorch/examples/issues/70)。

+   `nc` - 输入图像中的颜色通道数。对于彩色图像，这是3。

+   `nz` - 潜在向量的长度。

+   `ngf` - 与通过生成器传递的特征图的深度有关。

+   `ndf` - 设置通过鉴别器传播的特征图的深度。

+   `num_epochs` - 要运行的训练周期数。训练时间更长可能会导致更好的结果，但也会花费更多时间。

+   `lr` - 训练的学习率。如DCGAN论文所述，此数字应为0.0002。

+   `beta1` - Adam优化器的beta1超参数。如论文所述，此数字应为0.5。

+   `ngpu` - 可用的GPU数量。如果为0，则代码将在CPU模式下运行。如果此数字大于0，则将在该数量的GPU上运行。

```py
# Root directory for dataset
dataroot = "data/celeba"

# Number of workers for dataloader
workers = 2

# Batch size during training
batch_size = 128

# Spatial size of training images. All images will be resized to this
#   size using a transformer.
image_size = 64

# Number of channels in the training images. For color images this is 3
nc = 3

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# Number of training epochs
num_epochs = 5

# Learning rate for optimizers
lr = 0.0002

# Beta1 hyperparameter for Adam optimizers
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1 
```

## 数据

在本教程中，我们将使用[Celeb-A Faces数据集](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)，可以在链接的网站上下载，或在[Google Drive](https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg)中下载。数据集将下载为名为`img_align_celeba.zip`的文件。下载后，创建一个名为`celeba`的目录，并将zip文件解压缩到该目录中。然后，将此笔记本的`dataroot`输入设置为您刚刚创建的`celeba`目录。生成的目录结构应为：

```py
/path/to/celeba
  ->  img_align_celeba
  ->  188242.jpg
  ->  173822.jpg
  ->  284702.jpg
  ->  537394.jpg
  ... 
```

这是一个重要的步骤，因为我们将使用`ImageFolder`数据集类，这要求数据集根文件夹中有子目录。现在，我们可以创建数据集，创建数据加载器，设置设备运行，并最终可视化一些训练数据。

```py
# We can use an image folder dataset the way we have it setup.
# Create the dataset
[dataset](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder "torchvision.datasets.ImageFolder") = [dset.ImageFolder](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder "torchvision.datasets.ImageFolder")(root=dataroot,
                           transform=[transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose "torchvision.transforms.Compose")([
                               [transforms.Resize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize "torchvision.transforms.Resize")(image_size),
                               [transforms.CenterCrop](https://pytorch.org/vision/stable/generated/torchvision.transforms.CenterCrop.html#torchvision.transforms.CenterCrop "torchvision.transforms.CenterCrop")(image_size),
                               [transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor "torchvision.transforms.ToTensor")(),
                               [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize "torchvision.transforms.Normalize")((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ]))
# Create the dataloader
[dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader") = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader")([dataset](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder "torchvision.datasets.ImageFolder"), batch_size=batch_size,
                                         shuffle=True, num_workers=workers)

# Decide which device we want to run on
[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device") = [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")("cuda:0" if ([torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available")() and ngpu > 0) else "cpu")

# Plot some training images
real_batch = next(iter([dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader")))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose([vutils.make_grid](https://pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid "torchvision.utils.make_grid")(real_batch[0].to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))[:64], padding=2, normalize=True).cpu(),(1,2,0)))
plt.show() 
```

![训练图片](../Images/04fb3a8ed8e63cf7cffb5f29224decca.png)

## 实现

设置好我们的输入参数并准备好数据集后，现在可以开始实现了。我们将从权重初始化策略开始，然后详细讨论生成器、鉴别器、损失函数和训练循环。

### 权重初始化

根据DCGAN论文，作者规定所有模型权重应该从正态分布中随机初始化，`mean=0`，`stdev=0.02`。`weights_init`函数接受一个初始化的模型作为输入，并重新初始化所有卷积、卷积转置和批量归一化层，以满足这个标准。这个函数在初始化后立即应用于模型。

```py
# custom weights initialization called on ``netG`` and ``netD``
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        [nn.init.normal_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.normal_ "torch.nn.init.normal_")(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        [nn.init.normal_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.normal_ "torch.nn.init.normal_")(m.weight.data, 1.0, 0.02)
        [nn.init.constant_](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.constant_ "torch.nn.init.constant_")(m.bias.data, 0) 
```

### 生成器

生成器\(G\)旨在将潜在空间向量(\(z\))映射到数据空间。由于我们的数据是图像，将\(z\)转换为数据空间最终意味着创建一个与训练图像相同大小的RGB图像（即3x64x64）。在实践中，通过一系列步进的二维卷积转置层来实现这一点，每个层都与一个2D批量归一化层和一个relu激活函数配对。生成器的输出通过tanh函数传递，将其返回到输入数据范围\([-1,1]\)。值得注意的是，在卷积转置层之后存在批量归一化函数，这是DCGAN论文的一个重要贡献。这些层有助于训练过程中梯度的流动。下面是生成器的代码。

![dcgan_generator](../Images/85974d98be6202902f21ce274418953f.png)

注意，在输入部分设置的输入（`nz`、`ngf`和`nc`）如何影响代码中的生成器架构。`nz`是z输入向量的长度，`ngf`与通过生成器传播的特征图的大小有关，`nc`是输出图像中的通道数（对于RGB图像设置为3）。

```py
# Generator Code

class Generator([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")):
    def __init__(self, ngpu):
        super([Generator](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module"), self).__init__()
        self.ngpu = ngpu
        self.main = [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential "torch.nn.Sequential")(
            # input is Z, going into a convolution
            [nn.ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d "torch.nn.ConvTranspose2d")( nz, ngf * 8, 4, 1, 0, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ngf * 8),
            [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU "torch.nn.ReLU")(True),
            # state size. ``(ngf*8) x 4 x 4``
            [nn.ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d "torch.nn.ConvTranspose2d")(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ngf * 4),
            [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU "torch.nn.ReLU")(True),
            # state size. ``(ngf*4) x 8 x 8``
            [nn.ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d "torch.nn.ConvTranspose2d")( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ngf * 2),
            [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU "torch.nn.ReLU")(True),
            # state size. ``(ngf*2) x 16 x 16``
            [nn.ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d "torch.nn.ConvTranspose2d")( ngf * 2, ngf, 4, 2, 1, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ngf),
            [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU "torch.nn.ReLU")(True),
            # state size. ``(ngf) x 32 x 32``
            [nn.ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d "torch.nn.ConvTranspose2d")( ngf, nc, 4, 2, 1, bias=False),
            [nn.Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh "torch.nn.Tanh")()
            # state size. ``(nc) x 64 x 64``
        )

    def forward(self, input):
        return self.main(input) 
```

现在，我们可以实例化生成器并应用`weights_init`函数。查看打印出的模型，看看生成器对象的结构是如何的。

```py
# Create the generator
netG = [Generator](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")(ngpu).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))

# Handle multi-GPU if desired
if ([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device").type == 'cuda') and (ngpu > 1):
    netG = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel "torch.nn.DataParallel")(netG, list(range(ngpu)))

# Apply the ``weights_init`` function to randomly initialize all weights
#  to ``mean=0``, ``stdev=0.02``.
[netG.apply](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply "torch.nn.Module.apply")(weights_init)

# Print the model
print(netG) 
```

```py
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
) 
```

### 鉴别器

如前所述，鉴别器\(D\)是一个二元分类网络，接受图像作为输入，并输出一个标量概率，表示输入图像是真实的（而不是假的）。在这里，\(D\)接受一个3x64x64的输入图像，通过一系列的Conv2d、BatchNorm2d和LeakyReLU层处理，通过Sigmoid激活函数输出最终概率。如果需要，可以通过添加更多层来扩展这个架构，但是使用步进卷积、BatchNorm和LeakyReLU具有重要意义。DCGAN论文提到，使用步进卷积而不是池化进行下采样是一个好的做法，因为它让网络学习自己的池化函数。此外，批量归一化和LeakyReLU函数有助于促进健康的梯度流，这对于\(G\)和\(D\)的学习过程至关重要。

鉴别器代码

```py
class Discriminator([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")):
    def __init__(self, ngpu):
        super([Discriminator](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module"), self).__init__()
        self.ngpu = ngpu
        self.main = [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential "torch.nn.Sequential")(
            # input is ``(nc) x 64 x 64``
            [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(nc, ndf, 4, 2, 1, bias=False),
            [nn.LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU "torch.nn.LeakyReLU")(0.2, inplace=True),
            # state size. ``(ndf) x 32 x 32``
            [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(ndf, ndf * 2, 4, 2, 1, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ndf * 2),
            [nn.LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU "torch.nn.LeakyReLU")(0.2, inplace=True),
            # state size. ``(ndf*2) x 16 x 16``
            [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ndf * 4),
            [nn.LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU "torch.nn.LeakyReLU")(0.2, inplace=True),
            # state size. ``(ndf*4) x 8 x 8``
            [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d "torch.nn.BatchNorm2d")(ndf * 8),
            [nn.LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU "torch.nn.LeakyReLU")(0.2, inplace=True),
            # state size. ``(ndf*8) x 4 x 4``
            [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(ndf * 8, 1, 4, 1, 0, bias=False),
            [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid "torch.nn.Sigmoid")()
        )

    def forward(self, input):
        return self.main(input) 
```

现在，就像生成器一样，我们可以创建鉴别器，应用`weights_init`函数，并打印模型的结构。

```py
# Create the Discriminator
netD = [Discriminator](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")(ngpu).to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))

# Handle multi-GPU if desired
if ([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device").type == 'cuda') and (ngpu > 1):
    netD = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel "torch.nn.DataParallel")(netD, list(range(ngpu)))

# Apply the ``weights_init`` function to randomly initialize all weights
# like this: ``to mean=0, stdev=0.2``.
[netD.apply](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply "torch.nn.Module.apply")(weights_init)

# Print the model
print(netD) 
```

```py
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
) 
```

### 损失函数和优化器

设置好\(D\)和\(G\)后，我们可以通过损失函数和优化器指定它们的学习方式。我们将使用二元交叉熵损失（[BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)）函数，PyTorch中定义如下：

\[\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right] \]

请注意，此函数提供了目标函数中两个log组件的计算（即\(log(D(x))\)和\(log(1-D(G(z)))\)）。我们可以通过输入\(y\)来指定要使用BCE方程的哪一部分。这将在即将到来的训练循环中完成，但重要的是要理解我们如何通过改变\(y\)（即GT标签）来选择我们希望计算的组件。

接下来，我们将把真实标签定义为1，将假标签定义为0。在计算\(D\)和\(G\)的损失时将使用这些标签，这也是原始GAN论文中使用的惯例。最后，我们设置了两个单独的优化器，一个用于\(D\)，一个用于\(G\)。如DCGAN论文中所指定的，两者都是Adam优化器，学习率为0.0002，Beta1 = 0.5。为了跟踪生成器的学习进展，我们将生成一批固定的潜在向量，这些向量是从高斯分布中抽取的（即fixed_noise）。在训练循环中，我们将定期将这个fixed_noise输入到\(G\)中，随着迭代的进行，我们将看到图像从噪音中生成出来。

```py
# Initialize the ``BCELoss`` function
[criterion](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss "torch.nn.BCELoss") = [nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss "torch.nn.BCELoss")()

# Create batch of latent vectors that we will use to visualize
#  the progression of the generator
[fixed_noise](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [torch.randn](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn "torch.randn")(64, nz, 1, 1, [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))

# Establish convention for real and fake labels during training
real_label = 1.
fake_label = 0.

# Setup Adam optimizers for both G and D
[optimizerD](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam "torch.optim.Adam") = [optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam "torch.optim.Adam")([netD.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters "torch.nn.Module.parameters")(), lr=lr, betas=(beta1, 0.999))
[optimizerG](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam "torch.optim.Adam") = [optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam "torch.optim.Adam")([netG.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters "torch.nn.Module.parameters")(), lr=lr, betas=(beta1, 0.999)) 
```

### 训练

最后，现在我们已经定义了GAN框架的所有部分，我们可以开始训练。请注意，训练GAN有点像一种艺术形式，因为不正确的超参数设置会导致模式崩溃，而对出现问题的原因却没有太多解释。在这里，我们将紧密遵循[Goodfellow的论文](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)中的算法1，同时遵循[ganhacks](https://github.com/soumith/ganhacks)中显示的一些最佳实践。换句话说，我们将“为真实和伪造图像构建不同的小批量”，并调整G的目标函数以最大化\(log(D(G(z)))\)。训练分为两个主要部分。第一部分更新鉴别器，第二部分更新生成器。

**第一部分 - 训练鉴别器**

回想一下，训练鉴别器的目标是最大化将给定输入正确分类为真实或伪造的概率。就Goodfellow而言，我们希望“通过升高其随机梯度来更新鉴别器”。实际上，我们希望最大化\(log(D(x)) + log(1-D(G(z)))\)。由于[ganhacks](https://github.com/soumith/ganhacks)中的单独小批量建议，我们将分两步计算这个过程。首先，我们将从训练集中构建一批真实样本，通过\(D\)进行前向传播，计算损失（\(log(D(x))\)），然后通过反向传播计算梯度。其次，我们将使用当前生成器构建一批伪造样本，将这批样本通过\(D\)进行前向传播，计算损失（\(log(1-D(G(z)))\)），并通过反向传播*累积*梯度。现在，通过从所有真实和所有伪造批次中累积的梯度，我们调用鉴别器的优化器步骤。

**第二部分 - 训练生成器**

如原始论文所述，我们希望通过最小化\(log(1-D(G(z)))\)来训练生成器，以生成更好的伪造品。正如提到的，Goodfellow指出，特别是在学习过程的早期，这并不能提供足够的梯度。为了解决这个问题，我们希望最大化\(log(D(G(z)))\)。在代码中，我们通过以下方式实现这一点：用鉴别器对第一部分的生成器输出进行分类，使用真实标签作为GT计算G的损失，通过反向传播计算G的梯度，最后使用优化器步骤更新G的参数。在损失函数中使用真实标签作为GT标签可能看起来有些反直觉，但这使我们可以使用`BCELoss`中的\(log(x)\)部分（而不是\(log(1-x)\)部分），这正是我们想要的。

最后，我们将进行一些统计报告，并在每个时代结束时将我们的fixed_noise批次通过生成器，以直观地跟踪G的训练进度。报告的训练统计数据为：

+   **Loss_D** - 判别器损失，计算为所有真实批次和所有虚假批次的损失之和(\(log(D(x)) + log(1 - D(G(z)))\))。

+   **Loss_G** - 生成器损失，计算为\(log(D(G(z)))\)

+   **D(x)** - 判别器对所有真实批次的平均输出（跨批次）。这应该从接近1开始，然后在生成器变得更好时理论上收敛到0.5。想一想为什么会这样。

+   **D(G(z))** - 所有虚假批次的平均判别器输出。第一个数字是在更新D之前，第二个数字是在更新D之后。这些数字应该从接近0开始，随着G变得更好而收敛到0.5。想一想为什么会这样。

**注意：** 这一步可能需要一段时间，取决于您运行了多少个epochs以及是否从数据集中删除了一些数据。

```py
# Training Loop

# Lists to keep track of progress
img_list = []
G_losses = []
D_losses = []
iters = 0

print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate([dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader"), 0):

        ############################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        ## Train with all-real batch
        [netD.zero_grad](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.zero_grad "torch.nn.Module.zero_grad")()
        # Format batch
        [real_cpu](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = data[0].to([device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))
        b_size = [real_cpu](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").size(0)
        [label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [torch.full](https://pytorch.org/docs/stable/generated/torch.full.html#torch.full "torch.full")((b_size,), real_label, dtype=[torch.float](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype "torch.dtype"), [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))
        # Forward pass real batch through D
        [output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = netD([real_cpu](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")).view(-1)
        # Calculate loss on all-real batch
        [errD_real](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [criterion](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss "torch.nn.BCELoss")([output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
        # Calculate gradients for D in backward pass
        [errD_real.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward "torch.Tensor.backward")()
        D_x = [output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").mean().item()

        ## Train with all-fake batch
        # Generate batch of latent vectors
        [noise](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [torch.randn](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn "torch.randn")(b_size, nz, 1, 1, [device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device")=[device](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device "torch.device"))
        # Generate fake image batch with G
        [fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = netG([noise](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
        [label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").fill_(fake_label)
        # Classify all fake batch with D
        [output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = netD([fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").detach()).view(-1)
        # Calculate D's loss on the all-fake batch
        [errD_fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [criterion](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss "torch.nn.BCELoss")([output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
        # Calculate the gradients for this batch, accumulated (summed) with previous gradients
        [errD_fake.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward "torch.Tensor.backward")()
        D_G_z1 = [output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").mean().item()
        # Compute error of D as sum over the fake and the real batches
        [errD](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [errD_real](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") + [errD_fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")
        # Update D
        [optimizerD.step](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step "torch.optim.Adam.step")()

        ############################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        [netG.zero_grad](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.zero_grad "torch.nn.Module.zero_grad")()
        [label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").fill_(real_label)  # fake labels are real for generator cost
        # Since we just updated D, perform another forward pass of all-fake batch through D
        [output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = netD([fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")).view(-1)
        # Calculate G's loss based on this output
        [errG](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = [criterion](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss "torch.nn.BCELoss")([output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), [label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"))
        # Calculate gradients for G
        [errG.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward "torch.Tensor.backward")()
        D_G_z2 = [output](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").mean().item()
        # Update G
        [optimizerG.step](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step "torch.optim.Adam.step")()

        # Output training stats
        if i % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, num_epochs, i, len([dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader")),
                     [errD](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").item(), [errG](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").item(), D_x, D_G_z1, D_G_z2))

        # Save Losses for plotting later
        G_losses.append([errG](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").item())
        D_losses.append([errD](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor").item())

        # Check how the generator is doing by saving G's output on fixed_noise
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len([dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader"))-1)):
            with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad "torch.no_grad")():
                [fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor") = netG([fixed_noise](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")).detach().cpu()
            img_list.append([vutils.make_grid](https://pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid "torchvision.utils.make_grid")([fake](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor"), padding=2, normalize=True))

        iters += 1 
```

```py
Starting Training Loop...
[0/5][0/1583]   Loss_D: 1.4640  Loss_G: 6.9360  D(x): 0.7143    D(G(z)): 0.5877 / 0.0017
[0/5][50/1583]  Loss_D: 0.0174  Loss_G: 23.7368 D(x): 0.9881    D(G(z)): 0.0000 / 0.0000
[0/5][100/1583] Loss_D: 0.5983  Loss_G: 9.9471  D(x): 0.9715    D(G(z)): 0.3122 / 0.0003
[0/5][150/1583] Loss_D: 0.4940  Loss_G: 5.6772  D(x): 0.7028    D(G(z)): 0.0241 / 0.0091
[0/5][200/1583] Loss_D: 0.5931  Loss_G: 7.1186  D(x): 0.9423    D(G(z)): 0.3016 / 0.0018
[0/5][250/1583] Loss_D: 0.3846  Loss_G: 3.2697  D(x): 0.7663    D(G(z)): 0.0573 / 0.0739
[0/5][300/1583] Loss_D: 1.3306  Loss_G: 8.3204  D(x): 0.8768    D(G(z)): 0.6353 / 0.0009
[0/5][350/1583] Loss_D: 0.6451  Loss_G: 6.0499  D(x): 0.9025    D(G(z)): 0.3673 / 0.0060
[0/5][400/1583] Loss_D: 0.4211  Loss_G: 3.7316  D(x): 0.8407    D(G(z)): 0.1586 / 0.0392
[0/5][450/1583] Loss_D: 0.6569  Loss_G: 2.4818  D(x): 0.6437    D(G(z)): 0.0858 / 0.1129
[0/5][500/1583] Loss_D: 1.2208  Loss_G: 2.9943  D(x): 0.4179    D(G(z)): 0.0109 / 0.1133
[0/5][550/1583] Loss_D: 0.3400  Loss_G: 4.7669  D(x): 0.9135    D(G(z)): 0.1922 / 0.0145
[0/5][600/1583] Loss_D: 0.5756  Loss_G: 4.8500  D(x): 0.9189    D(G(z)): 0.3193 / 0.0187
[0/5][650/1583] Loss_D: 0.2470  Loss_G: 4.1606  D(x): 0.9460    D(G(z)): 0.1545 / 0.0250
[0/5][700/1583] Loss_D: 0.3887  Loss_G: 4.1884  D(x): 0.8518    D(G(z)): 0.1562 / 0.0297
[0/5][750/1583] Loss_D: 0.5353  Loss_G: 4.1742  D(x): 0.8034    D(G(z)): 0.1958 / 0.0302
[0/5][800/1583] Loss_D: 0.3213  Loss_G: 5.8919  D(x): 0.9076    D(G(z)): 0.1572 / 0.0065
[0/5][850/1583] Loss_D: 0.8850  Loss_G: 7.4333  D(x): 0.9258    D(G(z)): 0.4449 / 0.0017
[0/5][900/1583] Loss_D: 1.2624  Loss_G: 10.0392 D(x): 0.9896    D(G(z)): 0.6361 / 0.0002
[0/5][950/1583] Loss_D: 0.8802  Loss_G: 6.9221  D(x): 0.5527    D(G(z)): 0.0039 / 0.0045
[0/5][1000/1583]        Loss_D: 0.5799  Loss_G: 3.1800  D(x): 0.7062    D(G(z)): 0.0762 / 0.0884
[0/5][1050/1583]        Loss_D: 0.9647  Loss_G: 6.6894  D(x): 0.9429    D(G(z)): 0.5270 / 0.0035
[0/5][1100/1583]        Loss_D: 0.5624  Loss_G: 3.6715  D(x): 0.7944    D(G(z)): 0.2069 / 0.0445
[0/5][1150/1583]        Loss_D: 0.6205  Loss_G: 4.8995  D(x): 0.8634    D(G(z)): 0.3046 / 0.0169
[0/5][1200/1583]        Loss_D: 0.2569  Loss_G: 4.2945  D(x): 0.9455    D(G(z)): 0.1528 / 0.0255
[0/5][1250/1583]        Loss_D: 0.4921  Loss_G: 3.2500  D(x): 0.8152    D(G(z)): 0.1892 / 0.0753
[0/5][1300/1583]        Loss_D: 0.4068  Loss_G: 3.7702  D(x): 0.8153    D(G(z)): 0.1335 / 0.0472
[0/5][1350/1583]        Loss_D: 1.1704  Loss_G: 7.3408  D(x): 0.9443    D(G(z)): 0.5863 / 0.0022
[0/5][1400/1583]        Loss_D: 0.6111  Loss_G: 2.2676  D(x): 0.6714    D(G(z)): 0.0793 / 0.1510
[0/5][1450/1583]        Loss_D: 0.7817  Loss_G: 4.0744  D(x): 0.7915    D(G(z)): 0.3573 / 0.0242
[0/5][1500/1583]        Loss_D: 0.7177  Loss_G: 1.9253  D(x): 0.5770    D(G(z)): 0.0257 / 0.1909
[0/5][1550/1583]        Loss_D: 0.4518  Loss_G: 2.8314  D(x): 0.7991    D(G(z)): 0.1479 / 0.0885
[1/5][0/1583]   Loss_D: 0.4267  Loss_G: 4.5150  D(x): 0.8976    D(G(z)): 0.2401 / 0.0196
[1/5][50/1583]  Loss_D: 0.5106  Loss_G: 2.7800  D(x): 0.7073    D(G(z)): 0.0663 / 0.0932
[1/5][100/1583] Loss_D: 0.6300  Loss_G: 1.8648  D(x): 0.6557    D(G(z)): 0.0756 / 0.2118
[1/5][150/1583] Loss_D: 1.1727  Loss_G: 5.1536  D(x): 0.8397    D(G(z)): 0.5261 / 0.0125
[1/5][200/1583] Loss_D: 0.4675  Loss_G: 2.9615  D(x): 0.7645    D(G(z)): 0.1400 / 0.0780
[1/5][250/1583] Loss_D: 0.7938  Loss_G: 3.1614  D(x): 0.6958    D(G(z)): 0.2248 / 0.0678
[1/5][300/1583] Loss_D: 0.9869  Loss_G: 5.9243  D(x): 0.9619    D(G(z)): 0.5349 / 0.0063
[1/5][350/1583] Loss_D: 0.5178  Loss_G: 3.0236  D(x): 0.7795    D(G(z)): 0.1769 / 0.0700
[1/5][400/1583] Loss_D: 1.4509  Loss_G: 2.7187  D(x): 0.3278    D(G(z)): 0.0133 / 0.1273
[1/5][450/1583] Loss_D: 0.5530  Loss_G: 4.8110  D(x): 0.9151    D(G(z)): 0.3237 / 0.0160
[1/5][500/1583] Loss_D: 0.4621  Loss_G: 4.1158  D(x): 0.8720    D(G(z)): 0.2278 / 0.0293
[1/5][550/1583] Loss_D: 0.4987  Loss_G: 4.0199  D(x): 0.8533    D(G(z)): 0.2367 / 0.0287
[1/5][600/1583] Loss_D: 1.0630  Loss_G: 4.6502  D(x): 0.9145    D(G(z)): 0.5018 / 0.0218
[1/5][650/1583] Loss_D: 0.6081  Loss_G: 4.3172  D(x): 0.8670    D(G(z)): 0.3312 / 0.0221
[1/5][700/1583] Loss_D: 0.4703  Loss_G: 2.4900  D(x): 0.7538    D(G(z)): 0.1245 / 0.1188
[1/5][750/1583] Loss_D: 0.4827  Loss_G: 2.2941  D(x): 0.7372    D(G(z)): 0.1105 / 0.1300
[1/5][800/1583] Loss_D: 0.4013  Loss_G: 3.8850  D(x): 0.8895    D(G(z)): 0.2179 / 0.0324
[1/5][850/1583] Loss_D: 0.7245  Loss_G: 1.9088  D(x): 0.6100    D(G(z)): 0.0950 / 0.1898
[1/5][900/1583] Loss_D: 0.8372  Loss_G: 1.2346  D(x): 0.5232    D(G(z)): 0.0332 / 0.3633
[1/5][950/1583] Loss_D: 0.5561  Loss_G: 3.2048  D(x): 0.7660    D(G(z)): 0.2035 / 0.0594
[1/5][1000/1583]        Loss_D: 0.6859  Loss_G: 1.6347  D(x): 0.5764    D(G(z)): 0.0435 / 0.2540
[1/5][1050/1583]        Loss_D: 0.6785  Loss_G: 4.3244  D(x): 0.9066    D(G(z)): 0.3835 / 0.0203
[1/5][1100/1583]        Loss_D: 0.4835  Loss_G: 2.4080  D(x): 0.7428    D(G(z)): 0.1073 / 0.1147
[1/5][1150/1583]        Loss_D: 0.5507  Loss_G: 2.5400  D(x): 0.7857    D(G(z)): 0.2182 / 0.1092
[1/5][1200/1583]        Loss_D: 0.6054  Loss_G: 3.4802  D(x): 0.8263    D(G(z)): 0.2934 / 0.0441
[1/5][1250/1583]        Loss_D: 0.4788  Loss_G: 2.3533  D(x): 0.7872    D(G(z)): 0.1698 / 0.1327
[1/5][1300/1583]        Loss_D: 0.5314  Loss_G: 2.7018  D(x): 0.8273    D(G(z)): 0.2423 / 0.0921
[1/5][1350/1583]        Loss_D: 0.8579  Loss_G: 4.6214  D(x): 0.9623    D(G(z)): 0.5089 / 0.0159
[1/5][1400/1583]        Loss_D: 0.4919  Loss_G: 2.7656  D(x): 0.8122    D(G(z)): 0.2147 / 0.0864
[1/5][1450/1583]        Loss_D: 0.4461  Loss_G: 3.0576  D(x): 0.8042    D(G(z)): 0.1798 / 0.0619
[1/5][1500/1583]        Loss_D: 0.7182  Loss_G: 3.7270  D(x): 0.8553    D(G(z)): 0.3713 / 0.0382
[1/5][1550/1583]        Loss_D: 0.6378  Loss_G: 3.7489  D(x): 0.8757    D(G(z)): 0.3523 / 0.0317
[2/5][0/1583]   Loss_D: 0.3965  Loss_G: 2.6262  D(x): 0.7941    D(G(z)): 0.1247 / 0.0963
[2/5][50/1583]  Loss_D: 0.6504  Loss_G: 3.9890  D(x): 0.9267    D(G(z)): 0.3865 / 0.0275
[2/5][100/1583] Loss_D: 0.6523  Loss_G: 3.8724  D(x): 0.8707    D(G(z)): 0.3613 / 0.0299
[2/5][150/1583] Loss_D: 0.7685  Loss_G: 3.9059  D(x): 0.9361    D(G(z)): 0.4534 / 0.0278
[2/5][200/1583] Loss_D: 0.6587  Loss_G: 1.9218  D(x): 0.6469    D(G(z)): 0.1291 / 0.1888
[2/5][250/1583] Loss_D: 0.6971  Loss_G: 2.2256  D(x): 0.6208    D(G(z)): 0.1226 / 0.1465
[2/5][300/1583] Loss_D: 0.5797  Loss_G: 2.4846  D(x): 0.7762    D(G(z)): 0.2434 / 0.1098
[2/5][350/1583] Loss_D: 0.4674  Loss_G: 1.8800  D(x): 0.8045    D(G(z)): 0.1903 / 0.1877
[2/5][400/1583] Loss_D: 0.6462  Loss_G: 1.9510  D(x): 0.7018    D(G(z)): 0.1935 / 0.1792
[2/5][450/1583] Loss_D: 0.9817  Loss_G: 4.2519  D(x): 0.9421    D(G(z)): 0.5381 / 0.0233
[2/5][500/1583] Loss_D: 0.7721  Loss_G: 1.0928  D(x): 0.5402    D(G(z)): 0.0316 / 0.3927
[2/5][550/1583] Loss_D: 0.6037  Loss_G: 2.6914  D(x): 0.7719    D(G(z)): 0.2504 / 0.0896
[2/5][600/1583] Loss_D: 1.4213  Loss_G: 5.4727  D(x): 0.9408    D(G(z)): 0.6792 / 0.0064
[2/5][650/1583] Loss_D: 0.7246  Loss_G: 1.7030  D(x): 0.6716    D(G(z)): 0.2184 / 0.2246
[2/5][700/1583] Loss_D: 0.6642  Loss_G: 3.3809  D(x): 0.8554    D(G(z)): 0.3438 / 0.0591
[2/5][750/1583] Loss_D: 0.6649  Loss_G: 2.0197  D(x): 0.7169    D(G(z)): 0.2333 / 0.1565
[2/5][800/1583] Loss_D: 0.4594  Loss_G: 2.6623  D(x): 0.8150    D(G(z)): 0.1930 / 0.0944
[2/5][850/1583] Loss_D: 1.1957  Loss_G: 3.1871  D(x): 0.7790    D(G(z)): 0.5576 / 0.0568
[2/5][900/1583] Loss_D: 0.6657  Loss_G: 1.5311  D(x): 0.7092    D(G(z)): 0.2122 / 0.2558
[2/5][950/1583] Loss_D: 0.6795  Loss_G: 1.4149  D(x): 0.6134    D(G(z)): 0.1195 / 0.2937
[2/5][1000/1583]        Loss_D: 0.5995  Loss_G: 2.1744  D(x): 0.7325    D(G(z)): 0.2054 / 0.1484
[2/5][1050/1583]        Loss_D: 0.6706  Loss_G: 1.6705  D(x): 0.6425    D(G(z)): 0.1414 / 0.2310
[2/5][1100/1583]        Loss_D: 1.2840  Loss_G: 4.4620  D(x): 0.9736    D(G(z)): 0.6601 / 0.0225
[2/5][1150/1583]        Loss_D: 0.7568  Loss_G: 3.1238  D(x): 0.8153    D(G(z)): 0.3717 / 0.0581
[2/5][1200/1583]        Loss_D: 0.6331  Loss_G: 1.9048  D(x): 0.6799    D(G(z)): 0.1604 / 0.1814
[2/5][1250/1583]        Loss_D: 0.5802  Loss_G: 2.4358  D(x): 0.7561    D(G(z)): 0.2194 / 0.1095
[2/5][1300/1583]        Loss_D: 0.9613  Loss_G: 2.3290  D(x): 0.7463    D(G(z)): 0.3952 / 0.1349
[2/5][1350/1583]        Loss_D: 0.5367  Loss_G: 1.7398  D(x): 0.7580    D(G(z)): 0.1898 / 0.2216
[2/5][1400/1583]        Loss_D: 0.7762  Loss_G: 3.6246  D(x): 0.9006    D(G(z)): 0.4378 / 0.0364
[2/5][1450/1583]        Loss_D: 0.7183  Loss_G: 4.0442  D(x): 0.8602    D(G(z)): 0.3857 / 0.0254
[2/5][1500/1583]        Loss_D: 0.5416  Loss_G: 2.0642  D(x): 0.7393    D(G(z)): 0.1758 / 0.1532
[2/5][1550/1583]        Loss_D: 0.5295  Loss_G: 1.7855  D(x): 0.6768    D(G(z)): 0.0886 / 0.2154
[3/5][0/1583]   Loss_D: 0.8635  Loss_G: 1.7508  D(x): 0.4918    D(G(z)): 0.0280 / 0.2154
[3/5][50/1583]  Loss_D: 0.8697  Loss_G: 0.7859  D(x): 0.5216    D(G(z)): 0.1124 / 0.4941
[3/5][100/1583] Loss_D: 0.8607  Loss_G: 4.5255  D(x): 0.9197    D(G(z)): 0.4973 / 0.0157
[3/5][150/1583] Loss_D: 0.4805  Loss_G: 2.3071  D(x): 0.7743    D(G(z)): 0.1742 / 0.1291
[3/5][200/1583] Loss_D: 0.4925  Loss_G: 2.6018  D(x): 0.7907    D(G(z)): 0.1970 / 0.0948
[3/5][250/1583] Loss_D: 0.7870  Loss_G: 3.3529  D(x): 0.8408    D(G(z)): 0.4050 / 0.0469
[3/5][300/1583] Loss_D: 0.5479  Loss_G: 1.7376  D(x): 0.7216    D(G(z)): 0.1592 / 0.2227
[3/5][350/1583] Loss_D: 0.8117  Loss_G: 3.4145  D(x): 0.9076    D(G(z)): 0.4685 / 0.0437
[3/5][400/1583] Loss_D: 0.4210  Loss_G: 2.3880  D(x): 0.7543    D(G(z)): 0.1047 / 0.1217
[3/5][450/1583] Loss_D: 1.5745  Loss_G: 0.2366  D(x): 0.2747    D(G(z)): 0.0361 / 0.8096
[3/5][500/1583] Loss_D: 0.7196  Loss_G: 2.1319  D(x): 0.7332    D(G(z)): 0.2935 / 0.1403
[3/5][550/1583] Loss_D: 0.5697  Loss_G: 2.6649  D(x): 0.8816    D(G(z)): 0.3210 / 0.0917
[3/5][600/1583] Loss_D: 0.7779  Loss_G: 1.2727  D(x): 0.5540    D(G(z)): 0.0855 / 0.3412
[3/5][650/1583] Loss_D: 0.4090  Loss_G: 2.6893  D(x): 0.8334    D(G(z)): 0.1835 / 0.0855
[3/5][700/1583] Loss_D: 0.8108  Loss_G: 3.8991  D(x): 0.9241    D(G(z)): 0.4716 / 0.0281
[3/5][750/1583] Loss_D: 0.9907  Loss_G: 4.7885  D(x): 0.9111    D(G(z)): 0.5402 / 0.0123
[3/5][800/1583] Loss_D: 0.4725  Loss_G: 2.3347  D(x): 0.7577    D(G(z)): 0.1400 / 0.1222
[3/5][850/1583] Loss_D: 1.5580  Loss_G: 4.9586  D(x): 0.8954    D(G(z)): 0.7085 / 0.0132
[3/5][900/1583] Loss_D: 0.5785  Loss_G: 1.6395  D(x): 0.6581    D(G(z)): 0.1003 / 0.2411
[3/5][950/1583] Loss_D: 0.6592  Loss_G: 1.0890  D(x): 0.5893    D(G(z)): 0.0451 / 0.3809
[3/5][1000/1583]        Loss_D: 0.7280  Loss_G: 3.5368  D(x): 0.8898    D(G(z)): 0.4176 / 0.0409
[3/5][1050/1583]        Loss_D: 0.7088  Loss_G: 3.4301  D(x): 0.8558    D(G(z)): 0.3845 / 0.0457
[3/5][1100/1583]        Loss_D: 0.5651  Loss_G: 2.1150  D(x): 0.7602    D(G(z)): 0.2127 / 0.1532
[3/5][1150/1583]        Loss_D: 0.5412  Loss_G: 1.7790  D(x): 0.6602    D(G(z)): 0.0801 / 0.2088
[3/5][1200/1583]        Loss_D: 1.2277  Loss_G: 1.1464  D(x): 0.4864    D(G(z)): 0.2915 / 0.3665
[3/5][1250/1583]        Loss_D: 0.7148  Loss_G: 1.3957  D(x): 0.5948    D(G(z)): 0.1076 / 0.2876
[3/5][1300/1583]        Loss_D: 1.0675  Loss_G: 1.3018  D(x): 0.4056    D(G(z)): 0.0310 / 0.3355
[3/5][1350/1583]        Loss_D: 0.8064  Loss_G: 0.7482  D(x): 0.5846    D(G(z)): 0.1453 / 0.5147
[3/5][1400/1583]        Loss_D: 0.6032  Loss_G: 3.0601  D(x): 0.8474    D(G(z)): 0.3189 / 0.0590
[3/5][1450/1583]        Loss_D: 0.5329  Loss_G: 2.8172  D(x): 0.8234    D(G(z)): 0.2567 / 0.0795
[3/5][1500/1583]        Loss_D: 0.9292  Loss_G: 3.5544  D(x): 0.8686    D(G(z)): 0.4887 / 0.0410
[3/5][1550/1583]        Loss_D: 0.5929  Loss_G: 2.9118  D(x): 0.8614    D(G(z)): 0.3239 / 0.0702
[4/5][0/1583]   Loss_D: 0.5564  Loss_G: 2.7516  D(x): 0.8716    D(G(z)): 0.3145 / 0.0799
[4/5][50/1583]  Loss_D: 1.0485  Loss_G: 0.6751  D(x): 0.4332    D(G(z)): 0.0675 / 0.5568
[4/5][100/1583] Loss_D: 0.6753  Loss_G: 1.4046  D(x): 0.6028    D(G(z)): 0.0882 / 0.2901
[4/5][150/1583] Loss_D: 0.5946  Loss_G: 1.7618  D(x): 0.6862    D(G(z)): 0.1488 / 0.2016
[4/5][200/1583] Loss_D: 0.4866  Loss_G: 2.2638  D(x): 0.7628    D(G(z)): 0.1633 / 0.1321
[4/5][250/1583] Loss_D: 0.7493  Loss_G: 1.0999  D(x): 0.5541    D(G(z)): 0.0659 / 0.3787
[4/5][300/1583] Loss_D: 1.0886  Loss_G: 4.6532  D(x): 0.9370    D(G(z)): 0.5811 / 0.0149
[4/5][350/1583] Loss_D: 0.6106  Loss_G: 1.9212  D(x): 0.6594    D(G(z)): 0.1322 / 0.1825
[4/5][400/1583] Loss_D: 0.5226  Loss_G: 2.9611  D(x): 0.8178    D(G(z)): 0.2378 / 0.0731
[4/5][450/1583] Loss_D: 1.0068  Loss_G: 1.3267  D(x): 0.4310    D(G(z)): 0.0375 / 0.3179
[4/5][500/1583] Loss_D: 3.1088  Loss_G: 0.1269  D(x): 0.0706    D(G(z)): 0.0061 / 0.8897
[4/5][550/1583] Loss_D: 1.7889  Loss_G: 0.4800  D(x): 0.2175    D(G(z)): 0.0143 / 0.6479
[4/5][600/1583] Loss_D: 0.6732  Loss_G: 3.5685  D(x): 0.8775    D(G(z)): 0.3879 / 0.0362
[4/5][650/1583] Loss_D: 0.5169  Loss_G: 2.1943  D(x): 0.7222    D(G(z)): 0.1349 / 0.1416
[4/5][700/1583] Loss_D: 0.4567  Loss_G: 2.4442  D(x): 0.7666    D(G(z)): 0.1410 / 0.1204
[4/5][750/1583] Loss_D: 0.5972  Loss_G: 2.2992  D(x): 0.6286    D(G(z)): 0.0670 / 0.1283
[4/5][800/1583] Loss_D: 0.5461  Loss_G: 1.9777  D(x): 0.7013    D(G(z)): 0.1318 / 0.1795
[4/5][850/1583] Loss_D: 0.6317  Loss_G: 2.2345  D(x): 0.6962    D(G(z)): 0.1854 / 0.1385
[4/5][900/1583] Loss_D: 0.6034  Loss_G: 3.2300  D(x): 0.8781    D(G(z)): 0.3448 / 0.0517
[4/5][950/1583] Loss_D: 0.6371  Loss_G: 2.7755  D(x): 0.8595    D(G(z)): 0.3357 / 0.0826
[4/5][1000/1583]        Loss_D: 0.6077  Loss_G: 3.3958  D(x): 0.9026    D(G(z)): 0.3604 / 0.0458
[4/5][1050/1583]        Loss_D: 0.5057  Loss_G: 3.2545  D(x): 0.8705    D(G(z)): 0.2691 / 0.0546
[4/5][1100/1583]        Loss_D: 0.4552  Loss_G: 2.0632  D(x): 0.7887    D(G(z)): 0.1704 / 0.1524
[4/5][1150/1583]        Loss_D: 0.9933  Loss_G: 1.0264  D(x): 0.4507    D(G(z)): 0.0636 / 0.4182
[4/5][1200/1583]        Loss_D: 0.5037  Loss_G: 1.9940  D(x): 0.6967    D(G(z)): 0.0959 / 0.1698
[4/5][1250/1583]        Loss_D: 0.4760  Loss_G: 2.5973  D(x): 0.8192    D(G(z)): 0.2164 / 0.0945
[4/5][1300/1583]        Loss_D: 1.0137  Loss_G: 3.8782  D(x): 0.9330    D(G(z)): 0.5405 / 0.0309
[4/5][1350/1583]        Loss_D: 0.9084  Loss_G: 3.1406  D(x): 0.7540    D(G(z)): 0.3980 / 0.0648
[4/5][1400/1583]        Loss_D: 0.6724  Loss_G: 4.1269  D(x): 0.9536    D(G(z)): 0.4234 / 0.0236
[4/5][1450/1583]        Loss_D: 0.6452  Loss_G: 3.5163  D(x): 0.8730    D(G(z)): 0.3555 / 0.0412
[4/5][1500/1583]        Loss_D: 0.8843  Loss_G: 1.4950  D(x): 0.5314    D(G(z)): 0.1035 / 0.2835
[4/5][1550/1583]        Loss_D: 2.3345  Loss_G: 1.0675  D(x): 0.1448    D(G(z)): 0.0228 / 0.4177 
```

## 结果

最后，让我们看看我们的表现如何。在这里，我们将看到三种不同的结果。首先，我们将看到D和G的损失在训练过程中如何变化。其次，我们将可视化G在每个epoch的fixed_noise批次上的输出。第三，我们将查看一批真实数据和G生成的虚假数据相邻。

**损失与训练迭代次数**

下面是D和G的损失与训练迭代次数的图表。

```py
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,[label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")="G")
plt.plot(D_losses,[label](https://pytorch.org/docs/stable/tensors.html#torch.Tensor "torch.Tensor")="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show() 
```

训练过程中的生成器和判别器损失

**G的进展可视化**

记得我们在每个训练epoch后保存了生成器在fixed_noise批次上的输出。现在，我们可以通过动画来可视化G的训练进展。点击播放按钮开始动画。

```py
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml()) 
```

![dcgan faces tutorial](../Images/2a31b55ef7bfff0c24c35bc635656078.png)<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
