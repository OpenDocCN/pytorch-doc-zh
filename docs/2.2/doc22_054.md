# torch.compiler

> 原文：[`pytorch.org/docs/stable/torch.compiler.html`](https://pytorch.org/docs/stable/torch.compiler.html)> 
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


`torch.compiler` 是一个命名空间，通过该命名空间，一些内部编译器方法被公开供用户使用。该命名空间中的主要函数和特性是 `torch.compile`。

`torch.compile` 是 PyTorch 2.x 中引入的一个函数，旨在解决 PyTorch 中准确捕获图形的问题，最终使软件工程师能够更快地运行他们的 PyTorch 程序。`torch.compile` 是用 Python 编写的，标志着 PyTorch 从 C++ 转向 Python。

`torch.compile` 利用以下基础技术：

+   **TorchDynamo (torch._dynamo)** 是一个内部 API，使用了一个名为 Frame Evaluation API 的 CPython 特性，安全地捕获 PyTorch 图。对于 PyTorch 用户可用的方法通过 `torch.compiler` 命名空间公开。

+   **TorchInductor** 是默认的 `torch.compile` 深度学习编译器，可以为多个加速器和后端生成快速代码。您需要使用后端编译器才能通过 `torch.compile` 实现加速。对于 NVIDIA 和 AMD GPU，它利用 OpenAI Triton 作为关键构建模块。

+   **AOT Autograd** 不仅捕获用户级代码，还包括反向传播，这导致提前捕获反向传播。这使得使用 TorchInductor 加速前向和反向传播成为可能。

注意

在某些情况下，本文档中可能会互换使用术语 `torch.compile`、TorchDynamo、`torch.compiler`。

如上所述，为了更快地运行您的工作流程，通过 TorchDynamo 的 `torch.compile` 需要一个将捕获的图转换为快速机器代码的后端。不同的后端可能会导致不同的优化收益。默认后端称为 TorchInductor，也称为 *inductor*，TorchDynamo 有一个由我们的合作伙伴开发的支持后端列表，可以通过运行 `torch.compiler.list_backends()` 查看，每个后端都有其可选依赖项。

一些最常用的后端包括：

**训练和推理后端**

| 后端 | 描述 |
| --- | --- |
| `torch.compile(m, backend="inductor")` | 使用 TorchInductor 后端。[阅读更多](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747) |
| `torch.compile(m, backend="cudagraphs")` | 使用 CUDA 图形与 AOT Autograd。[阅读更多](https://github.com/pytorch/torchdynamo/pull/757) |
| `torch.compile(m, backend="ipex")` | 在 CPU 上使用 IPEX。[阅读更多](https://github.com/intel/intel-extension-for-pytorch) |
| `torch.compile(m, backend="onnxrt")` | 使用 ONNX Runtime 在 CPU/GPU 上进行训练。阅读更多 |

**仅推理后端**

| 后端 | 描述 |
| --- | --- |
| `torch.compile(m, backend="tensorrt")` | 使用 Torch-TensorRT 进行推理优化。需要在调用脚本中导入 `torch_tensorrt` 来注册后端。[阅读更多](https://github.com/pytorch/TensorRT) |
| `torch.compile(m, backend="ipex")` | 在 CPU 上使用 IPEX 进行推理。[阅读更多](https://github.com/intel/intel-extension-for-pytorch) |
| `torch.compile(m, backend="tvm")` | 使用 Apache TVM 进行推理优化。[阅读更多](https://tvm.apache.org/) |
| `torch.compile(m, backend="openvino")` | 使用 OpenVINO 进行推理优化。[阅读更多](https://docs.openvino.ai/2023.1/pytorch_2_0_torch_compile.html) |

## 阅读更多

PyTorch 用户入门

+   入门指南

+   torch.compiler API 参考

+   TorchDynamo 用于细粒度跟踪的 API

+   AOTInductor：Torch.Export-ed 模型的预编译

+   TorchInductor GPU Profiling

+   分析以了解 torch.compile 性能

+   常见问题解答

+   PyTorch 2.0 故障排除

+   PyTorch 2.0 性能仪表板

PyTorch 开发者深入研究

+   TorchDynamo 深入研究

+   守卫概述

+   动态形状

+   PyTorch 2.0 NNModule 支持

+   后端最佳实践

+   CUDAGraph 树

+   伪张量

PyTorch 后端供应商操作指南

+   自定义后端

+   在 ATen IR 上编写图转换

+   IRs
