# 保存和加载模型

> 原文：[`pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html`](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)

注意

点击这里下载完整示例代码

学习基础知识 || 快速入门 || 张量 || 数据集和数据加载器 || 转换 || 构建模型 || 自动求导 || 优化 || **保存和加载模型**

在本节中，我们将看看如何通过保存、加载和运行模型预测来持久化模型状态。

```py
import torch
import torchvision.models as models 
```

## 保存和加载模型权重

PyTorch 模型将学习到的参数存储在内部状态字典中，称为 `state_dict`。这些可以通过 `torch.save` 方法进行持久化：

```py
model = [models.vgg16](https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16 "torchvision.models.vgg16")(weights='IMAGENET1K_V1')
[torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save "torch.save")([model.state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict "torch.nn.Module.state_dict")(), 'model_weights.pth') 
```

```py
Downloading: "https://download.pytorch.org/models/vgg16-397923af.pth" to /var/lib/jenkins/.cache/torch/hub/checkpoints/vgg16-397923af.pth

  0%|          | 0.00/528M [00:00<?, ?B/s]
  2%|2         | 12.7M/528M [00:00<00:04, 133MB/s]
  5%|4         | 25.9M/528M [00:00<00:03, 136MB/s]
  8%|7         | 40.3M/528M [00:00<00:03, 143MB/s]
 10%|#         | 54.0M/528M [00:00<00:03, 141MB/s]
 13%|#2        | 67.4M/528M [00:00<00:03, 138MB/s]
 15%|#5        | 81.8M/528M [00:00<00:03, 142MB/s]
 18%|#8        | 96.2M/528M [00:00<00:03, 145MB/s]
 21%|##        | 110M/528M [00:00<00:03, 145MB/s]
 24%|##3       | 124M/528M [00:00<00:02, 147MB/s]
 26%|##6       | 139M/528M [00:01<00:02, 148MB/s]
 29%|##9       | 153M/528M [00:01<00:02, 149MB/s]
 32%|###1      | 168M/528M [00:01<00:02, 150MB/s]
 35%|###4      | 182M/528M [00:01<00:02, 151MB/s]
 37%|###7      | 197M/528M [00:01<00:02, 123MB/s]
 40%|###9      | 210M/528M [00:01<00:02, 127MB/s]
 42%|####2     | 223M/528M [00:01<00:02, 113MB/s]
 44%|####4     | 234M/528M [00:01<00:02, 112MB/s]
 47%|####6     | 248M/528M [00:01<00:02, 119MB/s]
 50%|####9     | 262M/528M [00:02<00:02, 128MB/s]
 52%|#####2    | 275M/528M [00:02<00:02, 129MB/s]
 55%|#####4    | 288M/528M [00:02<00:01, 132MB/s]
 57%|#####7    | 302M/528M [00:02<00:01, 136MB/s]
 60%|#####9    | 316M/528M [00:02<00:01, 140MB/s]
 63%|######2   | 331M/528M [00:02<00:01, 144MB/s]
 65%|######5   | 345M/528M [00:02<00:01, 146MB/s]
 68%|######8   | 360M/528M [00:02<00:01, 148MB/s]
 71%|#######   | 374M/528M [00:02<00:01, 149MB/s]
 74%|#######3  | 389M/528M [00:02<00:00, 150MB/s]
 76%|#######6  | 403M/528M [00:03<00:00, 151MB/s]
 79%|#######9  | 418M/528M [00:03<00:00, 151MB/s]
 82%|########1 | 432M/528M [00:03<00:00, 151MB/s]
 85%|########4 | 447M/528M [00:03<00:00, 152MB/s]
 87%|########7 | 461M/528M [00:03<00:00, 152MB/s]
 90%|######### | 476M/528M [00:03<00:00, 152MB/s]
 93%|#########2| 490M/528M [00:03<00:00, 152MB/s]
 96%|#########5| 505M/528M [00:03<00:00, 151MB/s]
 98%|#########8| 519M/528M [00:03<00:00, 151MB/s]
100%|##########| 528M/528M [00:03<00:00, 142MB/s] 
```

要加载模型权重，您需要首先创建相同模型的实例，然后使用 `load_state_dict()` 方法加载参数。

```py
model = [models.vgg16](https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16 "torchvision.models.vgg16")() # we do not specify ``weights``, i.e. create untrained model
[model.load_state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict "torch.nn.Module.load_state_dict")([torch.load](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load "torch.load")('model_weights.pth'))
[model.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval "torch.nn.Module.eval")() 
```

```py
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
) 
```

注意

在进行推理之前，请务必调用 `model.eval()` 方法，将丢弃和批量归一化层设置为评估模式。如果不这样做，将导致不一致的推理结果。

## 保存和加载带有形状的模型

在加载模型权重时，我们需要首先实例化模型类，因为类定义了网络的结构。我们可能希望将此类的结构与模型一起保存，这样我们可以将 `model`（而不是 `model.state_dict()`）传递给保存函数：

```py
[torch.save](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save "torch.save")(model, 'model.pth') 
```

我们可以像这样加载模型：

```py
model = [torch.load](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load "torch.load")('model.pth') 
```

注意

此方法在序列化模型时使用 Python [pickle](https://docs.python.org/3/library/pickle.html) 模块，因此在加载模型时依赖于实际的类定义。

## 相关教程

+   [在 PyTorch 中保存和加载通用检查点](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)

+   [从检查点加载 nn.Module 的提示](https://pytorch.org/tutorials/recipes/recipes/module_load_state_dict_tips.html?highlight=loading%20nn%20module%20from%20checkpoint)

**脚本的总运行时间：**（0 分钟 9.335 秒）

`下载 Python 源代码：saveloadrun_tutorial.py`

`下载 Jupyter 笔记本：saveloadrun_tutorial.ipynb`

[Sphinx-Gallery 生成的图库](https://sphinx-gallery.github.io)
