# 数值精度

> 原文：[`pytorch.org/docs/stable/notes/numerical_accuracy.html`](https://pytorch.org/docs/stable/notes/numerical_accuracy.html)> 
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


在现代计算机中，浮点数使用 IEEE 754 标准表示。有关浮点运算和 IEEE 754 标准的更多详细信息，请参见[浮点运算](https://en.wikipedia.org/wiki/Floating-point_arithmetic)。特别要注意的是，浮点提供有限的精度（单精度浮点数约为 7 位小数，双精度浮点数约为 16 位小数），浮点加法和乘法不是结合的，因此操作的顺序会影响结果。因此，PyTorch 不能保证对于数学上相同的浮点计算产生按位相同的结果。同样，即使在控制随机源后，PyTorch 发布、单个提交或不同平台之间也不能保证按位相同的结果。特别是，即使输入按位相同，CPU 和 GPU 的结果也可能不同。

## 批处理计算或切片计算

PyTorch 中的许多操作支持批处理计算，其中对输入批次的元素执行相同的操作。一个例子是`torch.mm()`和`torch.bmm()`。可以将批处理计算实现为对批处理元素的循环，并对各个批处理元素应用必要的数学操作，出于效率原因，我们没有这样做，通常对整个批次进行计算。在这种情况下，我们调用的数学库和 PyTorch 内部操作的实现可能与非批处理计算产生略有不同的结果。特别是，设`A`和`B`为适合批处理矩阵乘法的三维张量。那么`(A@B)[0]`（批处理结果的第一个元素）不能保证与`A[0]@B[0]`（输入批次的第一个元素的矩阵乘积）按位相同，尽管在数学上它是相同的计算。

类似地，对张量切片应用的操作不能保证产生与对完整张量应用相同操作的结果切片相同。例如，设`A`为一个二维张量。`A.sum(-1)[0]`不能保证与`A[:,0].sum()`按位相等。

## 极端值

当输入包含大值，使得中间结果可能溢出所使用数据类型的范围时，最终结果也可能溢出，即使它在原始数据类型中是可表示的。例如：

```py
import torch
a=torch.tensor([1e20, 1e20]) # fp32 type by default
a.norm() # produces tensor(inf)
a.double().norm() # produces tensor(1.4142e+20, dtype=torch.float64), representable in fp32 
```

## 线性代数（`torch.linalg`）

### 非有限值

`torch.linalg` 使用的外部库（后端）在输入具有非有限值（如`inf`或`NaN`）时不提供其行为的任何保证。因此，PyTorch 也不提供。这些操作可能返回一个带有非有限值的张量，或引发异常，甚至导致段错误。

在调用这些函数之前考虑使用`torch.isfinite()`来检测这种情况。

### linalg 中的极端值

`torch.linalg` 中的函数比其他 PyTorch 函数具有更多的极端值。

求解器和逆矩阵假设输入矩阵`A`是可逆的。如果它接近不可逆（例如，如果它具有非常小的奇异值），那么这些算法可能会悄悄返回不正确的结果。这些矩阵被称为[病态矩阵](https://nhigham.com/2020/03/19/what-is-a-condition-number/)。如果提供了病态输入，这些函数的结果可能会因在不同设备上使用相同输入或通过关键字`driver`使用不同后端而有所不同。

像`svd`、`eig`和`eigh`这样的谱操作在它们的输入具有接近的奇异值时也可能返回不正确的结果（它们的梯度可能是无穷大的）。这是因为用于计算这些分解的算法在这些输入上很难收敛。

以`float64`（默认情况下 NumPy 所做的）运行计算通常有所帮助，但并不总是解决所有问题。通过`torch.linalg.svdvals()`分析输入的频谱或通过`torch.linalg.cond()`分析它们的条件数可能有助于检测这些问题。

## Nvidia Ampere（以及之后）设备上的 TensorFloat-32（TF32）

在 Ampere（以及之后）的 Nvidia GPU 上，PyTorch 可以使用 TensorFloat32（TF32）来加速数学密集型操作，特别是矩阵乘法和卷积。当使用 TF32 张量核心执行操作时，只读取输入尾数的前 10 位。这可能会降低精度并产生令人惊讶的结果（例如，将矩阵乘以单位矩阵可能会产生与输入不同的结果）。默认情况下，TF32 张量核心在矩阵乘法中被禁用，并在卷积中启用，尽管大多数神经网络工作负载在使用 TF32 时具有与 fp32 相同的收敛行为。如果您的网络不需要完整的 float32 精度，我们建议通过`torch.backends.cuda.matmul.allow_tf32 = True`启用 TF32 张量核心进行矩阵乘法。如果您的网络在矩阵乘法和卷积中都需要完整的 float32 精度，则可以通过`torch.backends.cudnn.allow_tf32 = False`禁用卷积的 TF32 张量核心。

有关更多信息，请参阅 TensorFloat32。

## FP16 和 BF16 GEMM 的降低精度

半精度 GEMM 操作通常使用单精度进行中间累积（降低）以提高数值精度和对溢出的抵抗力。为了性能，某些 GPU 架构，特别是较新的架构，允许将中间累积结果截断为降低精度（例如，半精度）。从模型收敛的角度来看，这种变化通常是良性的，尽管它可能导致意外的结果（例如，当最终结果应该在半精度中表示时出现`inf`值）。如果降低精度的降低造成问题，可以通过`torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = False`关闭。

BF16 GEMM 操作也有类似的标志，默认情况下是打开的。如果 BF16 降低精度造成问题，可以通过`torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction = False`关闭。

有关更多信息，请参阅 allow_fp16_reduced_precision_reduction 和 allow_bf16_reduced_precision_reduction

## 在 AMD Instinct MI200 设备上降低精度的 FP16 和 BF16 GEMMs 和卷积

在 AMD Instinct MI200 GPU 上，FP16 和 BF16 V_DOT2 和 MFMA 矩阵指令会将输入和输出的非规范化值刷新为零。FP32 和 FP64 MFMA 矩阵指令不会将输入和输出的非规范化值刷新为零。受影响的指令仅由 rocBLAS（GEMM）和 MIOpen（卷积）内核使用；所有其他 PyTorch 操作不会遇到这种行为。所有其他支持的 AMD GPU 不会遇到这种行为。

rocBLAS 和 MIOpen 为受影响的 FP16 操作提供了替代实现。不提供 BF16 操作的替代实现；BF16 数字的动态范围比 FP16 数字大，不太可能遇到非规范化值。对于 FP16 替代实现，FP16 输入值被转换为中间 BF16 值，然后在累积 FP32 操作后转换回 FP16 输出。通过这种方式，输入和输出类型保持不变。

在使用 FP16 精度训练时，一些模型可能无法收敛，因为 FP16 denorms 被刷新为零。在训练的反向传播过程中，梯度计算过程中更频繁地出现非规范化值。PyTorch 默认会在反向传播过程中使用 rocBLAS 和 MIOpen 的替代实现。可以使用环境变量 ROCBLAS_INTERNAL_FP16_ALT_IMPL 和 MIOPEN_DEBUG_CONVOLUTION_ATTRIB_FP16_ALT_IMPL 来覆盖默认行为。这些环境变量的行为如下：

|  | 前向 | 反向 |
| --- | --- | --- |
| 环境取消设置 | 原始 | 替代 |
| 环境设置为 1 | 替代 | 替代 |
| 环境设置为 0 | 原始 | 原始 |

以下是可能使用 rocBLAS 的操作列表：

+   torch.addbmm

+   torch.addmm

+   torch.baddbmm

+   torch.bmm

+   torch.mm

+   torch.nn.GRUCell

+   torch.nn.LSTMCell

+   torch.nn.Linear

+   torch.sparse.addmm

+   以下是 torch._C._ConvBackend 实现列表：

    +   slowNd

    +   slowNd_transposed

    +   slowNd_dilated

    +   slowNd_dilated_transposed

以下是可能使用 MIOpen 的操作列表：

+   torch.nn.Conv[Transpose]Nd

+   以下是 torch._C._ConvBackend 实现列表：

    +   ConvBackend::Miopen

    +   ConvBackend::MiopenDepthwise

    +   ConvBackend::MiopenTranspose
