# 复数

> 原文：[`pytorch.org/docs/stable/complex_numbers.html`](https://pytorch.org/docs/stable/complex_numbers.html)
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)

复数是可以用形式$a + bj$ 表示的数，其中 a 和 b 是实数，*j*称为虚数单位，满足方程$j² = -1$。复数在数学和工程中经常出现，特别是在信号处理等主题中。传统上，许多用户和库（例如 TorchAudio）通过使用形状为$(..., 2)$的浮点张量来处理复数，其中最后一个维度包含实部和虚部值。

复数 dtype 的张量在处理复数时提供更自然的用户体验。对复数张量的操作（例如`torch.mv()`、`torch.matmul()`）可能比在模拟它们的浮点张量上的操作更快速、更节省内存。PyTorch 中涉及复数的操作经过优化，使用矢量化汇编指令和专门的内核（例如 LAPACK、cuBlas）。

注意

在[torch.fft 模块](https://pytorch.org/docs/stable/fft.html#torch-fft)中的频谱操作支持本机复数张量。

警告

复数张量是一个测试功能，可能会发生变化。

## 创建复数张量

我们支持两种复数 dtype：torch.cfloat 和 torch.cdouble

```py
>>> x = torch.randn(2,2, dtype=torch.cfloat)
>>> x
tensor([[-0.4621-0.0303j, -0.2438-0.5874j],
 [ 0.7706+0.1421j,  1.2110+0.1918j]]) 
```

注意

复数张量的默认 dtype 由默认浮点 dtype 确定。如果默认浮点 dtype 是 torch.float64，则推断复数的 dtype 为 torch.complex128，否则假定为 torch.complex64。

除了`torch.linspace()`、`torch.logspace()`和`torch.arange()`之外的所有工厂函数都支持复数张量。

## 从旧表示形式过渡[](#transition-from-the-old-representation "Permalink to this heading")

目前通过使用形状为$(..., 2)$(...,2)的实数张量绕过缺少复数张量的用户可以轻松地在其代码中使用复数张量切换，使用`torch.view_as_complex()`和`torch.view_as_real()`。请注意，这些函数不执行任何复制操作，返回输入张量的视图。

```py
>>> x = torch.randn(3, 2)
>>> x
tensor([[ 0.6125, -0.1681],
 [-0.3773,  1.3487],
 [-0.0861, -0.7981]])
>>> y = torch.view_as_complex(x)
>>> y
tensor([ 0.6125-0.1681j, -0.3773+1.3487j, -0.0861-0.7981j])
>>> torch.view_as_real(y)
tensor([[ 0.6125, -0.1681],
 [-0.3773,  1.3487],
 [-0.0861, -0.7981]]) 
```

## 访问 real 和 imag

可以使用`real`和`imag`访问复数张量的实部和虚部值。

注意

访问 real 和 imag 属性不会分配任何内存，并且对 real 和 imag 张量的原位更新将更新原始复数张量。此外，返回的 real 和 imag 张量不是连续的。

```py
>>> y.real
tensor([ 0.6125, -0.3773, -0.0861])
>>> y.imag
tensor([-0.1681,  1.3487, -0.7981])

>>> y.real.mul_(2)
tensor([ 1.2250, -0.7546, -0.1722])
>>> y
tensor([ 1.2250-0.1681j, -0.7546+1.3487j, -0.1722-0.7981j])
>>> y.real.stride()
(2,) 
```

## 角度和绝对值

可以使用`torch.angle()`和`torch.abs()`计算复数张量的角度和绝对值。

```py
>>> x1=torch.tensor([3j, 4+4j])
>>> x1.abs()
tensor([3.0000, 5.6569])
>>> x1.angle()
tensor([1.5708, 0.7854]) 
```

## 线性代数

许多线性代数操作，如`torch.matmul()`、`torch.linalg.svd()`、`torch.linalg.solve()`等，支持复数。如果您想请求我们目前不支持的操作，请[搜索](https://github.com/pytorch/pytorch/issues?q=is%3Aissue+is%3Aopen+complex)是否已经提交了问题，如果没有，请[提交一个](https://github.com/pytorch/pytorch/issues/new/choose)。

## 序列化

复数张量可以被序列化，允许数据保存为复数值。

```py
>>> torch.save(y, 'complex_tensor.pt')
>>> torch.load('complex_tensor.pt')
tensor([ 0.6125-0.1681j, -0.3773+1.3487j, -0.0861-0.7981j]) 
```

## 自动求导

PyTorch 支持复杂张量的自动求导。计算的梯度是共轭 Wirtinger 导数，其负值恰好是梯度下降算法中使用的最陡下降方向。因此，所有现有的优化器都可以直接与复杂参数一起使用。更多详情，请查看说明复数的自动求导。

我们不完全支持以下子系统：

+   量化

+   即时编译

+   稀疏张量

+   分布式

如果其中任何一个对您的用例有帮助，请搜索是否已经提交了问题，如果没有，请提交一个。
