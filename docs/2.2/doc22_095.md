# 命名张量

> 原文：[`pytorch.org/docs/stable/named_tensor.html`](https://pytorch.org/docs/stable/named_tensor.html)> 
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


命名张量允许用户为张量维度提供显式名称。在大多数情况下，接受维度参数的操作将接受维度名称，避免了按位置跟踪维度的需要。此外，命名张量使用名称在运行时自动检查 API 是否被正确使用，提供额外的安全性。名称还可以用于重新排列维度，例如，支持“按名称广播”而不是“按位置广播”。

警告

命名张量 API 是一个原型功能，可能会发生变化。

## 创建命名张量

工厂函数现在接受一个新的`names`参数，将每个维度与一个名称关联起来。

```py
>>> torch.zeros(2, 3, names=('N', 'C'))
tensor([[0., 0., 0.],
 [0., 0., 0.]], names=('N', 'C')) 
```

命名维度和常规张量维度一样是有序的。`tensor.names[i]`是`tensor`的维度`i`的名称。

以下工厂函数支持命名张量：

+   `torch.empty()`

+   `torch.rand()`

+   `torch.randn()`

+   `torch.ones()`

+   `torch.tensor()`

+   `torch.zeros()`

## 命名维度

请参阅`names`以了解张量名称的限制。

使用`names`来访问张量的维度名称，使用`rename()`来重命名命名维度。

```py
>>> imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W'))
>>> imgs.names
('N', 'C', 'H', 'W')

>>> renamed_imgs = imgs.rename(H='height', W='width')
>>> renamed_imgs.names
('N', 'C', 'height', 'width) 
```

命名张量可以与未命名张量共存；命名张量是`torch.Tensor`的实例。未命名张量具有`None`命名的维度。命名张量不要求所有维度都有名称。

```py
>>> imgs = torch.randn(1, 2, 2, 3 , names=(None, 'C', 'H', 'W'))
>>> imgs.names
(None, 'C', 'H', 'W') 
```

## 名称传播语义

命名张量使用名称在运行时自动检查 API 是否被正确调用。这发生在一个称为*名称推断*的过程中。更正式地说，名称推断包括以下两个步骤：

+   **检查名称**：运算符可能在运行时执行自动检查，检查某些维度名称必须匹配。

+   **传播名称**：名称推断将名称传播到输出张量。

所有支持命名张量的操作都会传播名称。

```py
>>> x = torch.randn(3, 3, names=('N', 'C'))
>>> x.abs().names
('N', 'C') 
```

### 匹配语义

如果两个名称相等（字符串相等）或至少一个为`None`，则两个名称*匹配*。`None`本质上是一个特殊的“通配符”名称。

`unify(A, B)`确定要传播到输出的名称`A`和`B`中的哪一个。如果它们匹配，则返回两个名称中更*具体*的名称。如果名称不匹配，则会出错。

注意

在实践中，当使用命名张量时，应避免具有未命名维度，因为它们的处理可能会变得复杂。建议使用`refine_names()`将所有未命名维度提升为命名维度。

### 基本名称推断规则

让我们看看在没有广播的情况下如何在名称推断中使用`match`和`unify`来添加两个一维张量。

```py
x = torch.randn(3, names=('X',))
y = torch.randn(3)
z = torch.randn(3, names=('Z',)) 
```

**检查名称**：检查两个张量的名称是否*匹配*。

对于以下示例：

```py
>>> # x + y  # match('X', None) is True
>>> # x + z  # match('X', 'Z') is False
>>> # x + x  # match('X', 'X') is True

>>> x + z
Error when attempting to broadcast dims ['X'] and dims ['Z']: dim 'X' and dim 'Z' are at the same position from the right but do not match. 
```

**传播名称**：*统一*名称以选择要传播的名称。在`x + y`的情况下，`unify('X', None) = 'X'`，因为`'X'`比`None`更具体。

```py
>>> (x + y).names
('X',)
>>> (x + x).names
('X',) 
```

有关名称推断规则的全面列表，请参见命名张量运算符覆盖范围。以下是可能有用的两个常见操作：

+   二进制算术运算：统一输入的名称

+   矩阵乘法运算：消除维度

## 通过名称进行显式对齐

使用`align_as()`或`align_to()`按名称对齐张量维度到指定的顺序。这对执行“按名称广播”很有用。

```py
# This function is agnostic to the dimension ordering of `input`,
# as long as it has a `C` dimension somewhere.
def scale_channels(input, scale):
    scale = scale.refine_names('C')
    return input * scale.align_as(input)

>>> num_channels = 3
>>> scale = torch.randn(num_channels, names=('C',))
>>> imgs = torch.rand(3, 3, 3, num_channels, names=('N', 'H', 'W', 'C'))
>>> more_imgs = torch.rand(3, num_channels, 3, 3, names=('N', 'C', 'H', 'W'))
>>> videos = torch.randn(3, num_channels, 3, 3, 3, names=('N', 'C', 'H', 'W', 'D')

>>> scale_channels(imgs, scale)
>>> scale_channels(more_imgs, scale)
>>> scale_channels(videos, scale) 
```

## 操作维度

使用`align_to()`来对大量维度进行排列，而不需要像`permute()`那样提及所有维度。

```py
>>> tensor = torch.randn(2, 2, 2, 2, 2, 2)
>>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')

# Move the F (dim 5) and E dimension (dim 4) to the front while keeping
# the rest in the same order
>>> tensor.permute(5, 4, 0, 1, 2, 3)
>>> named_tensor.align_to('F', 'E', ...) 
```

使用`flatten()`和`unflatten()`分别对维度进行展平和展开。这些方法比`view()`和`reshape()`更冗长，但对于阅读代码的人来说具有更多的语义意义。

```py
>>> imgs = torch.randn(32, 3, 128, 128)
>>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')

>>> flat_imgs = imgs.view(32, -1)
>>> named_flat_imgs = named_imgs.flatten(['C', 'H', 'W'], 'features')
>>> named_flat_imgs.names
('N', 'features')

>>> unflattened_named_imgs = named_flat_imgs.unflatten('features', [('C', 3), ('H', 128), ('W', 128)])
>>> unflattened_named_imgs.names
('N', 'C', 'H', 'W') 
```

## 自动求导支持

Autograd 目前以有限的方式支持命名张量：autograd 会忽略所有张量上的名称。梯度计算仍然是正确的，但我们失去了名称给我们带来的安全性。

```py
>>> x = torch.randn(3, names=('D',))
>>> weight = torch.randn(3, names=('D',), requires_grad=True)
>>> loss = (x - weight).abs()
>>> grad_loss = torch.randn(3)
>>> loss.backward(grad_loss)
>>> weight.grad  # Unnamed for now. Will be named in the future
tensor([-1.8107, -0.6357,  0.0783])

>>> weight.grad.zero_()
>>> grad_loss = grad_loss.refine_names('C')
>>> loss = (x - weight).abs()
# Ideally we'd check that the names of loss and grad_loss match but we don't yet.
>>> loss.backward(grad_loss)
>>> weight.grad
tensor([-1.8107, -0.6357,  0.0783]) 
```

## 当前支持的操作和子系统

### 运算符

查看命名张量运算符覆盖以获取支持的 torch 和张量操作的完整列表。我们尚不支持以下链接未涵盖的内容：

+   索引，高级索引。

对于`torch.nn.functional`运算符，我们支持以下内容：

+   `torch.nn.functional.relu()`

+   `torch.nn.functional.softmax()`

+   `torch.nn.functional.log_softmax()`

+   `torch.nn.functional.tanh()`

+   `torch.nn.functional.sigmoid()`

+   `torch.nn.functional.dropout()`

### 子系统

自动求导是支持的，请参见自动求导支持。因为梯度目前没有名称，优化器可能会工作，但尚未经过测试。

NN 模块目前不受支持。当使用具有命名张量输入的模块时，可能会导致以下情况：

+   NN 模块参数没有名称，因此输出可能部分具有名称。

+   NN 模块的前向传递代码不支持命名张量，并将适当地报错。

我们还不支持以下子系统，尽管其中一些可能可以直接使用：

+   分布

+   序列化（`torch.load()`, `torch.save()`)

+   多进程

+   JIT

+   分布

+   ONNX

如果其中任何一个对您的用例有帮助，请[搜索是否已经提交了问题](https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3A%22module%3A+named+tensor%22)，如果没有，请[提交一个](https://github.com/pytorch/pytorch/issues/new/choose)。

## 命名张量 API 参考

在本节中，请查找命名张量特定 API 的文档。有关如何通过其他 PyTorch 运算符传播名称的全面参考，请参见命名张量运算符覆盖。

```py
class torch.Tensor
```

```py
names
```

为该张量的每个维度存储名称。

`names[idx]` 对应于张量维度`idx`的名称。名称是一个字符串，如果维度有名称，或者是`None`，如果维度没有名称。

维度名称可以包含字符或下划线。此外，维度名称必须是有效的 Python 变量名（即不以下划线开头）。

张量不能具有两个具有相同名称的命名维度。

警告

命名张量 API 是实验性的，可能会发生变化。

```py
rename(*names, **rename_map)
```

重命名`self`的维度名称。

有两种主要用法：

`self.rename(**rename_map)` 返回一个张量视图，其维度按照映射`rename_map`中指定的方式重命名。

`self.rename(*names)` 返回一个张量视图，使用`names`按位置重命名所有维度。使用`self.rename(None)`来删除张量上的名称。

不能同时指定位置参数`names`和关键字参数`rename_map`。

示例：

```py
>>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))
>>> renamed_imgs = imgs.rename(N='batch', C='channels')
>>> renamed_imgs.names
('batch', 'channels', 'H', 'W')

>>> renamed_imgs = imgs.rename(None)
>>> renamed_imgs.names
(None, None, None, None)

>>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')
>>> renamed_imgs.names
('batch', 'channel', 'height', 'width') 
```

警告

命名张量 API 是实验性的，可能会发生变化。

```py
rename_(*names, **rename_map)
```

`rename()`的原地版本。

```py
refine_names(*names)
```

根据`names`细化`self`的维度名称。

细化是重命名的特殊情况，它“提升”了未命名的维度。`None`维度可以细化为任何名称；命名维度只能细化为相同的名称。

因为命名张量可以与未命名张量共存，细化名称提供了一种很好的方法来编写能够同时处理命名和未命名张量的命名张量感知代码。

`names` 可以包含最多一个省略号 (`...`)。省略号会贪婪地扩展；它会就地扩展以填充`names`，使其与`self.dim()`的长度相同，使用来自`self.names`相应索引的名称。

Python 2 不支持省略号，但可以使用字符串文字代替（`'...'`）。

参数

**names** (*iterable* *of* [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.12)")) – 输出张量的期望名称。可能包含最多一个省略号。

示例：

```py
>>> imgs = torch.randn(32, 3, 128, 128)
>>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')
>>> named_imgs.names
('N', 'C', 'H', 'W')

>>> tensor = torch.randn(2, 3, 5, 7, 11)
>>> tensor = tensor.refine_names('A', ..., 'B', 'C')
>>> tensor.names
('A', None, None, 'B', 'C') 
```

警告

命名张量 API 是实验性的，可能会发生变化。

```py
align_as(other) → Tensor
```

将`self`张量的维度重新排列以匹配`other`张量中的维度顺序，在任何新名称中添加大小为一的维度。

此操作对于通过名称进行显式广播很有用（请参见示例）。

`self`的所有维度必须按顺序命名才能使用此方法。结果张量是原始张量的视图。

`self`的所有维度名称必须存在于`other.names`中。`other`可能包含未在`self.names`中的命名维度；输出张量对于每个新名称都有一个大小为一的维度。

要将张量对齐到特定顺序，请使用`align_to()`。

示例：

```py
# Example 1: Applying a mask
>>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')
>>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))
>>> imgs.masked_fill_(mask.align_as(imgs), 0)

# Example 2: Applying a per-channel-scale
>>> def scale_channels(input, scale):
>>>    scale = scale.refine_names('C')
>>>    return input * scale.align_as(input)

>>> num_channels = 3
>>> scale = torch.randn(num_channels, names=('C',))
>>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))
>>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))
>>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))

# scale_channels is agnostic to the dimension order of the input
>>> scale_channels(imgs, scale)
>>> scale_channels(more_imgs, scale)
>>> scale_channels(videos, scale) 
```

警告

命名张量 API 是实验性的，可能会发生变化。

```py
align_to(*names)
```

重新排列`self`张量的维度，以匹配`names`中指定的顺序，在任何新名称中添加大小为一的维度。

`self`的所有维度必须按顺序命名才能使用此方法。结果张量是原始张量的视图。

`self`的所有维度名称必须存在于`names`中。`names`可能包含未在`self.names`中的其他名称；输出张量对于每个新名称都有一个大小为一的维度。

`names` 可以包含最多一个省略号 (`...`)。省略号会扩展为`self`中未在`names`中提到的所有维度名称，按照它们在`self`中出现的顺序。

Python 2 不支持省略号，但可以使用字符串文字代替（`'...'`）。

参数

**names**（*可迭代的* [*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")） - 输出张量的期望维度顺序。可能包含最多一个省略号，该省略号会扩展到`self`未提及的所有维度名称。

示例：

```py
>>> tensor = torch.randn(2, 2, 2, 2, 2, 2)
>>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')

# Move the F and E dims to the front while keeping the rest in order
>>> named_tensor.align_to('F', 'E', ...) 
```

警告

命名张量 API 是实验性的，可能会发生变化。

```py
flatten(dims, out_dim) → Tensor
```

将`dims`展平为具有名称`out_dim`的单个维度。

`self`张量中的所有维度必须按顺序连续，但在内存中不一定连续。

示例：

```py
>>> imgs = torch.randn(32, 3, 128, 128, names=('N', 'C', 'H', 'W'))
>>> flat_imgs = imgs.flatten(['C', 'H', 'W'], 'features')
>>> flat_imgs.names, flat_imgs.shape
(('N', 'features'), torch.Size([32, 49152])) 
```

警告

命名张量 API 是实验性的，可能会发生变化。
