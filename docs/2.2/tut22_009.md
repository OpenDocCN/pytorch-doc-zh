# 转换

> 原文：[`pytorch.org/tutorials/beginner/basics/transforms_tutorial.html`](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html)

注意

点击这里下载完整示例代码

学习基础知识 || 快速入门 || 张量 || 数据集和数据加载器 || **转换** || 构建模型 || 自动求导 || 优化 || 保存和加载模型

数据并不总是以训练机器学习算法所需的最终处理形式出现。我们使用**转换**对数据进行一些处理，使其适合训练。

所有 TorchVision 数据集都有两个参数-`transform`用于修改特征和`target_transform`用于修改标签-接受包含转换逻辑的可调用对象。[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)模块提供了几种常用的转换。

FashionMNIST 的特征以 PIL 图像格式呈现，标签为整数。对于训练，我们需要将特征作为标准化张量，将标签作为独热编码张量。为了进行这些转换，我们使用`ToTensor`和`Lambda`。

```py
import torch
from torchvision import datasets
from torchvision.transforms import [ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor "torchvision.transforms.ToTensor"), [Lambda](https://pytorch.org/vision/stable/generated/torchvision.transforms.Lambda.html#torchvision.transforms.Lambda "torchvision.transforms.Lambda")

[ds](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST "torchvision.datasets.FashionMNIST") = [datasets.FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST "torchvision.datasets.FashionMNIST")(
    root="data",
    train=True,
    download=True,
    transform=[ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor "torchvision.transforms.ToTensor")(),
    [target_transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Lambda.html#torchvision.transforms.Lambda "torchvision.transforms.Lambda")=[Lambda](https://pytorch.org/vision/stable/generated/torchvision.transforms.Lambda.html#torchvision.transforms.Lambda "torchvision.transforms.Lambda")(lambda y: [torch.zeros](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros "torch.zeros")(10, dtype=[torch.float](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype "torch.dtype")).scatter_(0, [torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor "torch.tensor")(y), value=1))
) 
```

```py
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz

  0%|          | 0/26421880 [00:00<?, ?it/s]
  0%|          | 65536/26421880 [00:00<01:12, 365341.60it/s]
  1%|          | 229376/26421880 [00:00<00:38, 686586.92it/s]
  3%|3         | 884736/26421880 [00:00<00:12, 2035271.39it/s]
 10%|#         | 2686976/26421880 [00:00<00:03, 6286060.82it/s]
 21%|##1       | 5603328/26421880 [00:00<00:01, 10565098.33it/s]
 36%|###5      | 9404416/26421880 [00:00<00:00, 17370347.01it/s]
 54%|#####4    | 14319616/26421880 [00:01<00:00, 21721945.28it/s]
 70%|######9   | 18382848/26421880 [00:01<00:00, 26260208.56it/s]
 90%|########9 | 23724032/26421880 [00:01<00:00, 28093598.52it/s]
100%|##########| 26421880/26421880 [00:01<00:00, 19334744.02it/s]
Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz

  0%|          | 0/29515 [00:00<?, ?it/s]
100%|##########| 29515/29515 [00:00<00:00, 329165.55it/s]
Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz

  0%|          | 0/4422102 [00:00<?, ?it/s]
  1%|1         | 65536/4422102 [00:00<00:12, 361576.31it/s]
  5%|5         | 229376/4422102 [00:00<00:06, 680517.35it/s]
 21%|##1       | 950272/4422102 [00:00<00:01, 2183882.82it/s]
 77%|#######7  | 3407872/4422102 [00:00<00:00, 6666873.55it/s]
100%|##########| 4422102/4422102 [00:00<00:00, 6066091.89it/s]
Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz

  0%|          | 0/5148 [00:00<?, ?it/s]
100%|##########| 5148/5148 [00:00<00:00, 41523609.60it/s]
Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw 
```

## ToTensor()

[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)将 PIL 图像或 NumPy `ndarray`转换为`FloatTensor`。并将图像的像素强度值缩放到范围[0., 1.]内。

## Lambda 转换

Lambda 转换应用任何用户定义的 lambda 函数。在这里，我们定义一个函数将整数转换为一个独热编码的张量。它首先创建一个大小为 10 的零张量（数据集中标签的数量），然后调用[scatter_](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html)，该函数根据标签`y`给定的索引分配`value=1`。

```py
[target_transform](https://pytorch.org/vision/stable/generated/torchvision.transforms.Lambda.html#torchvision.transforms.Lambda "torchvision.transforms.Lambda") = [Lambda](https://pytorch.org/vision/stable/generated/torchvision.transforms.Lambda.html#torchvision.transforms.Lambda "torchvision.transforms.Lambda")(lambda y: [torch.zeros](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros "torch.zeros")(
    10, dtype=[torch.float](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype "torch.dtype")).scatter_(dim=0, index=[torch.tensor](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor "torch.tensor")(y), value=1)) 
```

* * *

### 进一步阅读

+   [torchvision.transforms API](https://pytorch.org/vision/stable/transforms.html)

**脚本的总运行时间：**（0 分钟 4.410 秒）

`下载 Python 源代码：transforms_tutorial.py`

`下载 Jupyter 笔记本：transforms_tutorial.ipynb`

[Sphinx-Gallery 生成的画廊](https://sphinx-gallery.github.io)
