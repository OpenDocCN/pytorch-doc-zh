# 使用Ray Tune进行超参数调整

> 原文：[https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)

注意

点击[这里](#sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py)下载完整的示例代码

超参数调整可以使普通模型和高度准确的模型之间产生巨大差异。通常简单的事情，比如选择不同的学习率或改变网络层大小，都可以对模型性能产生显著影响。

幸运的是，有一些工具可以帮助找到最佳参数组合。[Ray Tune](https://docs.ray.io/en/latest/tune.html)是一个行业标准的分布式超参数调整工具。Ray Tune包括最新的超参数搜索算法，与TensorBoard和其他分析库集成，并通过[Ray的分布式机器学习引擎](https://ray.io/)原生支持分布式训练。

在本教程中，我们将向您展示如何将Ray Tune集成到PyTorch训练工作流程中。我们将扩展[来自PyTorch文档的这个教程](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)，用于训练CIFAR10图像分类器。

正如您将看到的，我们只需要添加一些轻微的修改。特别是，我们需要

1.  将数据加载和训练封装在函数中，

1.  使一些网络参数可配置，

1.  添加检查点（可选），

1.  并定义模型调优的搜索空间

要运行此教程，请确保安装了以下软件包：

+   `ray[tune]`：分布式超参数调整库

+   `torchvision`：用于数据转换器

## 设置/导入

让我们从导入开始：

```py
from functools import partial
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split "torch.utils.data.random_split")
import torchvision
import torchvision.transforms as transforms
from ray import tune
from ray.air import Checkpoint, session
from ray.tune.schedulers import ASHAScheduler 
```

大部分导入都是用于构建PyTorch模型。只有最后三个导入是为了Ray Tune。

## 数据加载器

我们将数据加载器封装在自己的函数中，并传递一个全局数据目录。这样我们可以在不同的试验之间共享一个数据目录。

```py
def load_data(data_dir="./data"):
    transform = [transforms.Compose](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose "torchvision.transforms.Compose")(
        [[transforms.ToTensor](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor "torchvision.transforms.ToTensor")(), [transforms.Normalize](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize "torchvision.transforms.Normalize")((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
    )

    trainset = [torchvision.datasets.CIFAR10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10 "torchvision.datasets.CIFAR10")(
        root=data_dir, train=True, download=True, transform=transform
    )

    testset = [torchvision.datasets.CIFAR10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10 "torchvision.datasets.CIFAR10")(
        root=data_dir, train=False, download=True, transform=transform
    )

    return trainset, testset 
```

## 可配置的神经网络

我们只能调整可配置的参数。在这个例子中，我们可以指定全连接层的层大小：

```py
class Net([nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")):
    def __init__(self, l1=120, l2=84):
        super([Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module"), self).__init__()
        self.conv1 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(3, 6, 5)
        self.pool = [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d "torch.nn.MaxPool2d")(2, 2)
        self.conv2 = [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d "torch.nn.Conv2d")(6, 16, 5)
        self.fc1 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear "torch.nn.Linear")(16 * 5 * 5, l1)
        self.fc2 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear "torch.nn.Linear")(l1, l2)
        self.fc3 = [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear "torch.nn.Linear")(l2, 10)

    def forward(self, x):
        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu "torch.nn.functional.relu")(self.conv1(x)))
        x = self.pool([F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu "torch.nn.functional.relu")(self.conv2(x)))
        x = [torch.flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten "torch.flatten")(x, 1)  # flatten all dimensions except batch
        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu "torch.nn.functional.relu")(self.fc1(x))
        x = [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu "torch.nn.functional.relu")(self.fc2(x))
        x = self.fc3(x)
        return x 
```

## 训练函数

现在变得有趣了，因为我们对示例进行了一些更改[来自PyTorch文档](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)。

我们将训练脚本封装在一个函数`train_cifar(config, data_dir=None)`中。`config`参数将接收我们想要训练的超参数。`data_dir`指定我们加载和存储数据的目录，以便多次运行可以共享相同的数据源。如果提供了检查点，我们还会在运行开始时加载模型和优化器状态。在本教程的后面部分，您将找到有关如何保存检查点以及它的用途的信息。

```py
net = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")(config["l1"], config["l2"])

checkpoint = session.get_checkpoint()

if checkpoint:
    checkpoint_state = checkpoint.to_dict()
    start_epoch = checkpoint_state["epoch"]
    net.load_state_dict(checkpoint_state["net_state_dict"])
    optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
else:
    start_epoch = 0 
```

优化器的学习率也是可配置的：

```py
optimizer = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD "torch.optim.SGD")(net.parameters(), lr=config["lr"], momentum=0.9) 
```

我们还将训练数据分成训练集和验证集。因此，我们在80%的数据上进行训练，并在剩余的20%上计算验证损失。我们可以配置通过训练和测试集的批处理大小。

### 使用DataParallel添加（多）GPU支持

图像分类在很大程度上受益于GPU。幸运的是，我们可以继续在Ray Tune中使用PyTorch的抽象。因此，我们可以将我们的模型包装在`nn.DataParallel`中，以支持在多个GPU上进行数据并行训练：

```py
device = "cpu"
if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available")():
    device = "cuda:0"
    if [torch.cuda.device_count](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count "torch.cuda.device_count")() > 1:
        net = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel "torch.nn.DataParallel")(net)
net.to(device) 
```

通过使用`device`变量，我们确保在没有GPU可用时训练也能正常进行。PyTorch要求我们明确将数据发送到GPU内存，就像这样：

```py
for i, data in enumerate(trainloader, 0):
    inputs, labels = data
    inputs, labels = inputs.to(device), labels.to(device) 
```

现在的代码支持在CPU上、单个GPU上和多个GPU上进行训练。值得注意的是，Ray还支持[分数GPU](https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus)，因此我们可以在试验之间共享GPU，只要模型仍适合GPU内存。我们稍后会回到这个问题。

### 与Ray Tune通信

最有趣的部分是与Ray Tune的通信：

```py
checkpoint_data = {
    "epoch": epoch,
    "net_state_dict": net.state_dict(),
    "optimizer_state_dict": optimizer.state_dict(),
}
checkpoint = Checkpoint.from_dict(checkpoint_data)

session.report(
    {"loss": val_loss / val_steps, "accuracy": correct / total},
    checkpoint=checkpoint,
) 
```

在这里，我们首先保存一个检查点，然后将一些指标报告给Ray Tune。具体来说，我们将验证损失和准确率发送回Ray Tune。然后，Ray Tune可以使用这些指标来决定哪种超参数配置会产生最佳结果。这些指标也可以用来及早停止表现不佳的试验，以避免浪费资源在这些试验上。

检查点保存是可选的，但是如果我们想要使用高级调度程序（如[基于种群的训练](https://docs.ray.io/en/latest/tune/examples/pbt_guide.html)），则是必要的。此外，通过保存检查点，我们可以稍后加载训练好的模型并在测试集上验证。最后，保存检查点对于容错性很有用，它允许我们中断训练并稍后继续训练。

### 完整的训练函数

完整的代码示例如下：

```py
def train_cifar(config, data_dir=None):
    net = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")(config["l1"], config["l2"])

    device = "cpu"
    if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available")():
        device = "cuda:0"
        if [torch.cuda.device_count](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count "torch.cuda.device_count")() > 1:
            net = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel "torch.nn.DataParallel")(net)
    net.to(device)

    criterion = [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss "torch.nn.CrossEntropyLoss")()
    optimizer = [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD "torch.optim.SGD")(net.parameters(), lr=config["lr"], momentum=0.9)

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

    trainset, testset = load_data(data_dir)

    test_abs = int(len(trainset) * 0.8)
    train_subset, val_subset = [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split "torch.utils.data.random_split")(
        trainset, [test_abs, len(trainset) - test_abs]
    )

    trainloader = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader")(
        train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
    )
    valloader = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader")(
        val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
    )

    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
        running_loss = 0.0
        epoch_steps = 0
        for i, data in enumerate(trainloader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward + backward + optimize
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            epoch_steps += 1
            if i % 2000 == 1999:  # print every 2000 mini-batches
                print(
                    "[%d, %5d] loss: %.3f"
                    % (epoch + 1, i + 1, running_loss / epoch_steps)
                )
                running_loss = 0.0

        # Validation loss
        val_loss = 0.0
        val_steps = 0
        total = 0
        correct = 0
        for i, data in enumerate(valloader, 0):
            with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad "torch.no_grad")():
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = net(inputs)
                _, predicted = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max "torch.max")(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                loss = criterion(outputs, labels)
                val_loss += loss.cpu().numpy()
                val_steps += 1

        checkpoint_data = {
            "epoch": epoch,
            "net_state_dict": net.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
        }
        checkpoint = Checkpoint.from_dict(checkpoint_data)

        session.report(
            {"loss": val_loss / val_steps, "accuracy": correct / total},
            checkpoint=checkpoint,
        )
    print("Finished Training") 
```

正如您所看到的，大部分代码直接从原始示例中适应而来。

## 测试集准确率

通常，机器学习模型的性能是在一个保留的测试集上测试的，该测试集包含未用于训练模型的数据。我们也将这包装在一个函数中：

```py
def test_accuracy(net, device="cpu"):
    trainset, testset = load_data()

    testloader = [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "torch.utils.data.DataLoader")(
        testset, batch_size=4, shuffle=False, num_workers=2
    )

    correct = 0
    total = 0
    with [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad "torch.no_grad")():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max "torch.max")(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    return correct / total 
```

该函数还期望一个`device`参数，因此我们可以在GPU上对测试集进行验证。

## 配置搜索空间

最后，我们需要定义Ray Tune的搜索空间。这是一个示例：

```py
config = {
    "l1": tune.choice([2 ** i for i in range(9)]),
    "l2": tune.choice([2 ** i for i in range(9)]),
    "lr": tune.loguniform(1e-4, 1e-1),
    "batch_size": tune.choice([2, 4, 8, 16])
} 
```

`tune.choice()`接受一个从中均匀抽样的值列表。在这个例子中，`l1`和`l2`参数应该是介于4和256之间的2的幂次方，因此可以是4、8、16、32、64、128或256。`lr`（学习率）应该在0.0001和0.1之间均匀抽样。最后，批量大小是2、4、8和16之间的选择。

在每次试验中，Ray Tune现在将从这些搜索空间中随机抽样一组参数的组合。然后，它将并行训练多个模型，并在其中找到表现最佳的模型。我们还使用`ASHAScheduler`，它将及早终止表现不佳的试验。

我们使用`functools.partial`将`train_cifar`函数包装起来，以设置常量`data_dir`参数。我们还可以告诉Ray Tune每个试验应该有哪些资源可用：

```py
gpus_per_trial = 2
# ...
result = tune.run(
    partial(train_cifar, data_dir=data_dir),
    resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
    config=config,
    num_samples=num_samples,
    scheduler=scheduler,
    checkpoint_at_end=True) 
```

您可以指定CPU的数量，然后可以将其用于增加PyTorch `DataLoader`实例的`num_workers`。所选数量的GPU在每个试验中对PyTorch可见。试验没有访问未为其请求的GPU - 因此您不必担心两个试验使用相同的资源集。

在这里，我们还可以指定分数GPU，因此像`gpus_per_trial=0.5`这样的东西是完全有效的。试验将在彼此之间共享GPU。您只需确保模型仍适合GPU内存。

训练模型后，我们将找到表现最佳的模型，并从检查点文件中加载训练好的网络。然后，我们获得测试集准确率，并通过打印报告所有内容。

完整的主函数如下：

```py
def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
    data_dir = os.path.abspath("./data")
    load_data(data_dir)
    config = {
        "l1": tune.choice([2**i for i in range(9)]),
        "l2": tune.choice([2**i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16]),
    }
    scheduler = ASHAScheduler(
        metric="loss",
        mode="min",
        max_t=max_num_epochs,
        grace_period=1,
        reduction_factor=2,
    )
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
    )

    best_trial = result.get_best_trial("loss", "min", "last")
    print(f"Best trial config: {best_trial.config}")
    print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
    print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

    best_trained_model = [Net](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module "torch.nn.Module")(best_trial.config["l1"], best_trial.config["l2"])
    device = "cpu"
    if [torch.cuda.is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available "torch.cuda.is_available")():
        device = "cuda:0"
        if gpus_per_trial > 1:
            best_trained_model = [nn.DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel "torch.nn.DataParallel")(best_trained_model)
    best_trained_model.to(device)

    best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
    best_checkpoint_data = best_checkpoint.to_dict()

    best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

    test_acc = test_accuracy(best_trained_model, device)
    print("Best trial test set accuracy: {}".format(test_acc))

if __name__ == "__main__":
    # You can change the number of GPUs per trial here:
    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0) 
```

```py
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

  0% 0/170498071 [00:00<?, ?it/s]
  0% 491520/170498071 [00:00<00:34, 4901426.98it/s]
  4% 7307264/170498071 [00:00<00:03, 42047898.29it/s]
 10% 17629184/170498071 [00:00<00:02, 69798204.67it/s]
 16% 27820032/170498071 [00:00<00:01, 82407622.17it/s]
 22% 38338560/170498071 [00:00<00:01, 90604441.34it/s]
 29% 48726016/170498071 [00:00<00:01, 95049915.99it/s]
 35% 59342848/170498071 [00:00<00:01, 98624828.60it/s]
 41% 69828608/170498071 [00:00<00:01, 100103452.88it/s]
 47% 80707584/170498071 [00:00<00:00, 102701251.79it/s]
 54% 91226112/170498071 [00:01<00:00, 103410219.64it/s]
 60% 101842944/170498071 [00:01<00:00, 104217418.28it/s]
 66% 112394240/170498071 [00:01<00:00, 104577303.94it/s]
 72% 122912768/170498071 [00:01<00:00, 104690232.44it/s]
 78% 133464064/170498071 [00:01<00:00, 104835011.32it/s]
 84% 144015360/170498071 [00:01<00:00, 104975230.73it/s]
 91% 154566656/170498071 [00:01<00:00, 105068640.23it/s]
 97% 165085184/170498071 [00:01<00:00, 104644047.95it/s]
100% 170498071/170498071 [00:01<00:00, 96529746.41it/s]
Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
Files already downloaded and verified
2024-02-03 05:16:34,052 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147479552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
2024-02-03 05:16:34,193 INFO worker.py:1625 -- Started a local Ray instance.
2024-02-03 05:16:35,349 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
(pid=2669) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
(pid=2669)   _torch_pytree._register_pytree_node(
== Status ==
Current time: 2024-02-03 05:16:40 (running for 00:00:05.27)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (9 PENDING, 1 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | PENDING  |                 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | PENDING  |                 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | PENDING  |                 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | PENDING  |                 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | PENDING  |                 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | PENDING  |                 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

(func pid=2669) Files already downloaded and verified
(func pid=2669) Files already downloaded and verified
(pid=2758)   _torch_pytree._register_pytree_node(
(pid=2758)   _torch_pytree._register_pytree_node(
(pid=2765) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
(pid=2765)   _torch_pytree._register_pytree_node(
== Status ==
Current time: 2024-02-03 05:16:46 (running for 00:00:11.10)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 PENDING, 7 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | PENDING  |                 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

(func pid=2756) Files already downloaded and verified
(func pid=2765) Files already downloaded and verified
(pid=3549) /opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead. [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
(pid=3549)   _torch_pytree._register_pytree_node( [repeated 5x across cluster]
(func pid=2669) [1,  2000] loss: 2.332
(func pid=2758) Files already downloaded and verified [repeated 10x across cluster]
== Status ==
Current time: 2024-02-03 05:16:53 (running for 00:00:18.39)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

== Status ==
Current time: 2024-02-03 05:16:58 (running for 00:00:23.40)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

(func pid=2756) [1,  2000] loss: 2.311
(func pid=3549) Files already downloaded and verified [repeated 2x across cluster]
(func pid=2764) [1,  2000] loss: 2.303
== Status ==
Current time: 2024-02-03 05:17:03 (running for 00:00:28.41)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

== Status ==
Current time: 2024-02-03 05:17:08 (running for 00:00:33.42)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

(func pid=3549) [1,  2000] loss: 1.855 [repeated 6x across cluster]
== Status ==
Current time: 2024-02-03 05:17:13 (running for 00:00:38.43)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

(func pid=2760) [1,  4000] loss: 1.031 [repeated 7x across cluster]
== Status ==
Current time: 2024-02-03 05:17:18 (running for 00:00:43.44)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

== Status ==
Current time: 2024-02-03 05:17:23 (running for 00:00:48.45)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

(func pid=2756) [1,  6000] loss: 0.770
(func pid=2764) [1,  6000] loss: 0.681
== Status ==
Current time: 2024-02-03 05:17:28 (running for 00:00:53.46)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
|-------------------------+----------+-----------------+--------------+------+------+-------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |
+-------------------------+----------+-----------------+--------------+------+------+-------------+

Result for train_cifar_668d1_00006:
  accuracy: 0.1208
  date: 2024-02-03_05-17-29
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.293956341743469
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 43.53398323059082
  time_this_iter_s: 43.53398323059082
  time_total_s: 43.53398323059082
  timestamp: 1706937449
  training_iteration: 1
  trial_id: 668d1_00006

Result for train_cifar_668d1_00003:
  accuracy: 0.2079
  date: 2024-02-03_05-17-31
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.028138545417786
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 45.46037745475769
  time_this_iter_s: 45.46037745475769
  time_total_s: 45.46037745475769
  timestamp: 1706937451
  training_iteration: 1
  trial_id: 668d1_00003

(func pid=2669) [1, 10000] loss: 0.461 [repeated 5x across cluster]
== Status ==
Current time: 2024-02-03 05:17:37 (running for 00:01:01.57)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |        |                  |         |            |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00007:
  accuracy: 0.4793
  date: 2024-02-03_05-17-40
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 1.4310961763858796
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 46.97845983505249
  time_this_iter_s: 46.97845983505249
  time_total_s: 46.97845983505249
  timestamp: 1706937460
  training_iteration: 1
  trial_id: 668d1_00007

(func pid=2758) [1,  8000] loss: 0.575 [repeated 4x across cluster]
== Status ==
Current time: 2024-02-03 05:17:45 (running for 00:01:10.40)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.028138545417786
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2762) [1, 10000] loss: 0.468 [repeated 6x across cluster]
== Status ==
Current time: 2024-02-03 05:17:50 (running for 00:01:15.41)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.028138545417786
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:17:55 (running for 00:01:20.42)
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.028138545417786
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 PENDING, 8 RUNNING)
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING  | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00001 | RUNNING  | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING  | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING  | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00004 | RUNNING  | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |        |                  |         |            |
| train_cifar_668d1_00005 | RUNNING  | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |        |                  |         |            |
| train_cifar_668d1_00006 | RUNNING  | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |
| train_cifar_668d1_00007 | RUNNING  | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | PENDING  |                 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | PENDING  |                 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
+-------------------------+----------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [2,  2000] loss: 1.406
(func pid=2669) [1, 14000] loss: 0.329
Result for train_cifar_668d1_00001:
  accuracy: 0.1009
  date: 2024-02-03_05-17-58
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.3118444224357604
  node_ip: 172.17.0.2
  pid: 2756
  should_checkpoint: true
  time_since_restore: 72.15020895004272
  time_this_iter_s: 72.15020895004272
  time_total_s: 72.15020895004272
  timestamp: 1706937478
  training_iteration: 1
  trial_id: 668d1_00001

Trial train_cifar_668d1_00001 completed.
Result for train_cifar_668d1_00005:
  accuracy: 0.3539
  date: 2024-02-03_05-17-58
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 1.7180780637741089
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 72.5149827003479
  time_this_iter_s: 72.5149827003479
  time_total_s: 72.5149827003479
  timestamp: 1706937478
  training_iteration: 1
  trial_id: 668d1_00005

(func pid=2756) Files already downloaded and verified
Result for train_cifar_668d1_00004:
  accuracy: 0.1042
  date: 2024-02-03_05-17-59
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.317199463367462
  node_ip: 172.17.0.2
  pid: 2762
  should_checkpoint: true
  time_since_restore: 73.49483036994934
  time_this_iter_s: 73.49483036994934
  time_total_s: 73.49483036994934
  timestamp: 1706937479
  training_iteration: 1
  trial_id: 668d1_00004

Trial train_cifar_668d1_00004 completed.
(func pid=2756) Files already downloaded and verified
== Status ==
Current time: 2024-02-03 05:18:04 (running for 00:01:29.51)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2669) [1, 16000] loss: 0.288 [repeated 4x across cluster]
(func pid=2762) Files already downloaded and verified [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:18:09 (running for 00:01:34.53)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      1 |          43.534  | 2.29396 |     0.1208 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00006:
  accuracy: 0.1824
  date: 2024-02-03_05-18-11
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 2
  loss: 2.1994362588882446
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 84.67864155769348
  time_this_iter_s: 41.14465832710266
  time_total_s: 84.67864155769348
  timestamp: 1706937491
  training_iteration: 2
  trial_id: 668d1_00006

(func pid=2756) [1,  2000] loss: 2.138 [repeated 5x across cluster]
== Status ==
Current time: 2024-02-03 05:18:16 (running for 00:01:40.64)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.1994362588882446 | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      1 |          45.4604 | 2.02814 |     0.2079 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00003:
  accuracy: 0.2459
  date: 2024-02-03_05-18-16
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 2
  loss: 1.9869435796737671
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 90.14830899238586
  time_this_iter_s: 44.687931537628174
  time_total_s: 90.14830899238586
  timestamp: 1706937496
  training_iteration: 2
  trial_id: 668d1_00003

== Status ==
Current time: 2024-02-03 05:18:21 (running for 00:01:46.25)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0931899192810057 | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      1 |          46.9785 | 1.4311  |     0.4793 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [2,  4000] loss: 0.814 [repeated 2x across cluster]
Result for train_cifar_668d1_00007:
  accuracy: 0.5056
  date: 2024-02-03_05-18-25
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 2
  loss: 1.4163358207702637
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 91.53078818321228
  time_this_iter_s: 44.55232834815979
  time_total_s: 91.53078818321228
  timestamp: 1706937505
  training_iteration: 2
  trial_id: 668d1_00007

(func pid=2758) [1, 14000] loss: 0.310 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:18:30 (running for 00:01:54.95)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:18:35 (running for 00:01:59.96)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2762) [1,  6000] loss: 0.779 [repeated 4x across cluster]
== Status ==
Current time: 2024-02-03 05:18:40 (running for 00:02:04.97)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [3,  2000] loss: 1.268 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:18:45 (running for 00:02:09.98)
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.1610474435806273
Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | RUNNING    | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |        |                  |         |            |
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      2 |          84.6786 | 2.19944 |     0.1824 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |        |                  |         |            |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00008:
  accuracy: 0.2278
  date: 2024-02-03_05-18-45
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.150844239425659
  node_ip: 172.17.0.2
  pid: 2756
  should_checkpoint: true
  time_since_restore: 47.30649995803833
  time_this_iter_s: 47.30649995803833
  time_total_s: 47.30649995803833
  timestamp: 1706937525
  training_iteration: 1
  trial_id: 668d1_00008

(func pid=2762) [1,  8000] loss: 0.585 [repeated 2x across cluster]
Result for train_cifar_668d1_00000:
  accuracy: 0.0961
  date: 2024-02-03_05-18-48
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.3129488151073456
  node_ip: 172.17.0.2
  pid: 2669
  should_checkpoint: true
  time_since_restore: 127.89715909957886
  time_this_iter_s: 127.89715909957886
  time_total_s: 127.89715909957886
  timestamp: 1706937528
  training_iteration: 1
  trial_id: 668d1_00000

Trial train_cifar_668d1_00000 completed.
Result for train_cifar_668d1_00006:
  accuracy: 0.2072
  date: 2024-02-03_05-18-51
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 3
  loss: 2.098891372299194
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 125.34813141822815
  time_this_iter_s: 40.66948986053467
  time_total_s: 125.34813141822815
  timestamp: 1706937531
  training_iteration: 3
  trial_id: 668d1_00006

== Status ==
Current time: 2024-02-03 05:18:51 (running for 00:02:16.30)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [3,  4000] loss: 0.627 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:18:56 (running for 00:02:21.31)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      2 |          90.1483 | 1.98694 |     0.2459 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00003:
  accuracy: 0.2298
  date: 2024-02-03_05-19-00
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 3
  loss: 2.000217504119873
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 133.78930187225342
  time_this_iter_s: 43.640992879867554
  time_total_s: 133.78930187225342
  timestamp: 1706937540
  training_iteration: 3
  trial_id: 668d1_00003

(func pid=2756) [2,  2000] loss: 2.167 [repeated 4x across cluster]
== Status ==
Current time: 2024-02-03 05:19:05 (running for 00:02:29.90)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      1 |          72.515  | 1.71808 |     0.3539 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      2 |          91.5308 | 1.41634 |     0.5056 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2762) [1, 12000] loss: 0.389 [repeated 2x across cluster]
Result for train_cifar_668d1_00005:
  accuracy: 0.4677
  date: 2024-02-03_05-19-08
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 2
  loss: 1.4615094123959542
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 141.90429210662842
  time_this_iter_s: 69.38930940628052
  time_total_s: 141.90429210662842
  timestamp: 1706937548
  training_iteration: 2
  trial_id: 668d1_00005

Result for train_cifar_668d1_00007:
  accuracy: 0.5436
  date: 2024-02-03_05-19-08
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 3
  loss: 1.3132171389341354
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 134.65492868423462
  time_this_iter_s: 43.12414050102234
  time_total_s: 134.65492868423462
  timestamp: 1706937548
  training_iteration: 3
  trial_id: 668d1_00007

== Status ==
Current time: 2024-02-03 05:19:13 (running for 00:02:38.06)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2758) [1, 20000] loss: 0.213
(func pid=2760) [4,  2000] loss: 2.060
== Status ==
Current time: 2024-02-03 05:19:18 (running for 00:02:43.08)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [4,  2000] loss: 1.165 [repeated 5x across cluster]
== Status ==
Current time: 2024-02-03 05:19:23 (running for 00:02:48.09)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:19:28 (running for 00:02:53.10)
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.7242264960348606 | Iter 1.000: -2.222400290584564
Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |        |                  |         |            |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      3 |         125.348  | 2.09889 |     0.2072 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |
| train_cifar_668d1_00008 | RUNNING    | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      1 |          47.3065 | 2.15084 |     0.2278 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2762) [1, 16000] loss: 0.292
(func pid=2760) [4,  4000] loss: 1.015
Result for train_cifar_668d1_00006:
  accuracy: 0.2527
  date: 2024-02-03_05-19-30
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 4
  loss: 1.9832857732772826
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 164.49138188362122
  time_this_iter_s: 39.143250465393066
  time_total_s: 164.49138188362122
  timestamp: 1706937570
  training_iteration: 4
  trial_id: 668d1_00006

Result for train_cifar_668d1_00002:
  accuracy: 0.2024
  date: 2024-02-03_05-19-31
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.10914013671875
  node_ip: 172.17.0.2
  pid: 2758
  should_checkpoint: true
  time_since_restore: 164.5055296421051
  time_this_iter_s: 164.5055296421051
  time_total_s: 164.5055296421051
  timestamp: 1706937571
  training_iteration: 1
  trial_id: 668d1_00002

Result for train_cifar_668d1_00008:
  accuracy: 0.1979
  date: 2024-02-03_05-19-32
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 2
  loss: 2.0927836849212644
  node_ip: 172.17.0.2
  pid: 2756
  should_checkpoint: true
  time_since_restore: 93.59351873397827
  time_this_iter_s: 46.28701877593994
  time_total_s: 93.59351873397827
  timestamp: 1706937572
  training_iteration: 2
  trial_id: 668d1_00008

Trial train_cifar_668d1_00008 completed.
== Status ==
Current time: 2024-02-03 05:19:37 (running for 00:03:01.79)
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9832857732772826 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659
Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      3 |         133.789  | 2.00022 |     0.2298 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [4,  4000] loss: 0.594 [repeated 2x across cluster]
Result for train_cifar_668d1_00003:
  accuracy: 0.2432
  date: 2024-02-03_05-19-42
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 4
  loss: 1.9813426310539246
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 175.52458882331848
  time_this_iter_s: 41.73528695106506
  time_total_s: 175.52458882331848
  timestamp: 1706937582
  training_iteration: 4
  trial_id: 668d1_00003

(func pid=2764) [3,  6000] loss: 0.479 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:19:47 (running for 00:03:11.64)
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9823142021656035 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659
Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      3 |         134.655  | 1.31322 |     0.5436 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2762) [1, 20000] loss: 0.234 [repeated 3x across cluster]
Result for train_cifar_668d1_00007:
  accuracy: 0.5489
  date: 2024-02-03_05-19-49
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 4
  loss: 1.3539480135917663
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 175.67858505249023
  time_this_iter_s: 41.023656368255615
  time_total_s: 175.67858505249023
  timestamp: 1706937589
  training_iteration: 4
  trial_id: 668d1_00007

== Status ==
Current time: 2024-02-03 05:19:54 (running for 00:03:19.09)
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659
Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2760) [5,  2000] loss: 2.053 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:19:59 (running for 00:03:24.10)
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659
Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [5,  2000] loss: 1.101 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:20:04 (running for 00:03:29.11)
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.150844239425659
Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      2 |         141.904  | 1.46151 |     0.4677 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      4 |         164.491  | 1.98329 |     0.2527 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |
| train_cifar_668d1_00009 | RUNNING    | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |        |                  |         |            |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00009:
  accuracy: 0.1016
  date: 2024-02-03_05-20-04
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 1
  loss: 2.3339982474803924
  node_ip: 172.17.0.2
  pid: 2762
  should_checkpoint: true
  time_since_restore: 124.63368916511536
  time_this_iter_s: 124.63368916511536
  time_total_s: 124.63368916511536
  timestamp: 1706937604
  training_iteration: 1
  trial_id: 668d1_00009

Trial train_cifar_668d1_00009 completed.
Result for train_cifar_668d1_00006:
  accuracy: 0.2585
  date: 2024-02-03_05-20-07
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 5
  loss: 1.8845026599884034
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 200.95251536369324
  time_this_iter_s: 36.46113348007202
  time_total_s: 200.95251536369324
  timestamp: 1706937607
  training_iteration: 5
  trial_id: 668d1_00006

(func pid=2760) [5,  4000] loss: 1.015 [repeated 2x across cluster]
Result for train_cifar_668d1_00005:
  accuracy: 0.494
  date: 2024-02-03_05-20-12
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 3
  loss: 1.3753272988915444
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 205.61224055290222
  time_this_iter_s: 63.707948446273804
  time_total_s: 205.61224055290222
  timestamp: 1706937612
  training_iteration: 3
  trial_id: 668d1_00005

== Status ==
Current time: 2024-02-03 05:20:12 (running for 00:03:36.62)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [5,  4000] loss: 0.562 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:20:17 (running for 00:03:41.64)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      4 |         175.525  | 1.98134 |     0.2432 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00003:
  accuracy: 0.2346
  date: 2024-02-03_05-20-21
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 5
  loss: 2.0240508323669433
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 214.7431402206421
  time_this_iter_s: 39.21855139732361
  time_total_s: 214.7431402206421
  timestamp: 1706937621
  training_iteration: 5
  trial_id: 668d1_00003

(func pid=2764) [4,  2000] loss: 1.377 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:20:26 (running for 00:03:50.84)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      4 |         175.679  | 1.35395 |     0.5489 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00007:
  accuracy: 0.5797
  date: 2024-02-03_05-20-27
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 5
  loss: 1.2155838934659957
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 213.9574224948883
  time_this_iter_s: 38.27883744239807
  time_total_s: 213.9574224948883
  timestamp: 1706937627
  training_iteration: 5
  trial_id: 668d1_00007

(func pid=2765) [6,  4000] loss: 0.918 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:20:32 (running for 00:03:57.37)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:20:37 (running for 00:04:02.38)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      5 |         200.953  | 1.8845  |     0.2585 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2758) [2, 10000] loss: 0.464 [repeated 3x across cluster]
Result for train_cifar_668d1_00006:
  accuracy: 0.2804
  date: 2024-02-03_05-20-42
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 6
  loss: 1.8407883693695068
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 235.6918430328369
  time_this_iter_s: 34.73932766914368
  time_total_s: 235.6918430328369
  timestamp: 1706937642
  training_iteration: 6
  trial_id: 668d1_00006

== Status ==
Current time: 2024-02-03 05:20:47 (running for 00:04:11.64)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2760) [6,  4000] loss: 1.016 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:20:52 (running for 00:04:16.65)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [4,  8000] loss: 0.331
(func pid=2765) [7,  2000] loss: 1.810
== Status ==
Current time: 2024-02-03 05:20:57 (running for 00:04:21.66)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      5 |         214.743  | 2.02405 |     0.2346 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00003:
  accuracy: 0.2534
  date: 2024-02-03_05-20-59
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 6
  loss: 1.9832046443939209
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 252.8883557319641
  time_this_iter_s: 38.14521551132202
  time_total_s: 252.8883557319641
  timestamp: 1706937659
  training_iteration: 6
  trial_id: 668d1_00003

(func pid=2764) [4, 10000] loss: 0.264 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:21:04 (running for 00:04:29.00)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      5 |         213.957  | 1.21558 |     0.5797 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00007:
  accuracy: 0.5712
  date: 2024-02-03_05-21-05
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 6
  loss: 1.256609897506237
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 251.51965427398682
  time_this_iter_s: 37.56223177909851
  time_total_s: 251.51965427398682
  timestamp: 1706937665
  training_iteration: 6
  trial_id: 668d1_00007

== Status ==
Current time: 2024-02-03 05:21:10 (running for 00:04:34.92)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9813426310539246 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      3 |         205.612  | 1.37533 |     0.494  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00005:
  accuracy: 0.5231
  date: 2024-02-03_05-21-11
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 4
  loss: 1.296015057128668
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 264.93886256217957
  time_this_iter_s: 59.326622009277344
  time_total_s: 264.93886256217957
  timestamp: 1706937671
  training_iteration: 4
  trial_id: 668d1_00005

(func pid=2760) [7,  2000] loss: 2.025 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:21:16 (running for 00:04:40.96)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      6 |         235.692  | 1.84079 |     0.2804 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00006:
  accuracy: 0.2967
  date: 2024-02-03_05-21-16
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 7
  loss: 1.792528931903839
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 270.1484785079956
  time_this_iter_s: 34.45663547515869
  time_total_s: 270.1484785079956
  timestamp: 1706937676
  training_iteration: 7
  trial_id: 668d1_00006

(func pid=3549) [7,  2000] loss: 0.982
== Status ==
Current time: 2024-02-03 05:21:21 (running for 00:04:46.10)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2758) [2, 16000] loss: 0.265
== Status ==
Current time: 2024-02-03 05:21:26 (running for 00:04:51.11)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2765) [8,  2000] loss: 1.780 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:21:31 (running for 00:04:56.12)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2758) [2, 18000] loss: 0.242 [repeated 3x across cluster]
== Status ==
Current time: 2024-02-03 05:21:36 (running for 00:05:01.13)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      6 |         252.888  | 1.9832  |     0.2534 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      6 |         251.52   | 1.25661 |     0.5712 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00003:
  accuracy: 0.2295
  date: 2024-02-03_05-21-37
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 7
  loss: 2.0266551568984985
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 291.2936282157898
  time_this_iter_s: 38.405272483825684
  time_total_s: 291.2936282157898
  timestamp: 1706937697
  training_iteration: 7
  trial_id: 668d1_00003

(func pid=2765) [8,  4000] loss: 0.883
(func pid=2764) [5,  6000] loss: 0.421
Result for train_cifar_668d1_00007:
  accuracy: 0.5504
  date: 2024-02-03_05-21-42
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 7
  loss: 1.3819816076278686
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 288.94591212272644
  time_this_iter_s: 37.426257848739624
  time_total_s: 288.94591212272644
  timestamp: 1706937702
  training_iteration: 7
  trial_id: 668d1_00007

== Status ==
Current time: 2024-02-03 05:21:42 (running for 00:05:07.34)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:21:47 (running for 00:05:12.36)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      7 |         270.148  | 1.79253 |     0.2967 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2758) [2, 20000] loss: 0.216
Result for train_cifar_668d1_00006:
  accuracy: 0.2982
  date: 2024-02-03_05-21-51
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 8
  loss: 1.7897322436332703
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 304.81253695487976
  time_this_iter_s: 34.664058446884155
  time_total_s: 304.81253695487976
  timestamp: 1706937711
  training_iteration: 8
  trial_id: 668d1_00006

(func pid=2760) [8,  2000] loss: 2.023
== Status ==
Current time: 2024-02-03 05:21:56 (running for 00:05:20.76)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:22:01 (running for 00:05:25.77)
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -1.9869435796737671 | Iter 1.000: -2.222400290584564
Logical resource usage: 10.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00002 | RUNNING    | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      1 |         164.506  | 2.10914 |     0.2024 |
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [5, 10000] loss: 0.254 [repeated 3x across cluster]
Result for train_cifar_668d1_00002:
  accuracy: 0.1941
  date: 2024-02-03_05-22-03
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 2
  loss: 2.08221128718853
  node_ip: 172.17.0.2
  pid: 2758
  should_checkpoint: true
  time_since_restore: 317.1054368019104
  time_this_iter_s: 152.5999071598053
  time_total_s: 317.1054368019104
  timestamp: 1706937723
  training_iteration: 2
  trial_id: 668d1_00002

Trial train_cifar_668d1_00002 completed.
== Status ==
Current time: 2024-02-03 05:22:08 (running for 00:05:33.23)
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      4 |         264.939  | 1.29602 |     0.5231 |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [8,  4000] loss: 0.510 [repeated 3x across cluster]
Result for train_cifar_668d1_00005:
  accuracy: 0.529
  date: 2024-02-03_05-22-10
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 5
  loss: 1.2870607646644114
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 324.0226089954376
  time_this_iter_s: 59.08374643325806
  time_total_s: 324.0226089954376
  timestamp: 1706937730
  training_iteration: 5
  trial_id: 668d1_00005

(func pid=2765) [9,  4000] loss: 0.870
== Status ==
Current time: 2024-02-03 05:22:15 (running for 00:05:40.04)
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00003 | RUNNING    | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      7 |         291.294  | 2.02666 |     0.2295 |
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      7 |         288.946  | 1.38198 |     0.5504 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00003:
  accuracy: 0.2151
  date: 2024-02-03_05-22-16
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 8
  loss: 2.0069383046150207
  node_ip: 172.17.0.2
  pid: 2760
  should_checkpoint: true
  time_since_restore: 329.57353925704956
  time_this_iter_s: 38.279911041259766
  time_total_s: 329.57353925704956
  timestamp: 1706937736
  training_iteration: 8
  trial_id: 668d1_00003

Trial train_cifar_668d1_00003 completed.
Result for train_cifar_668d1_00007:
  accuracy: 0.5562
  date: 2024-02-03_05-22-19
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 8
  loss: 1.386238949227333
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 325.1725585460663
  time_this_iter_s: 36.226646423339844
  time_total_s: 325.1725585460663
  timestamp: 1706937739
  training_iteration: 8
  trial_id: 668d1_00007

(func pid=2764) [6,  2000] loss: 1.247
== Status ==
Current time: 2024-02-03 05:22:24 (running for 00:05:48.58)
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      8 |         304.813  | 1.78973 |     0.2982 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00006:
  accuracy: 0.318
  date: 2024-02-03_05-22-24
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 9
  loss: 1.740590954399109
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 338.0199918746948
  time_this_iter_s: 33.20745491981506
  time_total_s: 338.0199918746948
  timestamp: 1706937744
  training_iteration: 9
  trial_id: 668d1_00006

(func pid=2764) [6,  4000] loss: 0.620
== Status ==
Current time: 2024-02-03 05:22:29 (running for 00:05:53.97)
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=3549) [9,  2000] loss: 0.930
== Status ==
Current time: 2024-02-03 05:22:34 (running for 00:05:58.98)
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [6,  6000] loss: 0.416 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:22:39 (running for 00:06:03.99)
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:22:44 (running for 00:06:09.00)
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2765) [10,  4000] loss: 0.860 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:22:49 (running for 00:06:14.01)
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00006 | RUNNING    | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |      9 |         338.02   | 1.74059 |     0.318  |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      8 |         325.173  | 1.38624 |     0.5562 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00007:
  accuracy: 0.5697
  date: 2024-02-03_05-22-50
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 9
  loss: 1.3044582264721394
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 356.96855640411377
  time_this_iter_s: 31.795997858047485
  time_total_s: 356.96855640411377
  timestamp: 1706937770
  training_iteration: 9
  trial_id: 668d1_00007

Result for train_cifar_668d1_00006:
  accuracy: 0.3233
  date: 2024-02-03_05-22-54
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 10
  loss: 1.7479507164001464
  node_ip: 172.17.0.2
  pid: 2765
  should_checkpoint: true
  time_since_restore: 367.6761510372162
  time_this_iter_s: 29.656159162521362
  time_total_s: 367.6761510372162
  timestamp: 1706937774
  training_iteration: 10
  trial_id: 668d1_00006

Trial train_cifar_668d1_00006 completed.
(func pid=2764) [6, 10000] loss: 0.244 [repeated 2x across cluster]
== Status ==
Current time: 2024-02-03 05:22:59 (running for 00:06:23.63)
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      5 |         324.023  | 1.28706 |     0.529  |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00005:
  accuracy: 0.5427
  date: 2024-02-03_05-23-01
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 6
  loss: 1.2477094298124314
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 375.21164202690125
  time_this_iter_s: 51.18903303146362
  time_total_s: 375.21164202690125
  timestamp: 1706937781
  training_iteration: 6
  trial_id: 668d1_00005

(func pid=3549) [10,  2000] loss: 0.915
== Status ==
Current time: 2024-02-03 05:23:06 (running for 00:06:31.24)
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [7,  2000] loss: 1.214
== Status ==
Current time: 2024-02-03 05:23:11 (running for 00:06:36.25)
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:23:16 (running for 00:06:41.26)
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00007 | RUNNING    | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |      9 |         356.969  | 1.30446 |     0.5697 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [7,  4000] loss: 0.603 [repeated 2x across cluster]
Result for train_cifar_668d1_00007:
  accuracy: 0.5706
  date: 2024-02-03_05-23-21
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 10
  loss: 1.4145498059391974
  node_ip: 172.17.0.2
  pid: 3549
  should_checkpoint: true
  time_since_restore: 387.638968706131
  time_this_iter_s: 30.670412302017212
  time_total_s: 387.638968706131
  timestamp: 1706937801
  training_iteration: 10
  trial_id: 668d1_00007

Trial train_cifar_668d1_00007 completed.
(func pid=2764) [7,  6000] loss: 0.396
== Status ==
Current time: 2024-02-03 05:23:26 (running for 00:06:51.05)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:23:31 (running for 00:06:56.05)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [7,  8000] loss: 0.300
== Status ==
Current time: 2024-02-03 05:23:36 (running for 00:07:01.06)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:23:41 (running for 00:07:06.07)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [7, 10000] loss: 0.236
== Status ==
Current time: 2024-02-03 05:23:46 (running for 00:07:11.08)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      6 |         375.212  | 1.24771 |     0.5427 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00005:
  accuracy: 0.5725
  date: 2024-02-03_05-23-48
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 7
  loss: 1.2115788961529732
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 421.9987733364105
  time_this_iter_s: 46.78713130950928
  time_total_s: 421.9987733364105
  timestamp: 1706937828
  training_iteration: 7
  trial_id: 668d1_00005

== Status ==
Current time: 2024-02-03 05:23:53 (running for 00:07:18.01)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [8,  2000] loss: 1.179
== Status ==
Current time: 2024-02-03 05:23:58 (running for 00:07:23.02)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:24:03 (running for 00:07:28.02)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [8,  4000] loss: 0.583
== Status ==
Current time: 2024-02-03 05:24:08 (running for 00:07:33.03)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [8,  6000] loss: 0.386
== Status ==
Current time: 2024-02-03 05:24:13 (running for 00:07:38.04)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:24:18 (running for 00:07:43.05)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [8,  8000] loss: 0.293
== Status ==
Current time: 2024-02-03 05:24:23 (running for 00:07:48.06)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:24:28 (running for 00:07:53.07)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [8, 10000] loss: 0.232
== Status ==
Current time: 2024-02-03 05:24:33 (running for 00:07:58.08)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.7897322436332703 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      7 |         421.999  | 1.21158 |     0.5725 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00005:
  accuracy: 0.5445
  date: 2024-02-03_05-24-34
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 8
  loss: 1.2921000151872635
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 468.24409079551697
  time_this_iter_s: 46.245317459106445
  time_total_s: 468.24409079551697
  timestamp: 1706937874
  training_iteration: 8
  trial_id: 668d1_00005

== Status ==
Current time: 2024-02-03 05:24:39 (running for 00:08:04.26)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [9,  2000] loss: 1.129
== Status ==
Current time: 2024-02-03 05:24:44 (running for 00:08:09.26)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:24:49 (running for 00:08:14.27)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [9,  4000] loss: 0.575
== Status ==
Current time: 2024-02-03 05:24:54 (running for 00:08:19.28)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [9,  6000] loss: 0.383
== Status ==
Current time: 2024-02-03 05:24:59 (running for 00:08:24.29)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:25:04 (running for 00:08:29.30)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [9,  8000] loss: 0.287
== Status ==
Current time: 2024-02-03 05:25:09 (running for 00:08:34.31)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [9, 10000] loss: 0.231
== Status ==
Current time: 2024-02-03 05:25:14 (running for 00:08:39.32)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:25:19 (running for 00:08:44.33)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      8 |         468.244  | 1.2921  |     0.5445 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00005:
  accuracy: 0.5753
  date: 2024-02-03_05-25-20
  done: false
  hostname: 8642c088913e
  iterations_since_restore: 9
  loss: 1.1927328542232514
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 514.1986174583435
  time_this_iter_s: 45.95452666282654
  time_total_s: 514.1986174583435
  timestamp: 1706937920
  training_iteration: 9
  trial_id: 668d1_00005

== Status ==
Current time: 2024-02-03 05:25:25 (running for 00:08:50.21)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [10,  2000] loss: 1.124
== Status ==
Current time: 2024-02-03 05:25:30 (running for 00:08:55.22)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:25:35 (running for 00:09:00.22)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [10,  4000] loss: 0.564
== Status ==
Current time: 2024-02-03 05:25:40 (running for 00:09:05.23)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [10,  6000] loss: 0.382
== Status ==
Current time: 2024-02-03 05:25:45 (running for 00:09:10.24)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:25:50 (running for 00:09:15.25)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [10,  8000] loss: 0.278
== Status ==
Current time: 2024-02-03 05:25:55 (running for 00:09:20.26)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

(func pid=2764) [10, 10000] loss: 0.223
== Status ==
Current time: 2024-02-03 05:26:00 (running for 00:09:25.27)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

== Status ==
Current time: 2024-02-03 05:26:05 (running for 00:09:30.28)
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00005 | RUNNING    | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |      9 |         514.199  | 1.19273 |     0.5753 |
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

Result for train_cifar_668d1_00005:
  accuracy: 0.5878
  date: 2024-02-03_05-26-06
  done: true
  hostname: 8642c088913e
  iterations_since_restore: 10
  loss: 1.1539024412691594
  node_ip: 172.17.0.2
  pid: 2764
  should_checkpoint: true
  time_since_restore: 560.4044351577759
  time_this_iter_s: 46.20581769943237
  time_total_s: 560.4044351577759
  timestamp: 1706937966
  training_iteration: 10
  trial_id: 668d1_00005

Trial train_cifar_668d1_00005 completed.
== Status ==
Current time: 2024-02-03 05:26:06 (running for 00:09:31.42)
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.5879855964303018 | Iter 4.000: -1.6676453223228456 | Iter 2.000: -2.0345774334311484 | Iter 1.000: -2.222400290584564
Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
Result logdir: /var/lib/jenkins/ray_results/train_cifar_2024-02-03_05-16-35
Number of trials: 10/10 (10 TERMINATED)
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
|-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
| train_cifar_668d1_00000 | TERMINATED | 172.17.0.2:2669 |            2 |   16 |    1 | 0.00213327  |      1 |         127.897  | 2.31295 |     0.0961 |
| train_cifar_668d1_00001 | TERMINATED | 172.17.0.2:2756 |            4 |    1 |    2 | 0.013416    |      1 |          72.1502 | 2.31184 |     0.1009 |
| train_cifar_668d1_00002 | TERMINATED | 172.17.0.2:2758 |            2 |  256 |   64 | 0.0113784   |      2 |         317.105  | 2.08221 |     0.1941 |
| train_cifar_668d1_00003 | TERMINATED | 172.17.0.2:2760 |            8 |   64 |  256 | 0.0274071   |      8 |         329.574  | 2.00694 |     0.2151 |
| train_cifar_668d1_00004 | TERMINATED | 172.17.0.2:2762 |            4 |   16 |    2 | 0.056666    |      1 |          73.4948 | 2.3172  |     0.1042 |
| train_cifar_668d1_00005 | TERMINATED | 172.17.0.2:2764 |            4 |    8 |   64 | 0.000353097 |     10 |         560.404  | 1.1539  |     0.5878 |
| train_cifar_668d1_00006 | TERMINATED | 172.17.0.2:2765 |            8 |   16 |    4 | 0.000147684 |     10 |         367.676  | 1.74795 |     0.3233 |
| train_cifar_668d1_00007 | TERMINATED | 172.17.0.2:3549 |            8 |  256 |  256 | 0.00477469  |     10 |         387.639  | 1.41455 |     0.5706 |
| train_cifar_668d1_00008 | TERMINATED | 172.17.0.2:2756 |            8 |  128 |  256 | 0.0306227   |      2 |          93.5935 | 2.09278 |     0.1979 |
| train_cifar_668d1_00009 | TERMINATED | 172.17.0.2:2762 |            2 |    2 |   16 | 0.0286986   |      1 |         124.634  | 2.334   |     0.1016 |
+-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+

2024-02-03 05:26:06,866 INFO tune.py:945 -- Total run time: 571.52 seconds (571.41 seconds for the tuning loop).
Best trial config: {'l1': 8, 'l2': 64, 'lr': 0.0003530972286268149, 'batch_size': 4}
Best trial final validation loss: 1.1539024412691594
Best trial final validation accuracy: 0.5878
Files already downloaded and verified
Files already downloaded and verified
Best trial test set accuracy: 0.5864 
```

如果您运行代码，示例输出可能如下所示：

```py
Number  of  trials:  10/10  (10  TERMINATED)
+-----+--------------+------+------+-------------+--------+---------+------------+
|  ...  |  batch_size  |  l1  |  l2  |  lr  |  iter  |  loss  |  accuracy  |
|-----+--------------+------+------+-------------+--------+---------+------------|
|  ...  |  2  |  1  |  256  |  0.000668163  |  1  |  2.31479  |  0.0977  |
|  ...  |  4  |  64  |  8  |  0.0331514  |  1  |  2.31605  |  0.0983  |
|  ...  |  4  |  2  |  1  |  0.000150295  |  1  |  2.30755  |  0.1023  |
|  ...  |  16  |  32  |  32  |  0.0128248  |  10  |  1.66912  |  0.4391  |
|  ...  |  4  |  8  |  128  |  0.00464561  |  2  |  1.7316  |  0.3463  |
|  ...  |  8  |  256  |  8  |  0.00031556  |  1  |  2.19409  |  0.1736  |
|  ...  |  4  |  16  |  256  |  0.00574329  |  2  |  1.85679  |  0.3368  |
|  ...  |  8  |  2  |  2  |  0.00325652  |  1  |  2.30272  |  0.0984  |
|  ...  |  2  |  2  |  2  |  0.000342987  |  2  |  1.76044  |  0.292  |
|  ...  |  4  |  64  |  32  |  0.003734  |  8  |  1.53101  |  0.4761  |
+-----+--------------+------+------+-------------+--------+---------+------------+

Best  trial  config:  {'l1':  64,  'l2':  32,  'lr':  0.0037339984519545164,  'batch_size':  4}
Best  trial  final  validation  loss:  1.5310075663924216
Best  trial  final  validation  accuracy:  0.4761
Best  trial  test  set  accuracy:  0.4737 
```

为了避免浪费资源，大多数试验都被提前停止了。表现最好的试验实现了约47%的验证准确率，这可以在测试集上得到确认。

就是这样！您现在可以调整PyTorch模型的参数了。

**脚本的总运行时间：**（9分钟49.698秒）

[`下载Python源代码：hyperparameter_tuning_tutorial.py`](../_downloads/b2e3bdbf14ea1e9b3a80770f0a498037/hyperparameter_tuning_tutorial.py)

[`下载Jupyter笔记本：hyperparameter_tuning_tutorial.ipynb`](../_downloads/30bcc2970bf630097b13789b5cdcea48/hyperparameter_tuning_tutorial.ipynb)

[Sphinx-Gallery生成的画廊](https://sphinx-gallery.github.io)
