# StreamReaderé«˜çº§ç”¨æ³•

> åŸæ–‡ï¼š[https://pytorch.org/audio/stable/tutorials/streamreader_advanced_tutorial.html](https://pytorch.org/audio/stable/tutorials/streamreader_advanced_tutorial.html)

æ³¨æ„

ç‚¹å‡»[è¿™é‡Œ](#sphx-glr-download-tutorials-streamreader-advanced-tutorial-py)ä¸‹è½½å®Œæ•´ç¤ºä¾‹ä»£ç 

**ä½œè€…**ï¼š[Moto Hira](mailto:moto%40meta.com)

æœ¬æ•™ç¨‹æ˜¯[StreamReaderåŸºæœ¬ç”¨æ³•](./streamreader_basic_tutorial.html)çš„å»¶ç»­ã€‚

è¿™æ˜¾ç¤ºäº†å¦‚ä½•ä½¿ç”¨[`StreamReader`](../generated/torchaudio.io.StreamReader.html#torchaudio.io.StreamReader "torchaudio.io.StreamReader")è¿›è¡Œ

+   è®¾å¤‡è¾“å…¥ï¼Œå¦‚éº¦å…‹é£ã€ç½‘ç»œæ‘„åƒå¤´å’Œå±å¹•å½•åˆ¶

+   ç”ŸæˆåˆæˆéŸ³é¢‘/è§†é¢‘

+   åº”ç”¨è‡ªå®šä¹‰æ»¤æ³¢å™¨è¡¨è¾¾å¼è¿›è¡Œé¢„å¤„ç†

```py
import torch
import torchaudio

print(torch.__version__)
print([torchaudio.__version__](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))

import IPython
import matplotlib.pyplot as plt
from torchaudio.io import StreamReader

[base_url](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = "https://download.pytorch.org/torchaudio/tutorial-assets"
[AUDIO_URL](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = f"{[base_url](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")}/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"
[VIDEO_URL](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") = f"{[base_url](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")}/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4" 
```

```py
2.2.0
2.2.0 
```

## éŸ³é¢‘/è§†é¢‘è®¾å¤‡è¾“å…¥[](#audio-video-device-input "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

å¦è¯·å‚é˜…

+   [ä½¿ç”¨NVDECè¿›è¡ŒåŠ é€Ÿè§†é¢‘è§£ç ](../hw_acceleration_tutorial.html)ã€‚

+   [ä½¿ç”¨Emformer RNN-Tè¿›è¡Œåœ¨çº¿ASR](./online_asr_tutorial.html)ã€‚

+   [ä½¿ç”¨Emformer RNN-Tè¿›è¡Œè®¾å¤‡ASR](./device_asr.html)ã€‚

å‡è®¾ç³»ç»Ÿå…·æœ‰é€‚å½“çš„åª’ä½“è®¾å¤‡å¹¶ä¸”libavdeviceå·²é…ç½®ä¸ºä½¿ç”¨è¿™äº›è®¾å¤‡ï¼Œåˆ™æµåª’ä½“APIå¯ä»¥ä»è¿™äº›è®¾å¤‡ä¸­æå–åª’ä½“æµã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å‘æ„é€ å‡½æ•°ä¼ é€’é¢å¤–çš„å‚æ•°`format`å’Œ`option`ã€‚`format`æŒ‡å®šè®¾å¤‡ç»„ä»¶ï¼Œ`option`å­—å…¸ç‰¹å®šäºæŒ‡å®šçš„ç»„ä»¶ã€‚

è¦ä¼ é€’çš„ç¡®åˆ‡å‚æ•°å–å†³äºç³»ç»Ÿé…ç½®ã€‚è¯·å‚è€ƒ[https://ffmpeg.org/ffmpeg-devices.html](https://ffmpeg.org/ffmpeg-devices.html)è·å–è¯¦ç»†ä¿¡æ¯ã€‚

ä»¥ä¸‹ç¤ºä¾‹è¯´æ˜äº†å¦‚ä½•åœ¨MacBook Proä¸Šæ‰§è¡Œæ­¤æ“ä½œã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥å¯ç”¨è®¾å¤‡ã€‚

```py
$ ffmpeg -f avfoundation -list_devices true -i ""
[AVFoundation indev @ 0x143f04e50] AVFoundation video devices:
[AVFoundation indev @ 0x143f04e50] [0] FaceTime HD Camera
[AVFoundation indev @ 0x143f04e50] [1] Capture screen 0
[AVFoundation indev @ 0x143f04e50] AVFoundation audio devices:
[AVFoundation indev @ 0x143f04e50] [0] MacBook Pro Microphone 
```

æˆ‘ä»¬ä½¿ç”¨FaceTime HDæ‘„åƒå¤´ä½œä¸ºè§†é¢‘è®¾å¤‡ï¼ˆç´¢å¼•0ï¼‰ï¼ŒMacBook Proéº¦å…‹é£ä½œä¸ºéŸ³é¢‘è®¾å¤‡ï¼ˆç´¢å¼•0ï¼‰ã€‚

å¦‚æœæˆ‘ä»¬ä¸ä¼ é€’ä»»ä½•`option`ï¼Œè®¾å¤‡å°†ä½¿ç”¨å…¶é»˜è®¤é…ç½®ã€‚è§£ç å™¨å¯èƒ½ä¸æ”¯æŒè¯¥é…ç½®ã€‚

```py
>>> StreamReader(
...     src="0:0",  # The first 0 means `FaceTime HD Camera`, and
...                 # the second 0 indicates `MacBook Pro Microphone`.
...     format="avfoundation",
... )
[avfoundation @ 0x125d4fe00] Selected framerate (29.970030) is not supported by the device.
[avfoundation @ 0x125d4fe00] Supported modes:
[avfoundation @ 0x125d4fe00]   1280x720@[1.000000 30.000000]fps
[avfoundation @ 0x125d4fe00]   640x480@[1.000000 30.000000]fps
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  ...
RuntimeError: Failed to open the input: 0:0 
```

é€šè¿‡æä¾›`option`ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ”¹è®¾å¤‡æµåˆ°è§£ç å™¨æ”¯æŒçš„æ ¼å¼ã€‚

```py
>>> streamer = StreamReader(
...     src="0:0",
...     format="avfoundation",
...     option={"framerate": "30", "pixel_format": "bgr0"},
... )
>>> for i in range(streamer.num_src_streams):
...     print(streamer.get_src_stream_info(i))
SourceVideoStream(media_type='video', codec='rawvideo', codec_long_name='raw video', format='bgr0', bit_rate=0, width=640, height=480, frame_rate=30.0)
SourceAudioStream(media_type='audio', codec='pcm_f32le', codec_long_name='PCM 32-bit floating point little-endian', format='flt', bit_rate=3072000, sample_rate=48000.0, num_channels=2) 
```

##åˆæˆæºæµ[](#synthetic-source-streams "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

ä½œä¸ºè®¾å¤‡é›†æˆçš„ä¸€éƒ¨åˆ†ï¼Œffmpegæä¾›äº†â€œè™šæ‹Ÿè®¾å¤‡â€æ¥å£ã€‚è¯¥æ¥å£ä½¿ç”¨libavfilteræä¾›åˆæˆéŸ³é¢‘/è§†é¢‘æ•°æ®ç”Ÿæˆã€‚

è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œæˆ‘ä»¬è®¾ç½®`format=lavfi`å¹¶ä¸º`src`æä¾›ä¸€ä¸ªæ»¤æ³¢å™¨æè¿°ã€‚

æœ‰å…³æ»¤æ³¢å™¨æè¿°çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[https://ffmpeg.org/ffmpeg-filters.html](https://ffmpeg.org/ffmpeg-filters.html)

### éŸ³é¢‘ç¤ºä¾‹[](#audio-examples "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

#### æ­£å¼¦æ³¢[](#sine-wave "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

[https://ffmpeg.org/ffmpeg-filters.html#sine](https://ffmpeg.org/ffmpeg-filters.html#sine)

```py
StreamReader(src="sine=sample_rate=8000:frequency=360", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/sine.wav>

![](../Images/4951828f6e6cb4ef7945b4445da896af.png)

#### å…·æœ‰ä»»æ„è¡¨è¾¾å¼çš„ä¿¡å·[](#signal-with-arbitral-expression "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

[https://ffmpeg.org/ffmpeg-filters.html#aevalsrc](https://ffmpeg.org/ffmpeg-filters.html#aevalsrc)

```py
# 5 Hz binaural beats on a 360 Hz carrier
StreamReader(
    src=(
        'aevalsrc='
        'sample_rate=8000:'
        'exprs=0.1*sin(2*PI*(360-5/2)*t)|0.1*sin(2*PI*(360+5/2)*t)'
    ),
    format='lavfi',
 ) 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/aevalsrc.wav>

![](../Images/fdbb3facca115030372b67b2e0a87035.png)

#### å™ªå£°[](#noise "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

[https://ffmpeg.org/ffmpeg-filters.html#anoisesrc](https://ffmpeg.org/ffmpeg-filters.html#anoisesrc)

```py
StreamReader(src="anoisesrc=color=pink:sample_rate=8000:amplitude=0.5", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/anoisesrc.wav>

![](../Images/221138e798d8d14f09df7f8607a3082b.png)

### è§†é¢‘ç¤ºä¾‹[](#video-examples "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

#### å…ƒèƒè‡ªåŠ¨æœº[](#cellular-automaton "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

[https://ffmpeg.org/ffmpeg-filters.html#cellauto](https://ffmpeg.org/ffmpeg-filters.html#cellauto)

```py
StreamReader(src=f"cellauto", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/cellauto.mp4>

#### æ›¼å¾·å°”å¸ƒç½—ç‰¹[](#mandelbrot "è·³è½¬åˆ°æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥")

[https://ffmpeg.org/ffmpeg-filters.html#cellauto](https://ffmpeg.org/ffmpeg-filters.html#cellauto)

```py
StreamReader(src=f"mandelbrot", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/mandelbrot.mp4>

#### MPlayeræµ‹è¯•æ¨¡å¼

[https://ffmpeg.org/ffmpeg-filters.html#mptestsrc](https://ffmpeg.org/ffmpeg-filters.html#mptestsrc)

```py
StreamReader(src=f"mptestsrc", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/mptestsrc.mp4>

#### çº¦ç¿°Â·åº·å¨çš„ç”Ÿå‘½æ¸¸æˆ

[https://ffmpeg.org/ffmpeg-filters.html#life](https://ffmpeg.org/ffmpeg-filters.html#life)

```py
StreamReader(src=f"life", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/life.mp4>

#### Sierpinski carpet/triangle fractal

[https://ffmpeg.org/ffmpeg-filters.html#sierpinski](https://ffmpeg.org/ffmpeg-filters.html#sierpinski)

```py
StreamReader(src=f"sierpinski", format="lavfi") 
```

<https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/sierpinski.mp4>

## è‡ªå®šä¹‰è¿‡æ»¤å™¨

åœ¨å®šä¹‰è¾“å‡ºæµæ—¶ï¼Œå¯ä»¥ä½¿ç”¨`add_audio_stream()`å’Œ`add_video_stream()`æ–¹æ³•ã€‚

è¿™äº›æ–¹æ³•æ¥å—`filter_desc`å‚æ•°ï¼Œè¯¥å‚æ•°æ˜¯æ ¹æ®ffmpegçš„[è¿‡æ»¤å™¨è¡¨è¾¾å¼](https://ffmpeg.org/ffmpeg-filters.html)æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²ã€‚

`add_basic_(audio|video)_stream`å’Œ`add_(audio|video)_stream`ä¹‹é—´çš„åŒºåˆ«åœ¨äº`add_basic_(audio|video)_stream`æ„å»ºäº†è¿‡æ»¤å™¨è¡¨è¾¾å¼å¹¶å°†å…¶ä¼ é€’ç»™ç›¸åŒçš„åº•å±‚å®ç°ã€‚ä¸€åˆ‡`add_basic_(audio|video)_stream`å¯ä»¥é€šè¿‡`add_(audio|video)_stream`å®ç°ã€‚

æ³¨æ„

+   åœ¨åº”ç”¨è‡ªå®šä¹‰è¿‡æ»¤å™¨æ—¶ï¼Œå®¢æˆ·ç«¯ä»£ç å¿…é¡»å°†éŸ³é¢‘/è§†é¢‘æµè½¬æ¢ä¸ºtorchaudioå¯ä»¥è½¬æ¢ä¸ºå¼ é‡æ ¼å¼çš„æ ¼å¼ä¹‹ä¸€ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡å°†`format=pix_fmts=rgb24`åº”ç”¨äºè§†é¢‘æµå’Œ`aformat=sample_fmts=fltp`åº”ç”¨äºéŸ³é¢‘æµæ¥å®ç°è¿™ä¸€ç‚¹ã€‚

+   æ¯ä¸ªè¾“å‡ºæµéƒ½æœ‰å•ç‹¬çš„è¿‡æ»¤å™¨å›¾ã€‚å› æ­¤ï¼Œä¸å¯èƒ½ä¸ºè¿‡æ»¤å™¨è¡¨è¾¾å¼ä½¿ç”¨ä¸åŒçš„è¾“å…¥/è¾“å‡ºæµã€‚ä½†æ˜¯ï¼Œå¯ä»¥å°†ä¸€ä¸ªè¾“å…¥æµæ‹†åˆ†ä¸ºå¤šä¸ªæµï¼Œç„¶åå°†å®ƒä»¬åˆå¹¶ã€‚

### éŸ³é¢‘ç¤ºä¾‹

```py
# fmt: off
[descs](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [
    # No filtering
    "anull",
    # Apply a highpass filter then a lowpass filter
    "highpass=f=200,lowpass=f=1000",
    # Manipulate spectrogram
    (
        "afftfilt="
        "real='hypot(re,im)*sin(0)':"
        "imag='hypot(re,im)*cos(0)':"
        "win_size=512:"
        "overlap=0.75"
    ),
    # Manipulate spectrogram
    (
        "afftfilt="
        "real='hypot(re,im)*cos((random(0)*2-1)*2*3.14)':"
        "imag='hypot(re,im)*sin((random(1)*2-1)*2*3.14)':"
        "win_size=128:"
        "overlap=0.8"
    ),
]
# fmt: on 
```

```py
[sample_rate](https://docs.python.org/3/library/functions.html#int "builtins.int") = 8000

streamer = StreamReader([AUDIO_URL](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
for [desc](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") in [descs](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    streamer.add_audio_stream(
        frames_per_chunk=40000,
        filter_desc=f"aresample={[sample_rate](https://docs.python.org/3/library/functions.html#int "builtins.int")},{[desc](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")},aformat=sample_fmts=fltp",
    )

[chunks](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = next(streamer.stream())

def _display(i):
    print("filter_desc:", streamer.get_out_stream_info(i).filter_description)
    fig, axs = plt.subplots(2, 1)
    waveform = [chunks](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i][:, 0]
    axs[0].plot(waveform)
    axs[0].grid(True)
    axs[0].set_ylim([-1, 1])
    plt.setp(axs[0].get_xticklabels(), visible=False)
    axs[1].specgram(waveform, Fs=[sample_rate](https://docs.python.org/3/library/functions.html#int "builtins.int"))
    fig.tight_layout()
    return IPython.display.Audio([chunks](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i].T, rate=[sample_rate](https://docs.python.org/3/library/functions.html#int "builtins.int")) 
```

#### åŸå§‹

```py
_display(0) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/9422f36c7502b1bcef0f877aa913b653.png)

```py
filter_desc: aresample=8000,anull,aformat=sample_fmts=fltp 
```

æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚

#### é«˜é€š/ä½é€šæ»¤æ³¢å™¨

```py
_display(1) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/265b57356aac35df68450a1af7d44461.png)

```py
filter_desc: aresample=8000,highpass=f=200,lowpass=f=1000,aformat=sample_fmts=fltp 
```

æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚

#### FFTæ»¤æ³¢å™¨ - æœºå™¨äººğŸ¤–

```py
_display(2) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/29cba5f8e6ece9a91c532b94bbd19c2a.png)

```py
filter_desc: aresample=8000,afftfilt=real='hypot(re,im)*sin(0)':imag='hypot(re,im)*cos(0)':win_size=512:overlap=0.75,aformat=sample_fmts=fltp 
```

æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚

#### FFTæ»¤æ³¢å™¨ - ä½è¯­

```py
_display(3) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/406d88c3a3f285f209ced7de7719ea34.png)

```py
filter_desc: aresample=8000,afftfilt=real='hypot(re,im)*cos((random(0)*2-1)*2*3.14)':imag='hypot(re,im)*sin((random(1)*2-1)*2*3.14)':win_size=128:overlap=0.8,aformat=sample_fmts=fltp 
```

æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚

### è§†é¢‘ç¤ºä¾‹

```py
# fmt: off
[descs](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = [
    # No effect
    "null",
    # Split the input stream and apply horizontal flip to the right half.
    (
        "split [main][tmp];"
        "[tmp] crop=iw/2:ih:0:0, hflip [flip];"
        "[main][flip] overlay=W/2:0"
    ),
    # Edge detection
    "edgedetect=mode=canny",
    # Rotate image by randomly and fill the background with brown
    "rotate=angle=-random(1)*PI:fillcolor=brown",
    # Manipulate pixel values based on the coordinate
    "geq=r='X/W*r(X,Y)':g='(1-X/W)*g(X,Y)':b='(H-Y)/H*b(X,Y)'"
]
# fmt: on 
```

```py
streamer = StreamReader([VIDEO_URL](https://docs.python.org/3/library/stdtypes.html#str "builtins.str"))
for [desc](https://docs.python.org/3/library/stdtypes.html#str "builtins.str") in [descs](https://docs.python.org/3/library/stdtypes.html#list "builtins.list"):
    streamer.add_video_stream(
        frames_per_chunk=30,
        filter_desc=f"fps=10,{[desc](https://docs.python.org/3/library/stdtypes.html#str "builtins.str")},format=pix_fmts=rgb24",
    )

streamer.seek(12)

[chunks](https://docs.python.org/3/library/stdtypes.html#list "builtins.list") = next(streamer.stream())

def _display(i):
    print("filter_desc:", streamer.get_out_stream_info(i).filter_description)
    _, axs = plt.subplots(1, 3, figsize=(8, 1.9))
    chunk = [chunks](https://docs.python.org/3/library/stdtypes.html#list "builtins.list")[i]
    for j in range(3):
        axs[j].imshow(chunk[10 * j + 1].permute(1, 2, 0))
        axs[j].set_axis_off()
    plt.tight_layout() 
```

#### åŸå§‹

```py
_display(0) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/e52ccb510fecdebbce6ae360b991f85d.png)

```py
filter_desc: fps=10,null,format=pix_fmts=rgb24 
```

#### é•œåƒ

```py
_display(1) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/0b38768351c328de5fdaae90f7fe7066.png)

```py
filter_desc: fps=10,split [main][tmp];[tmp] crop=iw/2:ih:0:0, hflip [flip];[main][flip] overlay=W/2:0,format=pix_fmts=rgb24 
```

#### è¾¹ç¼˜æ£€æµ‹

```py
_display(2) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/c9366a2d9e62e5faacc20268e77ce566.png)

```py
filter_desc: fps=10,edgedetect=mode=canny,format=pix_fmts=rgb24 
```

#### éšæœºæ—‹è½¬

```py
_display(3) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/9bcd668d0694dbc4b90b7d448cc142da.png)

```py
filter_desc: fps=10,rotate=angle=-random(1)*PI:fillcolor=brown,format=pix_fmts=rgb24 
```

#### åƒç´ æ“ä½œ

```py
_display(4) 
```

![streamreaderé«˜çº§æ•™ç¨‹](../Images/f5b57739b74a653aec75310af2f57814.png)

```py
filter_desc: fps=10,geq=r='X/W*r(X,Y)':g='(1-X/W)*g(X,Y)':b='(H-Y)/H*b(X,Y)',format=pix_fmts=rgb24 
```

æ ‡ç­¾ï¼š[`torchaudio.io`](../io.html#module-torchaudio.io)

**è„šæœ¬çš„æ€»è¿è¡Œæ—¶é—´ï¼š**ï¼ˆ0åˆ†é’Ÿ17.260ç§’ï¼‰

[`ä¸‹è½½Pythonæºä»£ç ï¼šstreamreader_advanced_tutorial.py`](../_downloads/21502c17878277ad648c064df573f05e/streamreader_advanced_tutorial.py)

[`ä¸‹è½½Jupyterç¬”è®°æœ¬ï¼šstreamreader_advanced_tutorial.ipynb`](../_downloads/f3b1cbeaf1ae66d226233d2ca3d0ef3d/streamreader_advanced_tutorial.ipynb)

[Sphinx-Galleryç”Ÿæˆçš„ç”»å»Š](https://sphinx-gallery.github.io)
