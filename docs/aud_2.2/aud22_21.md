# 使用 NVENC 进行加速视频编码

> 请参考[`pytorch.org/audio/stable/tutorials/nvenc_tutorial.html`](https://pytorch.org/audio/stable/tutorials/nvenc_tutorial.html)

注意

点击这里下载完整示例代码

**作者**：Moto Hira

本教程展示了如何在 TorchAudio 中使用 NVIDIA 的硬件视频编码器（NVENC），以及它如何提高视频编码的性能。

注意

本教程要求使用启用了 HW 加速的 FFmpeg 库进行编译。

请参考启用 GPU 视频解码器/编码器了解如何构建启用了 HW 加速的 FFmpeg。

注意

大多数现代 GPU 都具有 HW 解码器和编码器，但一些高端 GPU 如 A100 和 H100 没有 HW 编码器。请参考以下链接了解可用性和格式覆盖范围。[`developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new`](https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new)

尝试在这些 GPU 上使用 HW 编码器会失败，并显示类似`Generic error in an external library`的错误消息。您可以使用`torchaudio.utils.ffmpeg_utils.set_log_level()`启用调试日志，以查看沿途发出的更详细的错误消息。

```py
import torch
import torchaudio

print(torch.__version__)
print(torchaudio.__version__)

import io
import time

import matplotlib.pyplot as plt
from IPython.display import Video
from torchaudio.io import StreamReader, StreamWriter 
```

```py
2.2.0
2.2.0 
```

## 检查先决条件

首先，我们检查 TorchAudio 是否正确检测到支持 HW 解码器/编码器的 FFmpeg 库。

```py
from torchaudio.utils import ffmpeg_utils 
```

```py
print("FFmpeg Library versions:")
for k, ver in ffmpeg_utils.get_versions().items():
    print(f" {k}:\t{'.'.join(str(v)  for  v  in  ver)}") 
```

```py
FFmpeg Library versions:
  libavcodec:   60.3.100
  libavdevice:  60.1.100
  libavfilter:  9.3.100
  libavformat:  60.3.100
  libavutil:    58.2.100 
```

```py
print("Available NVENC Encoders:")
for k in ffmpeg_utils.get_video_encoders().keys():
    if "nvenc" in k:
        print(f" - {k}") 
```

```py
Available NVENC Encoders:
 - av1_nvenc
 - h264_nvenc
 - hevc_nvenc 
```

```py
print("Avaialbe GPU:")
print(torch.cuda.get_device_properties(0)) 
```

```py
Avaialbe GPU:
_CudaDeviceProperties(name='NVIDIA A10G', major=8, minor=6, total_memory=22515MB, multi_processor_count=80) 
```

我们使用以下辅助函数生成测试帧数据。有关合成视频生成的详细信息，请参考 StreamReader Advanced Usage。

```py
def get_data(height, width, format="yuv444p", frame_rate=30000 / 1001, duration=4):
    src = f"testsrc2=rate={frame_rate}:size={width}x{height}:duration={duration}"
    s = StreamReader(src=src, format="lavfi")
    s.add_basic_video_stream(-1, format=format)
    s.process_all_packets()
    (video,) = s.pop_chunks()
    return video 
```

## 使用 NVENC 对视频进行编码

在定义输出视频流时，需要通过向`add_video_stream()`提供`encoder`选项来指定使用 HW 视频编码器。

```py
pict_config = {
    "height": 360,
    "width": 640,
    "frame_rate": 30000 / 1001,
    "format": "yuv444p",
}

frame_data = get_data(**pict_config) 
```

```py
w = StreamWriter(io.BytesIO(), format="mp4")
w.add_video_stream(**pict_config, encoder="h264_nvenc", encoder_format="yuv444p")
with w.open():
    w.write_video_chunk(0, frame_data) 
```

与 HW 解码器类似，默认情况下，编码器期望帧数据位于 CPU 内存中。要从 CUDA 内存发送数据，需要指定`hw_accel`选项。

```py
buffer = io.BytesIO()
w = StreamWriter(buffer, format="mp4")
w.add_video_stream(**pict_config, encoder="h264_nvenc", encoder_format="yuv444p", hw_accel="cuda:0")
with w.open():
    w.write_video_chunk(0, frame_data.to(torch.device("cuda:0")))
buffer.seek(0)
video_cuda = buffer.read() 
```

```py
Video(video_cuda, embed=True, mimetype="video/mp4") 
```

您的浏览器不支持视频标签。

## 使用 StreamWriter 对 NVENC 进行基准测试

现在我们比较软件编码器和硬件编码器的性能。

与 NVDEC 中的基准测试类似，我们处理不同分辨率的视频，并测量编码所需的时间。

我们还测量生成的视频文件的大小。

以下函数对给定帧进行编码，并测量编码所需的时间以及生成的视频数据的大小。

```py
def test_encode(data, encoder, width, height, hw_accel=None, **config):
    assert data.is_cuda

    buffer = io.BytesIO()
    s = StreamWriter(buffer, format="mp4")
    s.add_video_stream(encoder=encoder, width=width, height=height, hw_accel=hw_accel, **config)
    with s.open():
        t0 = time.monotonic()
        if hw_accel is None:
            data = data.to("cpu")
        s.write_video_chunk(0, data)
        elapsed = time.monotonic() - t0
    size = buffer.tell()
    fps = len(data) / elapsed
    print(f" - Processed {len(data)} frames in {elapsed:.2f} seconds. ({fps:.2f} fps)")
    print(f" - Encoded data size: {size} bytes")
    return elapsed, size 
```

我们对以下配置进行测试

+   软件编码器，线程数为 1、4、8

+   硬件编码器使用和不使用`hw_accel`选项。

```py
def run_tests(height, width, duration=4):
    # Generate the test data
    print(f"Testing resolution: {width}x{height}")
    pict_config = {
        "height": height,
        "width": width,
        "frame_rate": 30000 / 1001,
        "format": "yuv444p",
    }

    data = get_data(**pict_config, duration=duration)
    data = data.to(torch.device("cuda:0"))

    times = []
    sizes = []

    # Test software encoding
    encoder_config = {
        "encoder": "libx264",
        "encoder_format": "yuv444p",
    }
    for i, num_threads in enumerate([1, 4, 8]):
        print(f"* Software Encoder (num_threads={num_threads})")
        time_, size = test_encode(
            data,
            encoder_option={"threads": str(num_threads)},
            **pict_config,
            **encoder_config,
        )
        times.append(time_)
        if i == 0:
            sizes.append(size)

    # Test hardware encoding
    encoder_config = {
        "encoder": "h264_nvenc",
        "encoder_format": "yuv444p",
        "encoder_option": {"gpu": "0"},
    }
    for i, hw_accel in enumerate([None, "cuda"]):
        print(f"* Hardware Encoder {'(CUDA frames)'  if  hw_accel  else  ''}")
        time_, size = test_encode(
            data,
            **pict_config,
            **encoder_config,
            hw_accel=hw_accel,
        )
        times.append(time_)
        if i == 0:
            sizes.append(size)
    return times, sizes 
```

我们改变视频的分辨率，看看这些测量值如何变化。

## 360P

```py
time_360, size_360 = run_tests(360, 640) 
```

```py
Testing resolution: 640x360
* Software Encoder (num_threads=1)
 - Processed 120 frames in 0.63 seconds. (189.63 fps)
 - Encoded data size: 381331 bytes
* Software Encoder (num_threads=4)
 - Processed 120 frames in 0.22 seconds. (538.22 fps)
 - Encoded data size: 381307 bytes
* Software Encoder (num_threads=8)
 - Processed 120 frames in 0.18 seconds. (666.06 fps)
 - Encoded data size: 390689 bytes
* Hardware Encoder
 - Processed 120 frames in 0.05 seconds. (2270.77 fps)
 - Encoded data size: 1262979 bytes
* Hardware Encoder (CUDA frames)
 - Processed 120 frames in 0.05 seconds. (2609.17 fps)
 - Encoded data size: 1262979 bytes 
```

## 720P

```py
time_720, size_720 = run_tests(720, 1280) 
```

```py
Testing resolution: 1280x720
* Software Encoder (num_threads=1)
 - Processed 120 frames in 2.22 seconds. (54.08 fps)
 - Encoded data size: 1335451 bytes
* Software Encoder (num_threads=4)
 - Processed 120 frames in 0.81 seconds. (147.66 fps)
 - Encoded data size: 1336418 bytes
* Software Encoder (num_threads=8)
 - Processed 120 frames in 0.69 seconds. (173.27 fps)
 - Encoded data size: 1344063 bytes
* Hardware Encoder
 - Processed 120 frames in 0.25 seconds. (476.69 fps)
 - Encoded data size: 1358969 bytes
* Hardware Encoder (CUDA frames)
 - Processed 120 frames in 0.15 seconds. (803.20 fps)
 - Encoded data size: 1358969 bytes 
```

## 1080P

```py
time_1080, size_1080 = run_tests(1080, 1920) 
```

```py
Testing resolution: 1920x1080
* Software Encoder (num_threads=1)
 - Processed 120 frames in 4.60 seconds. (26.10 fps)
 - Encoded data size: 2678241 bytes
* Software Encoder (num_threads=4)
 - Processed 120 frames in 1.66 seconds. (72.29 fps)
 - Encoded data size: 2682028 bytes
* Software Encoder (num_threads=8)
 - Processed 120 frames in 1.54 seconds. (77.93 fps)
 - Encoded data size: 2685086 bytes
* Hardware Encoder
 - Processed 120 frames in 0.55 seconds. (217.20 fps)
 - Encoded data size: 1705900 bytes
* Hardware Encoder (CUDA frames)
 - Processed 120 frames in 0.32 seconds. (371.21 fps)
 - Encoded data size: 1705900 bytes 
```

现在我们绘制结果。

```py
def plot():
    fig, axes = plt.subplots(2, 1, sharex=True, figsize=[9.6, 7.2])

    for items in zip(time_360, time_720, time_1080, "ov^X+"):
        axes[0].plot(items[:-1], marker=items[-1])
    axes[0].grid(axis="both")
    axes[0].set_xticks([0, 1, 2], ["360p", "720p", "1080p"], visible=True)
    axes[0].tick_params(labeltop=False)
    axes[0].legend(
        [
            "Software Encoding (threads=1)",
            "Software Encoding (threads=4)",
            "Software Encoding (threads=8)",
            "Hardware Encoding (CPU Tensor)",
            "Hardware Encoding (CUDA Tensor)",
        ]
    )
    axes[0].set_title("Time to encode videos with different resolutions")
    axes[0].set_ylabel("Time [s]")

    for items in zip(size_360, size_720, size_1080, "v^"):
        axes[1].plot(items[:-1], marker=items[-1])
    axes[1].grid(axis="both")
    axes[1].set_xticks([0, 1, 2], ["360p", "720p", "1080p"])
    axes[1].set_ylabel("The encoded size [bytes]")
    axes[1].set_title("The size of encoded videos")
    axes[1].legend(
        [
            "Software Encoding",
            "Hardware Encoding",
        ]
    )

    plt.tight_layout()

plot() 
```

![不同分辨率视频编码所需时间，编码视频的大小](img/376815bfe125a4d371e6b820662ee208.png)

## 结果

我们观察到几点：

+   随着分辨率变大，编码视频所需的时间也会增加。

+   在软件编码的情况下，增加线程数量有助于减少解码时间。

+   额外线程带来的收益在大约 8 个线程左右减少。

+   总体而言，硬件编码比软件编码更快。

+   使用`hw_accel`并不会像提高编码速度本身那样有效。

+   随着分辨率变大，生成的视频大小也会增加。

+   硬件编码器在较大分辨率下生成较小的视频文件。

最后一点对作者来说有些奇怪（作者不是视频制作专家）。通常有人说硬件解码器产生的视频比软件编码器大。有人说软件编码器允许对编码配置进行精细控制，因此生成的视频更加优化。与此同时，硬件编码器针对性能进行了优化，因此在质量和二进制大小上提供的控制不如软件编码器多。

## 质量检查

那么，使用硬件编码器生成的视频质量如何？对高分辨率视频进行快速检查发现，它们在更高分辨率上有更明显的伪影。这可能解释了较小的二进制大小。（意思是，它没有分配足够的位来产生高质量输出。）

以下图像是使用硬件编码器编码的视频的原始帧。

## 360P

![NVENC 样本 360P](img/0d390a20e0d981befe81d5b3393e1c1c.png)

## 720P

![NVENC 样本 720P](img/a685497b060cb3b2ca5a611ae2d70a86.png)

## 1080P

![NVENC 样本 1080P](img/87dc3b5de645b4f546370eb194db054a.png)

我们可以看到在更高分辨率下有更多的伪影，这是显而易见的。

也许可以使用`encoder_options`参数来减少这些问题。我们没有尝试，但如果您尝试并找到更好的质量设置，请随时告诉我们。 ;)

标签：`torchaudio.io`

**脚本的总运行时间：**（0 分钟 21.517 秒）

`下载 Python 源代码：nvenc_tutorial.py`

`下载 Jupyter 笔记本：nvenc_tutorial.ipynb`

[Sphinx-Gallery 生成的图库](https://sphinx-gallery.github.io)
