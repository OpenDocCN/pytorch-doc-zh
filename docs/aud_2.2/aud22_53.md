# torchaudio.models

> 原文：[`pytorch.org/audio/stable/models.html`](https://pytorch.org/audio/stable/models.html)
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


`torchaudio.models`子包含有用于处理常见音频任务的模型定义。

注意

对于具有预训练参数的模型，请参考`torchaudio.pipelines`模块。

模型定义负责构建计算图并执行它们。

一些模型具有复杂的结构和变体。对于这样的模型，提供了工厂函数。

| `Conformer` | Conformer 架构介绍在*Conformer: Convolution-augmented Transformer for Speech Recognition* [Gulati *et al.*, 2020]. |
| --- | --- |
| `ConvTasNet` | Conv-TasNet 架构介绍在*Conv-TasNet: Surpassing Ideal Time–Frequency Magnitude Masking for Speech Separation* [Luo and Mesgarani, 2019:1256–1266, Aug 2019\. URL: http://dx.doi.org/10.1109/TASLP.2019.2915167, doi:10.1109/taslp.2019.2915167.")]. |
| `DeepSpeech` | DeepSpeech 架构介绍在*Deep Speech: Scaling up end-to-end speech recognition* [Hannun *et al.*, 2014]. |
| `Emformer` | Emformer 架构介绍在*Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition* [Shi *et al.*, 2021, 6783-6787\. 2021.")]. |
| `HDemucs` | 来自*Hybrid Spectrogram and Waveform Source Separation*的混合 Demucs 模型[Défossez, 2021]. |
| `HuBERTPretrainModel` | HuBERT 模型用于*HuBERT*中的预训练 [Hsu *et al.*, 2021]. |
| `RNNT` | 循环神经网络转录器（RNN-T）模型。 |
| `RNNTBeamSearch` | RNN-T 模型的束搜索解码器。 |
| `SquimObjective` | 预测语音增强的**客观**度量分数（例如，STOI、PESQ 和 SI-SDR）的语音质量和可懂度测量（SQUIM）模型。 |
| `SquimSubjective` | 预测语音增强的**主观**度量分数（例如，平均意见分数（MOS））的语音质量和可懂度测量（SQUIM）模型。 |
| `Tacotron2` | 基于《自然 TTS 合成：通过在 Mel 频谱图预测上对 WaveNet 进行条件化》[Shen 等，2018] 的 Tacotron2 模型，基于[Nvidia 深度学习示例](https://github.com/NVIDIA/DeepLearningExamples/)的实现。 |
| `Wav2Letter` | 来自《Wav2Letter：基于端到端 ConvNet 的语音识别系统》[Collobert 等，2016] 的 Wav2Letter 模型架构。 |
| `Wav2Vec2Model` | *wav2vec 2.0*中使用的声学模型[Baevski 等，2020]。 |
| `WaveRNN` | 基于《高效神经音频合成》[Kalchbrenner 等，2018] 的 WaveRNN 模型，基于[fatchord/WaveRNN](https://github.com/fatchord/WaveRNN)的实现。 |
