# 音频特征增强

> 原文：[`pytorch.org/audio/stable/tutorials/audio_feature_augmentation_tutorial.html`](https://pytorch.org/audio/stable/tutorials/audio_feature_augmentation_tutorial.html)
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


注意

点击这里下载完整示例代码

**作者**：Moto Hira

```py
# When running this tutorial in Google Colab, install the required packages
# with the following.
# !pip install torchaudio librosa

import torch
import torchaudio
import torchaudio.transforms as T

print(torch.__version__)
print(torchaudio.__version__) 
```

```py
2.2.0
2.2.0 
```

## 准备工作

```py
import librosa
import matplotlib.pyplot as plt
from IPython.display import Audio
from torchaudio.utils import download_asset 
```

在本教程中，我们将使用来自[VOiCES 数据集](https://iqtlabs.github.io/voices/)的语音数据，该数据集在 Creative Commos BY 4.0 许可下发布。

```py
SAMPLE_WAV_SPEECH_PATH = download_asset("tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav")

def _get_sample(path, resample=None):
    effects = [["remix", "1"]]
    if resample:
        effects.extend(
            [
                ["lowpass", f"{resample  //  2}"],
                ["rate", f"{resample}"],
            ]
        )
    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)

def get_speech_sample(*, resample=None):
    return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)

def get_spectrogram(
    n_fft=400,
    win_len=None,
    hop_len=None,
    power=2.0,
):
    waveform, _ = get_speech_sample()
    spectrogram = T.Spectrogram(
        n_fft=n_fft,
        win_length=win_len,
        hop_length=hop_len,
        center=True,
        pad_mode="reflect",
        power=power,
    )
    return spectrogram(waveform) 
```

## SpecAugment

[SpecAugment](https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html) 是一种流行的频谱图增强技术。

`torchaudio` 实现了 `torchaudio.transforms.TimeStretch()`、`torchaudio.transforms.TimeMasking()` 和 `torchaudio.transforms.FrequencyMasking()`。

## TimeStretch

```py
spec = get_spectrogram(power=None)
stretch = T.TimeStretch()

spec_12 = stretch(spec, overriding_rate=1.2)
spec_09 = stretch(spec, overriding_rate=0.9) 
```

### 可视化

```py
def plot():
    def plot_spec(ax, spec, title):
        ax.set_title(title)
        ax.imshow(librosa.amplitude_to_db(spec), origin="lower", aspect="auto")

    fig, axes = plt.subplots(3, 1, sharex=True, sharey=True)
    plot_spec(axes[0], torch.abs(spec_12[0]), title="Stretched x1.2")
    plot_spec(axes[1], torch.abs(spec[0]), title="Original")
    plot_spec(axes[2], torch.abs(spec_09[0]), title="Stretched x0.9")
    fig.tight_layout()

plot() 
```

![拉伸 x1.2，原始，拉伸 x0.9](img/2d28a63fd3c52fb5175ba466b3a427ae.png)

### 音频样本

```py
def preview(spec, rate=16000):
    ispec = T.InverseSpectrogram()
    waveform = ispec(spec)

    return Audio(waveform[0].numpy().T, rate=rate)

preview(spec) 
```

您的浏览器不支持音频元素。

```py
preview(spec_12) 
```

您的浏览器不支持音频元素。

```py
preview(spec_09) 
```

您的浏览器不支持音频元素。

## 时间和频率遮蔽

```py
torch.random.manual_seed(4)

time_masking = T.TimeMasking(time_mask_param=80)
freq_masking = T.FrequencyMasking(freq_mask_param=80)

spec = get_spectrogram()
time_masked = time_masking(spec)
freq_masked = freq_masking(spec) 
```

```py
def plot():
    def plot_spec(ax, spec, title):
        ax.set_title(title)
        ax.imshow(librosa.power_to_db(spec), origin="lower", aspect="auto")

    fig, axes = plt.subplots(3, 1, sharex=True, sharey=True)
    plot_spec(axes[0], spec[0], title="Original")
    plot_spec(axes[1], time_masked[0], title="Masked along time axis")
    plot_spec(axes[2], freq_masked[0], title="Masked along frequency axis")
    fig.tight_layout()

plot() 
```

![原始，沿时间轴遮蔽，沿频率轴遮蔽](img/dfd47c6272905af9b424d7f0d4c7d9b6.png)

**脚本的总运行时间：**（0 分钟 2.241 秒）

`下载 Python 源代码：audio_feature_augmentation_tutorial.py`

`下载 Jupyter 笔记本：audio_feature_augmentation_tutorial.ipynb`

[Sphinx-Gallery 生成的画廊](https://sphinx-gallery.github.io)
