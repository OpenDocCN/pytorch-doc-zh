# 使用 CUDA CTC 解码器进行 ASR 推理

> 原文：[`pytorch.org/audio/stable/tutorials/asr_inference_with_cuda_ctc_decoder_tutorial.html`](https://pytorch.org/audio/stable/tutorials/asr_inference_with_cuda_ctc_decoder_tutorial.html)
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


注意

点击这里下载完整示例代码

作者：Yuekai Zhang

本教程展示了如何使用基于 CUDA 的 CTC 波束搜索解码器执行语音识别推理。我们在来自[Next-gen Kaldi](https://nadirapovey.com/next-gen-kaldi-what-is-it)项目的预训练[Zipformer](https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless7_ctc)模型上演示了这一点。

## 概述

波束搜索解码通过迭代地扩展文本假设（波束）与下一个可能的字符，并在每个时间步仅保留得分最高的假设来工作。

底层实现使用 cuda 来加速整个解码过程

解码器的数学公式可以是

在[论文](https://arxiv.org/pdf/1408.2873.pdf)中找到，并且更详细的算法可以在这个[博客](https://distill.pub/2017/ctc/)中找到。

使用 CUDA CTC 波束搜索解码器运行 ASR 推理需要以下组件

+   声学模型：从声学特征预测建模单元（本教程中为 BPE）的模型

+   BPE 模型：字节对编码（BPE）分词器文件

## 声学模型和设置

首先，我们导入必要的工具并获取我们要处理的数据

```py
import torch
import torchaudio

print(torch.__version__)
print(torchaudio.__version__) 
```

```py
2.2.0
2.2.0 
```

```py
import time
from pathlib import Path

import IPython
import sentencepiece as spm
from torchaudio.models.decoder import cuda_ctc_decoder
from torchaudio.utils import download_asset 
```

我们使用预训练的[Zipformer](https://huggingface.co/Zengwei/icefall-asr-librispeech-pruned-transducer-stateless7-ctc-2022-12-01)模型，该模型在[LibriSpeech 数据集](http://www.openslr.org/12)上进行了训练。该模型同时使用 CTC 和 Transducer 损失函数进行训练。在本教程中，我们仅使用模型的 CTC 头部。

```py
def download_asset_external(url, key):
    path = Path(torch.hub.get_dir()) / "torchaudio" / Path(key)
    if not path.exists():
        path.parent.mkdir(parents=True, exist_ok=True)
        torch.hub.download_url_to_file(url, path)
    return str(path)

url_prefix = "https://huggingface.co/Zengwei/icefall-asr-librispeech-pruned-transducer-stateless7-ctc-2022-12-01"
model_link = f"{url_prefix}/resolve/main/exp/cpu_jit.pt"
model_path = download_asset_external(model_link, "cuda_ctc_decoder/cpu_jit.pt") 
```

```py
 0%|          | 0.00/269M [00:00<?, ?B/s]
  4%|3         | 10.1M/269M [00:00<00:03, 78.9MB/s]
  9%|9         | 25.0M/269M [00:00<00:05, 49.1MB/s]
 18%|#8        | 49.6M/269M [00:00<00:02, 96.3MB/s]
 23%|##3       | 63.0M/269M [00:00<00:03, 67.8MB/s]
 28%|##7       | 74.9M/269M [00:01<00:03, 56.8MB/s]
 31%|###       | 83.4M/269M [00:01<00:03, 59.6MB/s]
 37%|###7      | 99.9M/269M [00:01<00:03, 48.1MB/s]
 39%|###9      | 106M/269M [00:02<00:05, 33.3MB/s]
 46%|####5     | 123M/269M [00:02<00:03, 48.0MB/s]
 48%|####8     | 130M/269M [00:02<00:03, 37.5MB/s]
 54%|#####3    | 145M/269M [00:02<00:02, 51.5MB/s]
 57%|#####6    | 153M/269M [00:03<00:03, 35.0MB/s]
 63%|######3   | 170M/269M [00:03<00:02, 49.3MB/s]
 66%|######6   | 178M/269M [00:04<00:03, 26.8MB/s]
 72%|#######1  | 194M/269M [00:04<00:02, 37.6MB/s]
 75%|#######4  | 201M/269M [00:05<00:02, 30.5MB/s]
 77%|#######6  | 207M/269M [00:05<00:02, 31.4MB/s]
 82%|########2 | 222M/269M [00:05<00:01, 45.5MB/s]
 85%|########5 | 230M/269M [00:05<00:01, 33.0MB/s]
 88%|########7 | 236M/269M [00:05<00:00, 35.8MB/s]
 93%|#########2| 250M/269M [00:06<00:00, 33.8MB/s]
 97%|#########7| 262M/269M [00:06<00:00, 44.9MB/s]
100%|#########9| 269M/269M [00:06<00:00, 34.9MB/s]
100%|##########| 269M/269M [00:06<00:00, 41.1MB/s] 
```

我们将从 LibriSpeech 测试其他数据集中加载一个样本。

```py
speech_file = download_asset("tutorial-assets/ctc-decoding/1688-142285-0007.wav")
waveform, sample_rate = torchaudio.load(speech_file)
assert sample_rate == 16000
IPython.display.Audio(speech_file) 
```

```py
 0%|          | 0.00/441k [00:00<?, ?B/s]
100%|##########| 441k/441k [00:00<00:00, 83.3MB/s] 
```

您的浏览器不支持音频元素。

与此音频文件对应的抄本是

```py
i really was very much afraid of showing him how much shocked i was at some parts of what he said 
```

## 解码器的文件和数据

接下来，我们从 BPE 模型中加载我们的标记，这是用于解码的分词器。

### 标记

标记是声学模型可以预测的可能符号，包括 CTC 中的空白符号。在本教程中，它包括 500 个 BPE 标记。它可以作为文件传入，其中每行包含与相同索引对应的标记，或作为标记列表传入，每个标记映射到一个唯一的索引。

```py
# tokens
<blk>
<sos/eos>
<unk>
S
_THE
_A
T
_AND
... 
```

```py
bpe_link = f"{url_prefix}/resolve/main/data/lang_bpe_500/bpe.model"
bpe_path = download_asset_external(bpe_link, "cuda_ctc_decoder/bpe.model")

bpe_model = spm.SentencePieceProcessor()
bpe_model.load(bpe_path)
tokens = [bpe_model.id_to_piece(id) for id in range(bpe_model.get_piece_size())]
print(tokens) 
```

```py
 0%|          | 0.00/239k [00:00<?, ?B/s]
100%|##########| 239k/239k [00:00<00:00, 63.9MB/s]
['<blk>', '<sos/eos>', '<unk>', 'S', '▁THE', '▁A', 'T', '▁AND', 'ED', '▁OF', '▁TO', 'E', 'D', 'N', 'ING', '▁IN', 'Y', 'M', 'C', '▁I', 'A', 'P', '▁HE', 'R', 'O', 'L', 'RE', 'I', 'U', 'ER', '▁IT', 'LY', '▁THAT', '▁WAS', '▁', '▁S', 'AR', '▁BE', 'F', '▁C', 'IN', 'B', '▁FOR', 'OR', 'LE', "'", '▁HIS', '▁YOU', 'AL', '▁RE', 'V', '▁B', 'G', 'RI', '▁E', '▁WITH', '▁T', '▁AS', 'LL', '▁P', '▁HER', 'ST', '▁HAD', '▁SO', '▁F', 'W', 'CE', '▁IS', 'ND', '▁NOT', 'TH', '▁BUT', 'EN', '▁SHE', '▁ON', 'VE', 'ON', 'SE', '▁DE', 'UR', '▁G', 'CH', 'K', 'TER', '▁AT', 'IT', '▁ME', 'RO', 'NE', 'RA', 'ES', 'IL', 'NG', 'IC', '▁NO', '▁HIM', 'ENT', 'IR', '▁WE', 'H', '▁DO', '▁ALL', '▁HAVE', 'LO', '▁BY', '▁MY', '▁MO', '▁THIS', 'LA', '▁ST', '▁WHICH', '▁CON', '▁THEY', 'CK', 'TE', '▁SAID', '▁FROM', '▁GO', '▁WHO', '▁TH', '▁OR', '▁D', '▁W', 'VER', 'LI', '▁SE', '▁ONE', '▁CA', '▁AN', '▁LA', '▁WERE', 'EL', '▁HA', '▁MAN', '▁FA', '▁EX', 'AD', '▁SU', 'RY', '▁MI', 'AT', '▁BO', '▁WHEN', 'AN', 'THER', 'PP', 'ATION', '▁FI', '▁WOULD', '▁PRO', 'OW', 'ET', '▁O', '▁THERE', '▁HO', 'ION', '▁WHAT', '▁FE', '▁PA', 'US', 'MENT', '▁MA', 'UT', '▁OUT', '▁THEIR', '▁IF', '▁LI', '▁K', '▁WILL', '▁ARE', 'ID', '▁RO', 'DE', 'TION', '▁WA', 'PE', '▁UP', '▁SP', '▁PO', 'IGHT', '▁UN', 'RU', '▁LO', 'AS', 'OL', '▁LE', '▁BEEN', '▁SH', '▁RA', '▁SEE', 'KE', 'UL', 'TED', '▁SA', 'UN', 'UND', 'ANT', '▁NE', 'IS', '▁THEM', 'CI', 'GE', '▁COULD', '▁DIS', 'OM', 'ISH', 'HE', 'EST', '▁SOME', 'ENCE', 'ITY', 'IVE', '▁US', '▁MORE', '▁EN', 'ARD', 'ATE', '▁YOUR', '▁INTO', '▁KNOW', '▁CO', 'ANCE', '▁TIME', '▁WI', '▁YE', 'AGE', '▁NOW', 'TI', 'FF', 'ABLE', '▁VERY', '▁LIKE', 'AM', 'HI', 'Z', '▁OTHER', '▁THAN', '▁LITTLE', '▁DID', '▁LOOK', 'TY', 'ERS', '▁CAN', '▁CHA', '▁AR', 'X', 'FUL', 'UGH', '▁BA', '▁DAY', '▁ABOUT', 'TEN', 'IM', '▁ANY', '▁PRE', '▁OVER', 'IES', 'NESS', 'ME', 'BLE', '▁M', 'ROW', '▁HAS', '▁GREAT', '▁VI', 'TA', '▁AFTER', 'PER', '▁AGAIN', 'HO', 'SH', '▁UPON', '▁DI', '▁HAND', '▁COM', 'IST', 'TURE', '▁STA', '▁THEN', '▁SHOULD', '▁GA', 'OUS', 'OUR', '▁WELL', '▁ONLY', 'MAN', '▁GOOD', '▁TWO', '▁MAR', '▁SAY', '▁HU', 'TING', '▁OUR', 'RESS', '▁DOWN', 'IOUS', '▁BEFORE', '▁DA', '▁NA', 'QUI', '▁MADE', '▁EVERY', '▁OLD', '▁EVEN', 'IG', '▁COME', '▁GRA', '▁RI', '▁LONG', 'OT', 'SIDE', 'WARD', '▁FO', '▁WHERE', 'MO', 'LESS', '▁SC', '▁MUST', '▁NEVER', '▁HOW', '▁CAME', '▁SUCH', '▁RU', '▁TAKE', '▁WO', '▁CAR', 'UM', 'AK', '▁THINK', '▁MUCH', '▁MISTER', '▁MAY', '▁JO', '▁WAY', '▁COMP', '▁THOUGHT', '▁STO', '▁MEN', '▁BACK', '▁DON', 'J', '▁LET', '▁TRA', '▁FIRST', '▁JUST', '▁VA', '▁OWN', '▁PLA', '▁MAKE', 'ATED', '▁HIMSELF', '▁WENT', '▁PI', 'GG', 'RING', '▁DU', '▁MIGHT', '▁PART', '▁GIVE', '▁IMP', '▁BU', '▁PER', '▁PLACE', '▁HOUSE', '▁THROUGH', 'IAN', '▁SW', '▁UNDER', 'QUE', '▁AWAY', '▁LOVE', 'QUA', '▁LIFE', '▁GET', '▁WITHOUT', '▁PASS', '▁TURN', 'IGN', '▁HEAD', '▁MOST', '▁THOSE', '▁SHALL', '▁EYES', '▁COL', '▁STILL', '▁NIGHT', '▁NOTHING', 'ITION', 'HA', '▁TELL', '▁WORK', '▁LAST', '▁NEW', '▁FACE', '▁HI', '▁WORD', '▁FOUND', '▁COUNT', '▁OB', '▁WHILE', '▁SHA', '▁MEAN', '▁SAW', '▁PEOPLE', '▁FRIEND', '▁THREE', '▁ROOM', '▁SAME', '▁THOUGH', '▁RIGHT', '▁CHILD', '▁FATHER', '▁ANOTHER', '▁HEART', '▁WANT', '▁TOOK', 'OOK', '▁LIGHT', '▁MISSUS', '▁OPEN', '▁JU', '▁ASKED', 'PORT', '▁LEFT', '▁JA', '▁WORLD', '▁HOME', '▁WHY', '▁ALWAYS', '▁ANSWER', '▁SEEMED', '▁SOMETHING', '▁GIRL', '▁BECAUSE', '▁NAME', '▁TOLD', '▁NI', '▁HIGH', 'IZE', '▁WOMAN', '▁FOLLOW', '▁RETURN', '▁KNEW', '▁EACH', '▁KIND', '▁JE', '▁ACT', '▁LU', '▁CERTAIN', '▁YEARS', '▁QUITE', '▁APPEAR', '▁BETTER', '▁HALF', '▁PRESENT', '▁PRINCE', 'SHIP', '▁ALSO', '▁BEGAN', '▁HAVING', '▁ENOUGH', '▁PERSON', '▁LADY', '▁WHITE', '▁COURSE', '▁VOICE', '▁SPEAK', '▁POWER', '▁MORNING', '▁BETWEEN', '▁AMONG', '▁KEEP', '▁WALK', '▁MATTER', '▁TEA', '▁BELIEVE', '▁SMALL', '▁TALK', '▁FELT', '▁HORSE', '▁MYSELF', '▁SIX', '▁HOWEVER', '▁FULL', '▁HERSELF', '▁POINT', '▁STOOD', '▁HUNDRED', '▁ALMOST', '▁SINCE', '▁LARGE', '▁LEAVE', '▁PERHAPS', '▁DARK', '▁SUDDEN', '▁REPLIED', '▁ANYTHING', '▁WONDER', '▁UNTIL', 'Q'] 
```

## 构建 CUDA 解码器

在本教程中，我们将构建一个 CUDA 波束搜索解码器。可以使用工厂函数`cuda_ctc_decoder()`来构建解码器。

```py
cuda_decoder = cuda_ctc_decoder(tokens, nbest=10, beam_size=10, blank_skip_threshold=0.95) 
```

## 运行推理

现在我们有了数据、声学模型和解码器，我们可以执行推理。波束搜索解码器的输出类型为`CUCTCHypothesis`，包括预测的标记 ID、单词（与标记 ID 对应的符号）和假设分数。回想一下与波形对应的抄本是

```py
i really was very much afraid of showing him how much shocked i was at some parts of what he said 
```

```py
actual_transcript = "i really was very much afraid of showing him how much shocked i was at some parts of what he said"
actual_transcript = actual_transcript.split()

device = torch.device("cuda", 0)
acoustic_model = torch.jit.load(model_path)
acoustic_model.to(device)
acoustic_model.eval()

waveform = waveform.to(device)

feat = torchaudio.compliance.kaldi.fbank(waveform, num_mel_bins=80, snip_edges=False)
feat = feat.unsqueeze(0)
feat_lens = torch.tensor(feat.size(1), device=device).unsqueeze(0)

encoder_out, encoder_out_lens = acoustic_model.encoder(feat, feat_lens)
nnet_output = acoustic_model.ctc_output(encoder_out)
log_prob = torch.nn.functional.log_softmax(nnet_output, -1)

print(f"The shape of log_prob: {log_prob.shape}, the shape of encoder_out_lens: {encoder_out_lens.shape}") 
```

```py
The shape of log_prob: torch.Size([1, 175, 500]), the shape of encoder_out_lens: torch.Size([1]) 
```

cuda ctc 解码器给出以下结果。

```py
results = cuda_decoder(log_prob, encoder_out_lens.to(torch.int32))
beam_search_transcript = bpe_model.decode(results[0][0].tokens).lower()
beam_search_wer = torchaudio.functional.edit_distance(actual_transcript, beam_search_transcript.split()) / len(
    actual_transcript
)

print(f"Transcript: {beam_search_transcript}")
print(f"WER: {beam_search_wer}") 
```

```py
Transcript: i really was very much afraid of showing him how much shocked i was at some parts of what he said
WER: 0.0 
```

## 波束搜索解码器参数

在本节中，我们将更深入地讨论一些不同参数和权衡。有关可自定义参数的完整列表，请参考`文档`。

### 辅助函数

```py
def print_decoded(cuda_decoder, bpe_model, log_prob, encoder_out_lens, param, param_value):
    start_time = time.monotonic()
    results = cuda_decoder(log_prob, encoder_out_lens.to(torch.int32))
    decode_time = time.monotonic() - start_time
    transcript = bpe_model.decode(results[0][0].tokens).lower()
    score = results[0][0].score
    print(f"{param}  {param_value:<3}: {transcript} (score: {score:.2f}; {decode_time:.4f} secs)") 
```

### nbest

此参数表示要返回的最佳假设数量。例如，在之前构建波束搜索解码器时设置 `nbest=10`，现在我们可以访问得分前 10 名的假设。

```py
for i in range(10):
    transcript = bpe_model.decode(results[0][i].tokens).lower()
    score = results[0][i].score
    print(f"{transcript} (score: {score})") 
```

```py
i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.2029460221529007)
i really was very much afraid of showing him how much shocked i was at some part of what he said (score: -1.7402369976043701)
i really was very much afraid of sheowing him how much shocked i was at some parts of what he said (score: -6.679358005523682)
i reallyly very much afraid of showing him how much shocked i was at some parts of what he said (score: -7.596949577331543)
i really was very much afraid of sheowing him how much shocked i was at some part of what he said (score: -8.223165512084961)
i really was very much afraid of shwing him how much shocked i was at some parts of what he said (score: -8.439875602722168)
i really was very much afraid of showing him how much shocked i was in some parts of what he said (score: -8.782379150390625)
i really was very much afraid of showing him how much shocked i was at some parts of what said (score: -8.884151458740234)
i really was very much afraid of showing him how much shocked i was at some partes of what he said (score: -8.999359130859375)
i really was very much afraid of showing him how much shocked i was at some parts of what he say (score: -9.138347625732422) 
```

### 波束大小

`beam_size`参数确定每个解码步骤后保留的最佳假设数量上限。使用更大的波束大小可以探索更广泛的可能假设范围，这可以产生得分更高的假设，但在一定程度上不会提供额外的收益。我们建议为 cuda 波束搜索解码器设置`beam_size=10`。

在下面的示例中，我们可以看到随着波束大小从 1 增加到 3，解码质量有所提高，但请注意，使用波束大小为 3 时提供与波束大小为 10 相同的输出。

```py
beam_sizes = [1, 2, 3, 10]

for beam_size in beam_sizes:
    beam_search_decoder = cuda_ctc_decoder(
        tokens,
        nbest=1,
        beam_size=beam_size,
        blank_skip_threshold=0.95,
    )
    print_decoded(beam_search_decoder, bpe_model, log_prob, encoder_out_lens, "beam size", beam_size) 
```

```py
beam size 1  : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -1.35; 0.0009 secs)
beam size 2  : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.21; 0.0009 secs)
beam size 3  : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.20; 0.0009 secs)
beam size 10 : i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.20; 0.0010 secs) 
```

### blank skip threshold

`blank_skip_threshold`参数用于修剪具有较大空白概率的帧。使用良好的`blank_skip_threshold`修剪这些帧可以大大加快解码过程，而不会降低准确性。根据 CTC 规则，我们应至少在两个非空白帧之间保留一个空白帧，以避免错误地合并两个连续相同的符号。我们建议为 cuda 波束搜索解码器设置`blank_skip_threshold=0.95`。

```py
blank_skip_probs = [0.25, 0.95, 1.0]

for blank_skip_prob in blank_skip_probs:
    beam_search_decoder = cuda_ctc_decoder(
        tokens,
        nbest=10,
        beam_size=10,
        blank_skip_threshold=blank_skip_prob,
    )
    print_decoded(beam_search_decoder, bpe_model, log_prob, encoder_out_lens, "blank_skip_threshold", blank_skip_prob)

del cuda_decoder 
```

```py
blank_skip_threshold 0.25: i really was very much afraid of showing him how much shocked i was at some part of what he said (score: -0.01; 0.0009 secs)
blank_skip_threshold 0.95: i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.20; 0.0010 secs)
blank_skip_threshold 1.0: i really was very much afraid of showing him how much shocked i was at some parts of what he said (score: -0.21; 0.0043 secs) 
```

## 使用手电筒 CPU 解码器进行基准测试

我们使用 librispeech test_other 数据集对 CUDA 解码器和 CPU 解码器之间的吞吐量和准确性进行基准测试。要重现下面的基准测试结果，您可以参考[这里](https://github.com/pytorch/audio/tree/main/examples/asr/librispeech_cuda_ctc_decoder)。

| 解码器 | 设置 | WER (%) | N-Best Oracle WER (%) | 解码器成本时间 (秒) |
| --- | --- | --- | --- | --- |
| CUDA 解码器 | blank_skip_threshold 0.95 | 5.81 | 4.11 | 2.57 |
| CUDA 解码器 | blank_skip_threshold 1.0 (无帧跳过) | 5.81 | 4.09 | 6.24 |
| CPU 解码器 | beam_size_token 10 | 5.86 | 4.30 | 28.61 |
| CPU 解码器 | beam_size_token 500 | 5.86 | 4.30 | 791.80 |

从上表中可以看出，CUDA 解码器在 WER 方面略有改善，并且吞吐量显著增加。

**脚本的总运行时间:** ( 0 分钟 8.752 秒)

`下载 Python 源代码: asr_inference_with_cuda_ctc_decoder_tutorial.py`

`下载 Jupyter 笔记本: asr_inference_with_cuda_ctc_decoder_tutorial.ipynb`

[Sphinx-Gallery 生成的图库](https://sphinx-gallery.github.io)
