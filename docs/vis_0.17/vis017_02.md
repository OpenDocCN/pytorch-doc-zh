# 转换和增强图像

> 无论您是新手还是已经熟悉 Torchvision 转换，我们鼓励您从开始使用转换 v2 开始，以了解新的 v2 转换可以做什么。

原文：[`pytorch.org/vision/stable/transforms.html`](https://pytorch.org/vision/stable/transforms.html)

```py
# Image Classification
import torch
from torchvision.transforms import v2

H, W = 32, 32
img = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8)

transforms = v2.Compose([
    v2.RandomResizedCrop(size=(224, 224), antialias=True),
    v2.RandomHorizontalFlip(p=0.5),
    v2.ToDtype(torch.float32, scale=True),
    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
img = transforms(img) 
```

```py
# Detection (re-using imports and transforms from above)
from torchvision import tv_tensors

img = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8)
boxes = torch.randint(0, H // 2, size=(3, 4))
boxes[:, 2:] += boxes[:, :2]
boxes = tv_tensors.BoundingBoxes(boxes, format="XYXY", canvas_size=(H, W))

# The same transforms can be used!
img, boxes = transforms(img, boxes)
# And you can pass arbitrary input structures
output_dict = transforms({"image": img, "boxes": boxes}) 
```

Torchvision 支持在`torchvision.transforms`和`torchvision.transforms.v2`模块中的常见计算机视觉转换。转换可用于转换或增强数据，用于不同任务的训练或推断（图像分类、检测、分割、视频分类）。

## 转换通常作为`transform`或`transforms`参数传递给数据集。开始阅读[](#start-here "Permalink to this heading")

然后，浏览本页下面的部分以获取一般信息和性能提示。可在 API 参考中列出可用的转换和功能。

## V1 还是 V2？我应该使用哪个？

更多信息和教程也可以在我们的示例库中找到，例如转换 v2：端到端目标检测/分割示例或如何编写自己的 v2 转换。

## 支持的输入类型和约定

大多数转换接受[PIL](https://pillow.readthedocs.io)图像和张量输入。支持 CPU 和 CUDA 张量。两个后端（PIL 或张量）的结果应该非常接近。一般来说，我们建议依赖张量后端以获得更好的性能。转换转换可用于转换为 PIL 图像，或用于转换 dtype 和范围。

张量图像的形状应为`(C, H, W)`，其中`C`是通道数，`H`和`W`分别是高度和宽度。大多数转换支持批量张量输入。一批张量图像是形状为`(N, C, H, W)`的张量，其中`N`是批量中的图像数量。v2 转换通常接受任意数量的前导维度`(..., C, H, W)`，并且可以处理批量图像或批量视频。

### Dtype 和预期值范围

张量图像的值的预期范围由张量 dtype 隐式定义。具有浮点 dtype 的张量图像的值应在`[0, 1]`范围内。具有整数 dtype 的张量图像的值应在`[0, MAX_DTYPE]`范围内，其中`MAX_DTYPE`是该 dtype 中可以表示的最大值。通常，dtype 为`torch.uint8`的图像的值应在`[0, 255]`范围内。

使用`ToDtype`来转换输入的 dtype 和范围。

**TL;DR** 我们建议使用`torchvision.transforms.v2`转换，而不是`torchvision.transforms`中的转换。它们更快，功能更强大。只需更改导入，您就可以开始使用。未来，新功能和改进将仅考虑 v2 转换。

在 Torchvision 0.15（2023 年 3 月）中，我们发布了一组新的转换，可在`torchvision.transforms.v2`命名空间中使用。与 v1 中的转换相比，这些转换具有许多优势：

+   它们可以转换图像**还可以**边界框、蒙版或视频。这为超出图像分类的任务提供了支持：检测、分割、视频分类等。请参阅开始使用转换 v2 和转换 v2：端到端目标检测/分割示例。

+   它们支持更多的转换，如`CutMix`和`MixUp`。请参阅如何使用 CutMix 和 MixUp。

+   它们更快(#transforms-perf)。

+   它们支持任意输入结构（字典、列表、元组等）。

+   未来的改进和功能将仅添加到 v2 转换中。

这些转换与 v1 版本完全兼容，因此如果您已经使用`torchvision.transforms`中的转换，您只需要更新导入为`torchvision.transforms.v2`。在输出方面，由于实现差异可能会有微不足道的差异。##性能考虑[](#performance-considerations "跳转到此标题的永久链接")

我们建议以下准则以获得最佳性能：

+   依赖于`torchvision.transforms.v2`中的 v2 转换

+   使用张量而不是 PIL 图像

+   使用`torch.uint8`数据类型，特别是用于调整大小

+   使用双线性或双三次插值模式调整大小

这是一个典型的转换流水线可能看起来像：

```py
from torchvision.transforms import v2
transforms = v2.Compose([
    v2.ToImage(),  # Convert to tensor, only needed if you had a PIL image
    v2.ToDtype(torch.uint8, scale=True),  # optional, most input are already uint8 at this point
    # ...
    v2.RandomResizedCrop(size=(224, 224), antialias=True),  # Or Resize(antialias=True)
    # ...
    v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input
    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
]) 
```

上述内容应该为依赖于`torch.utils.data.DataLoader`（https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader "(在 PyTorch v2.2 中)")且`num_workers > 0`的典型训练环境提供最佳性能。

转换往往对输入步幅/内存格式敏感。一些转换在通道优先图像上速度更快，而其他转换则更喜欢通道最后。与`torch`操作符一样，大多数转换将保留输入的内存格式，但由于实现细节，这并不总是被尊重。如果您追求最佳性能，您可能需要进行一些实验。在单个转换上使用[`torch.compile()`](https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile "(在 PyTorch v2.2 中)")也有助于分解内存格式变量（例如在`Normalize`上）。请注意，我们谈论的是**内存格式**，而不是张量形状。

请注意，像`Resize`和`RandomResizedCrop`这样的调整大小转换通常更喜欢通道最后的输入，并且目前**不**受益于[`torch.compile()`](https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile "(在 PyTorch v2.2 中)")。##转换类、功能和内核[](#transform-classes-functionals-and-kernels "跳转到此标题的永久链接")

转换可作为类（`Resize`）和 functionals（`resize()`）在`torchvision.transforms.v2.functional`命名空间中。这与[`torch.nn`](https://pytorch.org/docs/stable/nn.html#module-torch.nn "(在 PyTorch v2.2)")包非常相似，后者在[`torch.nn.functional`](https://pytorch.org/docs/stable/nn.html#module-torch.nn.functional "(在 PyTorch v2.2)")中定义了类和功能等效项。

functionals 支持 PIL 图像、纯张量或 TVTensors，例如`resize(image_tensor)`和`resize(boxes)`都是有效的。

注意

像`RandomCrop`这样的随机转换每次调用时都会随机抽样一些参数。它们的功能对应项（`crop()`）不进行任何随机抽样，因此具有略有不同的参数化。当使用功能 API 时，可以使用 transforms 类的`get_params()`类方法执行参数抽样。

`torchvision.transforms.v2.functional`命名空间还包含我们称之为“内核”的内容。这些是实现特定类型的核心功能的低级函数，例如`resize_bounding_boxes`或`resized_crop_mask`。它们是公开的，尽管没有文档记录。查看[代码](https://github.com/pytorch/vision/blob/main/torchvision/transforms/v2/functional/__init__.py)以查看可用的函数（请注意，以下划线开头的函数**不**是公开的！）。如果您想要对像边界框或掩码这样的类型进行 torchscript 支持，内核才真正有用。## Torchscript 支持[](#torchscript-support "跳转到此标题")

大多数转换类和 functionals 都支持 torchscript。对于组合转换，请使用[`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential "(在 PyTorch v2.2)")而不是`Compose`：

```py
transforms = torch.nn.Sequential(
    CenterCrop(10),
    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
)
scripted_transforms = torch.jit.script(transforms) 
```

警告

v2 转换支持 torchscript，但是如果您在 v2 **类**转换上调用`torch.jit.script()`，实际上会得到其（脚本化的）v1 等效项。由于 v1 和 v2 之间的实现差异，这可能导致脚本化和急切执行之间略有不同的结果。

如果您真的需要 v2 转换的 torchscript 支持，我们建议对`torchvision.transforms.v2.functional`命名空间中的**functionals**进行脚本化，以避免意外。

还要注意，functionals 仅支持纯张量的 torchscript，这些张量始终被视为图像。如果您需要对像边界框或掩码等其他类型进行 torchscript 支持，可以依赖于低级内核。

对于要与`torch.jit.script`一起使用的自定义转换，它们应该派生自`torch.nn.Module`。

另请参阅：Torchscript 支持。## V2 API 参考-推荐[](#v2-api-reference-recommended "跳转到此标题")

### 几何[](#geometry "跳转到此标题")

#### 调整大小[](#resizing "跳转到此标题")

| `v2.Resize`(size[, interpolation, max_size, ...]) | 将输入调整为给定大小。 |
| --- | --- |
| `v2.ScaleJitter`(target_size[, scale_range, ...]) | 根据["Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation"](https://arxiv.org/abs/2012.07177)对输入执行大规模抖动。 |
| `v2.RandomShortestSize`(min_size[, max_size, ...]) | 随机调整输入大小。 |
| `v2.RandomResize`(min_size, max_size[, ...]) | 随机调整输入大小。 |

功能

| `v2.functional.resize`(inpt, size[, ...]) | 详细信息请参见`Resize`。 |
| --- | --- |

#### 裁剪[](#cropping "跳转到此标题")

| `v2.RandomCrop`(size[, padding, ...]) | 在随机位置裁剪输入。 |
| --- | --- |
| `v2.RandomResizedCrop`(size[, scale, ratio, ...]) | 对输入进行随机裁剪并调整大小到给定大小。 |
| `v2.RandomIoUCrop`([min_scale, max_scale, ...]) | 来自["SSD: Single Shot MultiBox Detector"](https://arxiv.org/abs/1512.02325)的随机 IoU 裁剪转换。 |
| `v2.CenterCrop`(size) | 在中心裁剪输入。 |
| `v2.FiveCrop`(size) | 将图像或视频裁剪成四个角和中心裁剪。 |
| `v2.TenCrop`(size[, vertical_flip]) | 将图像或视频裁剪成四个角和中心裁剪以及这些的翻转版本（默认使用水平翻转）。 |

功能

| `v2.functional.crop`(inpt, top, left, height, ...) | 详细信息请参见`RandomCrop`。 |
| --- | --- |
| `v2.functional.resized_crop`(inpt, top, left, ...) | 详细信息请参见`RandomResizedCrop`。 |
| `v2.functional.ten_crop`(inpt, size[, ...]) | 查看详细信息，请参阅`TenCrop`。 |
| `v2.functional.center_crop`(inpt, output_size) | 查看详细信息，请参阅`RandomCrop`。 |
| `v2.functional.five_crop`(inpt, size) | 查看详细信息，请参阅`FiveCrop`。 |

#### 其他[](#others "跳转到此标题")

| `v2.RandomHorizontalFlip`([p]) | 按给定概率水平翻转输入。 |
| --- | --- |
| `v2.RandomVerticalFlip`([p]) | 按给定概率垂直翻转输入。 |
| `v2.Pad`(padding[, fill, padding_mode]) | 使用给定的“pad”值在所有边上填充输入。 |
| `v2.RandomZoomOut`([fill, side_range, p]) | 来自["SSD: Single Shot MultiBox Detector"](https://arxiv.org/abs/1512.02325)的"缩小"变换。 |
| `v2.RandomRotation`(degrees[, interpolation, ...]) | 将输入旋转指定角度。 |
| `v2.RandomAffine`(degrees[, translate, scale, ...]) | 随机仿射变换输入，保持中心不变。 |
| `v2.RandomPerspective`([distortion_scale, p, ...]) | 按给定概率对输入执行随机透视变换。 |
| `v2.ElasticTransform`([alpha, sigma, ...]) | 使用弹性变换对输入进行变换。 |

功能函数

| `v2.functional.horizontal_flip`(inpt) | 查看详细信息，请参阅`RandomHorizontalFlip`。 |
| --- | --- |
| `v2.functional.vertical_flip`(inpt) | 查看`RandomVerticalFlip`获取详细信息。 |
| `v2.functional.pad`(inpt, padding[, fill, ...]) | 查看`Pad`获取详细信息。 |
| `v2.functional.rotate`(inpt, angle[, ...]) | 查看`RandomRotation`获取详细信息。 |
| `v2.functional.affine`(inpt, angle, translate, ...) | 查看`RandomAffine`获取详细信息。 |
| `v2.functional.perspective`(inpt, startpoints, ...) | 查看`RandomPerspective`获取详细信息。 |
| `v2.functional.elastic`(inpt, displacement[, ...]) | 查看`ElasticTransform`获取详细信息。 |

### Color[](#color "Permalink to this heading")

| `v2.ColorJitter`([brightness, contrast, ...]) | 随机改变图像或视频的亮度、对比度、饱和度和色调。 |
| --- | --- |
| `v2.RandomChannelPermutation`() | 随机排列图像或视频的通道。 |
| `v2.RandomPhotometricDistort`([brightness, ...]) | 随机扭曲图像或视频，如[SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325)中所使用的。 |
| `v2.Grayscale`([num_output_channels]) | 将图像或视频转换为灰度图像。 |
| `v2.RandomGrayscale`([p]) | 随机将图像或视频转换为灰度图像，概率为 p（默认为 0.1）。 |
| `v2.GaussianBlur`(kernel_size[, sigma]) | 使用随机选择的高斯模糊对图像进行模糊处理。 |
| `v2.RandomInvert`([p]) | 使用给定的概率反转给定图像或视频的颜色。 |
| `v2.RandomPosterize`(bits[, p]) | 使用给定的概率通过减少每个颜色通道的位数来对图像或视频进行色调分离。 |
| `v2.RandomSolarize`(threshold[, p]) | 使用给定的概率通过反转高于阈值的所有像素值来对图像或视频进行日光曝光处理。 |
| `v2.RandomAdjustSharpness`(sharpness_factor[, p]) | 使用给定的概率调整图像或视频的锐度。 |
| `v2.RandomAutocontrast`([p]) | 使用给定的概率自动对给定图像或视频的像素进行自动对比度处理。 |
| `v2.RandomEqualize`([p]) | 使用给定的概率对给定图像或视频的直方图进行均衡化。 |

功能函数

| `v2.functional.permute_channels`(inpt, permutation) | 根据给定的排列方式重新排列输入的通道。 |
| --- | --- |
| `v2.functional.rgb_to_grayscale`(inpt[, ...]) | 查看`Grayscale`获取详细信息。 |
| `v2.functional.to_grayscale`(inpt[, ...]) | 查看`Grayscale`获取详细信息。 |
| `v2.functional.gaussian_blur`(inpt, kernel_size) | 查看`GaussianBlur`获取详细信息。 |
| `v2.functional.invert`(inpt) | 查看`RandomInvert()`. |
| `v2.functional.posterize`(inpt, bits) | 查看`RandomPosterize`获取详细信息。 |
| `v2.functional.solarize`(inpt, threshold) | 查看详细信息，请参阅`RandomSolarize` |
| `v2.functional.adjust_sharpness`(inpt, ...) | 请参阅`RandomAdjustSharpness` |
| `v2.functional.autocontrast`(inpt) | 查看详细信息，请参阅`RandomAutocontrast` |
| `v2.functional.adjust_contrast`(inpt, ...) | 请参阅`RandomAutocontrast` |
| `v2.functional.equalize`(inpt) | 查看详细信息，请参阅`RandomEqualize` |
| `v2.functional.adjust_brightness`(inpt, ...) | 调整亮度。 |
| `v2.functional.adjust_saturation`(inpt, ...) | 调整饱和度。 |
| `v2.functional.adjust_hue`(inpt, hue_factor) | 调整色调 |
| `v2.functional.adjust_gamma`(inpt, gamma[, gain]) | 调整伽马值。 |

### Composition[](#composition "Permalink to this heading")

| `v2.Compose`(transforms) | 将多个转换组合在一起。 |
| --- | --- |
| `v2.RandomApply`(transforms[, p]) | 以给定概率随机应用一系列转换。 |
| `v2.RandomChoice`(transforms[, p]) | 从列表中随机选择一个转换进行应用。 |
| `v2.RandomOrder`(transforms) | 以随机顺序应用一系列转换。 |

### Miscellaneous[](#miscellaneous "Permalink to this heading")

| `v2.LinearTransformation`(...) | 使用离线计算的方形变换矩阵和均值向量对张量图像或视频进行转换。 |
| --- | --- |
| `v2.Normalize`(mean, std[, inplace]) | 使用均值和标准差对张量图像或视频进行归一化。 |
| `v2.RandomErasing`([p, scale, ratio, value, ...]) | 随机选择输入图像或视频中的矩形区域并擦除其像素。 |
| `v2.Lambda`(lambd, *types) | 将用户定义的函数应用为转换。 |
| `v2.SanitizeBoundingBoxes`([min_size, ...]) | 删除退化/无效的边界框及其对应的标签和掩模。 |
| `v2.ClampBoundingBoxes`() | 将边界框限制在其对应的图像尺寸内。 |
| `v2.UniformTemporalSubsample`(num_samples) | 从视频的时间维度均匀地子采样 `num_samples` 个索引。 |

功能性

| `v2.functional.normalize`(inpt, mean, std[, ...]) | 详细信息请参见`Normalize`。 |
| --- | --- |
| `v2.functional.erase`(inpt, i, j, h, w, v[, ...]) | 详细信息请参见 `RandomErase`。 |
| `v2.functional.clamp_bounding_boxes`(inpt[, ...]) | 详细信息请参见`ClampBoundingBoxes()`。 |
| `v2.functional.uniform_temporal_subsample`(...) | 详细信息请参见`UniformTemporalSubsample`。 |

### 转换[](#conversion "跳转到此标题")

注意

警惕，下面的一些转换操作可能会在执行转换时对值进行缩放，而有些可能不会进行任何缩放。通过缩放，我们指的是例如 `uint8` -> `float32` 将把 [0, 255] 范围映射到 [0, 1]（反之亦然）。请参阅 Dtype 和期望值范围。

| `v2.ToImage`() | 将张量、ndarray 或 PIL 图像转换为`Image`；不会缩放值。 |
| --- | --- |
| `v2.ToPureTensor`() | 将所有 TVTensors 转换为纯张量，删除相关的元数据（如果有）。 |
| `v2.PILToTensor`() | 将 PIL 图像转换为相同类型的张量-不会缩放值。 |
| `v2.ToPILImage`([mode]) | 将张量或 ndarray 转换为 PIL 图像。 |
| `v2.ToDtype`(dtype[, scale]) | 将输入转换为特定的 dtype，可选择为图像或视频缩放值。 |
| `v2.ConvertBoundingBoxFormat`(format) | 将边界框坐标转换为给定的`format`，例如从"CXCYWH"到"XYXY"。 |

functionals

| `v2.functional.to_image`(inpt) | 有关详细信息，请参阅`ToImage`。 |
| --- | --- |
| `v2.functional.pil_to_tensor`(pic) | 将`PIL 图像`转换为相同类型的张量。 |
| `v2.functional.to_pil_image`(pic[, mode]) | 将张量或 ndarray 转换为 PIL 图像。 |
| `v2.functional.to_dtype`(inpt[, dtype, scale]) | 有关详细信息，请参阅`ToDtype()`。 |
| `v2.functional.convert_bounding_box_format`(inpt) | 有关详细信息，请参阅`ConvertBoundingBoxFormat()`。 |

Deprecated

| `v2.ToTensor`() | [DEPRECATED] 使用`v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`代替。 |
| --- | --- |
| `v2.functional.to_tensor`(inpt) | [DEPREACTED] Use to_image() and to_dtype() instead. |
| `v2.ConvertImageDtype`([dtype]) | [已弃用]请改用`v2.ToDtype(dtype, scale=True)`。 |
| `v2.functional.convert_image_dtype`(image[, dtype]) | [已弃用]请改用 to_dtype()。 |

### 自动增强[](#auto-augmentation "跳转到此标题的永久链接")

[AutoAugment](https://arxiv.org/pdf/1805.09501.pdf)是一种常见的数据增强技术，可以提高图像分类模型的准确性。尽管数据增强策略直接与其训练数据集相关联，但实证研究表明，将 ImageNet 策略应用于其他数据集时可以显著提高性能。在 TorchVision 中，我们实现了在以下数据集上学习的 3 种策略：ImageNet、CIFAR10 和 SVHN。新的转换可以独立使用，也可以与现有转换混合使用：

| `v2.AutoAugment`([policy, interpolation, fill]) | 基于["AutoAugment: Learning Augmentation Strategies from Data"](https://arxiv.org/pdf/1805.09501.pdf)的 AutoAugment 数据增强方法。 |
| --- | --- |
| `v2.RandAugment`([num_ops, magnitude, ...]) | 基于["RandAugment: Practical automated data augmentation with a reduced search space"](https://arxiv.org/abs/1909.13719)的 RandAugment 数据增强方法。 |
| `v2.TrivialAugmentWide`([num_magnitude_bins, ...]) | 使用 TrivialAugment Wide 进行与数据集无关的数据增强，如["TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation"](https://arxiv.org/abs/2103.10158)中所述。 |
| `v2.AugMix`([severity, mixture_width, ...]) | 基于["AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty"](https://arxiv.org/abs/1912.02781)的 AugMix 数据增强方法。 |

### CutMix - MixUp[](#cutmix-mixup "跳转到此标题的永久链接")

CutMix 和 MixUp 是特殊的变换，用于批处理而不是单个图像，因为它们将图像对组合在一起。这些可以在数据加载器之后使用（一旦样本被分批），或作为整理函数的一部分。详细使用示例请参见如何使用 CutMix 和 MixUp。

| `v2.CutMix`(*[, alpha, labels_getter]) | 将 CutMix 应用于提供的图像和标签批次。 |
| --- | --- |
| `v2.MixUp`(*[, alpha, labels_getter]) | 将 MixUp 应用于提供的图像和标签批次。 |

### 开发者工具[](#developer-tools "跳转到此标题的永久链接")

| `v2.functional.register_kernel`(functional, ...) | 装饰一个内核以为一个功能和一个（自定义的）tv_tensor 类型注册它。 |
| --- | --- |

## V1 API 参考[](#v1-api-reference "跳转到此标题的永久链接")

### 几何[](#id3 "跳转到此标题的永久链接")

| `Resize`(size[, interpolation, max_size, ...]) | 将输入图像调整为给定大小。 |
| --- | --- |
| `RandomCrop`(size[, padding, pad_if_needed, ...]) | 在随机位置裁剪给定图像。 |
| `RandomResizedCrop`(size[, scale, ratio, ...]) | 裁剪图像的随机部分并将其调整为给定大小。 |
| `CenterCrop`(size) | 在中心裁剪给定图像。 |
| `FiveCrop`(size) | 将给定图像裁剪为四个角和中心裁剪。 |
| `TenCrop`(size[, vertical_flip]) | 将给定图像裁剪为四个角和中心裁剪，以及这些裁剪的翻转版本（默认使用水平翻转）。 |
| `Pad`(padding[, fill, padding_mode]) | 使用给定的“pad”值在所有边上填充给定图像。 |
| `RandomRotation`(degrees[, interpolation, ...]) | 将图像旋转指定角度。 |
| `RandomAffine`(degrees[, translate, scale, ...]) | 对图像进行随机仿射变换，保持中心不变。 |
| `RandomPerspective`([distortion_scale, p, ...]) | 以给定概率对给定图像执行随机透视变换。 |
| `ElasticTransform`([alpha, sigma, ...]) | 使用弹性变换对张量图像进行转换。 |
| `RandomHorizontalFlip`([p]) | 以给定概率随机水平翻转给定图像。 |
| `RandomVerticalFlip`([p]) | 以给定概率随机垂直翻转给定图像。 |

### Color[](#id4 "Permalink to this heading")

| `ColorJitter`([brightness, contrast, ...]) | 随机改变图像的亮度、对比度、饱和度和色调。 |
| --- | --- |
| `Grayscale`([num_output_channels]) | 将图像转换为灰度图像。 |
| `RandomGrayscale`([p]) | 以概率 p（默认为 0.1）随机将图像转换为灰度图像。 |
| `GaussianBlur`(kernel_size[, sigma]) | 使用随机选择的高斯模糊对图像进行模糊处理。 |
| `RandomInvert`([p]) | 以给定概率随机反转给定图像的颜色。 |
| `RandomPosterize`(bits[, p]) | 以给定概率随机海报化图像，通过减少每个颜色通道的位数。 |
| `RandomSolarize`(threshold[, p]) | 以给定概率随机太阳化图像，通过反转所有高于阈值的像素值。 |
| `RandomAdjustSharpness`(sharpness_factor[, p]) | 以给定概率随机调整图像的清晰度。 |
| `RandomAutocontrast`([p]) | 以给定概率随机自动对比度调整给定图像的像素。 |
| `RandomEqualize`([p]) | 以给定概率随机均衡给定图像的直方图。 |

### 组合

| `Compose`(transforms) | 将多个变换组合在一起。 |
| --- | --- |
| `RandomApply`(transforms[, p]) | 以给定概率随机应用一系列变换。 |
| `RandomChoice`(transforms[, p]) | 从列表中随机选择一个单一变换。 |
| `RandomOrder`(transforms) | 以随机顺序应用一系列变换。 |

### 杂项

| `LinearTransformation`(transformation_matrix, ...) | 使用计算离线的方形变换矩阵和均值向量转换张量图像。 |
| --- | --- |
| `Normalize`(mean, std[, inplace]) | 使用均值和标准差对张量图像进行归一化。 |
| `RandomErasing`([p, scale, ratio, value, inplace]) | 随机选择 torch.Tensor 图像中的矩形区域并擦除其像素。 |
| `Lambda`(lambd) | 应用用户定义的 lambda 作为变换。 |

### 转换

注意

请注意，下面的一些转换会在执行转换时缩放值，而有些可能不会进行任何缩放。通过缩放，我们指的是例如 `uint8` -> `float32` 将 [0, 255] 范围映射到 [0, 1]（反之亦然）。请参阅 数据类型和期望值范围。

| `ToPILImage`([mode]) | 将张量或 ndarray 转换为 PIL 图像 |
| --- | --- |
| `ToTensor`() | 将 PIL 图像或 ndarray 转换为张量并相应地缩放值。 |
| `PILToTensor`() | 将 PIL 图像转换为相同类型的张量 - 不会缩放值。 |
| `ConvertImageDtype`(dtype) | 将张量图像转换为给定的`dtype`并相应地缩放值。 |

### 自动增强[](#id8 "跳转到此标题")

[AutoAugment](https://arxiv.org/pdf/1805.09501.pdf)是一种常见的数据增强技术，可以提高图像分类模型的准确性。尽管数据增强策略直接与它们训练的数据集相关联，但实证研究表明，当应用于其他数据集时，ImageNet 策略会显著改善。在 TorchVision 中，我们实现了在以下数据集上学习的 3 种策略：ImageNet、CIFAR10 和 SVHN。新的转换可以独立使用，也可以与现有转换混合使用：

| `AutoAugmentPolicy`(value) | 在不同数据集上学习的 AutoAugment 策略。 |
| --- | --- |
| `AutoAugment`([policy, interpolation, fill]) | 基于["AutoAugment: Learning Augmentation Strategies from Data"](https://arxiv.org/pdf/1805.09501.pdf)的 AutoAugment 数据增强方法。 |
| `RandAugment`([num_ops, magnitude, ...]) | 基于["RandAugment: Practical automated data augmentation with a reduced search space"](https://arxiv.org/abs/1909.13719)的 RandAugment 数据增强方法。 |
| `TrivialAugmentWide`([num_magnitude_bins, ...]) | 使用 TrivialAugment Wide 进行与数据集无关的数据增强，如["TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation"](https://arxiv.org/abs/2103.10158)中所述。 |
| `AugMix`([severity, mixture_width, ...]) | 基于["AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty"](https://arxiv.org/abs/1912.02781)的 AugMix 数据增强方法。 |

### 功能性转换[](#id14 "跳转到此标题")

| `adjust_brightness`(img, brightness_factor) | 调整图像的亮度。 |
| --- | --- |
| `adjust_contrast`(img, contrast_factor) | 调整图像的对比度。 |
| `adjust_gamma`(img, gamma[, gain]) | 对图像执行伽马校正。 |
| `adjust_hue`(img, hue_factor) | 调整图像的色调。 |
| `adjust_saturation`(img, saturation_factor) | 调整图像的颜色饱和度。 |
| `adjust_sharpness`(img, sharpness_factor) | 调整图像的锐度。 |
| `affine`(img, angle, translate, scale, shear) | 在保持图像中心不变的情况下对图像应用仿射变换。 |
| `autocontrast`(img) | 通过重新映射每个通道的像素，使最低值变为黑色，最亮值变为白色，从而最大化图像的对比度。 |
| `center_crop`(img, output_size) | 在中心裁剪给定图像。 |
| `convert_image_dtype`(image[, dtype]) | 将张量图像转换为给定的`dtype`并相应地缩放值。此函数不支持 PIL 图像。 |
| `crop`(img, top, left, height, width) | 在指定位置裁剪给定图像并输出大小。 |
| `equalize`(img) | 通过对输入应用非线性映射来均衡图像的直方图，以创建输出中灰度值的均匀分布。 |
| `erase`(img, i, j, h, w, v[, inplace]) | 用给定值擦除输入张量图像。 |
| `five_crop`(img, size) | 将给定图像裁剪成四个角和中心裁剪。 |
| `gaussian_blur`(img, kernel_size[, sigma]) | 通过给定的核对图像执行高斯模糊。 |
| `get_dimensions`(img) | 返回图像的尺寸为[通道，高度，宽度]。 |
| `get_image_num_channels`(img) | 返回图像的通道数。 |
| `get_image_size`(img) | 返回图像的尺寸为[宽度，高度]。 |
| `hflip`(img) | 水平翻转给定图像。 |
| `invert`(img) | 反转 RGB/灰度图像的颜色。 |
| `normalize`(tensor, mean, std[, inplace]) | 使用均值和标准差对浮点张量图像进行归一化。 |
| `pad`(img, padding[, fill, padding_mode]) | 使用给定的“填充”值在所有边上填充给定的图像。 |
| `perspective`(img, startpoints, endpoints[, ...]) | 对给定图像执行透视变换。 |
| `pil_to_tensor`(pic) | 将`PIL Image`转换为相同类型的张量。 |
| `posterize`(img, bits) | 通过减少每个颜色通道的位数来制作海报效果。 |
| `resize`(img, size[, interpolation, max_size, ...]) | 将输入图像调整大小为给定大小。 |
| `resized_crop`(img, top, left, height, width, size) | 裁剪给定的图像并将其调整大小到所需大小。 |
| `rgb_to_grayscale`(img[, num_output_channels]) | 将 RGB 图像转换为灰度图像。 |
| `rotate`(img, angle[, interpolation, expand, ...]) | 以角度旋转图像。 |
| `solarize`(img, threshold) | 通过反转所有高于阈值的像素值来使 RGB/灰度图像太阳化。 |
| `ten_crop`(img, size[, vertical_flip]) | 从给定图像生成十个裁剪图像。 |
| `to_grayscale`(img[, num_output_channels]) | 将任何模式的 PIL 图像（RGB、HSV、LAB 等）转换为灰度图像。 |
| `to_pil_image`(pic[, mode]) | 将张量或 ndarray 转换为 PIL 图像。 |
| `to_tensor`(pic) | 将`PIL Image`或`numpy.ndarray`转换为张量。 |
| `vflip`(img) | 垂直翻转给定的图像。 |
