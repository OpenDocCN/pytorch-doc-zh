# torchtext

> 原文：[https://pytorch.org/text/stable/index.html](https://pytorch.org/text/stable/index.html)

![_images/torchtext_logo.png](../Images/113ea1c7782e25cabab1e1b7a4e14a49.png)

这个库是[PyTorch](http://pytorch.org/)项目的一部分。PyTorch是一个开源的机器学习框架。

在本文档中描述的特性按发布状态分类：

> *稳定:* 这些特性将长期维护，通常不会有主要性能限制或文档中的差距。我们也期望保持向后兼容性（尽管可能会发生破坏性更改，提前一个版本发布通知）。
> 
> *Beta:* 特性被标记为Beta，因为API可能会根据用户反馈进行更改，因为性能需要改进，或者因为操作符的覆盖范围尚未完整。对于Beta特性，我们承诺将该特性推进到稳定分类。但是，我们不承诺向后兼容性。
> 
> *原型:* 这些特性通常不作为PyPI或Conda等二进制发行版的一部分提供，除非有时在运行时标志后面，目前处于早期阶段以获取反馈和测试。

[`torchtext`](#module-torchtext "torchtext") 包包括自然语言处理的数据处理工具和流行数据集。

包参考

+   torchtext.nn

    +   MultiheadAttentionContainer

    +   InProjContainer

    +   ScaledDotProduct

+   torchtext.data.functional

    +   generate_sp_model

    +   load_sp_model

    +   sentencepiece_numericalizer

    +   sentencepiece_tokenizer

    +   custom_replace

    +   simple_space_split

    +   numericalize_tokens_from_iterator

    +   filter_wikipedia_xml

    +   to_map_style_dataset

+   torchtext.data.metrics

    +   bleu_score

+   torchtext.data.utils

    +   get_tokenizer

    +   ngrams_iterator

+   torchtext.datasets

    +   文本分类

    +   语言建模

    +   机器翻译

    +   序列标注

    +   Question Answer

    +   无监督学习

+   torchtext.vocab

    +   Vocab

    +   vocab

    +   build_vocab_from_iterator

    +   Vectors

    +   GloVe

    +   FastText

    +   CharNGram

+   torchtext.utils

    +   reporthook

    +   download_from_url

    +   extract_archive

+   torchtext.transforms

    +   SentencePieceTokenizer

    +   GPT2BPETokenizer

    +   CLIPTokenizer

    +   RegexTokenizer

    +   BERTTokenizer

    +   VocabTransform

    +   ToTensor

    +   LabelToIndex

    +   Truncate

    +   AddToken

    +   Sequential

    +   PadTransform

    +   StrToIntTransform

    +   CharBPETokenizer

+   torchtext.functional

    +   [to_tensor](functional.html#to-tensor)

    +   [truncate](functional.html#truncate)

    +   [add_token](functional.html#add-token)

    +   [str_to_int](functional.html#str-to-int)

+   [torchtext.models](模型.html)

    +   [RobertaBundle](模型.html#robertabundle)

    +   [XLMR_BASE_ENCODER](模型.html#xlmr-base-encoder)

    +   [XLMR_LARGE_ENCODER](模型.html#xlmr-large-encoder)

    +   [ROBERTA_BASE_ENCODER](模型.html#roberta-base-encoder)

    +   [ROBERTA_LARGE_ENCODER](模型.html#roberta-large-encoder)

## 入门[](#getting-started "跳转到此标题")

入门

+   [SST-2二进制文本分类与XLM-RoBERTa模型](教程/sst2_classification_non_distributed.html)

+   [T5-基础模型用于摘要、情感分类和翻译](教程/t5_demo.html)

PyTorch库

+   [PyTorch](https://pytorch.org/docs)

+   [torchaudio](https://pytorch.org/audio)

+   [torchtext](https://pytorch.org/text)

+   [torchvision](https://pytorch.org/vision)

+   [TorchElastic](https://pytorch.org/elastic/)

+   [TorchServe](https://pytorch.org/serve)

+   [在XLA设备上的PyTorch](http://pytorch.org/xla/)
