# 参考文献

> [`pytorch.org/audio/stable/references.html`](https://pytorch.org/audio/stable/references.html)

[Yes]

Yesno。网址：[`www.openslr.org/1/`](http://www.openslr.org/1/)。

[AB79]

Jont B Allen 和 David A Berkley。用于高效模拟小房间声学的图像方法。*美国声学学会杂志*，65(4)：943-950，1979 年。

[ABD+20]

Rosana Ardila，Megan Branson，Kelly Davis，Michael Henretty，Michael Kohler，Josh Meyer，Reuben Morais，Lindsay Saunders，Francis M. Tyers 和 Gregor Weber。Common voice：一个大规模多语言语音语料库。2020 年。[arXiv:1912.06670](https://arxiv.org/abs/1912.06670)。

[BWT+21]

Arun Babu，王长翰，Andros Tjandra，Kushal Lakhotia，徐前通，Naman Goyal，Kritika Singh，Patrick von Platen，Yatharth Saraf，Juan Pino 等人。Xls-r：规模化的自监督跨语言语音表示学习。*arXiv 预印本 arXiv:2111.09296*，2021 年。

[BZMA20]

Alexei Baevski，Henry Zhou，Abdelrahman Mohamed 和 Michael Auli。Wav2vec 2.0：一种用于自监督学习语音表示的框架。2020 年。[arXiv:2006.11477](https://arxiv.org/abs/2006.11477)。

[BBL+08]

Carlos Busso，Murtaza Bulut，李志俊，Abe Kazemzadeh，Emily Mower Provost，Samuel Kim，Jeannette Chang，李成博，Shrikanth Narayanan。Iemocap：交互式情感二元动作捕捉数据库。*语言资源与评估*，42：335-359，2008 年 12 月。[doi:10.1007/s10579-008-9076-6](https://doi.org/10.1007/s10579-008-9076-6)。

[Cap69]

Jack Capon。高分辨率频率-波数谱分析。*IEEE 会议论文集*，57(8)：1408-1418，1969 年。

[CDiGangiB+21]

Roldano Cattoni，Mattia Antonino Di Gangi，Luisa Bentivogli，Matteo Negri 和 Marco Turchi。Must-c：用于端到端语音翻译的多语言语料库。*计算机语音与语言*，66：101155，2021 年。网址：[`www.sciencedirect.com/science/article/pii/S0885230820300887`](https://www.sciencedirect.com/science/article/pii/S0885230820300887)，[doi:https://doi.org/10.1016/j.csl.2020.101155](https://doi.org/https://doi.org/10.1016/j.csl.2020.101155)。

[CCW+21]

Guoguo Chen，柴树洲，王冠波，杜佳宇，张伟强，翁超，苏丹，Daniel Povey，Jan Trmal，张俊博，金明杰，Sanjeev Khudanpur，Shinji Watanabe，赵帅江，邹伟，李相刚，姚旭晨，王永庆，王玉军，尤赵，严志勇。Gigaspeech：一个不断发展的、多领域的带有 10000 小时转录音频的自动语音识别语料库。在*Interspeech 2021*会议上。2021 年。

[CWC+22]

三元陈，程毅王，正阳陈，宇吴，树杰刘，卓陈，金宇李，神行祥，吉田直之，吉冈拓也，肖雄，等人。Wavlm：用于全栈语音处理的大规模自监督预训练。*IEEE 信号处理领域选题杂志*，16(6)：1505-1518，2022 年。

[CPS16]

Ronan Collobert，Christian Puhrsch 和 Gabriel Synnaeve。Wav2letter：一种端到端的基于卷积神经网络的语音识别系统。2016 年。[arXiv:1609.03193](https://arxiv.org/abs/1609.03193)。

[CBC+20]

Alexis Conneau，Alexei Baevski，Ronan Collobert，Abdelrahman Mohamed 和 Michael Auli。用于语音识别的无监督跨语言表示学习。2020 年。[arXiv:2006.13979](https://arxiv.org/abs/2006.13979)。

[CY21]

Erica Cooper 和山岸纯一。过去语音合成挑战中的声音如何与今天相比？*arXiv 预印本 arXiv:2105.02373*，2021 年。

[CPC+20]

Joris Cosentino，Manuel Pariente，Samuele Cornell，Antoine Deleforge 和 Emmanuel Vincent。Librimix：一个用于通用语音分离的开源数据集。2020 年。[arXiv:2005.11262](https://arxiv.org/abs/2005.11262)。

[CSB+18]

Alice Coucke，Alaa Saade，Adrien Ball，Théodore Bluche，Alexandre Caulier，David Leroy，Clément Doumouro，Thibault Gisselbrecht，Francesco Caltagirone，Thibaut Lavril 等人。Snips 语音平台：一种用于私密设计语音界面的嵌入式口语理解系统。*arXiv 预印本 arXiv:1805.10190*，2018 年。

[DL82]

DC 道森和 BV666017 兰道。多元正态分布之间的弗雷歇距离。*多元分析杂志*，12(3)：450-455，1982 年。

[Defossez21]

亚历山大·德福塞。混合谱图和波形源分离。在*ISMIR 2021 音乐源分离研讨会论文集*中。2021 年。

[GKRR14]

马克·约翰·弗朗西斯·盖尔斯、凯特·尼尔、安东·拉格尼和沙克提·普拉萨德·拉特。低资源语言的语音识别和关键词检测：剑桥大学 babel 项目研究。在*SLTU*中。2014 年。

[Gra12]

亚历克斯·格雷夫斯。使用递归神经网络进行序列转导。2012 年。[arXiv:1211.3711](https://arxiv.org/abs/1211.3711)。

[GL83]

D.格里芬和林杰。从修改后的短时傅里叶变换中估计信号。在*ICASSP '83。IEEE 国际声学、语音和信号处理会议*中，卷 8，804-807。1983 年。[doi:10.1109/ICASSP.1983.1172092](https://doi.org/10.1109/ICASSP.1983.1172092)。

[GQC+20]

安莫尔·古拉蒂、詹姆斯·秦、邱中成、尼基·帕马尔、张宇、余佳辉、韩伟、王世博、张正东、吴永辉和庞若明。Conformer：用于语音识别的卷积增强变压器。2020 年。[arXiv:2005.08100](https://arxiv.org/abs/2005.08100)。

[HCC+14]

奥尼·汉农、卡尔·凯斯、贾里德·卡斯珀、布莱恩·卡坦扎罗、格雷格·迪阿莫斯、埃里希·埃尔森、瑞安·普伦格、桑杰夫·萨蒂什、舒博·森古普塔、亚当·科茨和安德鲁·Y. 吴。深度语音：扩展端到端语音识别。2014 年。[arXiv:1412.5567](https://arxiv.org/abs/1412.5567)。

[HCE+17]

肖恩·赫尔希、索里什·乔杜里、丹尼尔·P. W. 艾利斯、约特·F. 格梅克、阿伦·詹森、查宁·摩尔、马诺杰·普拉卡尔、德文·普拉特、里夫·A. 索罗斯、布莱恩·塞伯尔德、马尔科姆·斯兰尼、罗恩·韦斯和凯文·威尔逊。用于大规模音频分类的 CNN 架构。在*国际声学、语音和信号处理会议（ICASSP）*中。2017 年。网址：[`arxiv.org/abs/1609.09430`](https://arxiv.org/abs/1609.09430)。

[HIA+17]

樋口拓也、伊藤伸孝、荒木祥子、吉冈拓也、马克·德尔克罗伊和中谷智博。基于复高斯混合模型的在线 mvdr 波束形成器，具有空间先验用于噪声鲁棒的 asr。*IEEE/ACM 音频、语音和语言处理交易*，25(4)：780-793，2017 年。

[HIYN16]

樋口拓也、伊藤伸孝、吉冈拓也和中谷智博。使用时频掩模进行在线/离线噪声下的鲁棒 mvdr 波束形成。在*2016 年 IEEE 国际声学、语音和信号处理会议（ICASSP）*中，5210-5214。IEEE，2016 年。

[HBT+21]

徐伟宁、本杰明·博尔特、蔡耀宏、库沙尔·拉克霍蒂亚、鲁斯兰·萨拉胡特迪诺夫和阿卜杜勒拉曼·穆罕默德。Hubert：通过隐藏单元的掩码预测进行自监督语音表示学习。2021 年。[arXiv:2106.07447](https://arxiv.org/abs/2106.07447)。

[IJ17]

基思伊托和琳达约翰逊。LJ 语音数据集。[`keithito.com/LJ-Speech-Dataset/`](https://keithito.com/LJ-Speech-Dataset/)，2017 年。

[KPL+22]

雅各布·卡恩、维尼尔·普拉塔普、塔蒂亚娜·利霍马年科、钱通徐、奥尼·汉农、杰夫·凯、帕登·托马塞洛、安·李、埃杜瓦·格雷夫、吉拉德·阿维多夫等。Flashlight：为机器学习工具创新提供支持。*arXiv 预印本 arXiv:2201.12465*，2022 年。

[KES+18a]

纳尔·卡尔布伦纳、埃里希·埃尔森、卡伦·西蒙扬、塞布·努里、诺曼·卡萨格兰德、爱德华·洛克哈特、弗洛里安·斯蒂姆伯格、亚伦·范登·奥尔德、桑德·迪勒曼和科雷·卡武克乔格卢。高效的神经音频合成。2018 年。[arXiv:1802.08435](https://arxiv.org/abs/1802.08435)。

[KES+18b]

纳尔·卡尔布伦纳、埃里希·埃尔森、卡伦·西蒙扬、塞布·努里、诺曼·卡萨格兰德、爱德华·洛克哈特、弗洛里安·斯蒂姆伯格、阿伦·范登·奥尔德、桑德·迪勒曼和科雷·卡武克乔格卢。高效的神经音频合成。*CoRR*，2018 年。网址：[`arxiv.org/abs/1802.08435`](http://arxiv.org/abs/1802.08435)，[arXiv:1802.08435](https://arxiv.org/abs/1802.08435)。

[KPPK15]

Tom Ko，Vijayaditya Peddinti，Daniel Povey 和 Sanjeev Khudanpur。用于语音识别的音频增强。在*Interspeech 2015 会议论文集*中，3586-3589。2015 年。[doi:10.21437/Interspeech.2015-711](https://doi.org/10.21437/Interspeech.2015-711)。

[KBV03]

John Kominek，Alan W Black 和 Ver Ver。用于语音合成的 CMU 北极数据库。技术报告，2003 年。

[KKB20]

Jungil Kong，Jaehyeon Kim 和 Jaekyoung Bae。Hifi-gan：用于高效和高保真度语音合成的生成对抗网络。在 H. Larochelle，M. Ranzato，R. Hadsell，M.F. Balcan 和 H. Lin 编辑的*神经信息处理系统进展*中，卷 33，17022-17033。Curran Associates, Inc.，2020 年。网址：[`proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf`](https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf)。

[KTN+23]

Anurag Kumar，Ke Tan，Zhaoheng Ni，Pranay Manocha，Xiaohui Zhang，Ethan Henderson 和 Buye Xu。Torchaudio-squim：Torchaudio 中无参考语音质量和可懂度测量。*arXiv 预印本 arXiv:2304.01448*，2023 年。

[LRI+19]

Loren Lugosch，Mirco Ravanelli，Patrick Ignoto，Vikrant Singh Tomar 和 Yoshua Bengio。端到端口语言理解的语音模型预训练。在 Gernot Kubin 和 Zdravko Kacic 编辑的*Interspeech 会议论文集*中，814-818。2019 年。

[LM19]

Yi Luo 和 Nima Mesgarani。Conv-tasnet：超越理想的时频幅度屏蔽进行语音分离。*IEEE/ACM 音频、语音和语言处理交易*，27(8)：1256-1266，2019 年 8 月。网址：[`dx.doi.org/10.1109/TASLP.2019.2915167`](http://dx.doi.org/10.1109/TASLP.2019.2915167)，[doi:10.1109/taslp.2019.2915167](https://doi.org/10.1109/taslp.2019.2915167)。

[MK22]

Pranay Manocha 和 Anurag Kumar。使用非匹配参考进行 MOS 的语音质量评估。*arXiv 预印本 arXiv:2206.12285*，2022 年。

[MRFB+15]

Xavier Anguera Miro，Luis Javier Rodriguez-Fuentes，Andi Buzo，Florian Metze，Igor Szoke 和 Mikel Peñagarikano。Quesst2014：在零资源环境中使用真实查询评估基于示例语音搜索。*2015 年 IEEE 国际声学、语音和信号处理会议（ICASSP）*，2015 年，页码 5833-5837。

[MPG29]

RV Mises 和 Hilda Pollaczek-Geiringer。等式求解的实用方法。*ZAMM-应用数学和力学杂志/应用数学和力学杂志*，9(1)：58-77，1929 年。

[Mys14]

Gautham J Mysore。我们能否自动将在真实环境中使用普通消费设备录制的语音转换为专业制作质量的语音？—数据集、见解和挑战。*IEEE 信号处理通信*，22(8)：1006-1010，2014 年。

[NCZ17]

Arsha Nagrani，Joon Son Chung 和 Andrew Zisserman。Voxceleb：一个大规模的说话者识别数据集。*arXiv 预印本 arXiv:1706.08612*，2017 年。

[PCPK15]

Vassil Panayotov，Guoguo Chen，Daniel Povey 和 Sanjeev Khudanpur。Librispeech：基于公共领域有声书的 ASR 语料库。在*2015 年 IEEE 国际声学、语音和信号处理会议（ICASSP）*中，卷，5206-5210。2015 年。[doi:10.1109/ICASSP.2015.7178964](https://doi.org/10.1109/ICASSP.2015.7178964)。

[PCZ+19]

Daniel S. Park，William Chan，Yu Zhang，Chung-Cheng Chiu，Barret Zoph，Ekin D. Cubuk 和 Quoc V. Le。Specaugment：一种用于自动语音识别的简单数据增强方法。*Interspeech 2019*，2019 年 9 月。网址：[`dx.doi.org/10.21437/Interspeech.2019-2680`](http://dx.doi.org/10.21437/Interspeech.2019-2680)，[doi:10.21437/interspeech.2019-2680](https://doi.org/10.21437/interspeech.2019-2680)。

[PBS13]

Nathanaël Perraudin，Peter Balazs 和 Peter L. Søndergaard。一种快速的 Griffin-Lim 算法。在*2013 年 IEEE 信号处理应用研讨会*中，卷，1-4。2013 年。[doi:10.1109/WASPAA.2013.6701851](https://doi.org/10.1109/WASPAA.2013.6701851)。

[PTS+23]

Vineel Pratap，Andros Tjandra，Bowen Shi，Paden Tomasello，Arun Babu，Sayani Kundu，Ali Elkahky，Zhaoheng Ni，Apoorv Vyas，Maryam Fazel-Zarandi，Alexei Baevski，Yossi Adi，张晓辉，徐伟宁，Alexis Conneau 和 Michael Auli。将语音技术扩展到 1000 多种语言。2023 年。arXiv:2305.13516。

[PXS+20]

Vineel Pratap，Qiantong Xu，Anuroop Sriram，Gabriel Synnaeve 和 Ronan Collobert。MLS：用于语音研究的大规模多语言数据集。Interspeech 2020，2020 年 10 月。URL：http://dx.doi.org/10.21437/Interspeech.2020-2826，doi:10.21437/interspeech.2020-2826。

[RLStoter+19]

Zafar Rafii，Antoine Liutkus，Fabian-Robert Stöter，Stylianos Ioannis Mimilakis 和 Rachel Bittner。MUSDB18-HQ - musdb18 的未压缩版本。2019 年 12 月。URL：https://doi.org/10.5281/zenodo.3338373，doi:10.5281/zenodo.3338373。

[RGC+20]

Chandan KA Reddy，Vishak Gopal，Ross Cutler，Ebrahim Beyrami，Roger Cheng，Harishchandra Dubey，Sergiy Matusevych，Robert Aichner，Ashkan Aazami，Sebastian Braun 等人。Interspeech 2020 深度降噪挑战：数据集，主观测试框架和挑战结果。arXiv 预印本 arXiv:2005.13981，2020 年。

[RDelegliseEsteve12]

安东尼·鲁索，保罗·德勒格利斯和亚尼克·埃斯特韦。Ted-lium：一种专用于自动语音识别的语料库。在语言资源和评估会议（LREC）中，125-129 页。2012 年。

[SY18]

Seyyed Saeed Sarfjoo 和山岸淳一。设备录制的 vctk（小型子集版本）。2018 年。

[SBDokmanic18]

罗宾·施伯勒，埃里克·贝扎姆和伊万·多克曼尼奇。Pyroomacoustics：用于音频房间模拟和阵列处理算法的 Python 软件包。在 2018 年 IEEE 国际声学、语音和信号处理会议（ICASSP）中，351-355 页。IEEE，2018 年。

[SPW+18]

乔纳森·申，Ruoming Pang，Ron J Weiss，Mike Schuster，Navdeep Jaitly，Zongheng Yang，Zhifeng Chen，张宇，王宇轩，Rj Skerrv-Ryan 等人。通过在 mel 频谱图预测上对 wavenet 进行条件化的自然 tts 合成。在 2018 年 IEEE 国际声学、语音和信号处理会议（ICASSP）中，4779-4783 页。IEEE，2018 年。

[SWW+21]

杨洋石，王永强，吴春阳，叶青峰，陈俊，张弗兰克，勒杜克和迈克·塞尔策。Emformer：用于低延迟流式语音识别的高效内存变压器基础声学模型。在 ICASSP 2021 - 2021 年 IEEE 国际声学、语音和信号处理会议（ICASSP）中，6783-6787 页。2021 年。

[SWW+22]

杨洋石，春阳吴，迪林王，Alex Xiao，Jay Mahadeokar，张晓辉，刘春喜，李克，尚冠元，瓦伦·纳加拉贾，奥兹莱姆·卡林利和迈克·塞尔策。基于非因果卷积的流式变压器传导器语音识别。在 ICASSP 2022 - 2022 年 IEEE 国际声学、语音和信号处理会议（ICASSP）中，卷，8277-8281 页。2022 年。doi:10.1109/ICASSP43922.2022.9747706。

[Smi20]

朱利叶斯·O·史密斯。数字音频重采样主页“理想带限插值理论”部分。2020 年 9 月。URL：https://ccrma.stanford.edu/~jos/resample/Theory_Ideal_Bandlimited_Interpolation.html。

[SCP15]

大卫·斯奈德，陈国国和丹尼尔·波维。MUSAN：一个音乐、语音和噪声语料库。2015 年。arXiv:1510.08484v1。arXiv:1510.08484。

[SBA09]

Mehrez Souden，Jacob Benesty 和 Sofiene Affes。关于噪声降低的最佳频域多通道线性滤波。在 IEEE 音频、语音和语言处理交易中，卷 18，260-276 页。IEEE，2009 年。

[SWT+22]

Sangeeta Srivastava, Yun Wang, Andros Tjandra, Anurag Kumar, Chunxi Liu, Kritika Singh, and Yatharth Saraf. Conformer-based self-supervised learning for non-speech audio tasks. In *ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, volume, 8862–8866\. 2022\. [doi:10.1109/ICASSP43922.2022.9746490](https://doi.org/10.1109/ICASSP43922.2022.9746490).

[TEC01]

George Tzanetakis, Georg Essl, and Perry Cook. Automatic musical genre classification of audio signals. 2001\. URL: [`ismir2001.ismir.net/pdf/tzanetakis.pdf`](http://ismir2001.ismir.net/pdf/tzanetakis.pdf).

[VAlumae21]

Jörgen Valk and Tanel Alumäe. Voxlingua107: a dataset for spoken language recognition. In *2021 IEEE Spoken Language Technology Workshop (SLT)*, 652–658\. IEEE, 2021.

[WRiviereL+21]

Changhan Wang, Morgane Rivière, Ann Lee, Anne Wu, Chaitanya Talnikar, Daniel Haziza, Mary Williamson, Juan Miguel Pino, and Emmanuel Dupoux. Voxpopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation. *CoRR*, 2021\. URL: [`arxiv.org/abs/2101.00390`](https://arxiv.org/abs/2101.00390), [arXiv:2101.00390](https://arxiv.org/abs/2101.00390).

[Wei98]

R.L. Weide. The carnegie mellon pronuncing dictionary. 1998\. URL: [`www.speech.cs.cmu.edu/cgi-bin/cmudict`](http://www.speech.cs.cmu.edu/cgi-bin/cmudict).

[YVM19]

Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald. CSTR VCTK Corpus: english multi-speaker corpus for CSTR voice cloning toolkit (version 0.92). 2019\. [doi:10.7488/ds/2645](https://doi.org/10.7488/ds/2645).

[ZDC+19]

Heiga Zen, Viet-Trung Dang, Robert A. J. Clark, Yu Zhang, Ron J. Weiss, Ye Jia, Z. Chen, and Yonghui Wu. Libritts: a corpus derived from librispeech for text-to-speech. *ArXiv*, 2019.

[ZSN21]

Albert Zeyer, Ralf Schlüter, and Hermann Ney. Why does ctc result in peaky behavior? 2021\. [arXiv:2105.14849](https://arxiv.org/abs/2105.14849).

[BrianMcFeeColinRaffelDawenLiang+15]

Brian McFee, Colin Raffel, Dawen Liang, Daniel P.W. Ellis, Matt McVicar, Eric Battenberg, and Oriol Nieto. Librosa: Audio and Music Signal Analysis in Python. In Kathryn Huff and James Bergstra, editors, *Proceedings of the 14th Python in Science Conference*, 18 – 24\. 2015\. [doi:10.25080/Majora-7b98e3ed-003](https://doi.org/10.25080/Majora-7b98e3ed-003).

[KahnRiviereZheng+20]

J. Kahn, M. Rivière, W. Zheng, E. Kharitonov, Q. Xu, P. E. Mazaré, J. Karadayi, V. Liptchinsky, R. Collobert, C. Fuegen, T. Likhomanenko, G. Synnaeve, A. Joulin, A. Mohamed, and E. Dupoux. Libri-light: a benchmark for asr with limited or no supervision. In *ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, 7669–7673\. 2020\. [`github.com/facebookresearch/libri-light`](https://github.com/facebookresearch/libri-light).

[Warden18]

P. Warden. Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition. *ArXiv e-prints*, April 2018\. URL: [`arxiv.org/abs/1804.03209`](https://arxiv.org/abs/1804.03209), [arXiv:1804.03209](https://arxiv.org/abs/1804.03209).

[Wikipediacontributors]

Wikipedia contributors. Absorption (acoustics) — Wikipedia, the free encyclopedia. [Online]. URL: [`en.wikipedia.org/wiki/Absorption_(acoustics)`](https://en.wikipedia.org/wiki/Absorption_(acoustics)).
