# torchtext

> 原文：[`pytorch.org/text/stable/index.html`](https://pytorch.org/text/stable/index.html)

![_images/torchtext_logo.png](img/113ea1c7782e25cabab1e1b7a4e14a49.png)

这个库是[PyTorch](http://pytorch.org/)项目的一部分。PyTorch 是一个开源的机器学习框架。

在本文档中描述的特性按发布状态分类：

> *稳定:* 这些特性将长期维护，通常不会有主要性能限制或文档中的差距。我们也期望保持向后兼容性（尽管可能会发生破坏性更改，提前一个版本发布通知）。
> 
> *Beta:* 特性被标记为 Beta，因为 API 可能会根据用户反馈进行更改，因为性能需要改进，或者因为操作符的覆盖范围尚未完整。对于 Beta 特性，我们承诺将该特性推进到稳定分类。但是，我们不承诺向后兼容性。
> 
> *原型:* 这些特性通常不作为 PyPI 或 Conda 等二进制发行版的一部分提供，除非有时在运行时标志后面，目前处于早期阶段以获取反馈和测试。

`torchtext` 包包括自然语言处理的数据处理工具和流行数据集。

包参考

+   torchtext.nn

    +   MultiheadAttentionContainer

    +   InProjContainer

    +   ScaledDotProduct

+   torchtext.data.functional

    +   generate_sp_model

    +   load_sp_model

    +   sentencepiece_numericalizer

    +   sentencepiece_tokenizer

    +   custom_replace

    +   simple_space_split

    +   numericalize_tokens_from_iterator

    +   filter_wikipedia_xml

    +   to_map_style_dataset

+   torchtext.data.metrics

    +   bleu_score

+   torchtext.data.utils

    +   get_tokenizer

    +   ngrams_iterator

+   torchtext.datasets

    +   文本分类

    +   语言建模

    +   机器翻译

    +   序列标注

    +   Question Answer

    +   无监督学习

+   torchtext.vocab

    +   Vocab

    +   vocab

    +   build_vocab_from_iterator

    +   Vectors

    +   GloVe

    +   FastText

    +   CharNGram

+   torchtext.utils

    +   reporthook

    +   download_from_url

    +   extract_archive

+   torchtext.transforms

    +   SentencePieceTokenizer

    +   GPT2BPETokenizer

    +   CLIPTokenizer

    +   RegexTokenizer

    +   BERTTokenizer

    +   VocabTransform

    +   ToTensor

    +   LabelToIndex

    +   Truncate

    +   AddToken

    +   Sequential

    +   PadTransform

    +   StrToIntTransform

    +   CharBPETokenizer

+   torchtext.functional

    +   to_tensor

    +   truncate

    +   add_token

    +   str_to_int

+   torchtext.models

    +   RobertaBundle

    +   XLMR_BASE_ENCODER

    +   XLMR_LARGE_ENCODER

    +   ROBERTA_BASE_ENCODER

    +   ROBERTA_LARGE_ENCODER

## 入门

入门

+   SST-2 二进制文本分类与 XLM-RoBERTa 模型

+   T5-基础模型用于摘要、情感分类和翻译

PyTorch 库

+   [PyTorch](https://pytorch.org/docs)

+   [torchaudio](https://pytorch.org/audio)

+   [torchtext](https://pytorch.org/text)

+   [torchvision](https://pytorch.org/vision)

+   [TorchElastic](https://pytorch.org/elastic/)

+   [TorchServe](https://pytorch.org/serve)

+   [在 XLA 设备上的 PyTorch](http://pytorch.org/xla/)
