# torch.Storage

* * *

`torch.Storage`是单个数据类型的连续的`一维数组`，每个`torch.Tensor`都具有相同数据类型的相应存储。

```py
class torch.FloatStorage 
```

*   `byte()`：将 Storage 转为 byte 类型
*   `char()`:将 Storage 转为 char 类型
*   `clone()`:返回 Storage 的副本
*   `copy_()`
*   `cpu()`：如果尚未在 CPU 上，则返回 Storage 的 CPU 副本
*   `cuda(device=None, async=False)`：在 CUDA 内存中返回此对象的副本。如果该对象已经在 CUDA 内存中，并且在正确的设备上，则不会执行任何操作，并返回原始对象。 参数说明：

    1.  device (int) - 目标 GPU 的 id。默认值是当前设备。
    2.  async (bool) -如果值为 True，且源在锁定内存中，则副本相对于宿主是异步的。否则此参数不起效果。
*   `data_ptr()`： 返回一个时间戳
*   `double()`：将 Storage 转为 double 类型
*   `element_size()`：返回参数的 size
*   `fill_()`
*   `float()`:将 Storage 转为 float 类型
*   `from_buffer()`
*   `half()`:将 Storage 转为 half 类型
*   `int()`:将 Storage 转为 int 类型
*   `is_cuda = False`
*   `is_pinned()`
*   `is_shared()`
*   `is_sparse = False`
*   `long()`:将 Storage 转为 long 类型
*   `new()`
*   `pin_memory()`：将存储复制到固定内存（如果尚未固定）。
*   `resize_()`
*   `share_memory_()`：这对于已经在共享内存和 CUDA 存储器中的存储器是无效的，不需要为了跨进程共享而移动。无法调整共享内存中的存储空间。返回：self
*   `short()`:将 Storage 转为 short 类型
*   `size()`：返回 Storage 转的大小
*   `tolist()`:返回一个包含 Storage 中元素的列表
*   `type(new_type=None, async=False)`：将此对象转为指定类型。如果已经是正确类型，不会执行复制操作，直接返回原对象。

参数说明：

1.  `new_type` (type 或 string) -需要转成的类型
2.  `async (bool)` -如果值为 True，并且源处于固定内存中，目标位于 GPU 上，反之亦然，则相对于主机异步执行该副本。否则，参数没有效果。

具体使用教程请参考：[使用 torch.Storage 共享多个张量的相同存储以及将 torch.Tensor 转化为 torch.Storage](https://ptorch.com/news/52.html)

### 译者署名

| 用户名 | 头像 | 职能 | 签名 |
| --- | --- | --- | --- |
| [Song](https://ptorch.com) | ![](img/2018033000352689884.jpeg) | 翻译 | 人生总要追求点什么 |