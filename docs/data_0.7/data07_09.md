# DataLoader2 教程

> 原文：[`pytorch.org/data/beta/dlv2_tutorial.html`](https://pytorch.org/data/beta/dlv2_tutorial.html)
>
> 译者：[飞龙](https://github.com/wizardforcel)
>
> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)


这是用户创建`DataPipe`图并通过不同后端系统(`ReadingService`)加载数据的教程。可以在[此 colab 笔记本](https://colab.research.google.com/drive/1eSvp-eUDYPj0Sd0X_Mv9s9VkE8RNDg1u)中找到一个使用示例。

## DataPipe

有关更多详细信息，请参阅 DataPipe 教程。以下是必要的最重要注意事项：确保数据管道每个时期具有不同的顺序，并且数据分片是互斥且完全穷尽的。

+   尽早在管道中放置`sharding_filter`或`sharding_round_robin_dispatch`，以避免在工作/分布式进程中重复昂贵的操作。

+   在分片之前添加一个`shuffle` DataPipe 以实现分片间的洗牌。`ReadingService`将处理这些`shuffle`操作的同步，以确保在分片之前数据的顺序相同，以使所有分片互斥且完全穷尽。

以下是一个`DataPipe`图的示例：

```py
datapipe = IterableWrapper(["./train1.csv", "./train2.csv"])
datapipe = datapipe.open_files(encoding="utf-8").parse_csv()
datapipe = datapipe.shuffle().sharding_filter()
datapipe = datapipe.map(fn).batch(8) 
```

## 多进程

`MultiProcessingReadingService` 在`sharding_filter`点处理多进程分片，并在工作进程之间同步种子。

```py
rs = MultiProcessingReadingService(num_workers=4)
dl = DataLoader2(datapipe, reading_service=rs)
for epoch in range(10):
    dl.seed(epoch)
    for d in dl:
        model(d)
dl.shutdown() 
```

## 分布式

`DistributedReadingService` 在`sharding_filter`点处理分布式分片，并在分布式进程之间同步种子。为了平衡分布式节点之间的数据分片，将在`DataPipe`图中附加一个`fullsync` `DataPipe`，以使分布式排名之间的批次数量保持一致。这将防止分布式训练中由不均匀分片引起的挂起问题。

```py
rs = DistributedReadingService()
dl = DataLoader2(datapipe, reading_service=rs)
for epoch in range(10):
    dl.seed(epoch)
    for d in dl:
        model(d)
dl.shutdown() 
```

## 多进程+分布式

`SequentialReadingService`可用于将两个`ReadingServices`组合在一起，以同时实现多进程和分布式训练。

```py
mp_rs = MultiProcessingReadingService(num_workers=4)
dist_rs = DistributedReadingService()
rs = SequentialReadingService(dist_rs, mp_rs)

dl = DataLoader2(datapipe, reading_service=rs)
for epoch in range(10):
    dl.seed(epoch)
    for d in dl:
        model(d)
dl.shutdown() 
```
