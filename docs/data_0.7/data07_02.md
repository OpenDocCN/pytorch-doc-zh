# 可迭代式DataPipes

> 原文：[https://pytorch.org/data/beta/torchdata.datapipes.iter.html](https://pytorch.org/data/beta/torchdata.datapipes.iter.html)

可迭代式数据集是IterableDataset子类的实例，实现了`__iter__()`协议，并表示数据样本的可迭代。这种类型的数据集特别适用于随机读取昂贵甚至不太可能的情况，批量大小取决于获取的数据。

例如，这样一个数据集，当调用`iter(iterdatapipe)`时，可以返回从数据库、远程服务器或实时生成的日志中读取的数据流。

这是`torch`中`IterableDataset`的更新版本。

```py
class torchdata.datapipes.iter.IterDataPipe(*args, **kwds)¶
```

可迭代式DataPipe。

所有表示数据样本可迭代的DataPipes都应该是这样的子类。当数据来自流时，或者样本数量太大无法全部放入内存时，这种DataPipes风格特别有用。`IterDataPipe`是惰性初始化的，只有在对`IterDataPipe`的迭代器调用`next()`时才计算其元素。

所有子类应该重写`__iter__()`，它将返回此DataPipe中样本的迭代器。调用`IterDataPipe`的`__iter__`会自动调用其方法`reset()`，默认情况下不执行任何操作。当编写自定义`IterDataPipe`时，用户应该根据需要重写`reset()`。常见用法包括重置自定义`IterDataPipe`中的缓冲区、指针和各种状态变量。

注意

每次只能有一个迭代器对`IterDataPipe`有效，创建第二个迭代器将使第一个迭代器无效。这个约束是必要的，因为一些`IterDataPipe`具有内部缓冲区，如果有多个迭代器，其状态可能会变得无效。下面的代码示例详细介绍了这个约束在实践中的样子。如果您对这个约束有任何反馈，请参阅[GitHub IterDataPipe Single Iterator Issue](https://github.com/pytorch/data/issues/45)。

这些DataPipes可以以两种方式调用，使用类构造函数或将它们的函数形式应用于现有的`IterDataPipe`（推荐，大多数但不是所有DataPipes都可用）。您可以将多个IterDataPipe链接在一起，形成一个连续执行多个操作的管道。

注意

当子类与`DataLoader`一起使用时，DataPipe中的每个项目将从`DataLoader`迭代器中产生。当`num_workers > 0`时，每个工作进程将拥有DataPipe对象的不同副本，因此通常希望配置每个副本独立以避免从工作进程返回重复数据。`get_worker_info()`在工作进程中调用时，返回有关工作进程的信息。它可以在数据集的`__iter__()`方法或`DataLoader`的`worker_init_fn`选项中使用，以修改每个副本的行为。

示例

通用用法：

```py
>>> # xdoctest: +SKIP
>>> from torchdata.datapipes.iter import IterableWrapper, Mapper
>>> dp = IterableWrapper(range(10))
>>> map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
>>> map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
>>> list(map_dp_1)
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> list(map_dp_2)
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
>>> list(filter_dp)
[2, 4, 6, 8, 10] 
```

单迭代器约束示例：

```py
>>> from torchdata.datapipes.iter import IterableWrapper, Mapper
>>> source_dp = IterableWrapper(range(10))
>>> it1 = iter(source_dp)
>>> list(it1)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> it1 = iter(source_dp)
>>> it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
>>> next(it2)
0
>>> next(it1)  # Further usage of `it1` will raise a `RunTimeError` 
```

我们有不同类型的Iterable DataPipes：

1.  存档 - 打开和解压不同格式的存档文件。

1.  增强 - 增强您的样本（例如添加索引，或无限循环）。

1.  组合 - 执行组合操作（例如采样、洗牌）。

1.  组合/拆分 - 通过组合多个DataPipes或将一个DataPipe拆分为多个来进行交互。

1.  分组 - 在DataPipe中对样本进行分组

1.  IO - 与文件系统或远程服务器交互（例如下载、打开、保存文件，并列出目录中的文件）。

1.  映射 - 将给定函数应用于DataPipe中的每个元素。

1.  其他 - 执行各种操作。

1.  选择 - 在DataPipe中选择特定样本。

1.  文本 - 解析、读取和转换文本文件和数据

## 存档DataPipes

这些DataPipes帮助打开和解压不同格式的存档文件。

| [`Bz2FileLoader`](generated/torchdata.datapipes.iter.Bz2FileLoader.html#torchdata.datapipes.iter.Bz2FileLoader "torchdata.datapipes.iter.Bz2FileLoader") | 从包含路径名和bz2二进制流元组的可迭代DataPipe中解压缩bz2二进制流，并产生一个路径名和提取的二进制流元组（函数名：`load_from_bz2`）。 |
| --- | --- |
| [`Decompressor`](generated/torchdata.datapipes.iter.Decompressor.html#torchdata.datapipes.iter.Decompressor "torchdata.datapipes.iter.Decompressor") | 接受路径和压缩数据流的元组，并返回路径和解压缩数据流的元组（函数名：`decompress`）。 |
| [`RarArchiveLoader`](generated/torchdata.datapipes.iter.RarArchiveLoader.html#torchdata.datapipes.iter.RarArchiveLoader "torchdata.datapipes.iter.RarArchiveLoader") | 从包含路径名和rar二进制流元组的输入可迭代DataPipe中解压缩rar二进制流，并产生一个路径名和提取的二进制流元组（函数名：`load_from_rar`）。 |
| [`TarArchiveLoader`](generated/torchdata.datapipes.iter.TarArchiveLoader.html#torchdata.datapipes.iter.TarArchiveLoader "torchdata.datapipes.iter.TarArchiveLoader") | 从包含路径名和tar二进制流元组的可迭代DataPipe中打开/解压缩tar二进制流，并产生一个路径名和提取的二进制流元组（函数名：`load_from_tar`）。 |
| [`TFRecordLoader`](generated/torchdata.datapipes.iter.TFRecordLoader.html#torchdata.datapipes.iter.TFRecordLoader "torchdata.datapipes.iter.TFRecordLoader") | 从包含路径名和tfrecord二进制流元组的可迭代DataPipe中打开/解压缩tfrecord二进制流，并产生存储的记录（函数名：`load_from_tfrecord`）。 |
| [`WebDataset`](generated/torchdata.datapipes.iter.WebDataset.html#torchdata.datapipes.iter.WebDataset "torchdata.datapipes.iter.WebDataset") | 接受（路径，数据）元组流的可迭代DataPipe，通常表示tar存档的路径名和文件（函数名：`webdataset`）。 |
| [`XzFileLoader`](generated/torchdata.datapipes.iter.XzFileLoader.html#torchdata.datapipes.iter.XzFileLoader "torchdata.datapipes.iter.XzFileLoader") | 从包含路径名和xz二进制流元组的可迭代DataPipe中解压缩xz（lzma）二进制流，并产生一个路径名和提取的二进制流元组（函数名：`load_from_xz`）。 |
| [`ZipArchiveLoader`](generated/torchdata.datapipes.iter.ZipArchiveLoader.html#torchdata.datapipes.iter.ZipArchiveLoader "torchdata.datapipes.iter.ZipArchiveLoader") | 从包含路径名和zip二进制流元组的可迭代DataPipe中打开/解压缩zip二进制流，并产生一个路径名和提取的二进制流元组（函数名：`load_from_zip`）。 |

## 增强DataPipes[](#augmenting-datapipes "Permalink to this heading")

这些DataPipes有助于增强您的样本。

| [`Cycler`](generated/torchdata.datapipes.iter.Cycler.html#torchdata.datapipes.iter.Cycler "torchdata.datapipes.iter.Cycler") | 默认情况下永久循环指定的输入，或者循环指定次数（函数名：`cycle`）。 |
| --- | --- |
| [`Enumerator`](generated/torchdata.datapipes.iter.Enumerator.html#torchdata.datapipes.iter.Enumerator "torchdata.datapipes.iter.Enumerator") | 通过枚举向现有DataPipe添加索引，默认情况下索引从0开始（函数名：`enumerate`）。 |
| [`IndexAdder`](generated/torchdata.datapipes.iter.IndexAdder.html#torchdata.datapipes.iter.IndexAdder "torchdata.datapipes.iter.IndexAdder") | 向现有可迭代DataPipe添加索引（函数名：`add_index`）。 |
| [`Repeater`](生成/torchdata.datapipes.iter.Repeater.html#torchdata.datapipes.iter.Repeater "torchdata.datapipes.iter.Repeater") | 在移动到下一个元素之前，重复为源DataPipe的每个元素指定次数的输出（功能名称：`repeat`）。 |

## 组合式DataPipes[](#combinatorial-datapipes "跳转到此标题的永久链接")

这些DataPipes有助于执行组合操作。

| [`InBatchShuffler`](生成/torchdata.datapipes.iter.InBatchShuffler.html#torchdata.datapipes.iter.InBatchShuffler "torchdata.datapipes.iter.InBatchShuffler") | 对来自先前DataPipe的每个小批次进行洗牌（功能名称：`in_batch_shuffle`）。 |
| --- | --- |
| [`Sampler`](生成/torchdata.datapipes.iter.Sampler.html#torchdata.datapipes.iter.Sampler "torchdata.datapipes.iter.Sampler") | 使用提供的`Sampler`生成样本元素（默认为`SequentialSampler`）。 |
| [`Shuffler`](生成/torchdata.datapipes.iter.Shuffler.html#torchdata.datapipes.iter.Shuffler "torchdata.datapipes.iter.Shuffler") | 使用缓冲区对输入DataPipe进行洗牌（功能名称：`shuffle`）。 |

## 组合/拆分DataPipes[](#combining-splitting-datapipes "跳转到此标题的永久链接")

这些通常涉及多个DataPipes，将它们组合在一起或将一个拆分为多个。 

| [`Concater`](生成/torchdata.datapipes.iter.Concater.html#torchdata.datapipes.iter.Concater "torchdata.datapipes.iter.Concater") | 连接多个Iterable DataPipes（功能名称：`concat`）。 |
| --- | --- |
| [`Demultiplexer`](生成/torchdata.datapipes.iter.Demultiplexer.html#torchdata.datapipes.iter.Demultiplexer "torchdata.datapipes.iter.Demultiplexer") | 使用给定的分类函数将输入DataPipe拆分为多个子DataPipes（功能名称：`demux`）。 |
| [`Forker`](生成/torchdata.datapipes.iter.Forker.html#torchdata.datapipes.iter.Forker "torchdata.datapipes.iter.Forker") | 创建相同Iterable DataPipe的多个实例（功能名称：`fork`）。 |
| [`IterKeyZipper`](生成/torchdata.datapipes.iter.IterKeyZipper.html#torchdata.datapipes.iter.IterKeyZipper "torchdata.datapipes.iter.IterKeyZipper") | 根据匹配的键将两个IterDataPipes一起压缩（功能名称：`zip_with_iter`）。 |
| [`MapKeyZipper`](生成/torchdata.datapipes.iter.MapKeyZipper.html#torchdata.datapipes.iter.MapKeyZipper "torchdata.datapipes.iter.MapKeyZipper") | 将源IterDataPipe的项目与MapDataPipe的项目结合（功能名称：`zip_with_map`）。 |
| [`Multiplexer`](生成/torchdata.datapipes.iter.Multiplexer.html#torchdata.datapipes.iter.Multiplexer "torchdata.datapipes.iter.Multiplexer") | 从输入的每个Iterable DataPipe中一次产生一个元素（功能名称：`mux`）。 |
| [`MultiplexerLongest`](生成/torchdata.datapipes.iter.MultiplexerLongest.html#torchdata.datapipes.iter.MultiplexerLongest "torchdata.datapipes.iter.MultiplexerLongest") | 从输入的每个Iterable DataPipe中一次产生一个元素（功能名称：`mux_longest`）。 |
| [`RoundRobinDemultiplexer`](生成/torchdata.datapipes.iter.RoundRobinDemultiplexer.html#torchdata.datapipes.iter.RoundRobinDemultiplexer "torchdata.datapipes.iter.RoundRobinDemultiplexer") | 按照轮询顺序将输入DataPipe拆分为多个子DataPipes（功能名称：`round_robin_demux`）。 |
| [`SampleMultiplexer`](生成/torchdata.datapipes.iter.SampleMultiplexer.html#torchdata.datapipes.iter.SampleMultiplexer "torchdata.datapipes.iter.SampleMultiplexer") | 接受一个(IterDataPipe, Weight)字典，并根据权重从这些DataPipes中进行采样生成项目。 |
| [`UnZipper`](生成/torchdata.datapipes.iter.UnZipper.html#torchdata.datapipes.iter.UnZipper "torchdata.datapipes.iter.UnZipper") | 接受一个序列的DataPipe，解压每个序列，并根据序列中的位置将元素分别返回到不同的DataPipes中（功能名称：`unzip`）。 |
| [`Zipper`](generated/torchdata.datapipes.iter.Zipper.html#torchdata.datapipes.iter.Zipper "torchdata.datapipes.iter.Zipper") | 从每个输入DataPipe中聚合元素为元组（功能名称：`zip`）。 |
| [`ZipperLongest`](generated/torchdata.datapipes.iter.ZipperLongest.html#torchdata.datapipes.iter.ZipperLongest "torchdata.datapipes.iter.ZipperLongest") | 从每个输入DataPipe中聚合元素为元组（功能名称：`zip_longest`）。 |

## Grouping DataPipes[](#grouping-datapipes "Permalink to this heading")

这些DataPipes让您在DataPipe中对样本进行分组。

| [`Batcher`](generated/torchdata.datapipes.iter.Batcher.html#torchdata.datapipes.iter.Batcher "torchdata.datapipes.iter.Batcher") | 创建数据的小批次（功能名称：`batch`）。 |
| --- | --- |
| [`BucketBatcher`](generated/torchdata.datapipes.iter.BucketBatcher.html#torchdata.datapipes.iter.BucketBatcher "torchdata.datapipes.iter.BucketBatcher") | 从排序的桶中创建数据的小批次（功能名称：`bucketbatch`）。 |
| [`Collator`](generated/torchdata.datapipes.iter.Collator.html#torchdata.datapipes.iter.Collator "torchdata.datapipes.iter.Collator") | 通过自定义整理函数将DataPipe中的样本整理为张量（功能名称：`collate`）。 |
| [`Grouper`](generated/torchdata.datapipes.iter.Grouper.html#torchdata.datapipes.iter.Grouper "torchdata.datapipes.iter.Grouper") | 通过从`group_key_fn`生成的键对来自输入IterDataPipe的数据进行分组，并在定义了`group_size`的情况下生成具有最大批量大小的`DataChunk`（功能名称：`groupby`）。 |
| [`MaxTokenBucketizer`](generated/torchdata.datapipes.iter.MaxTokenBucketizer.html#torchdata.datapipes.iter.MaxTokenBucketizer "torchdata.datapipes.iter.MaxTokenBucketizer") | 从具有限制大小的最小堆中创建数据的小批次，并且每个批次中由`len_fn`返回的样本的总长度将受到`max_token_count`的限制（功能名称：`max_token_bucketize`）。 |
| [`UnBatcher`](generated/torchdata.datapipes.iter.UnBatcher.html#torchdata.datapipes.iter.UnBatcher "torchdata.datapipes.iter.UnBatcher") | 撤消数据的批处理（功能名称：`unbatch`）。 |

## IO DataPipes[](#io-datapipes "Permalink to this heading")

这些DataPipes有助于与文件系统或远程服务器进行交互（例如下载、打开、保存文件以及列出目录中的文件）。

| [`AISFileLister`](generated/torchdata.datapipes.iter.AISFileLister.html#torchdata.datapipes.iter.AISFileLister "torchdata.datapipes.iter.AISFileLister") | 可迭代的Datapipe，列出具有给定URL前缀的AIStore后端的文件（功能名称：`list_files_by_ais`）。 |
| --- | --- |
| [`AISFileLoader`](generated/torchdata.datapipes.iter.AISFileLoader.html#torchdata.datapipes.iter.AISFileLoader "torchdata.datapipes.iter.AISFileLoader") | 可迭代的DataPipe，从具有给定URL的AIStore中加载文件（功能名称：`load_files_by_ais`）。 |
| [`FSSpecFileLister`](generated/torchdata.datapipes.iter.FSSpecFileLister.html#torchdata.datapipes.iter.FSSpecFileLister "torchdata.datapipes.iter.FSSpecFileLister") | 列出提供的`root`路径名或URL的目录内容，并为目录中的每个文件生成完整的路径名或URL（功能名称：`list_files_by_fsspec`）。 |
| [`FSSpecFileOpener`](generated/torchdata.datapipes.iter.FSSpecFileOpener.html#torchdata.datapipes.iter.FSSpecFileOpener "torchdata.datapipes.iter.FSSpecFileOpener") | 从包含fsspec路径的输入datapipe中打开文件，并生成路径名和打开的文件流的元组（功能名称：`open_files_by_fsspec`）。 |
| [`FSSpecSaver`](generated/torchdata.datapipes.iter.FSSpecSaver.html#torchdata.datapipes.iter.FSSpecSaver "torchdata.datapipes.iter.FSSpecSaver") | 接收元数据和数据元组的DataPipe，将数据保存到目标路径（由filepath_fn和元数据生成），并产生结果的fsspec路径（函数名：`save_by_fsspec`）。 |
| [`FileLister`](generated/torchdata.datapipes.iter.FileLister.html#torchdata.datapipes.iter.FileLister "torchdata.datapipes.iter.FileLister") | 给定根目录的路径，产生根目录中文件的路径名（路径+文件名）。 |
| [`FileOpener`](generated/torchdata.datapipes.iter.FileOpener.html#torchdata.datapipes.iter.FileOpener "torchdata.datapipes.iter.FileOpener") | 给定路径名，打开文件并以元组形式产生路径名和文件流（函数名：`open_files`）。 |
| [`GDriveReader`](generated/torchdata.datapipes.iter.GDriveReader.html#torchdata.datapipes.iter.GDriveReader "torchdata.datapipes.iter.GDriveReader") | 接收指向GDrive文件的URL，并产生文件名和IO流的元组（函数名：`read_from_gdrive`）。 |
| [`HttpReader`](generated/torchdata.datapipes.iter.HttpReader.html#torchdata.datapipes.iter.HttpReader "torchdata.datapipes.iter.HttpReader") | 接收文件URL（指向文件的HTTP URL），并产生文件URL和IO流的元组（函数名：`read_from_http`）。 |
| [`HuggingFaceHubReader`](generated/torchdata.datapipes.iter.HuggingFaceHubReader.html#torchdata.datapipes.iter.HuggingFaceHubReader "torchdata.datapipes.iter.HuggingFaceHubReader") | 接收数据集名称并返回一个可迭代的HuggingFace数据集。 |
| [`IoPathFileLister`](generated/torchdata.datapipes.iter.IoPathFileLister.html#torchdata.datapipes.iter.IoPathFileLister "torchdata.datapipes.iter.IoPathFileLister") | 列出提供的`root`路径名或URL的目录内容，并为目录中的每个文件产生完整的路径名或URL（函数名：`list_files_by_iopath`）。 |
| [`IoPathFileOpener`](generated/torchdata.datapipes.iter.IoPathFileOpener.html#torchdata.datapipes.iter.IoPathFileOpener "torchdata.datapipes.iter.IoPathFileOpener") | 从包含路径名或URL的输入datapipe中打开文件，并产生路径名和已打开文件流的元组（函数名：`open_files_by_iopath`）。 |
| [`IoPathSaver`](generated/torchdata.datapipes.iter.IoPathSaver.html#torchdata.datapipes.iter.IoPathSaver "torchdata.datapipes.iter.IoPathSaver") | 接收元数据和数据元组的DataPipe，将数据保存到由`filepath_fn`和元数据生成的目标路径，并以iopath格式（函数名：`save_by_iopath`）产生结果路径。 |
| [`OnlineReader`](generated/torchdata.datapipes.iter.OnlineReader.html#torchdata.datapipes.iter.OnlineReader "torchdata.datapipes.iter.OnlineReader") | 接收文件URL（可以是指向文件的HTTP URL或指向GDrive文件的URL），并产生文件URL和IO流的元组（函数名：`read_from_remote`）。 |
| [`ParquetDataFrameLoader`](generated/torchdata.datapipes.iter.ParquetDataFrameLoader.html#torchdata.datapipes.iter.ParquetDataFrameLoader "torchdata.datapipes.iter.ParquetDataFrameLoader") | 接收Parquet文件的路径，并为Parquet文件中的每个行组返回一个TorchArrow DataFrame（函数名：`load_parquet_as_df`）。 |
| [`S3FileLister`](generated/torchdata.datapipes.iter.S3FileLister.html#torchdata.datapipes.iter.S3FileLister "torchdata.datapipes.iter.S3FileLister") | 可迭代的DataPipe，列出具有给定前缀的Amazon S3文件URL（函数名：`list_files_by_s3`）。 |
| [`S3FileLoader`](generated/torchdata.datapipes.iter.S3FileLoader.html#torchdata.datapipes.iter.S3FileLoader "torchdata.datapipes.iter.S3FileLoader") | 可迭代的DataPipe，从给定的S3 URL加载Amazon S3文件（函数名：`load_files_by_s3`）。 |
| [`Saver`](生成/torchdata.datapipes.iter.Saver.html#torchdata.datapipes.iter.Saver "torchdata.datapipes.iter.Saver") | 接收元数据和数据元组的DataPipe，将数据保存到由`filepath_fn`生成的目标路径和元数据中，并在本地文件系统上生成文件路径（函数名称：`save_to_disk`）。 |

## Mapping DataPipes[](#mapping-datapipes "跳转到此标题")

这些DataPipes将给定的函数应用于DataPipe中的每个元素。

| [`BatchAsyncMapper`](生成/torchdata.datapipes.iter.BatchAsyncMapper.html#torchdata.datapipes.iter.BatchAsyncMapper "torchdata.datapipes.iter.BatchAsyncMapper") | 将源DataPipe中的元素组合成批次，并对每个批次中的每个元素并发地应用协程函数，然后将输出展平为单个、非嵌套的IterDataPipe（函数名称：`async_map_batches`）。 |
| --- | --- |
| [`BatchMapper`](生成/torchdata.datapipes.iter.BatchMapper.html#torchdata.datapipes.iter.BatchMapper "torchdata.datapipes.iter.BatchMapper") | 将源DataPipe中的元素组合成批次，并对每个批次应用函数，然后将输出展平为单个、非嵌套的IterDataPipe（函数名称：`map_batches`）。 |
| [`FlatMapper`](生成/torchdata.datapipes.iter.FlatMapper.html#torchdata.datapipes.iter.FlatMapper "torchdata.datapipes.iter.FlatMapper") | 对源DataPipe中的每个项目应用函数，然后将输出展平为单个、非嵌套的IterDataPipe（函数名称：`flatmap`）。 |
| [`Mapper`](生成/torchdata.datapipes.iter.Mapper.html#torchdata.datapipes.iter.Mapper "torchdata.datapipes.iter.Mapper") | 对源DataPipe中的每个项目应用函数（函数名称：`map`）。 |
| [`ShuffledFlatMapper`](生成/torchdata.datapipes.iter.ShuffledFlatMapper.html#torchdata.datapipes.iter.ShuffledFlatMapper "torchdata.datapipes.iter.ShuffledFlatMapper") | 对源DataPipe中的每个项目应用函数，然后将返回的可迭代对象收集到缓冲区中，然后，在每次迭代时，随机选择缓冲区中的一个可迭代对象，并从该可迭代对象中产生一个项目（函数名称：`shuffled_flatmap`）。 |
| [`ThreadPoolMapper`](生成/torchdata.datapipes.iter.ThreadPoolMapper.html#torchdata.datapipes.iter.ThreadPoolMapper "torchdata.datapipes.iter.ThreadPoolMapper") | 并发地对源DataPipe中的每个项目应用函数，使用`ThreadPoolExecutor`（函数名称：`threadpool_map`）。 |

## 其他DataPipes[](#other-datapipes "跳转到此标题")

一组具有不同功能的杂项DataPipes。

| [`DataFrameMaker`](生成/torchdata.datapipes.iter.DataFrameMaker.html#torchdata.datapipes.iter.DataFrameMaker "torchdata.datapipes.iter.DataFrameMaker") | 获取数据行，将其中一些数据批量处理并创建TorchArrow数据框（函数名称：`dataframe`）。 |
| --- | --- |
| [`EndOnDiskCacheHolder`](生成/torchdata.datapipes.iter.EndOnDiskCacheHolder.html#torchdata.datapipes.iter.EndOnDiskCacheHolder "torchdata.datapipes.iter.EndOnDiskCacheHolder") | 指示先前DataPipe的结果将保存在由`filepath_fn`指定的本地文件中（函数名称：`end_caching`）。 |
| [`FullSync`](生成/torchdata.datapipes.iter.FullSync.html#torchdata.datapipes.iter.FullSync "torchdata.datapipes.iter.FullSync") | 同步分布式进程中的数据，以防止训练过程中出现挂起，这是由不均匀的分片数据引起的（函数名称：`fullsync`）。 |
| [`HashChecker`](生成/torchdata.datapipes.iter.HashChecker.html#torchdata.datapipes.iter.HashChecker "torchdata.datapipes.iter.HashChecker") | 计算并检查每个文件的哈希值，从文件名和数据/流的元组输入DataPipe中（函数名称：`check_hash`）。 |
| [`InMemoryCacheHolder`](generated/torchdata.datapipes.iter.InMemoryCacheHolder.html#torchdata.datapipes.iter.InMemoryCacheHolder "torchdata.datapipes.iter.InMemoryCacheHolder") | 将来自源DataPipe的元素存储在内存中，如果指定了大小限制，则存储在内存中（功能名称：`in_memory_cache`）。 |
| [`IterableWrapper`](generated/torchdata.datapipes.iter.IterableWrapper.html#torchdata.datapipes.iter.IterableWrapper "torchdata.datapipes.iter.IterableWrapper") | 包装可迭代对象以创建IterDataPipe。 |
| [`LengthSetter`](generated/torchdata.datapipes.iter.LengthSetter.html#torchdata.datapipes.iter.LengthSetter "torchdata.datapipes.iter.LengthSetter") | 设置DataPipe的长度属性，该属性由`__len__`返回（功能名称：`set_length`）。 |
| [`MapToIterConverter`](generated/torchdata.datapipes.iter.MapToIterConverter.html#torchdata.datapipes.iter.MapToIterConverter "torchdata.datapipes.iter.MapToIterConverter") | 将`MapDataPipe`转换为`IterDataPipe`（功能名称：`to_iter_datapipe`）。 |
| [`OnDiskCacheHolder`](generated/torchdata.datapipes.iter.OnDiskCacheHolder.html#torchdata.datapipes.iter.OnDiskCacheHolder "torchdata.datapipes.iter.OnDiskCacheHolder") | 将多个DataPipe操作的输出缓存到本地文件中，这些操作通常是性能瓶颈，如下载、解压等（功能名称：`on_disk_cache`）。 |
| [`PinMemory`](generated/torchdata.datapipes.iter.PinMemory.html#torchdata.datapipes.iter.PinMemory "torchdata.datapipes.iter.PinMemory") | 预取源DataPipe中的一个元素并将其移动到固定内存中（功能名称：`pin_memory`）。 |
| [`Prefetcher`](generated/torchdata.datapipes.iter.Prefetcher.html#torchdata.datapipes.iter.Prefetcher "torchdata.datapipes.iter.Prefetcher") | 预取来自源DataPipe的元素并将它们放入缓冲区（功能名称：`prefetch`）。 |
| [`RandomSplitter`](generated/torchdata.datapipes.iter.RandomSplitter.html#torchdata.datapipes.iter.RandomSplitter "torchdata.datapipes.iter.RandomSplitter") | 将源DataPipe中的样本随机分成组（功能名称：`random_split`）。 |
| [`ShardExpander`](generated/torchdata.datapipes.iter.ShardExpander.html#torchdata.datapipes.iter.ShardExpander "torchdata.datapipes.iter.ShardExpander") | 将传入的分片字符串扩展为分片。 |
| [`ShardingFilter`](generated/torchdata.datapipes.iter.ShardingFilter.html#torchdata.datapipes.iter.ShardingFilter "torchdata.datapipes.iter.ShardingFilter") | 允许DataPipe被分片的包装器（功能名称：`sharding_filter`）。 |
| [`ShardingRoundRobinDispatcher`](generated/torchdata.datapipes.iter.ShardingRoundRobinDispatcher.html#torchdata.datapipes.iter.ShardingRoundRobinDispatcher "torchdata.datapipes.iter.ShardingRoundRobinDispatcher") | 包装器，指示`DataPipe`图的前一部分是不可复制的，并且在使用多处理时将以循环方式将数据分发到工作进程中（功能名称：`sharding_round_robin_dispatcher`）。 |

## 选择DataPipes[](#selecting-datapipes "Permalink to this heading")

这些DataPipes帮助您在DataPipe中选择特定的样本。

| [`Filter`](generated/torchdata.datapipes.iter.Filter.html#torchdata.datapipes.iter.Filter "torchdata.datapipes.iter.Filter") | 根据输入的`filter_fn`从源datapipe中过滤出元素（功能名称：`filter`）。 |
| --- | --- |
| [`Header`](generated/torchdata.datapipes.iter.Header.html#torchdata.datapipes.iter.Header "torchdata.datapipes.iter.Header") | 从源DataPipe中产生元素，直到达到指定的限制为止（功能名称：`header`）。 |
| [`Dropper`](generated/torchdata.datapipes.iter.Dropper.html#torchdata.datapipes.iter.Dropper "torchdata.datapipes.iter.Dropper") | 通过其索引在输入DataPipe中删除列/元素（功能名称：`drop`）。 |
| [`Slicer`](generated/torchdata.datapipes.iter.Slicer.html#torchdata.datapipes.iter.Slicer "torchdata.datapipes.iter.Slicer") | 通过起始/停止/步长或索引返回输入DataPipe中元素的切片（功能名称：`slice`）。 |
| [`Flattener`](generated/torchdata.datapipes.iter.Flattener.html#torchdata.datapipes.iter.Flattener "torchdata.datapipes.iter.Flattener") | 根据提供的索引，在每个样本/元素级别返回输入DataPipe的扁平副本（功能名称：`flatten`）。 |

## 文本DataPipes[](#text-datapipes "Permalink to this heading")

这些DataPipes帮助您解析、读取和转换文本文件和数据。

| [`CSVDictParser`](generated/torchdata.datapipes.iter.CSVDictParser.html#torchdata.datapipes.iter.CSVDictParser "torchdata.datapipes.iter.CSVDictParser") | 接受由文件名和CSV数据流元组组成的DataPipe，逐行读取并返回CSV文件中的内容（功能名称：`parse_csv_as_dict`）。 |
| --- | --- |
| [`CSVParser`](generated/torchdata.datapipes.iter.CSVParser.html#torchdata.datapipes.iter.CSVParser "torchdata.datapipes.iter.CSVParser") | 接受由文件名和CSV数据流元组组成的DataPipe，逐行读取并返回CSV文件中的内容（功能名称：`parse_csv`）。 |
| [`JsonParser`](generated/torchdata.datapipes.iter.JsonParser.html#torchdata.datapipes.iter.JsonParser "torchdata.datapipes.iter.JsonParser") | 从JSON数据流中读取并产生一个由文件名和JSON数据组成的元组（功能名称：`parse_json_files`）。 |
| [`LineReader`](generated/torchdata.datapipes.iter.LineReader.html#torchdata.datapipes.iter.LineReader "torchdata.datapipes.iter.LineReader") | 接受由文件名和字符串数据流元组组成的DataPipe，对流中的每一行，产生一个由文件名和该行组成的元组（功能名称：`readlines`）。 |
| [`ParagraphAggregator`](generated/torchdata.datapipes.iter.ParagraphAggregator.html#torchdata.datapipes.iter.ParagraphAggregator "torchdata.datapipes.iter.ParagraphAggregator") | 将同一文件中的文本行聚合成一个段落（功能名称：`lines_to_paragraphs`）。 |
| [`RoutedDecoder`](generated/torchdata.datapipes.iter.RoutedDecoder.html#torchdata.datapipes.iter.RoutedDecoder "torchdata.datapipes.iter.RoutedDecoder") | 从输入DataPipe解码二进制流，以元组形式产生路径名和解码数据（功能名称：`routed_decode`）。 |
| [`Rows2Columnar`](generated/torchdata.datapipes.iter.Rows2Columnar.html#torchdata.datapipes.iter.Rows2Columnar "torchdata.datapipes.iter.Rows2Columnar") | 接受一个带有数据批次的输入DataPipe，逐批处理并为每批产生一个字典，其中`column_names`作为键，每行对应值的列表作为值（功能名称：`rows2columnar`）。 |
| [`StreamReader`](generated/torchdata.datapipes.iter.StreamReader.html#torchdata.datapipes.iter.StreamReader "torchdata.datapipes.iter.StreamReader") | 给定IO流及其标签名称，以元组形式产生带有标签名称的字节（功能名称：`read_from_stream`）。 |
