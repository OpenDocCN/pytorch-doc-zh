# ReadingService

> [https://pytorch.org/data/beta/reading_service.html](https://pytorch.org/data/beta/reading_service.html)

`ReadingService`处理基于不同用例的`DataPipe`图的原地修改。

## 特性[](#features "跳转到此标题")

### 动态分片[](#dynamic-sharding "跳转到此标题")

动态分片是通过`MultiProcessingReadingService`和`DistributedReadingService`实现的，根据相应的多进程和分布式工作者的信息对管道进行分片。TorchData提供了两种类型的`DataPipe`，让用户在管道内定义分片位置。

+   `sharding_filter`（[`ShardingFilter`](generated/torchdata.datapipes.iter.ShardingFilter.html#torchdata.datapipes.iter.ShardingFilter "torchdata.datapipes.iter.ShardingFilter")）: 当管道可复制时，每个分布/多进程工作者从其自己的`DataPipe`图的副本加载数据，同时跳过不属于相应工作者的样本，即在放置`sharding_filter`的点。

+   `sharding_round_robin_dispatch`（[`ShardingRoundRobinDispatcher`](generated/torchdata.datapipes.iter.ShardingRoundRobinDispatcher.html#torchdata.datapipes.iter.ShardingRoundRobinDispatcher "torchdata.datapipes.iter.ShardingRoundRobinDispatcher")）: 当管道中存在任何`sharding_round_robin_dispatch` `DataPipe`时，该分支（即所有在`sharding_round_robin_dispatch`之前的DataPipes）将被视为不可复制的分支（在多进程的上下文中）。将创建一个单一的调度过程，从不可复制的分支加载数据并将数据分发给后续的工作进程。

以下是在管道中使用两种分片策略的示例。

![有向图示例{

    子图cluster_replicable {

        标签="可复制"

        a -> b -> c -> d -> l;

        颜色=蓝色;

    }

    子图cluster_non_replicable {

        样式=填充;

        颜色=浅灰色;

        节点[样式=填充,颜色=白色];

        标签="不可复制"

        e -> f -> g -> k;

        h -> i -> j -> k;

    }

    k -> l -> fullsync -> 结束;

    a [标签="DP1"];

    b [标签="洗牌"];

    c [标签="分片过滤器", 颜色=蓝色];

    d [标签="DP4"];

    e [标签="DP2"];

    f [标签="洗牌"];

    g [标签="分片轮询调度", 样式="填充,圆角", 颜色=红色, 填充颜色=白色];

    h [标签="DP3"];

    i [标签="洗牌"];

    j [标签="分片轮询调度", 样式="填充,圆角", 颜色=红色, 填充颜色=白色];

    k [标签="DP5（最低公共祖先）"];

    l [标签="DP6"];

    fullsync;

    结束[形状=方框];

}](../Images/ded90db7e9b275c0ce72673dbdb87c9c.png)

当多进程发生时，图变为:

![有向图示例{

    子图cluster_worker_0 {

        标签="工作者0"

        a0 -> b0 -> c0 -> d0 -> l0;

        m0 -> l0;

        颜色=蓝色;

    }

    子图cluster_worker_1 {

        标签="工作者1"

        a1 -> b1 -> c1 -> d1 -> l1;

        m1 -> l1;

        颜色=蓝色;

    }

    子图cluster_non_replicable {

        样式=填充;

        颜色=浅灰色;

        节点[样式=填充,颜色=白色];

        标签="不可复制"

        e -> f -> g -> k;

        h -> i -> j -> k;

        k -> 轮询解复用;

    }

    轮询解复用 -> m0;

    轮询解复用 -> m1;

    l0 -> n;

    l1 -> n;

    n -> fullsync -> 结束;

    a0 [标签="DP1"];

    b0 [标签="洗牌"];

    c0 [标签="分片过滤器", 颜色=蓝色];

    d0 [标签="DP4"];

    a1 [标签="DP1"];

    b1 [标签="洗牌"];

    c1 [标签="分片过滤器", 颜色=蓝色];

    d1 [标签="DP4"];

    e [标签="DP2"];

    f [标签="洗牌"];

    g [标签="分片轮询调度", 样式="填充,圆角", 颜色=红色, 填充颜色=白色];

    h [标签="DP3"];

    i [标签="洗牌"];

    j [标签="分片轮询调度", 样式="填充,圆角", 颜色=红色, 填充颜色=白色];

    k [标签="DP5（最低公共祖先）"];

    fullsync;

    l0 [标签="DP6"];

    l1 [标签="DP6"];

    m0 [标签="客户端"]

    m1 [标签="客户端"]

    n [标签="客户端"]

    结束[形状=方框];

}](../Images/43cb85d64c97047f6451f776a8417bfc.png)

图中的`客户端`是一个`DataPipe`，它向多进程队列发送请求并接收响应。

### 确定性[](#determinism "跳转到此标题")

在`DataLoader2`中，`SeedGenerator`成为随机性的单一来源，每个`ReadingService`都可以通过`initialize_iteration()`访问它，并为随机的`DataPipe`操作生成相应的随机种子。

为了确保数据集分片在多进程和分布式节点上是互斥且完全穷尽的，`MultiProcessingReadingService`和`DistributedReadingService`将帮助[`DataLoader2`](dataloader2.html#torchdata.dataloader2.DataLoader2 "torchdata.dataloader2.DataLoader2")在`sharding_filter`或`sharding_round_robin_dispatch`之前同步任何随机`DataPipe`操作的随机状态。在分片之后的剩余`DataPipe`操作中，每个`ReadingService`基于分布式排名和工作进程ID生成唯一的随机状态，以执行不同的随机变换。

### 图模式[](#graph-mode "跳转到此标题")

这也使得从研究到生产的数据预处理流水线更容易过渡。在`DataPipe`图与`ReadingServices`创建和验证后，可以提供一个不同的`ReadingService`，配置并连接到生产服务/基础设施，比如`AIStore`，作为[`DataLoader2`](dataloader2.html#torchdata.dataloader2.DataLoader2 "torchdata.dataloader2.DataLoader2")的替换。`ReadingService`可能会搜索图，并找到可以委托给生产服务/基础设施的`DataPipe`操作，然后相应地修改图以实现更高性能的执行。

## 扩展`ReadingService`[](#extend-readingservice "跳转到此标题")

以下是自定义`ReadingService`的接口。

```py
class torchdata.dataloader2.ReadingServiceInterface¶
```

`ReadingService`的接口。请根据这个接口类扩展自定义的`ReadingService`。

在调用`initialize`之前，`ReadingService`必须是可picklable的。这是因为`DataLoader2`会创建它的副本，以避免同一个`ReadingService`对象被多个`DataLoader2`使用，并且它的内部状态将被每个对象修改。

由于这个限制，某些初始化步骤可能需要在`initialize`方法中进行，而不是在`ReadingService`类的`__init__`中进行。

```py
finalize() → None¶
```

`ReadingService`清理内部状态并完全关闭服务。在`DataLoader2`的`shutdown`和`__del__`中调用。

```py
finalize_iteration() → None¶
```

`ReadingService`在一个epoch结束后终止服务。当`DataLoader2`的迭代器耗尽时调用。

```py
abstract initialize(datapipe: Union[IterDataPipe, MapDataPipe]) → Union[IterDataPipe, MapDataPipe]¶
```

`ReadingService`接受一个`DataPipe`图，根据自定义需求将其调整为一个新的`DataPipe`图。在首次创建`DataLoader2`迭代器时调用一次。在调用此方法之前，`ReadingService`对象必须是可picklable的。

参数：

**datapipe** - 原始的`DataPipe`图。

返回值：

一个调整或新的`DataPipe`图。

```py
initialize_iteration(seed_generator: SeedGenerator, iter_reset_fn: Optional[Callable[[Union[IterDataPipe, MapDataPipe]], Union[IterDataPipe, MapDataPipe]]] = None) → Optional[Callable[[Union[IterDataPipe, MapDataPipe]], Union[IterDataPipe, MapDataPipe]]]¶
```

`ReadingService`为一个epoch启动服务。在每次获取`DataLoader2`迭代器时调用。

参数：

+   **seed_generator** - 由`DataLoader2`创建和管理的SeedGenerator对象。作为随机性的单一来源，它将控制所有DataPipes图中的随机操作的确定性。

+   **iter_reset_fn** - 当`SequentialReadingService`链多个`ReadingServices`时，来自先前`ReadingServcie`的可选重置函数

返回值：

一个新的`iter_reset_fn`供后续`ReadingService`使用

示例

MultiProcessingReadingService开始为每个进程设置工作器种子，并从图中预取项目。

检查点/快照功能正在进行中。这是初步接口（可能会有小的更改）：

```py
class torchdata.dataloader2.CheckpointableReadingServiceInterface¶
```

通过两个额外的方法扩展`ReadingServiceInterface`以保存/恢复数据处理图的状态。

```py
abstract checkpoint() → bytes¶
```

`ReadingService`序列化内部状态。在`DataLoader2.state_dict`中调用。

```py
abstract restore(datapipe: Union[IterDataPipe, MapDataPipe], serialized_state: bytes) → Union[IterDataPipe, MapDataPipe]¶
```

`ReadingService` 根据序列化状态调整 `DataPipe` 图。在首次创建 `DataLoader2` 迭代器时调用一次。与 `initialize` 相对应，从头开始调整 `DataPipe` 图。

参数：

+   **datapipe** – 在被 `ReadingService` 调整之前的原始 `DataPipe` 图。

+   **serialized_state** – 用于恢复适应的 `DataPipe` 图状态的内部状态的序列化状态。

返回：

根据序列化状态生成的适应的 `DataPipe`。

### 图函数[](#graph-functions "Permalink to this heading")

另外，`torchdata.dataloader.graph` 中提供了图实用函数，帮助用户为自定义 `ReadingService` 进行 `DataPipe` 图重写：

| [`traverse_dps`](generated/torchdata.dataloader2.graph.traverse_dps.html#torchdata.dataloader2.graph.traverse_dps "torchdata.dataloader2.graph.traverse_dps") | 遍历 DataPipes 及其属性以提取 DataPipe 图。 |
| --- | --- |
| [`find_dps`](generated/torchdata.dataloader2.graph.find_dps.html#torchdata.dataloader2.graph.find_dps "torchdata.dataloader2.graph.find_dps") | 给定由 `traverse_dps` 函数生成的 DataPipe 图，返回具有提供的 DataPipe 类型的 DataPipe 实例。 |
| [`list_dps`](generated/torchdata.dataloader2.graph.list_dps.html#torchdata.dataloader2.graph.list_dps "torchdata.dataloader2.graph.list_dps") | 给定由 `traverse_dps` 函数生成的 DataPipe 图，返回所有 DataPipe 实例的列表，不重复。 |
| [`remove_dp`](generated/torchdata.dataloader2.graph.remove_dp.html#torchdata.dataloader2.graph.remove_dp "torchdata.dataloader2.graph.remove_dp") | 给定由 `traverse_dps` 函数生成的 DataPipe 图以及要移除的 DataPipe，返回新的 DataPipe 图。 |
| [`replace_dp`](generated/torchdata.dataloader2.graph.replace_dp.html#torchdata.dataloader2.graph.replace_dp "torchdata.dataloader2.graph.replace_dp") | 给定由 `traverse_dps` 函数生成的 DataPipe 图以及要替换的 DataPipe 和新的 DataPipe，返回新的 DataPipe 图。 |
